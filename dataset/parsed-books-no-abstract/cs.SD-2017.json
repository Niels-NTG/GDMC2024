{title:'Fabbri et al. (§72017§r)', author: 'Renato Fabbri; Vilson Vieira da Silva Junior; Antônio Carlos Silvano Pessotti; Débora Cristina Corrêa; Jr Osvaldo N. Oliveira', display:{Lore:['[{"text": "arXiv:1412.6853", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a75physics.pop-ph\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMusical elements in the discrete-time representation of sound\\u00a7r\\n\\n\\u00a78\\u00a7oRenato Fabbri\\nVilson Vieira da Silva Junior\\nAnt\\u00f4nio Carlos Silvano Pessotti\\nD\\u00e9bora Cristina Corr\\u00eaa\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1412.6853\\u00a7r\\n\\nVersion:\\u00a77v2 (Thu, 26 Oct 2017 23:07:52 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oA software toolbox, a Python Package, musical pieces and further documents arein: https://github.com/ttm/mass\\u00a7r"}']}
{title:'Zhang (§72017§r)', author: 'Xiao-Lei Zhang', display:{Lore:['[{"text": "arXiv:1509.07298", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAn Investigation of Universal Background Sparse Coding Based Speaker Verification on TIMIT\\u00a7r\\n\\n\\u00a78\\u00a7oXiao-Lei Zhang\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1509.07298\\u00a7r\\n\\nVersion:\\u00a77v4 (Mon, 13 Mar 2017 16:27:03 GMT)\\u00a7r"}']}
{title:'Febres et al. (§72017§r)', author: 'Gerardo Febres; Klaus Jaffe', display:{Lore:['[{"text": "arXiv:1510.01806", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMusic Viewed by its Entropy Content: A Novel Window for Comparative Analysis\\u00a7r\\n\\n\\u00a78\\u00a7oGerardo Febres\\nKlaus Jaffe\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1510.01806\\u00a7r\\n\\nVersion:\\u00a77v3 (Thu, 12 Jan 2017 01:45:08 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o41 pages, 15 figures, 3 tables\\u00a7r"}']}
{title:'Klein-Hennig et al. (§72017§r)', author: 'Martin Klein-Hennig; Mathias Dietz; Volker Hohmann', display:{Lore:['[{"text": "arXiv:1511.03440", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lCombination of binaural and harmonic masking release effects in the detection of a single component in complex tones\\u00a7r\\n\\n\\u00a78\\u00a7oMartin Klein-Hennig\\nMathias Dietz\\nVolker Hohmann\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1511.03440\\u00a7r\\n\\nVersion:\\u00a77v2 (Thu, 30 Mar 2017 19:17:51 GMT)\\u00a7r"}']}
{title:'Koldovský et al. (§72017§r)', author: 'Zbyněk Koldovský; Francesco Nesta', display:{Lore:['[{"text": "arXiv:1603.04179", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.IT\\u00a7r, \\u00a7acs.SY\\u00a7r, \\u00a72math.IT\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lPerformance Analysis of Source Image Estimators in Blind Source Separation\\u00a7r\\n\\n\\u00a78\\u00a7oZbyn\\u011bk Koldovsk\\u00fd\\nFrancesco Nesta\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1603.04179\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/TSP.2017.2709269\\u00a7r\\n\\nVersion:\\u00a77v3 (Mon, 22 May 2017 10:43:16 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o24 pages\\u00a7r"}']}
{title:'Ryan (§72017§r)', author: 'David Ryan', display:{Lore:['[{"text": "arXiv:1603.08904", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMathematical Harmony Analysis\\u00a7r\\n\\n\\u00a78\\u00a7oDavid Ryan\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1603.08904\\u00a7r\\n\\nVersion:\\u00a77v4 (Tue, 24 Jan 2017 16:23:45 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oThis is the fourth draft of the paper (24th Jan 2017). Minor changes have been made in the last two versions, such as updating notation for 11th harmonic in light ofalgorithm change from the prime comma paper, and adding "}','{"text": "inversions / different voicings to table of Complexity calculations.Any comments or feedback are welcome\\u00a7r"}']}
{title:'Barfuss et al. (§72017§r)', author: 'Hendrik Barfuss; Christian Huemmer; Andreas Schwarz; Walter Kellermann', display:{Lore:['[{"text": "arXiv:1604.03393", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lRobust coherence-based spectral enhancement for speech recognition in adverse real-world environments\\u00a7r\\n\\n\\u00a78\\u00a7oHendrik Barfuss\\nChristian Huemmer\\nAndreas Schwarz\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1604.03393\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1016/j.csl.2017.02.005\\u00a7r\\n\\nVersion:\\u00a77v4 (Mon, 7 Aug 2017 16:25:04 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o21 pages, 5 figures. arXiv admin note: substantial text overlap with arXiv:1509.06882, Elsevier Computer Speech Language (CSL), 2017\\u00a7r"}']}
{title:'Lostanlen et al. (§72017§r)', author: 'Vincent Lostanlen; Carmine-Emanuele Cella', display:{Lore:['[{"text": "arXiv:1605.06644", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDeep convolutional networks on the pitch spiral for musical instrument recognition\\u00a7r\\n\\n\\u00a78\\u00a7oVincent Lostanlen\\nCarmine-Emanuele Cella\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1605.06644\\u00a7r\\n\\nVersion:\\u00a77v3 (Tue, 10 Jan 2017 14:29:13 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o7 pages, 3 figures. Accepted at the International Society for Music Information Retrieval Conference (ISMIR) conference in New York City, NY, USA, August 2016\\u00a7r"}']}
{title:'Eaton et al. (§72017§r)', author: 'James Eaton; Nikolay D. Gaubitch; Alastair H. Moore; Patrick A. Naylor', display:{Lore:['[{"text": "arXiv:1606.03365", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAcoustic Characterization of Environments (ACE) Challenge Results Technical Report\\u00a7r\\n\\n\\u00a78\\u00a7oJames Eaton\\nNikolay D. Gaubitch\\nAlastair H. Moore\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1606.03365\\u00a7r\\n\\nVersion:\\u00a77v4 (Tue, 27 Jun 2017 09:34:28 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSupporting material for Proceedings of the ACEChallenge Workshop - asatellite event of IEEE-WASPAA 2015 (arXiv:1510.00383)\\u00a7r"}']}
{title:'Bredin (§72017§r)', author: 'Hervé Bredin', display:{Lore:['[{"text": "arXiv:1609.04301", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lTristouNet: Triplet Loss for Speaker Turn Embedding\\u00a7r\\n\\n\\u00a78\\u00a7oHerv\\u00e9 Bredin\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1609.04301\\u00a7r\\n\\nVersion:\\u00a77v3 (Tue, 11 Apr 2017 15:15:20 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oICASSP 2017 (42nd IEEE International Conference on Acoustics, Speech and Signal Processing). Code available at http://github.com/hbredin/TristouNet\\u00a7r"}']}
{title:'Elizalde et al. (§72017§r)', author: 'Benjamin Elizalde; Ankit Shah; Siddharth Dalmia; Min Hun Lee; Rohan Badlani; Anurag Kumar; Bhiksha Raj; Ian Lane', display:{Lore:['[{"text": "arXiv:1609.06026", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.MM\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAn Approach for Self-Training Audio Event Detectors Using Web Data\\u00a7r\\n\\n\\u00a78\\u00a7oBenjamin Elizalde\\nAnkit Shah\\nSiddharth Dalmia\\n+ 4 others\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1609.06026\\u00a7r\\n\\nVersion:\\u00a77v3 (Tue, 27 Jun 2017 17:09:59 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages\\u00a7r"}']}
{title:'Yela et al. (§72017§r)', author: 'Delia Fano Yela; Sebastian Ewert; Derry FitzGerald; Mark Sandler', display:{Lore:['[{"text": "arXiv:1609.06210", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lInterference Reduction in Music Recordings Combining Kernel Additive Modelling and Non-Negative Matrix Factorization\\u00a7r\\n\\n\\u00a78\\u00a7oDelia Fano Yela\\nSebastian Ewert\\nDerry FitzGerald\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1609.06210\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nProceedings of the IEEE International Conference on Acoustics,\\n  Speech, and Signal Processing (ICASSP), New Orleans, USA, pp. 51-55, 2017\\u00a7r\\n\\nVersion:\\u00a77v2 (Wed, 8 Feb 2017 13:00:52 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oInternational Conference on Acoustics, Speech and Signal Processing (ICASSP)\\u00a7r"}']}
{title:'Kumar et al. (§72017§r)', author: 'Anurag Kumar; Bhiksha Raj; Ndapandula Nakashole', display:{Lore:['[{"text": "arXiv:1609.07384", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.AI\\u00a7r, \\u00a7acs.LG\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDiscovering Sound Concepts and Acoustic Relations In Text\\u00a7r\\n\\n\\u00a78\\u00a7oAnurag Kumar\\nBhiksha Raj\\nNdapandula Nakashole\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1609.07384\\u00a7r\\n\\nVersion:\\u00a77v2 (Mon, 13 Feb 2017 01:09:27 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oICASSP 2017\\u00a7r"}']}
{title:'Li et al. (§72017§r)', author: 'Lantian Li; Zhiyuan Tang; Dong Wang; Andrew Abel; Yang Feng; Shiyue Zhang', display:{Lore:['[{"text": "arXiv:1609.08442", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lCollaborative Learning for Language and Speaker Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oLantian Li\\nZhiyuan Tang\\nDong Wang\\n+ 2 others\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1609.08442\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 23 May 2017 09:56:54 GMT)\\u00a7r"}']}
{title:'Hershey et al. (§72017§r)', author: 'Shawn Hershey; Sourish Chaudhuri; Daniel P. W. Ellis; Jort F. Gemmeke; Aren Jansen; R. Channing Moore; Manoj Plakal; Devin Platt; Rif A. Saurous; Bryan Seybold; Malcolm Slaney; Ron J. Weiss; Kevin Wilson', display:{Lore:['[{"text": "arXiv:1609.09430", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lCNN Architectures for Large-Scale Audio Classification\\u00a7r\\n\\n\\u00a78\\u00a7oShawn Hershey\\nSourish Chaudhuri\\nDaniel P. W. Ellis\\n+ 9 others\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1609.09430\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 10 Jan 2017 18:06:51 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted for publication at ICASSP 2017 Changes: Added definitions of mAP, AUC, and d-prime. Updated mAP/AUC/d-prime numbers for Audio Set based on changes of latest Audio Set revision. Changed wording to fit 4 page "}','{"text": "limit with new additions\\u00a7r"}']}
{title:'Sun et al. (§72017§r)', author: 'Pengfei Sun; Jun Qin', display:{Lore:['[{"text": "arXiv:1609.09443", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSemi-supervised Speech Enhancement in Envelop and Details Subspaces\\u00a7r\\n\\n\\u00a78\\u00a7oPengfei Sun\\nJun Qin\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1609.09443\\u00a7r\\n\\nVersion:\\u00a77v2 (Thu, 23 Feb 2017 05:20:54 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o25 pages, 11 figures\\u00a7r"}']}
{title:'Deleforge et al. (§72017§r)', author: 'Antoine Deleforge; Yann Traonmilin', display:{Lore:['[{"text": "arXiv:1609.09744", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lPhase Unmixing : Multichannel Source Separation with Magnitude Constraints\\u00a7r\\n\\n\\u00a78\\u00a7oAntoine Deleforge\\nYann Traonmilin\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1609.09744\\u00a7r\\n\\nVersion:\\u00a77v2 (Mon, 20 Mar 2017 13:36:08 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), Mar 2017, New Orleans, United States\\u00a7r"}']}
{title:'Kataria et al. (§72017§r)', author: 'Saurabh Kataria; Clément Gaultier; Antoine Deleforge', display:{Lore:['[{"text": "arXiv:1609.09747", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lHearing in a shoe-box : binaural source position and wall absorption estimation using virtually supervised learning\\u00a7r\\n\\n\\u00a78\\u00a7oSaurabh Kataria\\nCl\\u00e9ment Gaultier\\nAntoine Deleforge\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1609.09747\\u00a7r\\n\\nVersion:\\u00a77v2 (Mon, 20 Mar 2017 13:39:49 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), Mar 2017, New-Orleans, United States\\u00a7r"}']}
{title:'Useche et al. (§72017§r)', author: 'Jorge Useche; Rafael Hurtado', display:{Lore:['[{"text": "arXiv:1610.04551", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.IT\\u00a7r, \\u00a72math.IT\\u00a7r, \\u00a75physics.data-an\\u00a7r, \\u00a75physics.soc-ph\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lTonal consonance parameters link microscopic and macroscopic properties of music exposing a hidden order in melody\\u00a7r\\n\\n\\u00a78\\u00a7oJorge Useche\\nRafael Hurtado\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1610.04551\\u00a7r\\n\\nVersion:\\u00a77v4 (Sun, 23 Apr 2017 16:31:08 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o11 pages, 7 figures. Supplemental material contains 3 figures and 3 tables. An spreadsheet .xlsx contains data, fitting parameters, determination coefficients, expected values, and Lagrange multipliers\\u00a7r"}']}
{title:'Remaggi et al. (§72017§r)', author: 'Luca Remaggi; Philip J. B. Jackson; Philip Coleman; Wenwu Wang', display:{Lore:['[{"text": "arXiv:1610.05653", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAcoustic Reflector Localization: Novel Image Source Reversion and Direct Localization Methods\\u00a7r\\n\\n\\u00a78\\u00a7oLuca Remaggi\\nPhilip J. B. Jackson\\nPhilip Coleman\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1610.05653\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/TASLP.2016.2633802\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nIEEE/ACM Transactions on Audio, Speech, and Language Processing,\\n  vol. 25, no. 2, pp. 296-309, February 2017\\u00a7r\\n\\nVersion:\\u00a77v2 (Thu, 5 Jan 2017 13:34:14 GMT)\\u00a7r"}']}
{title:'Sun et al. (§72017§r)', author: 'Pengfei Sun; Jun Qin', display:{Lore:['[{"text": "arXiv:1611.00326", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lEnhanced Factored Three-Way Restricted Boltzmann Machines for Speech Detection\\u00a7r\\n\\n\\u00a78\\u00a7oPengfei Sun\\nJun Qin\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1611.00326\\u00a7r\\n\\nVersion:\\u00a77v3 (Thu, 20 Apr 2017 18:43:29 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o8 pages, Pattern Recognition Letter 2016\\u00a7r"}']}
{title:'Li et al. (§72017§r)', author: 'Xiaofei Li; Laurent Girin; Sharon Gannot; Radu Horaud', display:{Lore:['[{"text": "arXiv:1611.01172", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMultiple-Speaker Localization Based on Direct-Path Features and Likelihood Maximization with Spatial Sparsity Regularization\\u00a7r\\n\\n\\u00a78\\u00a7oXiaofei Li\\nLaurent Girin\\nSharon Gannot\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1611.01172\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/TASLP.2017.2740001\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nIEEE/ACM Transactions on Audio, Speech and Language Processing,\\n  25(10), pp 1997 - 2012, October 2017\\u00a7r\\n\\nVersion:\\u00a77v2 (Wed, 17 May 2017 14:31:00 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o16 pages, 4 figures, 4 tables\\u00a7r"}']}
{title:'Glotin et al. (§72017§r)', author: 'Herve Glotin; Julien Ricard; Randall Balestriero', display:{Lore:['[{"text": "arXiv:1611.08749", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lFast Chirplet Transform to Enhance CNN Machine Listening - Validation on Animal calls and Speech\\u00a7r\\n\\n\\u00a78\\u00a7oHerve Glotin\\nJulien Ricard\\nRandall Balestriero\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1611.08749\\u00a7r\\n\\nVersion:\\u00a77v2 (Sun, 22 Jan 2017 22:28:47 GMT)\\u00a7r"}']}
{title:'Chen et al. (§72017§r)', author: 'Zhuo Chen; Yi Luo; Nima Mesgarani', display:{Lore:['[{"text": "arXiv:1611.08930", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDeep attractor network for single-microphone speaker separation\\u00a7r\\n\\n\\u00a78\\u00a7oZhuo Chen\\nYi Luo\\nNima Mesgarani\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1611.08930\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/ICASSP.2017.7952155\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 28 Mar 2017 03:15:07 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\\u00a7r"}']}
{title:'Defferrard et al. (§72017§r)', author: 'Michaël Defferrard; Kirell Benzi; Pierre Vandergheynst; Xavier Bresson', display:{Lore:['[{"text": "arXiv:1612.01840", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.IR\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lFMA: A Dataset For Music Analysis\\u00a7r\\n\\n\\u00a78\\u00a7oMicha\\u00ebl Defferrard\\nKirell Benzi\\nPierre Vandergheynst\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1612.01840\\u00a7r\\n\\nVersion:\\u00a77v3 (Tue, 5 Sep 2017 18:38:33 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oISMIR 2017 camera-ready\\u00a7r"}']}
{title:'Ryan (§72017§r)', author: 'David Ryan', display:{Lore:['[{"text": "arXiv:1612.01860", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAn algorithm to assign musical prime commas to every prime number and construct a universal and compact free Just Intonation musical notation\\u00a7r\\n\\n\\u00a78\\u00a7oDavid Ryan\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1612.01860\\u00a7r\\n\\nVersion:\\u00a77v5 (Tue, 28 Mar 2017 14:57:07 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oThis pre-print is a fifth draft, 28th March 2017.It incorporates an updated algorithm KG2 from its author, an updated 3-way comparison between DR,SAG, KG2 algorithms, some extra information about higher Pythagorean "}','{"text": "integers, functions 3EPO and CSPO, and normalisation of comma pumps. Any feedback is welcome, the author\'s contact details are listed at the end of the paper\\u00a7r"}']}
{title:'Xian et al. (§72017§r)', author: 'Yin Xian; Yunchen Pu; Zhe Gan; Liang Lu; Andrew Thompson', display:{Lore:['[{"text": "arXiv:1612.04028", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAdaptive DCTNet for Audio Signal Classification\\u00a7r\\n\\n\\u00a78\\u00a7oYin Xian\\nYunchen Pu\\nZhe Gan\\nLiang Lu\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1612.04028\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1121/1.4970932\\u00a7r\\n\\nVersion:\\u00a77v3 (Sat, 29 Apr 2017 20:31:18 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oInternational Conference of Acoustic and Speech Signal Processing (ICASSP). New Orleans, United States, March, 2017\\u00a7r"}']}
{title:'Wang et al. (§72017§r)', author: 'Yiyan Wang; Haotian Xu; Zhijian Ou', display:{Lore:['[{"text": "arXiv:1612.04056", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lJoint Bayesian Gaussian discriminant analysis for speaker verification\\u00a7r\\n\\n\\u00a78\\u00a7oYiyan Wang\\nHaotian Xu\\nZhijian Ou\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1612.04056\\u00a7r\\n\\nVersion:\\u00a77v2 (Thu, 19 Jan 2017 15:33:53 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oaccepted by ICASSP2017\\u00a7r"}']}
{title:'Ottosen et al. (§72017§r)', author: 'Emil Solsbæk Ottosen; Monika Dörfler', display:{Lore:['[{"text": "arXiv:1612.05156", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Phase Vocoder based on Nonstationary Gabor Frames\\u00a7r\\n\\n\\u00a78\\u00a7oEmil Solsb\\u00e6k Ottosen\\nMonika D\\u00f6rfler\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1612.05156\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/TASLP.2017.2750767\\u00a7r\\n\\nVersion:\\u00a77v2 (Wed, 6 Sep 2017 11:35:59 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o10 pages, 6 figures\\u00a7r"}']}
{title:'Sun et al. (§72017§r)', author: 'Pengfei Sun; Jun Qin', display:{Lore:['[{"text": "arXiv:1612.05369", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lNeural networks based EEG-Speech Models\\u00a7r\\n\\n\\u00a78\\u00a7oPengfei Sun\\nJun Qin\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1612.05369\\u00a7r\\n\\nVersion:\\u00a77v2 (Fri, 31 Mar 2017 20:17:12 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o10 pages\\u00a7r"}']}
{title:'Barfuss et al. (§72017§r)', author: 'Hendrik Barfuss; Michael Buerger; Jasper Podschus; Walter Kellermann', display:{Lore:['[{"text": "arXiv:1612.06151", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lHRTF-based two-dimensional robust least-squares frequency-invariant beamformer design for robot audition\\u00a7r\\n\\n\\u00a78\\u00a7oHendrik Barfuss\\nMichael Buerger\\nJasper Podschus\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1612.06151\\u00a7r\\n\\nVersion:\\u00a77v3 (Thu, 9 Mar 2017 08:47:38 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oJoint Workshop on Hands-free Speech Communication and Microphone Arrays (HSCMA), March 2017, San Francisco, CA, USA\\u00a7r"}']}
{title:'Mehri et al. (§72017§r)', author: 'Soroush Mehri; Kundan Kumar; Ishaan Gulrajani; Rithesh Kumar; Shubham Jain; Jose Sotelo; Aaron Courville; Yoshua Bengio', display:{Lore:['[{"text": "arXiv:1612.07837", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.AI\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSampleRNN: An Unconditional End-to-End Neural Audio Generation Model\\u00a7r\\n\\n\\u00a78\\u00a7oSoroush Mehri\\nKundan Kumar\\nIshaan Gulrajani\\n+ 4 others\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1612.07837\\u00a7r\\n\\nVersion:\\u00a77v2 (Sat, 11 Feb 2017 20:04:46 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oPublished as a conference paper at ICLR 2017\\u00a7r"}']}
{title:'Javaheri et al. (§72017§r)', author: 'Amirhossein Javaheri; Mohammad Bagher Shamsollahi', display:{Lore:['[{"text": "arXiv:1701.03834", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lOn Higher Order Positive Differential Energy Operator\\u00a7r\\n\\n\\u00a78\\u00a7oAmirhossein Javaheri\\nMohammad Bagher Shamsollahi\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1701.03834\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 9 Jan 2017 15:10:38 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages\\u00a7r"}']}
{title:'Jeon et al. (§72017§r)', author: 'Sungho Jeon; Jong-Woo Shin; Young-Jun Lee; Woong-Hee Kim; YoungHyoun Kwon; Hae-Yong Yang', display:{Lore:['[{"text": "arXiv:1701.05779", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lEmpirical Study of Drone Sound Detection in Real-Life Environment with Deep Neural Networks\\u00a7r\\n\\n\\u00a78\\u00a7oSungho Jeon\\nJong-Woo Shin\\nYoung-Jun Lee\\n+ 2 others\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1701.05779\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 20 Jan 2017 12:48:02 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oIEEE 5 Pages, Submitted\\u00a7r"}']}
{title:'Chang et al. (§72017§r)', author: 'Sungkyun Chang; Kyogu Lee', display:{Lore:['[{"text": "arXiv:1701.06078", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.AI\\u00a7r, \\u00a7acs.IR\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lLyrics-to-Audio Alignment by Unsupervised Discovery of Repetitive Patterns in Vowel Acoustics\\u00a7r\\n\\n\\u00a78\\u00a7oSungkyun Chang\\nKyogu Lee\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1701.06078\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/ACCESS.2017.2738558\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nIEEE Access, Vol. 5, (2017) 16635-16648\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 24 Jan 2017 16:25:15 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o13 pages\\u00a7r"}']}
{title:'Kelz et al. (§72017§r)', author: 'Rainer Kelz; Gerhard Widmer', display:{Lore:['[{"text": "arXiv:1702.00025", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAn Experimental Analysis of the Entanglement Problem in Neural-Network-based Music Transcription Systems\\u00a7r\\n\\n\\u00a78\\u00a7oRainer Kelz\\nGerhard Widmer\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1702.00025\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 31 Jan 2017 19:21:41 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to AES Conference on Semantic Audio, Erlangen, Germany, 2017 June 22, 24\\u00a7r"}']}
{title:'Korzeniowski et al. (§72017§r)', author: 'Filip Korzeniowski; Gerhard Widmer', display:{Lore:['[{"text": "arXiv:1702.00178", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lOn the Futility of Learning Complex Frame-Level Language Models for Chord Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oFilip Korzeniowski\\nGerhard Widmer\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1702.00178\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.17743/aesconf.2017.978-1-942220-15-2\\u00a7r\\n\\nVersion:\\u00a77v2 (Fri, 31 Mar 2017 11:24:42 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oPublished at AES Conference on Semantic Audio 2017\\u00a7r"}']}
{title:'Shon et al. (§72017§r)', author: 'Suwon Shon; Hanseok Ko', display:{Lore:['[{"text": "arXiv:1702.00956", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lKU-ISPL Speaker Recognition Systems under Language mismatch condition for NIST 2016 Speaker Recognition Evaluation\\u00a7r\\n\\n\\u00a78\\u00a7oSuwon Shon\\nHanseok Ko\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1702.00956\\u00a7r\\n\\nVersion:\\u00a77v2 (Mon, 6 Feb 2017 03:37:28 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSRE16,NIST SRE 2016 system description\\u00a7r"}']}
{title:'Huizen et al. (§72017§r)', author: 'Roy Rudolf Huizen; Jazi Eko Istiyanto; Agfianto Eko Putra', display:{Lore:['[{"text": "arXiv:1702.01999", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lIdentification of Voice Utterance with Aging Factor Using the Method of MFCC Multichannel\\u00a7r\\n\\n\\u00a78\\u00a7oRoy Rudolf Huizen\\nJazi Eko Istiyanto\\nAgfianto Eko Putra\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1702.01999\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nHuizen, R.R., Istiyanto, J.E. and Putra, A.E., 2017, International\\n  Journal of Advanced Studies in Computer Science and Engineering (IJASCSE),\\n  Volume 6 Issue 01\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 7 Feb 2017 13:19:08 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o6 Pages\\u00a7r"}']}
{title:'Yela et al. (§72017§r)', author: 'Delia Fano Yela; Sebastian Ewert; Derry FitzGerald; Mark Sandler', display:{Lore:['[{"text": "arXiv:1702.02130", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lOn the Importance of Temporal Context in Proximity Kernels: A Vocal Separation Case Study\\u00a7r\\n\\n\\u00a78\\u00a7oDelia Fano Yela\\nSebastian Ewert\\nDerry FitzGerald\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1702.02130\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nProceedings of the AES International Conference on Semantic Audio,\\n  Erlangen, Germany, pp. 13-20, 2017\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 11 Apr 2017 12:23:37 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o2017 AES International Conference on Semantic Audio\\u00a7r"}']}
{title:'Ge et al. (§72017§r)', author: 'Zhenhao Ge; Ananth N. Iyer; Srinath Cheluvaraja; Aravind Ganapathiraju', display:{Lore:['[{"text": "arXiv:1702.02285", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSpeaker Change Detection Using Features through A Neural Network Speaker Classifier\\u00a7r\\n\\n\\u00a78\\u00a7oZhenhao Ge\\nAnanth N. Iyer\\nSrinath Cheluvaraja\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1702.02285\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 8 Feb 2017 04:37:40 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oIntelligent System Conference 2017, Sep. 7-8, 2017, London, UK. arXiv admin note: text overlap with arXiv:1702.02289\\u00a7r"}']}
{title:'Ge et al. (§72017§r)', author: 'Zhenhao Ge; Ananth N. Iyer; Srinath Cheluvaraja; Ram Sundaram; Aravind Ganapathiraju', display:{Lore:['[{"text": "arXiv:1702.02289", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lNeural Network Based Speaker Classification and Verification Systems with Enhanced Features\\u00a7r\\n\\n\\u00a78\\u00a7oZhenhao Ge\\nAnanth N. Iyer\\nSrinath Cheluvaraja\\nRam Sundaram\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1702.02289\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 8 Feb 2017 04:59:00 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oIntelligent Systems Conference 2017, Sep. 7-8 2017, London, UK. arXiv admin note: text overlap with arXiv:1702.02285\\u00a7r"}']}
{title:'Yu et al. (§72017§r)', author: 'Hong Yu; Zheng-Hua Tan; Zhanyu Ma; Jun Guo', display:{Lore:['[{"text": "arXiv:1702.03791", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CR\\u00a7r, \\u00a7acs.LG\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDNN Filter Bank Cepstral Coefficients for Spoofing Detection\\u00a7r\\n\\n\\u00a78\\u00a7oHong Yu\\nZheng-Hua Tan\\nZhanyu Ma\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1702.03791\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 13 Feb 2017 14:44:17 GMT)\\u00a7r"}']}
{title:'Bayram et al. (§72017§r)', author: 'İlker Bayram; Savaşkan Bulek', display:{Lore:['[{"text": "arXiv:1702.07713", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CE\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMultichannel Linear Prediction for Blind Reverberant Audio Source Separation\\u00a7r\\n\\n\\u00a78\\u00a7o\\u0130lker Bayram\\nSava\\u015fkan Bulek\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1702.07713\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 24 Feb 2017 17:23:01 GMT)\\u00a7r"}']}
{title:'Xu et al. (§72017§r)', author: 'Yong Xu; Qiuqiang Kong; Qiang Huang; Wenwu Wang; Mark D. Plumbley', display:{Lore:['[{"text": "arXiv:1702.07787", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.NE\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lConvolutional Gated Recurrent Neural Network Incorporating Spatial Features for Audio Tagging\\u00a7r\\n\\n\\u00a78\\u00a7oYong Xu\\nQiuqiang Kong\\nQiang Huang\\nWenwu Wang\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1702.07787\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 24 Feb 2017 22:27:29 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted to IJCNN2017, Anchorage, Alaska, USA\\u00a7r"}']}
{title:'Loriga (§72017§r)', author: 'Alessandro Loriga', display:{Lore:['[{"text": "arXiv:1703.00009", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lNonlinear Model and its Inverse of an Audio System\\u00a7r\\n\\n\\u00a78\\u00a7oAlessandro Loriga\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1703.00009\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 28 Feb 2017 18:26:44 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o113 pages, master thesis\\u00a7r"}']}
{title:'Loriga et al. (§72017§r)', author: 'Alessandro Loriga; Parvin Moyassari; Daniele Bernardini; Gregorio Landi; Francesca Venturini; Elisabeth Dumont', display:{Lore:['[{"text": "arXiv:1703.00384", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lNonlinear Volterra model of a loudspeaker behavior based on Laser Doppler Vibrometry\\u00a7r\\n\\n\\u00a78\\u00a7oAlessandro Loriga\\nParvin Moyassari\\nDaniele Bernardini\\n+ 2 others\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1703.00384\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 28 Feb 2017 11:00:19 GMT)\\u00a7r"}']}
{title:'Lee et al. (§72017§r)', author: 'Jongpil Lee; Jiyoung Park; Keunhyoung Luke Kim; Juhan Nam', display:{Lore:['[{"text": "arXiv:1703.01789", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.MM\\u00a7r, \\u00a7acs.NE\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSample-level Deep Convolutional Neural Networks for Music Auto-tagging Using Raw Waveforms\\u00a7r\\n\\n\\u00a78\\u00a7oJongpil Lee\\nJiyoung Park\\nKeunhyoung Luke Kim\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1703.01789\\u00a7r\\n\\nVersion:\\u00a77v2 (Mon, 22 May 2017 04:46:36 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o7 pages, Sound and Music Computing Conference (SMC), 2017\\u00a7r"}']}
{title:'EmreÇakır et al. (§72017§r)', author: 'EmreÇakır; Sharath Adavanne; Giambattista Parascandolo; Konstantinos Drossos; Tuomas Virtanen', display:{Lore:['[{"text": "arXiv:1703.02317", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lConvolutional Recurrent Neural Networks for Bird Audio Detection\\u00a7r\\n\\n\\u00a78\\u00a7oEmre\\u00c7ak\\u0131r\\nSharath Adavanne\\nGiambattista Parascandolo\\nKonstantinos Drossos\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1703.02317\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 7 Mar 2017 10:36:30 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to EUSIPCO 2017 Special Session on Bird Audio Signal Processing\\u00a7r"}']}
{title:'AlShehhi et al. (§72017§r)', author: 'Abdulla AlShehhi; M. Luai Hammadih; M. Sami Zitouni; Saif AlKindi; Nazar Ali; Luis Weruaga', display:{Lore:['[{"text": "arXiv:1703.02318", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lLinear and Circular Microphone Array for Remote Surveillance: Simulated Performance Analysis\\u00a7r\\n\\n\\u00a78\\u00a7oAbdulla AlShehhi\\nM. Luai Hammadih\\nM. Sami Zitouni\\n+ 2 others\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1703.02318\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 7 Mar 2017 10:36:50 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oBCS International IT Conference 2013\\u00a7r"}']}
{title:'Phan et al. (§72017§r)', author: 'Huy Phan; Philipp Koch; Fabrice Katzberg; Marco Maass; Radoslaw Mazur; Alfred Mertins', display:{Lore:['[{"text": "arXiv:1703.04770", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAudio Scene Classification with Deep Recurrent Neural Networks\\u00a7r\\n\\n\\u00a78\\u00a7oHuy Phan\\nPhilipp Koch\\nFabrice Katzberg\\n+ 2 others\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1703.04770\\u00a7r\\n\\nVersion:\\u00a77v2 (Mon, 5 Jun 2017 12:41:28 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted for Interspeech 2017\\u00a7r"}']}
{title:'Ochiai et al. (§72017§r)', author: 'Tsubasa Ochiai; Shinji Watanabe; Takaaki Hori; John R. Hershey', display:{Lore:['[{"text": "arXiv:1703.04783", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMultichannel End-to-end Speech Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oTsubasa Ochiai\\nShinji Watanabe\\nTakaaki Hori\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1703.04783\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 14 Mar 2017 22:28:51 GMT)\\u00a7r"}']}
{title:'Singh et al. (§72017§r)', author: 'Rita Singh; Justin Baker; Luciana Pennant; Louis-Philippe Morency', display:{Lore:['[{"text": "arXiv:1703.05344", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7bq-bio.NC\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDeducing the severity of psychiatric symptoms from the human voice\\u00a7r\\n\\n\\u00a78\\u00a7oRita Singh\\nJustin Baker\\nLuciana Pennant\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1703.05344\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 15 Mar 2017 18:41:37 GMT)\\u00a7r"}']}
{title:'Xu et al. (§72017§r)', author: 'Yong Xu; Qiuqiang Kong; Qiang Huang; Wenwu Wang; Mark D. Plumbley', display:{Lore:['[{"text": "arXiv:1703.06052", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAttention and Localization based on a Deep Convolutional Recurrent Model for Weakly Supervised Audio Tagging\\u00a7r\\n\\n\\u00a78\\u00a7oYong Xu\\nQiuqiang Kong\\nQiang Huang\\nWenwu Wang\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1703.06052\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 17 Mar 2017 15:31:58 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, submitted to interspeech2017\\u00a7r"}']}
{title:'Kolbæk et al. (§72017§r)', author: 'Morten Kolbæk; Dong Yu; Zheng-Hua Tan; Jesper Jensen', display:{Lore:['[{"text": "arXiv:1703.06284", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMulti-talker Speech Separation with Utterance-level Permutation Invariant Training of Deep Recurrent Neural Networks\\u00a7r\\n\\n\\u00a78\\u00a7oMorten Kolb\\u00e6k\\nDong Yu\\nZheng-Hua Tan\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1703.06284\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 11 Jul 2017 12:02:01 GMT)\\u00a7r"}']}
{title:'Sanyal et al. (§72017§r)', author: 'Shankha Sanyal; Archi Banerjee; Souparno Roy; Sourya Sengupta; Sayan Biswas; Sayan Nag; Ranjan Sengupta; Dipak Ghosh', display:{Lore:['[{"text": "arXiv:1703.06491", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7bq-bio.NC\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lGestalt Phenomenon in Music? A Neurocognitive Physics Study with EEG\\u00a7r\\n\\n\\u00a78\\u00a7oShankha Sanyal\\nArchi Banerjee\\nSouparno Roy\\n+ 4 others\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1703.06491\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 19 Mar 2017 19:10:27 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o14 Pages, 5 Figures, Presented in International Conference on Creativity and Cognitionin Art and Design, NIMHANS, Bangalore; 19-21 January, 2017\\u00a7r"}']}
{title:'Pons et al. (§72017§r)', author: 'Jordi Pons; Olga Slizovskaia; Rong Gong; Emilia Gómez; Xavier Serra', display:{Lore:['[{"text": "arXiv:1703.06697", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lTimbre Analysis of Music Audio Signals with Convolutional Neural Networks\\u00a7r\\n\\n\\u00a78\\u00a7oJordi Pons\\nOlga Slizovskaia\\nRong Gong\\nEmilia G\\u00f3mez\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1703.06697\\u00a7r\\n\\nVersion:\\u00a77v2 (Fri, 2 Jun 2017 11:10:47 GMT)\\u00a7r"}']}
{title:'Li et al. (§72017§r)', author: 'Juncheng Li; Wei Dai; Florian Metze; Shuhui Qu; Samarjit Das', display:{Lore:['[{"text": "arXiv:1703.06902", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Comparison of deep learning methods for environmental sound\\u00a7r\\n\\n\\u00a78\\u00a7oJuncheng Li\\nWei Dai\\nFlorian Metze\\nShuhui Qu\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1703.06902\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7npublished at ICASSP 2017\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 20 Mar 2017 18:11:47 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages including reference\\u00a7r"}']}
{title:'Won et al. (§72017§r)', author: 'Myounggyu Won; Haitham Alsaadan; Yongsoon Eun', display:{Lore:['[{"text": "arXiv:1703.07065", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAdaptive Multi-Class Audio Classification in Noisy In-Vehicle Environment\\u00a7r\\n\\n\\u00a78\\u00a7oMyounggyu Won\\nHaitham Alsaadan\\nYongsoon Eun\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1703.07065\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1145/3123266.3123397\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 21 Mar 2017 06:09:32 GMT)\\u00a7r"}']}
{title:'Xu et al. (§72017§r)', author: 'Yong Xu; Jun Du; Zhen Huang; Li-Rong Dai; Chin-Hui Lee', display:{Lore:['[{"text": "arXiv:1703.07172", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMulti-Objective Learning and Mask-Based Post-Processing for Deep Neural Network Based Speech Enhancement\\u00a7r\\n\\n\\u00a78\\u00a7oYong Xu\\nJun Du\\nZhen Huang\\nLi-Rong Dai\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1703.07172\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 21 Mar 2017 12:35:21 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7ointerspeech2015 paper, Germany\\u00a7r"}']}
{title:'Wang et al. (§72017§r)', author: 'Yu-Hsuan Wang; Cheng-Tao Chung; Hung-yi Lee', display:{Lore:['[{"text": "arXiv:1703.07588", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lGate Activation Signal Analysis for Gated Recurrent Neural Networks and Its Correlation with Phoneme Boundaries\\u00a7r\\n\\n\\u00a78\\u00a7oYu-Hsuan Wang\\nCheng-Tao Chung\\nHung-yi Lee\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1703.07588\\u00a7r\\n\\nVersion:\\u00a77v2 (Thu, 31 Aug 2017 12:01:36 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, The code is available at https://github.com/allyoushawn/timit_gas.git\\u00a7r"}']}
{title:'Grais et al. (§72017§r)', author: 'Emad M. Grais; Mark D. Plumbley', display:{Lore:['[{"text": "arXiv:1703.08019", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSingle Channel Audio Source Separation using Convolutional Denoising Autoencoders\\u00a7r\\n\\n\\u00a78\\u00a7oEmad M. Grais\\nMark D. Plumbley\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1703.08019\\u00a7r\\n\\nVersion:\\u00a77v2 (Fri, 13 Oct 2017 16:00:02 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted at GlobalSIP 2017 and the final version is available at http://epubs.surrey.ac.uk/841860/\\u00a7r"}']}
{title:'Chazan et al. (§72017§r)', author: 'Shlomo E. Chazan; Jacob Goldberger; Sharon Gannot', display:{Lore:['[{"text": "arXiv:1703.09302", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSpeech Enhancement using a Deep Mixture of Experts\\u00a7r\\n\\n\\u00a78\\u00a7oShlomo E. Chazan\\nJacob Goldberger\\nSharon Gannot\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1703.09302\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 27 Mar 2017 20:37:33 GMT)\\u00a7r"}']}
{title:'Yang et al. (§72017§r)', author: 'Li-Chia Yang; Szu-Yu Chou; Yi-Hsuan Yang', display:{Lore:['[{"text": "arXiv:1703.10847", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.AI\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMidiNet: A Convolutional Generative Adversarial Network for Symbolic-domain Music Generation\\u00a7r\\n\\n\\u00a78\\u00a7oLi-Chia Yang\\nSzu-Yu Chou\\nYi-Hsuan Yang\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1703.10847\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 18 Jul 2017 08:07:36 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o8 pages, Accepted to ISMIR (International Society of Music Information Retrieval) Conference 2017\\u00a7r"}']}
{title:'Yang et al. (§72017§r)', author: 'Li-Chia Yang; Szu-Yu Chou; Jen-Yu Liu; Yi-Hsuan Yang; Yi-An Chen', display:{Lore:['[{"text": "arXiv:1704.01280", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lRevisiting the problem of audio-based hit song prediction using convolutional neural networks\\u00a7r\\n\\n\\u00a78\\u00a7oLi-Chia Yang\\nSzu-Yu Chou\\nJen-Yu Liu\\nYi-Hsuan Yang\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1704.01280\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 5 Apr 2017 06:39:51 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oTo appear in the proceedings of 2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\\u00a7r"}']}
{title:'Yu et al. (§72017§r)', author: 'Dong Yu; Xuankai Chang; Yanmin Qian', display:{Lore:['[{"text": "arXiv:1704.01985", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lRecognizing Multi-talker Speech with Permutation Invariant Training\\u00a7r\\n\\n\\u00a78\\u00a7oDong Yu\\nXuankai Chang\\nYanmin Qian\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1704.01985\\u00a7r\\n\\nVersion:\\u00a77v4 (Mon, 19 Jun 2017 10:57:38 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 6 figures, InterSpeech2017\\u00a7r"}']}
{title:'Mottaghi et al. (§72017§r)', author: 'Ali Mottaghi; Kayhan Behdin; Ashkan Esmaeili; Mohammadreza Heydari; Farokh Marvasti', display:{Lore:['[{"text": "arXiv:1704.02216", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.IR\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.MM\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lOBTAIN: Real-Time Beat Tracking in Audio Signals\\u00a7r\\n\\n\\u00a78\\u00a7oAli Mottaghi\\nKayhan Behdin\\nAshkan Esmaeili\\nMohammadreza Heydari\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1704.02216\\u00a7r\\n\\nVersion:\\u00a77v2 (Fri, 27 Oct 2017 19:36:55 GMT)\\u00a7r"}']}
{title:'Miyoshi et al. (§72017§r)', author: 'Hiroyuki Miyoshi; Yuki Saito; Shinnosuke Takamichi; Hiroshi Saruwatari', display:{Lore:['[{"text": "arXiv:1704.02360", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lVoice Conversion Using Sequence-to-Sequence Learning of Context Posterior Probabilities\\u00a7r\\n\\n\\u00a78\\u00a7oHiroyuki Miyoshi\\nYuki Saito\\nShinnosuke Takamichi\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1704.02360\\u00a7r\\n\\nVersion:\\u00a77v4 (Mon, 7 Aug 2017 02:42:01 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted to INTERSPEECH 2017\\u00a7r"}']}
{title:'Takamichi et al. (§72017§r)', author: 'Shinnosuke Takamichi; Tomoki Koriyama; Hiroshi Saruwatari', display:{Lore:['[{"text": "arXiv:1704.03626", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSampling-based speech parameter generation using moment-matching networks\\u00a7r\\n\\n\\u00a78\\u00a7oShinnosuke Takamichi\\nTomoki Koriyama\\nHiroshi Saruwatari\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1704.03626\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 12 Apr 2017 05:46:44 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to INTERSPEECH 2017\\u00a7r"}']}
{title:'Blaauw et al. (§72017§r)', author: 'Merlijn Blaauw; Jordi Bonada', display:{Lore:['[{"text": "arXiv:1704.03809", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Neural Parametric Singing Synthesizer\\u00a7r\\n\\n\\u00a78\\u00a7oMerlijn Blaauw\\nJordi Bonada\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1704.03809\\u00a7r\\n\\nVersion:\\u00a77v3 (Thu, 17 Aug 2017 12:20:01 GMT)\\u00a7r"}']}
{title:'Kanrar (§72017§r)', author: 'Soumen Kanrar', display:{Lore:['[{"text": "arXiv:1704.03934", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7li Vector used in Speaker Identification by Dimension Compactness\\u00a7r\\n\\n\\u00a78\\u00a7oSoumen Kanrar\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1704.03934\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 12 Apr 2017 21:12:34 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o6 pages,7 figures\\u00a7r"}']}
{title:'Kanrar (§72017§r)', author: 'Soumen Kanrar', display:{Lore:['[{"text": "arXiv:1704.03939", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSpeaker Identification by GMM based i Vector\\u00a7r\\n\\n\\u00a78\\u00a7oSoumen Kanrar\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1704.03939\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 12 Apr 2017 21:43:20 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o6 Pages, 12 figures\\u00a7r"}']}
{title:'Rungta et al. (§72017§r)', author: 'Atul Rungta; Nicholas Rewkowski; Roberta Klatzky; Ming Lin; Dinesh Manocha', display:{Lore:['[{"text": "arXiv:1704.06008", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lEffects of virtual acoustics on dynamic auditory distance perception\\u00a7r\\n\\n\\u00a78\\u00a7oAtul Rungta\\nNicholas Rewkowski\\nRoberta Klatzky\\nMing Lin\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1704.06008\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1121/1.4981234\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 20 Apr 2017 04:38:29 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o8 Pages, 7 figures\\u00a7r"}']}
{title:'Dubey et al. (§72017§r)', author: 'Harishchandra Dubey; Abhijeet Sangwan; John H. L. Hansen', display:{Lore:['[{"text": "arXiv:1704.07274", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lUsing Speech Technology for Quantifying Behavioral Characteristics in Peer-Led Team Learning Sessions\\u00a7r\\n\\n\\u00a78\\u00a7oHarishchandra Dubey\\nAbhijeet Sangwan\\nJohn H. L. Hansen\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1704.07274\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1016/j.csl.2017.04.002\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 24 Apr 2017 15:10:06 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o24 pages, 8 Tables, 14 Figures, 6 Equations, Computer Speech Language 2017\\u00a7r"}']}
{title:'Barfuss et al. (§72017§r)', author: 'Hendrik Barfuss; Markus Bachmann; Michael Buerger; Martin Schneider; Walter Kellerman', display:{Lore:['[{"text": "arXiv:1704.08953", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDesign of robust two-dimensional polynomial beamformers as a convex optimization problem with application to robot audition\\u00a7r\\n\\n\\u00a78\\u00a7oHendrik Barfuss\\nMarkus Bachmann\\nMichael Buerger\\nMartin Schneider\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1704.08953\\u00a7r\\n\\nVersion:\\u00a77v3 (Tue, 1 Aug 2017 13:27:34 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7osubmitted to IEEEWorkshop on Applications of Signal Processing to Audio and Acoustics (WASPAA)2017\\u00a7r"}']}
{title:'Chakrabarty et al. (§72017§r)', author: 'Soumitro Chakrabarty; Emanuël. A. P. Habets', display:{Lore:['[{"text": "arXiv:1705.00919", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lBroadband DOA estimation using Convolutional neural networks trained with noise signals\\u00a7r\\n\\n\\u00a78\\u00a7oSoumitro Chakrabarty\\nEmanu\\u00ebl. A. P. Habets\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1705.00919\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/WASPAA.2017.8170010\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 12 Dec 2017 12:57:36 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oPublished in Proceedings of IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA)2017\\u00a7r"}']}
{title:'Toro et al. (§72017§r)', author: 'Mauricio Toro; Myriam Desainte-Catherine; Antoine Allombert', display:{Lore:['[{"text": "arXiv:1705.01651", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LO\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lModeling temporal constraints for a system of interactive scores\\u00a7r\\n\\n\\u00a78\\u00a7oMauricio Toro\\nMyriam Desainte-Catherine\\nAntoine Allombert\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1705.01651\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 3 May 2017 23:19:56 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oExtended version of Book Chapter published in Constraint Programming in Music, 2012\\u00a7r"}']}
{title:'Venkataramani et al. (§72017§r)', author: 'Shrikant Venkataramani; Jonah Casebeer; Paris Smaragdis', display:{Lore:['[{"text": "arXiv:1705.02514", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lEnd-to-end Source Separation with Adaptive Front-Ends\\u00a7r\\n\\n\\u00a78\\u00a7oShrikant Venkataramani\\nJonah Casebeer\\nParis Smaragdis\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1705.02514\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 31 Oct 2017 01:58:50 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o4 figures, 4 pages\\u00a7r"}']}
{title:'Li et al. (§72017§r)', author: 'Lantian Li; Yixiang Chen; Ying Shi; Zhiyuan Tang; Dong Wang', display:{Lore:['[{"text": "arXiv:1705.03670", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDeep Speaker Feature Learning for Text-independent Speaker Verification\\u00a7r\\n\\n\\u00a78\\u00a7oLantian Li\\nYixiang Chen\\nYing Shi\\nZhiyuan Tang\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1705.03670\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 10 May 2017 09:30:42 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7odeep neural networks, speaker verification, speaker feature\\u00a7r"}']}
{title:'Zamani et al. (§72017§r)', author: 'Sina Zamani; Tejaswi Nanjundaswamy; Kenneth Rose', display:{Lore:['[{"text": "arXiv:1705.03877", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lFrequency Domain Singular Value Decomposition for Efficient Spatial Audio Coding\\u00a7r\\n\\n\\u00a78\\u00a7oSina Zamani\\nTejaswi Nanjundaswamy\\nKenneth Rose\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1705.03877\\u00a7r\\n\\nVersion:\\u00a77v2 (Mon, 15 May 2017 20:49:42 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 3 figures\\u00a7r"}']}
{title:'Stephenson et al. (§72017§r)', author: 'Cory Stephenson; Patrick Callier; Abhinav Ganesh; Karl Ni', display:{Lore:['[{"text": "arXiv:1705.04662", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.AI\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMonaural Audio Speaker Separation with Source Contrastive Estimation\\u00a7r\\n\\n\\u00a78\\u00a7oCory Stephenson\\nPatrick Callier\\nAbhinav Ganesh\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1705.04662\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 12 May 2017 17:23:02 GMT)\\u00a7r"}']}
{title:'Orife (§72017§r)', author: 'Iroro Orife', display:{Lore:['[{"text": "arXiv:1705.04792", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lRiddim: A Rhythm Analysis and Decomposition Tool Based On Independent Subspace Analysis\\u00a7r\\n\\n\\u00a78\\u00a7oIroro Orife\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1705.04792\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 13 May 2017 06:43:46 GMT)\\u00a7r"}']}
{title:'Toghiani-Rizi et al. (§72017§r)', author: 'Babak Toghiani-Rizi; Marcus Windmark', display:{Lore:['[{"text": "arXiv:1705.04971", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMusical Instrument Recognition Using Their Distinctive Characteristics in Artificial Neural Networks\\u00a7r\\n\\n\\u00a78\\u00a7oBabak Toghiani-Rizi\\nMarcus Windmark\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1705.04971\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 14 May 2017 14:43:10 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oResults based ona study conducted during the course Machine Learning at Uppsala University\\u00a7r"}']}
{title:'Xing et al. (§72017§r)', author: 'Zhou Xing; Eddy Baik; Yan Jiao; Nilesh Kulkarni; Chris Li; Gautam Muralidhar; Marzieh Parandehgheibi; Erik Reed; Abhishek Singhal; Fei Xiao; Chris Pouliot', display:{Lore:['[{"text": "arXiv:1705.05229", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lModeling of the Latent Embedding of Music using Deep Neural Network\\u00a7r\\n\\n\\u00a78\\u00a7oZhou Xing\\nEddy Baik\\nYan Jiao\\n+ 7 others\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1705.05229\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 12 May 2017 01:08:31 GMT)\\u00a7r"}']}
{title:'van Elburg et al. (§72017§r)', author: 'Ronald A. J. van Elburg; Tjeerd C. Andringa', display:{Lore:['[{"text": "arXiv:1705.05271", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lTexture features for the reproduction of the perceptual organization of sound\\u00a7r\\n\\n\\u00a78\\u00a7oRonald A. J. van Elburg\\nTjeerd C. Andringa\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1705.05271\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 15 May 2017 14:41:49 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o20 pages, 6 figures. The underlying code is madeavailable under the Apache License, Version 2.0 as an open source repository through GitHub: https://github.com/soundappraisal/libsoundannotator. Documented code examples "}','{"text": "are available through GitHub licensed under the same Apache License, Version 2.0: https://github.com/soundappraisal/soundannotatordemo\\u00a7r"}']}
{title:'de Oliveira et al. (§72017§r)', author: 'H. M. de Oliveira; R. C. de Oliveira', display:{Lore:['[{"text": "arXiv:1705.05322", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lUnderstanding MIDI: A Painless Tutorial on Midi Format\\u00a7r\\n\\n\\u00a78\\u00a7oH. M. de Oliveira\\nR. C. de Oliveira\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1705.05322\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 15 May 2017 16:34:20 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o7 pages, 7 figures\\u00a7r"}']}
{title:'Moore et al. (§72017§r)', author: 'Roger K. Moore; Ben Mitchinson', display:{Lore:['[{"text": "arXiv:1705.05472", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.RO\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Biomimetic Vocalisation System for MiRo\\u00a7r\\n\\n\\u00a78\\u00a7oRoger K. Moore\\nBen Mitchinson\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1705.05472\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 15 May 2017 22:20:22 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o12 pages; accepted for publication at Living Machines 2017, Stanford, USA; 25-28 July 2017; http://livingmachinesconference.eu/2017/\\u00a7r"}']}
{title:'Jonker et al. (§72017§r)', author: 'Coen Jonker; Arryon D. Tijsma; Ronald A. J. van Elburg', display:{Lore:['[{"text": "arXiv:1705.05874", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lTime-frequency or time-scale representation fission and fusion rules\\u00a7r\\n\\n\\u00a78\\u00a7oCoen Jonker\\nArryon D. Tijsma\\nRonald A. J. van Elburg\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1705.05874\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 16 May 2017 18:45:41 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oThis paper is accompanying the release of libSoundAnnotator. Thewhole implementation is open sourced through GitHub: https://github.com/soundappraisal/libsoundannotator under the Apache License, Version 2.0. Both "}','{"text": "UseCases described are available as documented code through GitHub https://github.com/soundappraisal/soundannotatordemo under the Apache License, Version 2.0. 11 pages, 5 figures\\u00a7r"}']}
{title:'Zhang et al. (§72017§r)', author: 'Jie Zhang; Sundeep Prabhakar Chepuri; Richard C. Hendriks; Richard Heusdens', display:{Lore:['[{"text": "arXiv:1705.08255", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMicrophone Subset Selection for MVDR Beamformer Based Noise Reduction\\u00a7r\\n\\n\\u00a78\\u00a7oJie Zhang\\nSundeep Prabhakar Chepuri\\nRichard C. Hendriks\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1705.08255\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 16 May 2017 14:26:33 GMT)\\u00a7r"}']}
{title:'Guan et al. (§72017§r)', author: 'Jian Guan; Xuan Wang; Pengming Feng; Jing Dong; Wenwu Wang', display:{Lore:['[{"text": "arXiv:1705.08660", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMatrix of Polynomials Model based Polynomial Dictionary Learning Method for Acoustic Impulse Response Modeling\\u00a7r\\n\\n\\u00a78\\u00a7oJian Guan\\nXuan Wang\\nPengming Feng\\nJing Dong\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1705.08660\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 24 May 2017 08:39:04 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 2 figures\\u00a7r"}']}
{title:'Lavrentyeva et al. (§72017§r)', author: 'Galina Lavrentyeva; Sergey Novoselov; Egor Malykh; Alexander Kozlov; Oleg Kudashev; Vadim Shchemelinin', display:{Lore:['[{"text": "arXiv:1705.08858", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAudio-replay attack detection countermeasures\\u00a7r\\n\\n\\u00a78\\u00a7oGalina Lavrentyeva\\nSergey Novoselov\\nEgor Malykh\\n+ 2 others\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1705.08858\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 24 May 2017 16:48:03 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o11 pages, 3 figures, accepted for Specom 2017\\u00a7r"}']}
{title:'Lavrentyeva et al. (§72017§r)', author: 'Galina Lavrentyeva; Sergey Novoselov; Konstantin Simonchik', display:{Lore:['[{"text": "arXiv:1705.08865", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAnti-spoofing Methods for Automatic SpeakerVerification System\\u00a7r\\n\\n\\u00a78\\u00a7oGalina Lavrentyeva\\nSergey Novoselov\\nKonstantin Simonchik\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1705.08865\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 24 May 2017 16:58:03 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o12 pages, 0 figures, published in Springer Communications in Computer and Information Science (CCIS) vol. 661\\u00a7r"}']}
{title:'Pekhovsky et al. (§72017§r)', author: 'Timur Pekhovsky; Maxim Korenevsky', display:{Lore:['[{"text": "arXiv:1705.09185", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lInvestigation of Using VAE for i-Vector Speaker Verification\\u00a7r\\n\\n\\u00a78\\u00a7oTimur Pekhovsky\\nMaxim Korenevsky\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1705.09185\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 25 May 2017 13:59:18 GMT)\\u00a7r"}']}
{title:'Dumpala et al. (§72017§r)', author: 'Sri Harsha Dumpala; Ashish Panda; Sunil Kumar Kopparapu', display:{Lore:['[{"text": "arXiv:1705.09289", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lImproved I-vector-based Speaker Recognition for Utterances with Speaker Generated Non-speech sounds\\u00a7r\\n\\n\\u00a78\\u00a7oSri Harsha Dumpala\\nAshish Panda\\nSunil Kumar Kopparapu\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1705.09289\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 25 May 2017 19:08:08 GMT)\\u00a7r"}']}
{title:'Malykh et al. (§72017§r)', author: 'Egor Malykh; Sergey Novoselov; Oleg Kudashev', display:{Lore:['[{"text": "arXiv:1705.10134", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lOn Residual CNN in text-dependent speaker verification task\\u00a7r\\n\\n\\u00a78\\u00a7oEgor Malykh\\nSergey Novoselov\\nOleg Kudashev\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1705.10134\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 30 May 2017 13:17:47 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted for Specom 2017\\u00a7r"}']}
{title:'Novoa et al. (§72017§r)', author: 'José Novoa; Josué Fredes; Néstor Becerra Yoma', display:{Lore:['[{"text": "arXiv:1705.10368", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.NE\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDNN-based uncertainty estimation for weighted DNN-HMM ASR\\u00a7r\\n\\n\\u00a78\\u00a7oJos\\u00e9 Novoa\\nJosu\\u00e9 Fredes\\nN\\u00e9stor Becerra Yoma\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1705.10368\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 29 May 2017 19:24:14 GMT)\\u00a7r"}']}
{title:'Kim (§72017§r)', author: 'Minje Kim', display:{Lore:['[{"text": "arXiv:1705.10385", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lCollaborative Deep Learning for Speech Enhancement: A Run-Time Model Selection Method Using Autoencoders\\u00a7r\\n\\n\\u00a78\\u00a7oMinje Kim\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1705.10385\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nProc. of the IEEE International Conference on Acoustics, Speech\\n  and Signal Processing (ICASSP), pp 76-80, March 2017\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 29 May 2017 20:30:24 GMT)\\u00a7r"}']}
{title:'Grønnesby et al. (§72017§r)', author: 'Morten Grønnesby; Juan Carlos Aviles Solis; Einar Holsbø; Hasse Melbye; Lars Ailo Bongo', display:{Lore:['[{"text": "arXiv:1706.00005", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lFeature Extraction for Machine Learning Based Crackle Detection in Lung Sounds from a Health Survey\\u00a7r\\n\\n\\u00a78\\u00a7oMorten Gr\\u00f8nnesby\\nJuan Carlos Aviles Solis\\nEinar Holsb\\u00f8\\nHasse Melbye\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1706.00005\\u00a7r\\n\\nVersion:\\u00a77v2 (Sat, 23 Dec 2017 22:25:06 GMT)\\u00a7r"}']}
{title:'Ibarrola et al. (§72017§r)', author: 'Francisco J. Ibarrola; Leandro E. Di Persia; Ruben D. Spies', display:{Lore:['[{"text": "arXiv:1706.00114", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMixed penalization in convolutive nonnegative matrix factorization for blind speech dereverberation\\u00a7r\\n\\n\\u00a78\\u00a7oFrancisco J. Ibarrola\\nLeandro E. Di Persia\\nRuben D. Spies\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1706.00114\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 31 May 2017 22:27:37 GMT)\\u00a7r"}']}
{title:'Wang et al. (§72017§r)', author: 'Dong Wang; Lantian Li; Ying Shi; Yixiang Chen; Zhiyuan Tang', display:{Lore:['[{"text": "arXiv:1706.01777", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDeep Factorization for Speech Signal\\u00a7r\\n\\n\\u00a78\\u00a7oDong Wang\\nLantian Li\\nYing Shi\\nYixiang Chen\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1706.01777\\u00a7r\\n\\nVersion:\\u00a77v2 (Sun, 25 Jun 2017 10:10:35 GMT)\\u00a7r"}']}
{title:'Adavanne et al. (§72017§r)', author: 'Sharath Adavanne; Konstantinos Drossos; Emre Çakır; Tuomas Virtanen', display:{Lore:['[{"text": "arXiv:1706.02047", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lStacked Convolutional and Recurrent Neural Networks for Bird Audio Detection\\u00a7r\\n\\n\\u00a78\\u00a7oSharath Adavanne\\nKonstantinos Drossos\\nEmre \\u00c7ak\\u0131r\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1706.02047\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 7 Jun 2017 05:09:41 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted for European Signal Processing Conference 2017\\u00a7r"}']}
{title:'Li et al. (§72017§r)', author: 'Lantian Li; Yixiang Chen; Dong Wang; Thomas Fang Zheng', display:{Lore:['[{"text": "arXiv:1706.02101", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Study on Replay Attack and Anti-Spoofing for Automatic Speaker Verification\\u00a7r\\n\\n\\u00a78\\u00a7oLantian Li\\nYixiang Chen\\nDong Wang\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1706.02101\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 7 Jun 2017 09:31:00 GMT)\\u00a7r"}']}
{title:'Adavanne et al. (§72017§r)', author: 'Sharath Adavanne; Pasi Pertilä; Tuomas Virtanen', display:{Lore:['[{"text": "arXiv:1706.02291", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSound Event Detection Using Spatial Features and Convolutional Recurrent Neural Network\\u00a7r\\n\\n\\u00a78\\u00a7oSharath Adavanne\\nPasi Pertil\\u00e4\\nTuomas Virtanen\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1706.02291\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 7 Jun 2017 06:01:48 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted for IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP 2017)\\u00a7r"}']}
{title:'Malik et al. (§72017§r)', author: 'Miroslav Malik; Sharath Adavanne; Konstantinos Drossos; Tuomas Virtanen; Dasa Ticha; Roman Jarina', display:{Lore:['[{"text": "arXiv:1706.02292", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lStacked Convolutional and Recurrent Neural Networks for Music Emotion Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oMiroslav Malik\\nSharath Adavanne\\nKonstantinos Drossos\\n+ 2 others\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1706.02292\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 7 Jun 2017 06:06:14 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted for Sound and Music Computing (SMC 2017)\\u00a7r"}']}
{title:'Adavanne et al. (§72017§r)', author: 'Sharath Adavanne; Giambattista Parascandolo; Pasi Pertilä; Toni Heittola; Tuomas Virtanen', display:{Lore:['[{"text": "arXiv:1706.02293", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSound Event Detection in Multichannel Audio Using Spatial and Harmonic Features\\u00a7r\\n\\n\\u00a78\\u00a7oSharath Adavanne\\nGiambattista Parascandolo\\nPasi Pertil\\u00e4\\nToni Heittola\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1706.02293\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 7 Jun 2017 06:11:32 GMT)\\u00a7r"}']}
{title:'Yu et al. (§72017§r)', author: 'Hong Yu; Zheng-Hua Tan; Zhanyu Ma; Jun Guo', display:{Lore:['[{"text": "arXiv:1706.03397", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAdversarial Network Bottleneck Features for Noise Robust Speaker Verification\\u00a7r\\n\\n\\u00a78\\u00a7oHong Yu\\nZheng-Hua Tan\\nZhanyu Ma\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1706.03397\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 11 Jun 2017 19:42:31 GMT)\\u00a7r"}']}
{title:'Li et al. (§72017§r)', author: 'Xiaofei Li; Radu Horaud; Sharon Gannot', display:{Lore:['[{"text": "arXiv:1706.03652", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lBlind MultiChannel Identification and Equalization for Dereverberation and Noise Reduction based on Convolutive Transfer Function\\u00a7r\\n\\n\\u00a78\\u00a7oXiaofei Li\\nRadu Horaud\\nSharon Gannot\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1706.03652\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/TPAMI.2017.2717829\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nIEEE/ACM Transactions on Audio, Speech and Language processing,\\n  26(10), 1755-1768, 2018\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 12 Jun 2017 14:13:01 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o13 pages, 5 figures, 5 tables\\u00a7r"}']}
{title:'Bretan et al. (§72017§r)', author: 'Mason Bretan; Sageev Oore; Doug Eck; Larry Heck', display:{Lore:['[{"text": "arXiv:1706.04486", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.AI\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lLearning and Evaluating Musical Features with Deep Autoencoders\\u00a7r\\n\\n\\u00a78\\u00a7oMason Bretan\\nSageev Oore\\nDoug Eck\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1706.04486\\u00a7r\\n\\nVersion:\\u00a77v2 (Thu, 15 Jun 2017 20:09:52 GMT)\\u00a7r"}']}
{title:'Mimilakis et al. (§72017§r)', author: 'Stylianos Ioannis Mimilakis; Gerald Schuller', display:{Lore:['[{"text": "arXiv:1706.04924", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lInvestigating the Potential of Pseudo Quadrature Mirror Filter-Banks in Music Source Separation Tasks\\u00a7r\\n\\n\\u00a78\\u00a7oStylianos Ioannis Mimilakis\\nGerald Schuller\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1706.04924\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 15 Jun 2017 15:24:44 GMT)\\u00a7r"}']}
{title:'Zeinali et al. (§72017§r)', author: 'Hossein Zeinali; Hossein Sameti; Nooshin Maghsoodi', display:{Lore:['[{"text": "arXiv:1706.05077", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSUT System Description for NIST SRE 2016\\u00a7r\\n\\n\\u00a78\\u00a7oHossein Zeinali\\nHossein Sameti\\nNooshin Maghsoodi\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1706.05077\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 8 Jun 2017 11:13:32 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oPresented in NIST SRE 2016 Evaluation Workshop\\u00a7r"}']}
{title:'Choi et al. (§72017§r)', author: 'Keunwoo Choi; Deokjin Joo; Juho Kim', display:{Lore:['[{"text": "arXiv:1706.05781", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.MM\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lKapre: On-GPU Audio Preprocessing Layers for a Quick Implementation of Deep Neural Network Models with Keras\\u00a7r\\n\\n\\u00a78\\u00a7oKeunwoo Choi\\nDeokjin Joo\\nJuho Kim\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1706.05781\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 19 Jun 2017 04:42:14 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oICML 2017 machine learning for music discovery\\u00a7r"}']}
{title:'Eghbal-zadeh et al. (§72017§r)', author: 'Hamid Eghbal-zadeh; Bernhard Lehner; Matthias Dorfer; Gerhard Widmer', display:{Lore:['[{"text": "arXiv:1706.06525", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.AI\\u00a7r, \\u00a7acs.LG\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Hybrid Approach with Multi-channel I-Vectors and Convolutional Neural Networks for Acoustic Scene Classification\\u00a7r\\n\\n\\u00a78\\u00a7oHamid Eghbal-zadeh\\nBernhard Lehner\\nMatthias Dorfer\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1706.06525\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 20 Jun 2017 15:44:09 GMT)\\u00a7r"}']}
{title:'Lee et al. (§72017§r)', author: 'Jongpil Lee; Juhan Nam', display:{Lore:['[{"text": "arXiv:1706.06810", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.MM\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMulti-Level and Multi-Scale Feature Aggregation Using Sample-level Deep Convolutional Neural Networks for Music Classification\\u00a7r\\n\\n\\u00a78\\u00a7oJongpil Lee\\nJuhan Nam\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1706.06810\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 21 Jun 2017 09:57:24 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oICML Music Discovery Workshop 2017\\u00a7r"}']}
{title:'Voss (§72017§r)', author: 'Henning U. Voss', display:{Lore:['[{"text": "arXiv:1706.07326", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA universal negative group delay filter for the prediction of band-limited signals\\u00a7r\\n\\n\\u00a78\\u00a7oHenning U. Voss\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1706.07326\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 28 Nov 2017 15:52:27 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oTo be re-submitted to IEEE-TSP\\u00a7r"}']}
{title:'Bayle et al. (§72017§r)', author: 'Yann Bayle; Matthias Robine; Pierre Hanna', display:{Lore:['[{"text": "arXiv:1706.07613", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.IR\\u00a7r, \\u00a7acs.MM\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lToward Faultless Content-Based Playlists Generation for Instrumentals\\u00a7r\\n\\n\\u00a78\\u00a7oYann Bayle\\nMatthias Robine\\nPierre Hanna\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1706.07613\\u00a7r\\n\\nVersion:\\u00a77v2 (Wed, 22 Nov 2017 11:05:00 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7osingle-column 20pages, 3 figures, 6 tables\\u00a7r"}']}
{title:'Wei et al. (§72017§r)', author: 'Cheng-Kuan Wei; Cheng-Tao Chung; Hung-Yi Lee; Lin-Shan Lee', display:{Lore:['[{"text": "arXiv:1706.07793", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lPersonalized Acoustic Modeling by Weakly Supervised Multi-Task Deep Learning using Acoustic Tokens Discovered from Unlabeled Data\\u00a7r\\n\\n\\u00a78\\u00a7oCheng-Kuan Wei\\nCheng-Tao Chung\\nHung-Yi Lee\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1706.07793\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/ICASSP.2017.7953141\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nIEEE International Conference on Acoustics, Speech and Signal\\n  Processing (ICASSP), New Orleans, LA, USA, 2017, pp. 5165-5169 (2017)\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 23 Jun 2017 12:54:43 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 5 figures, published in IEEE ICASSP 2017\\u00a7r"}']}
{title:'Wang et al. (§72017§r)', author: 'Dong Wang; Lantian Li; Zhiyuan Tang; Thomas Fang Zheng', display:{Lore:['[{"text": "arXiv:1706.07859", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDeep Speaker Verification: Do We Need End to End?\\u00a7r\\n\\n\\u00a78\\u00a7oDong Wang\\nLantian Li\\nZhiyuan Tang\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1706.07859\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 22 Jun 2017 04:33:59 GMT)\\u00a7r"}']}
{title:'Zhang et al. (§72017§r)', author: 'Miao Zhang; Yixiang Chen; Lantian Li; Dong Wang', display:{Lore:['[{"text": "arXiv:1706.07860", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSpeaker Recognition with Cough, Laugh and \\"Wei\\"\\u00a7r\\n\\n\\u00a78\\u00a7oMiao Zhang\\nYixiang Chen\\nLantian Li\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1706.07860\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 22 Jun 2017 04:26:39 GMT)\\u00a7r"}']}
{title:'Li et al. (§72017§r)', author: 'Lantian Li; Dong Wang; Askar Rozi; Thomas Fang Zheng', display:{Lore:['[{"text": "arXiv:1706.07861", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lCross-lingual Speaker Verification with Deep Feature Learning\\u00a7r\\n\\n\\u00a78\\u00a7oLantian Li\\nDong Wang\\nAskar Rozi\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1706.07861\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 22 Jun 2017 04:32:40 GMT)\\u00a7r"}']}
{title:'Shi et al. (§72017§r)', author: 'Liming Shi; Jesper Kjær Nielsen; Jesper Rindom Jensen; Mads Græsbøll Christensen', display:{Lore:['[{"text": "arXiv:1706.07927", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Variational EM Method for Pole-Zero Modeling of Speech with Mixed Block Sparse and Gaussian Excitation\\u00a7r\\n\\n\\u00a78\\u00a7oLiming Shi\\nJesper Kj\\u00e6r Nielsen\\nJesper Rindom Jensen\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1706.07927\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 24 Jun 2017 08:50:20 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted in the 25th European Signal Processing Conference (EUSIPCO 2017), published by EUROSIP, scheduled forAug. 28 - Sep. 2 in Kos island, Greece\\u00a7r"}']}
{title:'Su (§72017§r)', author: 'Li Su', display:{Lore:['[{"text": "arXiv:1706.08231", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.NE\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lBetween Homomorphic Signal Processing and Deep Neural Networks: Constructing Deep Algorithms for Polyphonic Music Transcription\\u00a7r\\n\\n\\u00a78\\u00a7oLi Su\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1706.08231\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 26 Jun 2017 04:57:06 GMT)\\u00a7r"}']}
{title:'Arslan (§72017§r)', author: 'Yüksel Arslan', display:{Lore:['[{"text": "arXiv:1706.08759", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lImpulsive Sound Detection by a Novel Energy Formula and its Usage for Gunshot Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oY\\u00fcksel Arslan\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1706.08759\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 27 Jun 2017 10:03:52 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o4 pages, 3 figures\\u00a7r"}']}
{title:'Shulby et al. (§72017§r)', author: 'Christopher Dane Shulby; Martha Dais Ferreira; Rodrigo F. de Mello; Sandra Maria Aluisio', display:{Lore:['[{"text": "arXiv:1706.09055", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAcoustic Modeling Using a Shallow CNN-HTSVM Architecture\\u00a7r\\n\\n\\u00a78\\u00a7oChristopher Dane Shulby\\nMartha Dais Ferreira\\nRodrigo F. de Mello\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1706.09055\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 27 Jun 2017 21:28:31 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oPre-review version of Bracis 2017\\u00a7r"}']}
{title:'Herremans et al. (§72017§r)', author: 'Dorien Herremans; Ching-Hua Chuan', display:{Lore:['[{"text": "arXiv:1706.09088", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.IR\\u00a7r, \\u00a7acs.MM\\u00a7r, \\u00a7acs.NE\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lModeling Musical Context with Word2vec\\u00a7r\\n\\n\\u00a78\\u00a7oDorien Herremans\\nChing-Hua Chuan\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1706.09088\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nProceedings of the First International Workshop on Deep Learning\\n  and Music joint with IJCNN. Anchorage, US. 1(1). pp 11-18 (2017)\\u00a7r\\n\\nVersion:\\u00a77v2 (Thu, 29 Jun 2017 02:33:06 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oProceedings of the First International Conference on Deep Learning and Music, Anchorage, US, May, 2017 (arXiv:1706.08675v1 [cs.NE])\\u00a7r"}']}
{title:'Pfalz et al. (§72017§r)', author: 'A. Pfalz; E. Berdahl', display:{Lore:['[{"text": "arXiv:1706.09551", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.MM\\u00a7r, \\u00a7acs.NE\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lToward Inverse Control of Physics-Based Sound Synthesis\\u00a7r\\n\\n\\u00a78\\u00a7oA. Pfalz\\nE. Berdahl\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1706.09551\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nProceedings of the First International Workshop on Deep Learning\\n  and Music joint with IJCNN, 1(1). pp 56-61 (2017)\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 29 Jun 2017 02:33:56 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oProceedings of the First International Conference on Deep Learning and Music, Anchorage, US, May, 2017 (arXiv:1706.08675v1 [cs.NE])\\u00a7r"}']}
{title:'Koops et al. (§72017§r)', author: 'H. V. Koops; W. B. de Haas; J. Bransen; A. Volk', display:{Lore:['[{"text": "arXiv:1706.09552", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.MM\\u00a7r, \\u00a7acs.NE\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lChord Label Personalization through Deep Learning of Integrated Harmonic Interval-based Representations\\u00a7r\\n\\n\\u00a78\\u00a7oH. V. Koops\\nW. B. de Haas\\nJ. Bransen\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1706.09552\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nProc. of the Int. Workshop on Deep Learning and Music. Anchorage,\\n  US. 1(1). pp19-25 (2017)\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 29 Jun 2017 02:38:02 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oProceedings of the First International Conference on Deep Learning and Music, Anchorage, US, May, 2017 (arXiv:1706.08675v1 [cs.NE])\\u00a7r"}']}
{title:'Geng et al. (§72017§r)', author: 'S. Geng; G. Ren; M. Ogihara', display:{Lore:['[{"text": "arXiv:1706.09553", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.MM\\u00a7r, \\u00a7acs.NE\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lTransforming Musical Signals through a Genre Classifying Convolutional Neural Network\\u00a7r\\n\\n\\u00a78\\u00a7oS. Geng\\nG. Ren\\nM. Ogihara\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1706.09553\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nProc. of the First Int. Workshop on Deep Learning and Music joint\\n  with IJCNN. Anchorage, US. 1(1). pp 48-49 (2017)\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 29 Jun 2017 02:39:00 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oProceedings of the First International Conference on Deep Learning and Music, Anchorage, US, May, 2017 (arXiv:1706.08675v1 [cs.NE])\\u00a7r"}']}
{title:'Fan et al. (§72017§r)', author: 'Z. C. Fan; T. S. Chan; Y. H. Yang; J. S. R. Jang', display:{Lore:['[{"text": "arXiv:1706.09555", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.MM\\u00a7r, \\u00a7acs.NE\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMusic Signal Processing Using Vector Product Neural Networks\\u00a7r\\n\\n\\u00a78\\u00a7oZ. C. Fan\\nT. S. Chan\\nY. H. Yang\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1706.09555\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nProc. of the First Int. Workshop on Deep Learning and Music joint\\n  with IJCNN. Anchorage, US. 1(1). pp 36-30 (2017)\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 29 Jun 2017 02:41:30 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oProceedings of the First International Conference on Deep Learning and Music, Anchorage, US, May, 2017 (arXiv:1706.08675v1 [cs.NE])\\u00a7r"}']}
{title:'Cella (§72017§r)', author: 'C. E. Cella', display:{Lore:['[{"text": "arXiv:1706.09557", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMachine listening intelligence\\u00a7r\\n\\n\\u00a78\\u00a7oC. E. Cella\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1706.09557\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nProceedings of the First International Workshop on Deep Learning\\n  and Music joint with IJCNN. Anchorage, US. 1(1). pp 50-55 (2017)\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 29 Jun 2017 02:52:25 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oProceedings of the First International Conference on Deep Learning and Music, Anchorage, US, May, 2017 (arXiv:1706.08675v1 [cs.NE])\\u00a7r"}']}
{title:'Hutchings (§72017§r)', author: 'P. Hutchings', display:{Lore:['[{"text": "arXiv:1706.09558", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.MM\\u00a7r, \\u00a7acs.NE\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lTalking Drums: Generating drum grooves with neural networks\\u00a7r\\n\\n\\u00a78\\u00a7oP. Hutchings\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1706.09558\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nProceedings of the First International Workshop on Deep Learning\\n  and Music joint with IJCNN. Anchorage, US. 1(1). pp 43-47 (2017)\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 29 Jun 2017 03:03:35 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oProceedings of the First International Conference on Deep Learning and Music, Anchorage, US, May, 2017 (arXiv:1706.08675v1 [cs.NE])\\u00a7r"}']}
{title:'Wyse (§72017§r)', author: 'L. Wyse', display:{Lore:['[{"text": "arXiv:1706.09559", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.MM\\u00a7r, \\u00a7acs.NE\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAudio Spectrogram Representations for Processing with Convolutional Neural Networks\\u00a7r\\n\\n\\u00a78\\u00a7oL. Wyse\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1706.09559\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nProceedings of the First International Workshop on Deep Learning\\n  and Music joint with IJCNN. Anchorage, US. 1(1). pp 37-41 (2017)\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 29 Jun 2017 03:04:06 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oProceedings of the First International Conference on Deep Learning and Music, Anchorage, US, May, 2017 (arXiv:1706.08675v1 [cs.NE])\\u00a7r"}']}
{title:'Takahashi et al. (§72017§r)', author: 'Naoya Takahashi; Yuki Mitsufuji', display:{Lore:['[{"text": "arXiv:1706.09588", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.MM\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMulti-scale Multi-band DenseNets for Audio Source Separation\\u00a7r\\n\\n\\u00a78\\u00a7oNaoya Takahashi\\nYuki Mitsufuji\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1706.09588\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 29 Jun 2017 05:56:06 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oto appear at WASPAA 2017\\u00a7r"}']}
{title:'Shahin (§72017§r)', author: 'Ismail Shahin', display:{Lore:['[{"text": "arXiv:1706.09691", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSpeaker Identification in the Shouted Environment Using Suprasegmental Hidden Markov Models\\u00a7r\\n\\n\\u00a78\\u00a7oIsmail Shahin\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1706.09691\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1016/j.sigpro.2008.05.012\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 29 Jun 2017 11:43:44 GMT)\\u00a7r"}']}
{title:'Shahin (§72017§r)', author: 'Ismail Shahin', display:{Lore:['[{"text": "arXiv:1706.09716", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lEnhancing speaker identification performance under the shouted talking condition using second-order circular hidden Markov models\\u00a7r\\n\\n\\u00a78\\u00a7oIsmail Shahin\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1706.09716\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1016/j.specom.2006.01.005\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 29 Jun 2017 12:33:27 GMT)\\u00a7r"}']}
{title:'Shahin (§72017§r)', author: 'Ismail Shahin', display:{Lore:['[{"text": "arXiv:1706.09722", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lEmploying Second-Order Circular Suprasegmental Hidden Markov Models to Enhance Speaker Identification Performance in Shouted Talking Environments\\u00a7r\\n\\n\\u00a78\\u00a7oIsmail Shahin\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1706.09722\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1155/2010/862138\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 29 Jun 2017 12:45:35 GMT)\\u00a7r"}']}
{title:'Shahin et al. (§72017§r)', author: 'Ismail Shahin; Mohammed Nasser Ba-Hutair', display:{Lore:['[{"text": "arXiv:1706.09729", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lTalking Condition Recognition in Stressful and Emotional Talking Environments Based on CSPHMM2s\\u00a7r\\n\\n\\u00a78\\u00a7oIsmail Shahin\\nMohammed Nasser Ba-Hutair\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1706.09729\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1007/s10772-014-9251-7\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 29 Jun 2017 12:54:31 GMT)\\u00a7r"}']}
{title:'Shahin (§72017§r)', author: 'Ismail Shahin', display:{Lore:['[{"text": "arXiv:1706.09736", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSpeaking Style Authentication Using Suprasegmental Hidden Markov Models\\u00a7r\\n\\n\\u00a78\\u00a7oIsmail Shahin\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1706.09736\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 29 Jun 2017 13:04:50 GMT)\\u00a7r"}']}
{title:'Shahin (§72017§r)', author: 'Ismail Shahin', display:{Lore:['[{"text": "arXiv:1706.09754", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSpeaker Identification Investigation and Analysis in Unbiased and Biased Emotional Talking Environments\\u00a7r\\n\\n\\u00a78\\u00a7oIsmail Shahin\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1706.09754\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1007/s10772-012-9156-2\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 29 Jun 2017 13:45:09 GMT)\\u00a7r"}']}
{title:'Shahin (§72017§r)', author: 'Ismail Shahin', display:{Lore:['[{"text": "arXiv:1706.09758", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lUsing Second-Order Hidden Markov Model to Improve Speaker Identification Recognition Performance under Neutral Condition\\u00a7r\\n\\n\\u00a78\\u00a7oIsmail Shahin\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1706.09758\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 29 Jun 2017 13:51:31 GMT)\\u00a7r"}']}
{title:'Shahin (§72017§r)', author: 'Ismail Shahin', display:{Lore:['[{"text": "arXiv:1706.09760", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lEmploying both Gender and Emotion Cues to Enhance Speaker Identification Performance in Emotional Talking Environments\\u00a7r\\n\\n\\u00a78\\u00a7oIsmail Shahin\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1706.09760\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1007/s10772-013-9188-2\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 29 Jun 2017 13:57:12 GMT)\\u00a7r"}']}
{title:'Drossos et al. (§72017§r)', author: 'Konstantinos Drossos; Sharath Adavanne; Tuomas Virtanen', display:{Lore:['[{"text": "arXiv:1706.10006", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAutomated Audio Captioning with Recurrent Neural Networks\\u00a7r\\n\\n\\u00a78\\u00a7oKonstantinos Drossos\\nSharath Adavanne\\nTuomas Virtanen\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1706.10006\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 24 Oct 2017 11:36:08 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oPresented at the11th IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA), 2017\\u00a7r"}']}
{title:'Shahin (§72017§r)', author: 'Ismail Shahin', display:{Lore:['[{"text": "arXiv:1707.00137", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lEmploying Emotion Cues to Verify Speakers in Emotional Talking Environments\\u00a7r\\n\\n\\u00a78\\u00a7oIsmail Shahin\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1707.00137\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1515/jisys-2014-0118\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 1 Jul 2017 10:54:10 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oJournal of Intelligent Systems, Special Issue on Intelligent Healthcare Systems, De Gruyter, 2016\\u00a7r"}']}
{title:'Shahin (§72017§r)', author: 'Ismail Shahin', display:{Lore:['[{"text": "arXiv:1707.00138", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSpeaker Identification in Shouted Talking Environments Based on Novel Third-Order Hidden Markov Models\\u00a7r\\n\\n\\u00a78\\u00a7oIsmail Shahin\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1707.00138\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 1 Jul 2017 11:15:21 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oThe 4th International Conference on Audio, Language and Image Processing (ICALIP2014), Shanghai,China, 2014\\u00a7r"}']}
{title:'Shahin et al. (§72017§r)', author: 'Ismail Shahin; Nazeih Botros', display:{Lore:['[{"text": "arXiv:1707.00149", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lModeling and Analyzing the Vocal Tract under Normal and Stressful Talking Conditions\\u00a7r\\n\\n\\u00a78\\u00a7oIsmail Shahin\\nNazeih Botros\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1707.00149\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 1 Jul 2017 12:23:37 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oIEEE SOUTHEASTCON 2001, Clemson, South Carolina, USA, 2001\\u00a7r"}']}
{title:'Ewert et al. (§72017§r)', author: 'Sebastian Ewert; Mark B. Sandler', display:{Lore:['[{"text": "arXiv:1707.00160", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.NE\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAn Augmented Lagrangian Method for Piano Transcription using Equal Loudness Thresholding and LSTM-based Decoding\\u00a7r\\n\\n\\u00a78\\u00a7oSebastian Ewert\\nMark B. Sandler\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1707.00160\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nProceedings of the IEEE Workshop on Applications of Signal\\n  Processing to Audio and Acoustics (WASPAA), New Paltz, NY, USA, pp. 146-150,\\n  2017\\u00a7r\\n\\nVersion:\\u00a77v3 (Sun, 30 Jul 2017 11:13:30 GMT)\\u00a7r"}']}
{title:'Wang et al. (§72017§r)', author: 'Ziteng Wang; Emmanuel Vincent; Romain Serizel; Yonghong Yan', display:{Lore:['[{"text": "arXiv:1707.00201", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lRank-1 Constrained Multichannel Wiener Filter for Speech Recognition in Noisy Environments\\u00a7r\\n\\n\\u00a78\\u00a7oZiteng Wang\\nEmmanuel Vincent\\nRomain Serizel\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1707.00201\\u00a7r\\n\\nVersion:\\u00a77v2 (Wed, 15 Nov 2017 03:26:31 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7ofor Computer Speech and Language\\u00a7r"}']}
{title:'Shahin (§72017§r)', author: 'Ismail Shahin', display:{Lore:['[{"text": "arXiv:1707.00276", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lEmirati Speaker Verification Based on HMM1s, HMM2s, and HMM3s\\u00a7r\\n\\n\\u00a78\\u00a7oIsmail Shahin\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1707.00276\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 2 Jul 2017 10:31:10 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o13th International Conference on Signal Processing, Chengdu, China, 2016\\u00a7r"}']}
{title:'Shahin (§72017§r)', author: 'Ismail Shahin', display:{Lore:['[{"text": "arXiv:1707.00679", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lTalking Condition Identification Using Second-Order Hidden Markov Models\\u00a7r\\n\\n\\u00a78\\u00a7oIsmail Shahin\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1707.00679\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 1 Jul 2017 10:25:21 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o3rd International Conference on Information Communication Technologies: from Theory to Applications, Damascus, Syria, 2008. arXiv admin note: text overlap with arXiv:1706.09691, arXiv:1706.09716\\u00a7r"}']}
{title:'Shahin (§72017§r)', author: 'Ismail Shahin', display:{Lore:['[{"text": "arXiv:1707.00680", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lStudying and Enhancing Talking Condition Recognition in Stressful and Emotional Talking Environments Based on HMMs, CHMM2s and SPHMMs\\u00a7r\\n\\n\\u00a78\\u00a7oIsmail Shahin\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1707.00680\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1007/s12193-011-0082-4\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nJournal on Multimodal User Interfaces July 2012, Volume 6, Issue\\n  1-2, pp 59-71\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 1 Jul 2017 11:00:36 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oarXiv admin note: substantial text overlap with arXiv:1706.09729\\u00a7r"}']}
{title:'Shahin (§72017§r)', author: 'Ismail Shahin', display:{Lore:['[{"text": "arXiv:1707.00686", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSpeaker Identification in a Shouted Talking Environment Based on Novel Third-Order Circular Suprasegmental Hidden Markov Models\\u00a7r\\n\\n\\u00a78\\u00a7oIsmail Shahin\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1707.00686\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1007/s00034-015-0220-4\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nCircuits Syst Signal Process (2016) 35: 3770\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 2 Jul 2017 10:36:17 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oarXiv admin note: substantial text overlap with arXiv:1706.09722, arXiv:1707.00138\\u00a7r"}']}
{title:'Nikrang et al. (§72017§r)', author: 'Ali Nikrang; David R. W. Sears; Gerhard Widmer', display:{Lore:['[{"text": "arXiv:1707.00972", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.IR\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAutomatic estimation of harmonic tension by distributed representation of chords\\u00a7r\\n\\n\\u00a78\\u00a7oAli Nikrang\\nDavid R. W. Sears\\nGerhard Widmer\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1707.00972\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 4 Jul 2017 13:31:34 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o12 pages, 4 figures. To appear in Proceedings of the 13th International Symposium on Computer Music Multidisciplinary Research (CMMR), Porto, Portugal\\u00a7r"}']}
{title:'Dzibela et al. (§72017§r)', author: 'Daniel Dzibela; Armin Sehr', display:{Lore:['[{"text": "arXiv:1707.01090", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lHidden-Markov-Model Based Speech Enhancement\\u00a7r\\n\\n\\u00a78\\u00a7oDaniel Dzibela\\nArmin Sehr\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1707.01090\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 4 Jul 2017 09:58:40 GMT)\\u00a7r"}']}
{title:'Rogozinsky et al. (§72017§r)', author: 'Gleb Rogozinsky; Mihail Chesnokov; Eugene Cherny', display:{Lore:['[{"text": "arXiv:1707.01653", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lpch2csd: an application for converting Nord Modular G2 patches into Csound code\\u00a7r\\n\\n\\u00a78\\u00a7oGleb Rogozinsky\\nMihail Chesnokov\\nEugene Cherny\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1707.01653\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nProc. 14th Sound and Music Computing Conf. (SMC 2017) (2017)\\n  415-421\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 6 Jul 2017 06:40:19 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o7 pages, 4 figures, for associated source code, see https://github.com/gleb812/pch2csd/\\u00a7r"}']}
{title:'Yang et al. (§72017§r)', author: 'Shan Yang; Lei Xie; Xiao Chen; Xiaoyan Lou; Xuan Zhu; Dongyan Huang; Haizhou Li', display:{Lore:['[{"text": "arXiv:1707.01670", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lStatistical Parametric Speech Synthesis Using Generative Adversarial Networks Under A Multi-task Learning Framework\\u00a7r\\n\\n\\u00a78\\u00a7oShan Yang\\nLei Xie\\nXiao Chen\\n+ 3 others\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1707.01670\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 11 Jul 2017 04:00:23 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to Automatic Speech Recognition and Understanding (ASRU) 2017 Workshop\\u00a7r"}']}
{title:'Khademian et al. (§72017§r)', author: 'Mahdi Khademian; Mohammad Mehdi Homayounpour', display:{Lore:['[{"text": "arXiv:1707.02661", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lFeature Joint-State Posterior Estimation in Factorial Speech Processing Models using Deep Neural Networks\\u00a7r\\n\\n\\u00a78\\u00a7oMahdi Khademian\\nMohammad Mehdi Homayounpour\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1707.02661\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 10 Jul 2017 00:14:32 GMT)\\u00a7r"}']}
{title:'Pons et al. (§72017§r)', author: 'Jordi Pons; Rong Gong; Xavier Serra', display:{Lore:['[{"text": "arXiv:1707.03544", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lScore-informed syllable segmentation for a cappella singing voice with convolutional neural networks\\u00a7r\\n\\n\\u00a78\\u00a7oJordi Pons\\nRong Gong\\nXavier Serra\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1707.03544\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 12 Jul 2017 05:15:23 GMT)\\u00a7r"}']}
{title:'Gong et al. (§72017§r)', author: 'Rong Gong; Jordi Pons; Xavier Serra', display:{Lore:['[{"text": "arXiv:1707.03547", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAudio to score matching by combining phonetic and duration information\\u00a7r\\n\\n\\u00a78\\u00a7oRong Gong\\nJordi Pons\\nXavier Serra\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1707.03547\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 12 Jul 2017 05:32:22 GMT)\\u00a7r"}']}
{title:'Liu et al. (§72017§r)', author: 'Yi Liu; Liang He; Yao Tian; Zhuzi Chen; Jia Liu; Michael T. Johnson', display:{Lore:['[{"text": "arXiv:1707.04373", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.AI\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lComparison of Multiple Features and Modeling Methods for Text-dependent Speaker Verification\\u00a7r\\n\\n\\u00a78\\u00a7oYi Liu\\nLiang He\\nYao Tian\\n+ 2 others\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1707.04373\\u00a7r\\n\\nVersion:\\u00a77v2 (Sat, 9 Sep 2017 07:59:07 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oThe 2017 IEEE Automatic Speech Recognition andUnderstanding Workshop (ASRU 2017)\\u00a7r"}']}
{title:'Tukuljac et al. (§72017§r)', author: 'Helena Peic Tukuljac; Herve Lissek; Pierre Vandergheynst', display:{Lore:['[{"text": "arXiv:1707.04504", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lLocalization of Sound Sources in a Room with One Microphone\\u00a7r\\n\\n\\u00a78\\u00a7oHelena Peic Tukuljac\\nHerve Lissek\\nPierre Vandergheynst\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1707.04504\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 14 Jul 2017 13:25:44 GMT)\\u00a7r"}']}
{title:'Rubin et al. (§72017§r)', author: 'Jonathan Rubin; Rui Abreu; Anurag Ganguli; Saigopal Nelaturi; Ion Matei; Kumar Sricharan', display:{Lore:['[{"text": "arXiv:1707.04642", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CV\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lRecognizing Abnormal Heart Sounds Using Deep Learning\\u00a7r\\n\\n\\u00a78\\u00a7oJonathan Rubin\\nRui Abreu\\nAnurag Ganguli\\n+ 2 others\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1707.04642\\u00a7r\\n\\nVersion:\\u00a77v2 (Thu, 19 Oct 2017 08:27:01 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oIJCAI 2017 Knowledge Discovery in Healthcare Workshop\\u00a7r"}']}
{title:'Dzhambazov et al. (§72017§r)', author: 'Georgi Dzhambazov; Andre Holzapfel; Ajay Srinivasamurthy; Xavier Serra', display:{Lore:['[{"text": "arXiv:1707.06163", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.MM\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMetrical-accent Aware Vocal Onset Detection in Polyphonic Audio\\u00a7r\\n\\n\\u00a78\\u00a7oGeorgi Dzhambazov\\nAndre Holzapfel\\nAjay Srinivasamurthy\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1707.06163\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 19 Jul 2017 15:39:09 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oInternational Society for Music Information Retrieval Conferece (ISMIR 2017)\\u00a7r"}']}
{title:'Cancino-Chacón et al. (§72017§r)', author: 'Carlos Cancino-Chacón; Maarten Grachten; Kat Agres', display:{Lore:['[{"text": "arXiv:1707.06231", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lFrom Bach to the Beatles: The simulation of human tonal expectation using ecologically-trained predictive models\\u00a7r\\n\\n\\u00a78\\u00a7oCarlos Cancino-Chac\\u00f3n\\nMaarten Grachten\\nKat Agres\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1707.06231\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 19 Jul 2017 16:37:23 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oIn Proceedings of the 18th International Society of Music Information Retrieval Conference (ISMIR 2017)\\u00a7r"}']}
{title:'Qian et al. (§72017§r)', author: 'Yanmin Qian; Xuankai Chang; Dong Yu', display:{Lore:['[{"text": "arXiv:1707.06527", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSingle-Channel Multi-talker Speech Recognition with Permutation Invariant Training\\u00a7r\\n\\n\\u00a78\\u00a7oYanmin Qian\\nXuankai Chang\\nDong Yu\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1707.06527\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 19 Jul 2017 03:48:54 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o11 pages, 6 figures, Submitted to IEEE/ACM Transactions on Audio, Speech and Language Processing. arXiv adminnote: text overlap with arXiv:1704.01985\\u00a7r"}']}
{title:'Zhang et al. (§72017§r)', author: 'Bo Zhang; Wei Li; Zhe Tong; Meng Zhang', display:{Lore:['[{"text": "arXiv:1707.09890", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lBearing fault diagnosis under varying working condition based on domain adaptation\\u00a7r\\n\\n\\u00a78\\u00a7oBo Zhang\\nWei Li\\nZhe Tong\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1707.09890\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 31 Jul 2017 14:41:00 GMT)\\u00a7r"}']}
{title:'Niu et al. (§72017§r)', author: 'Yafeng Niu; Dongsheng Zou; Yadong Niu; Zhongshi He; Hua Tan', display:{Lore:['[{"text": "arXiv:1707.09917", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA breakthrough in Speech emotion recognition using Deep Retinal Convolution Neural Networks\\u00a7r\\n\\n\\u00a78\\u00a7oYafeng Niu\\nDongsheng Zou\\nYadong Niu\\nZhongshi He\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1707.09917\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 12 Jul 2017 02:00:15 GMT)\\u00a7r"}']}
{title:'Kuleshov et al. (§72017§r)', author: 'Volodymyr Kuleshov; S. Zayd Enam; Stefano Ermon', display:{Lore:['[{"text": "arXiv:1708.00853", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAudio Super Resolution using Neural Networks\\u00a7r\\n\\n\\u00a78\\u00a7oVolodymyr Kuleshov\\nS. Zayd Enam\\nStefano Ermon\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1708.00853\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 2 Aug 2017 20:07:39 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oPresented at the5th International Conference on Learning Representations (ICLR)2017, Workshop Track, Toulon, France\\u00a7r"}']}
{title:'Shon et al. (§72017§r)', author: 'Suwon Shon; Seongkyu Mun; Wooil Kim; Hanseok Ko', display:{Lore:['[{"text": "arXiv:1708.01227", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAutoencoder based Domain Adaptation for Speaker Recognition under Insufficient Channel Information\\u00a7r\\n\\n\\u00a78\\u00a7oSuwon Shon\\nSeongkyu Mun\\nWooil Kim\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1708.01227\\u00a7r\\n\\nVersion:\\u00a77v2 (Mon, 28 Aug 2017 14:29:48 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oInterspeech 2017, pp 1014-1018\\u00a7r"}']}
{title:'Shon et al. (§72017§r)', author: 'Suwon Shon; Seongkyu Mun; Hanseok Ko', display:{Lore:['[{"text": "arXiv:1708.01232", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lRecursive Whitening Transformation for Speaker Recognition on Language Mismatched Condition\\u00a7r\\n\\n\\u00a78\\u00a7oSuwon Shon\\nSeongkyu Mun\\nHanseok Ko\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1708.01232\\u00a7r\\n\\nVersion:\\u00a77v2 (Mon, 28 Aug 2017 14:30:07 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oInterspeech 2017, pp 2869-2873\\u00a7r"}']}
{title:'Dionelis et al. (§72017§r)', author: 'Nikolaos Dionelis; Mike Brookes', display:{Lore:['[{"text": "arXiv:1708.02171", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lPhase-Aware Single-Channel Speech Enhancement with Modulation-Domain Kalman Filtering\\u00a7r\\n\\n\\u00a78\\u00a7oNikolaos Dionelis\\nMike Brookes\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1708.02171\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 7 Aug 2017 15:42:48 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o13 pages, 17 figures, Submitted to IEEE/ACM Transactions on Audio, Speech and Language Processing\\u00a7r"}']}
{title:'Alekh (§72017§r)', author: 'Sanchit Alekh', display:{Lore:['[{"text": "arXiv:1708.02322", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAutomatic Raga Recognition in Hindustani Classical Music\\u00a7r\\n\\n\\u00a78\\u00a7oSanchit Alekh\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1708.02322\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 7 Aug 2017 22:18:55 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSeminar on Computer Music, RWTH Aachen, http://hpac.rwth-aachen.de/teaching/sem-mus-17/Reports/Alekh.pdf\\u00a7r"}']}
{title:'Cyrta et al. (§72017§r)', author: 'Pawel Cyrta; Tomasz Trzciński; Wojciech Stokowiec', display:{Lore:['[{"text": "arXiv:1708.02840", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.MM\\u00a7r, \\u00a7acs.NE\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSpeaker Diarization using Deep Recurrent Convolutional Neural Networks for Speaker Embeddings\\u00a7r\\n\\n\\u00a78\\u00a7oPawel Cyrta\\nTomasz Trzci\\u0144ski\\nWojciech Stokowiec\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1708.02840\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1007/978-3-319-67220-5_10\\u00a7r\\n\\nVersion:\\u00a77v2 (Fri, 15 Sep 2017 13:49:45 GMT)\\u00a7r"}']}
{title:'Phan et al. (§72017§r)', author: 'Huy Phan; Martin Krawczyk-Becker; Timo Gerkmann; Alfred Mertins', display:{Lore:['[{"text": "arXiv:1708.03211", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDNN and CNN with Weighted and Multi-task Loss Functions for Audio Event Detection\\u00a7r\\n\\n\\u00a78\\u00a7oHuy Phan\\nMartin Krawczyk-Becker\\nTimo Gerkmann\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1708.03211\\u00a7r\\n\\nVersion:\\u00a77v2 (Wed, 18 Oct 2017 14:38:07 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oDCASE 2017 technical report\\u00a7r"}']}
{title:'Mun et al. (§72017§r)', author: 'Seongkyu Mun; Minkyu Shin; Suwon Shon; Wooil Kim; David K. Han; Hanseok Ko', display:{Lore:['[{"text": "arXiv:1708.03465", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDNN Transfer Learning based Non-linear Feature Extraction for Acoustic Event Classification\\u00a7r\\n\\n\\u00a78\\u00a7oSeongkyu Mun\\nMinkyu Shin\\nSuwon Shon\\n+ 2 others\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1708.03465\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1587/transinf.2017EDL8048\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nIEICE TRANSACTIONS on Information and Systems, Vol.E100-D, No.9\\n  (2017)\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 11 Aug 2017 08:14:19 GMT)\\u00a7r"}']}
{title:'Malik et al. (§72017§r)', author: 'Iman Malik; Carl Henrik Ek', display:{Lore:['[{"text": "arXiv:1708.03535", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.NE\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lNeural Translation of Musical Style\\u00a7r\\n\\n\\u00a78\\u00a7oIman Malik\\nCarl Henrik Ek\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1708.03535\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 11 Aug 2017 13:24:32 GMT)\\u00a7r"}']}
{title:'Gong et al. (§72017§r)', author: 'Rong Gong; Rafael Caro Repetto; Xavier Serra', display:{Lore:['[{"text": "arXiv:1708.03986", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.DL\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lCreating an A Cappella Singing Audio Dataset for Automatic Jingju Singing Evaluation Research\\u00a7r\\n\\n\\u00a78\\u00a7oRong Gong\\nRafael Caro Repetto\\nXavier Serra\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1708.03986\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 14 Aug 2017 01:43:13 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o4th International Digital Libraries for Musicology workshop (DLfM 2017), Shanghai, China\\u00a7r"}']}
{title:'Mallis et al. (§72017§r)', author: 'Dimitrios Mallis; Thomas Sgouros; Nikolaos Mitianoudis', display:{Lore:['[{"text": "arXiv:1708.03989", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.NE\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lConvolutive Audio Source Separation using Robust ICA and an intelligent evolving permutation ambiguity solution\\u00a7r\\n\\n\\u00a78\\u00a7oDimitrios Mallis\\nThomas Sgouros\\nNikolaos Mitianoudis\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1708.03989\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1007/s12530-017-9199-3\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nEvolving Systems, Volume 9, Issue 4, pp 315,329, December 2018\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 14 Aug 2017 01:59:34 GMT)\\u00a7r"}']}
{title:'Mogami et al. (§72017§r)', author: 'Shinichi Mogami; Daichi Kitamura; Yoshiki Mitsui; Norihiro Takamune; Hiroshi Saruwatari; Nobutaka Ono', display:{Lore:['[{"text": "arXiv:1708.04795", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lIndependent Low-Rank Matrix Analysis Based on Complex Student\'s t-Distribution for Blind Audio Source Separation\\u00a7r\\n\\n\\u00a78\\u00a7oShinichi Mogami\\nDaichi Kitamura\\nYoshiki Mitsui\\n+ 2 others\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1708.04795\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 16 Aug 2017 07:44:36 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oPreprint manuscript of 2017 IEEE International Workshop on Machine Learning for Signal Processing\\u00a7r"}']}
{title:'Mitianoudis (§72017§r)', author: 'Nikolaos Mitianoudis', display:{Lore:['[{"text": "arXiv:1708.04816", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CV\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Generalised Directional Laplacian Distribution: Estimation, Mixture Models and Audio Source Separation\\u00a7r\\n\\n\\u00a78\\u00a7oNikolaos Mitianoudis\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1708.04816\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/TASL.2012.2203804\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nIEEE Transactions on Audio, Speech and Language Processing, Vol.\\n  20, No. 9, pp. 2397- 2408 (2012)\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 16 Aug 2017 08:56:51 GMT)\\u00a7r"}']}
{title:'Sgouros et al. (§72017§r)', author: 'Thomas Sgouros; Nikolaos Mitianoudis', display:{Lore:['[{"text": "arXiv:1708.04821", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lUnderdetermined source separation using a sparse STFT framework and weighted laplacian directional modelling\\u00a7r\\n\\n\\u00a78\\u00a7oThomas Sgouros\\nNikolaos Mitianoudis\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1708.04821\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/EUSIPCO.2016.7760549\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 16 Aug 2017 09:23:28 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oEUSIPCO 2016, Budapest, Hungary\\u00a7r"}']}
{title:'Lattner et al. (§72017§r)', author: 'Stefan Lattner; Maarten Grachten; Gerhard Widmer', display:{Lore:['[{"text": "arXiv:1708.05325", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.AI\\u00a7r, \\u00a7acs.LG\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lLearning Musical Relations using Gated Autoencoders\\u00a7r\\n\\n\\u00a78\\u00a7oStefan Lattner\\nMaarten Grachten\\nGerhard Widmer\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1708.05325\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 17 Aug 2017 15:04:37 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oIn Proceedings of the 2ndConference on Computer Simulation of Musical Creativity (CSMC2017)\\u00a7r"}']}
{title:'Duppada et al. (§72017§r)', author: 'Venkatesh Duppada; Sushant Hiray', display:{Lore:['[{"text": "arXiv:1708.05826", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lEnsemble Of Deep Neural Networks For Acoustic Scene Classification\\u00a7r\\n\\n\\u00a78\\u00a7oVenkatesh Duppada\\nSushant Hiray\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1708.05826\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 3 Oct 2017 11:14:13 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oDetection and Classification of Acoustic Scenes and Events 2017\\u00a7r"}']}
{title:'Elbaz et al. (§72017§r)', author: 'Dan Elbaz; Michael Zibulevsky', display:{Lore:['[{"text": "arXiv:1708.05987", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lPerceptual audio loss function for deep learning\\u00a7r\\n\\n\\u00a78\\u00a7oDan Elbaz\\nMichael Zibulevsky\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1708.05987\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 20 Aug 2017 16:18:20 GMT)\\u00a7r"}']}
{title:'Guo et al. (§72017§r)', author: 'Lijiang Guo; Minje Kim', display:{Lore:['[{"text": "arXiv:1708.06750", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lBitwise Source Separation on Hashed Spectra: An Efficient Posterior Estimation Scheme Using Partial Rank Order Metrics\\u00a7r\\n\\n\\u00a78\\u00a7oLijiang Guo\\nMinje Kim\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1708.06750\\u00a7r\\n\\nVersion:\\u00a77v3 (Fri, 1 Dec 2017 16:47:22 GMT)\\u00a7r"}']}
{title:'Khorram et al. (§72017§r)', author: 'Soheil Khorram; Zakaria Aldeneh; Dimitrios Dimitriadis; Melvin McInnis; Emily Mower Provost', display:{Lore:['[{"text": "arXiv:1708.07050", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.AI\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lCapturing Long-term Temporal Dependencies with Convolutional Networks for Continuous Emotion Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oSoheil Khorram\\nZakaria Aldeneh\\nDimitrios Dimitriadis\\nMelvin McInnis\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1708.07050\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 23 Aug 2017 15:27:00 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 5 figures, 2 tables, Interspeech 2017\\u00a7r"}']}
{title:'Jackson et al. (§72017§r)', author: 'Philip Jackson; Filippo Fazi; Frank Melchior; Trevor Cox; Adrian Hilton; Chris Pike; Jon Francombe; Andreas Franck; Philip Coleman; Dylan Menzies-Gow; James Woodcock; Yan Tang; Qingju Liu; Rick Hughes; Marcos Simon Galvez; Teo de Campos; Hansung Kim; Hanne Stenzel', display:{Lore:['[{"text": "arXiv:1708.07218", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lObject-Based Audio Rendering\\u00a7r\\n\\n\\u00a78\\u00a7oPhilip Jackson\\nFilippo Fazi\\nFrank Melchior\\n+ 14 others\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1708.07218\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 23 Aug 2017 23:43:09 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oThis is a transcript of GB Patent Application No: GB1609316.3, filed in the UK by the Universityof Surrey on 23 May 2016. It describes an intelligent system for customising, personalising and perceptually monitoring the"}','{"text": "rendering of an object-based audio stream for an arbitrary connected system of loudspeakers to optimize the listening experience as the producer intended. 30 pages, 5 figures\\u00a7r"}']}
{title:'Li et al. (§72017§r)', author: 'Hao Li; Xueliang Zhang; Hui Zhang; Guanglai Gao', display:{Lore:['[{"text": "arXiv:1708.08251", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lIntegrated Speech Enhancement Method Based on Weighted Prediction Error and DNN for Dereverberation and Denoising\\u00a7r\\n\\n\\u00a78\\u00a7oHao Li\\nXueliang Zhang\\nHui Zhang\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1708.08251\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 28 Aug 2017 09:41:41 GMT)\\u00a7r"}']}
{title:'Zegers et al. (§72017§r)', author: 'Jeroen Zegers; Hugo Van hamme', display:{Lore:['[{"text": "arXiv:1708.08740", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lImproving Source Separation via Multi-Speaker Representations\\u00a7r\\n\\n\\u00a78\\u00a7oJeroen Zegers\\nHugo Van hamme\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1708.08740\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.21437/Interspeech.2017-754\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 29 Aug 2017 13:38:39 GMT)\\u00a7r"}']}
{title:'Kolbæk et al. (§72017§r)', author: 'Morten Kolbæk; Dong Yu; Zheng-Hua Tan; Jesper Jensen', display:{Lore:['[{"text": "arXiv:1708.09588", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lJoint Separation and Denoising of Noisy Multi-talker Speech using Recurrent Neural Networks and Permutation Invariant Training\\u00a7r\\n\\n\\u00a78\\u00a7oMorten Kolb\\u00e6k\\nDong Yu\\nZheng-Hua Tan\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1708.09588\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 31 Aug 2017 07:01:21 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oTo appear in MLSP 2017\\u00a7r"}']}
{title:'Xu et al. (§72017§r)', author: 'Yong Xu; Qiuqiang Kong; Wenwu Wang; Mark D. Plumbley', display:{Lore:['[{"text": "arXiv:1709.00551", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSurrey-cvssp system for DCASE2017 challenge task4\\u00a7r\\n\\n\\u00a78\\u00a7oYong Xu\\nQiuqiang Kong\\nWenwu Wang\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1709.00551\\u00a7r\\n\\nVersion:\\u00a77v2 (Sat, 25 Nov 2017 20:21:32 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oDCASE2017 challenge ranked 1st system, task4, tech report\\u00a7r"}']}
{title:'Xia et al. (§72017§r)', author: 'Shasha Xia; Hao Li; Xueliang Zhang', display:{Lore:['[{"text": "arXiv:1709.00917", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lUsing Optimal Ratio Mask as Training Target for Supervised Speech Separation\\u00a7r\\n\\n\\u00a78\\u00a7oShasha Xia\\nHao Li\\nXueliang Zhang\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1709.00917\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 4 Sep 2017 12:25:18 GMT)\\u00a7r"}']}
{title:'Dighe et al. (§72017§r)', author: 'Pranay Dighe; Afsaneh Asaei; Hervé Bourlard', display:{Lore:['[{"text": "arXiv:1709.01144", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lInformation Theoretic Analysis of DNN-HMM Acoustic Modeling\\u00a7r\\n\\n\\u00a78\\u00a7oPranay Dighe\\nAfsaneh Asaei\\nHerv\\u00e9 Bourlard\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1709.01144\\u00a7r\\n\\nVersion:\\u00a77v2 (Wed, 8 Nov 2017 15:52:53 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oTheoretical flaw,needs major revision\\u00a7r"}']}
{title:'Fahim et al. (§72017§r)', author: 'Abdullah Fahim; Prasanga N. Samarasinghe; Thushara D. Abhayapala', display:{Lore:['[{"text": "arXiv:1709.01346", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lPSD Estimation of Multiple Sound Sources in a Reverberant Room Using a Spherical Microphone Array\\u00a7r\\n\\n\\u00a78\\u00a7oAbdullah Fahim\\nPrasanga N. Samarasinghe\\nThushara D. Abhayapala\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1709.01346\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/WASPAA.2017.8169998\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 5 Sep 2017 12:22:01 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted for WASPAA 2017\\u00a7r"}']}
{title:'Quick et al. (§72017§r)', author: 'Donya Quick; Clayton T. Morrison', display:{Lore:['[{"text": "arXiv:1709.02076", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.IR\\u00a7r, \\u00a7acs.PL\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lComposition by Conversation\\u00a7r\\n\\n\\u00a78\\u00a7oDonya Quick\\nClayton T. Morrison\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1709.02076\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 7 Sep 2017 05:39:00 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o6 pages, 8 figures, accepted to ICMC 2017\\u00a7r"}']}
{title:'Cancino-Chacón et al. (§72017§r)', author: 'Carlos Cancino-Chacón; Maarten Grachten; David R. W. Sears; Gerhard Widmer', display:{Lore:['[{"text": "arXiv:1709.03629", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.IT\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a72math.IT\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lWhat were you expecting? Using Expectancy Features to Predict Expressive Performances of Classical Piano Music\\u00a7r\\n\\n\\u00a78\\u00a7oCarlos Cancino-Chac\\u00f3n\\nMaarten Grachten\\nDavid R. W. Sears\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1709.03629\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 11 Sep 2017 23:56:37 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o6 pages, 1 figure, 10th International Workshopon Machine Learning and Music (MML 2017)\\u00a7r"}']}
{title:'Mohammadiha et al. (§72017§r)', author: 'Nasser Mohammadiha; Paris Smaragdis; Arne Leijon', display:{Lore:['[{"text": "arXiv:1709.05362", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSupervised and Unsupervised Speech Enhancement Using Nonnegative Matrix Factorization\\u00a7r\\n\\n\\u00a78\\u00a7oNasser Mohammadiha\\nParis Smaragdis\\nArne Leijon\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1709.05362\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/TASL.2013.2270369\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nIEEE Trans. Audio, Speech and Language Process., vol. 21, no. 10,\\n  Oct. 2013\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 15 Sep 2017 18:34:52 GMT)\\u00a7r"}']}
{title:'Mohammadiha et al. (§72017§r)', author: 'Nasser Mohammadiha; Simon Doclo', display:{Lore:['[{"text": "arXiv:1709.05557", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSpeech Dereverberation Using Nonnegative Convolutive Transfer Function and Spectro temporal Modeling\\u00a7r\\n\\n\\u00a78\\u00a7oNasser Mohammadiha\\nSimon Doclo\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1709.05557\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/TASLP.2015.2501724\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nIEEE Trans. Audio, Speech and Language Process., vol. 24, no. 2,\\n  Feb. 2016\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 16 Sep 2017 19:43:44 GMT)\\u00a7r"}']}
{title:'Mohammadiha et al. (§72017§r)', author: 'Nasser Mohammadiha; Arne Leijon', display:{Lore:['[{"text": "arXiv:1709.05559", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lNonnegative HMM for Babble Noise Derived from Speech HMM: Application to Speech Enhancement\\u00a7r\\n\\n\\u00a78\\u00a7oNasser Mohammadiha\\nArne Leijon\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1709.05559\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/TASL.2013.2243435\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nIEEE Trans. Audio, Speech and Language Process., vol. 21, no. 5,\\n  pp. 998-1011, May 2013\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 16 Sep 2017 19:56:05 GMT)\\u00a7r"}']}
{title:'de Oliveira et al. (§72017§r)', author: 'H. M. de Oliveira; R. C. de Oliveira', display:{Lore:['[{"text": "arXiv:1709.06663", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lLinear Computer-Music through Sequences over Galois Fields\\u00a7r\\n\\n\\u00a78\\u00a7oH. M. de Oliveira\\nR. C. de Oliveira\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1709.06663\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 19 Sep 2017 22:36:16 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 2 figures, 5 tables\\u00a7r"}']}
{title:'Wisdom et al. (§72017§r)', author: 'Scott Wisdom; Thomas Powers; James Pitton; Les Atlas', display:{Lore:['[{"text": "arXiv:1709.07124", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDeep Recurrent NMF for Speech Separation by Unfolding Iterative Thresholding\\u00a7r\\n\\n\\u00a78\\u00a7oScott Wisdom\\nThomas Powers\\nJames Pitton\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1709.07124\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 21 Sep 2017 01:46:19 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oTo be presented at WASPAA 2017\\u00a7r"}']}
{title:'Deng et al. (§72017§r)', author: 'Junqi Deng; Yu-Kwong Kwok', display:{Lore:['[{"text": "arXiv:1709.07153", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lLarge Vocabulary Automatic Chord Estimation Using Deep Neural Nets: Design Framework, System Variations and Limitations\\u00a7r\\n\\n\\u00a78\\u00a7oJunqi Deng\\nYu-Kwong Kwok\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1709.07153\\u00a7r\\n\\nVersion:\\u00a77v2 (Fri, 22 Sep 2017 01:49:31 GMT)\\u00a7r"}']}
{title:'Jarne (§72017§r)', author: 'C. Jarne', display:{Lore:['[{"text": "arXiv:1709.07541", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA fundamental frequency estimation method for tonal sounds inspired on bird song studies\\u00a7r\\n\\n\\u00a78\\u00a7oC. Jarne\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1709.07541\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1016/j.mex.2018.12.011\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 21 Sep 2017 23:23:49 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7opre-print version of fundamentalfrequency estimation method for tonal sounds\\u00a7r"}']}
{title:'Ferris (§72017§r)', author: 'David Ferris', display:{Lore:['[{"text": "arXiv:1709.07552", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lTechniques and Challenges in Speech Synthesis\\u00a7r\\n\\n\\u00a78\\u00a7oDavid Ferris\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1709.07552\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 22 Sep 2017 00:45:12 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o138 pages, 46 figures, Undergraduate Honours Thesis towards a Bachelor of Electrical Engineering, November 2016, The University of Newcastle, Australia\\u00a7r"}']}
{title:'Venkataramani et al. (§72017§r)', author: 'Shrikant Venkataramani; Y. Cem Subakan; Paris Smaragdis', display:{Lore:['[{"text": "arXiv:1709.07908", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lNeural Network Alternatives to Convolutive Audio Models for Source Separation\\u00a7r\\n\\n\\u00a78\\u00a7oShrikant Venkataramani\\nY. Cem Subakan\\nParis Smaragdis\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1709.07908\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 20 Sep 2017 20:45:53 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oPublished in MLSP2017\\u00a7r"}']}
{title:'Saito et al. (§72017§r)', author: 'Yuki Saito; Shinnosuke Takamichi; Hiroshi Saruwatari', display:{Lore:['[{"text": "arXiv:1709.08041", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lStatistical Parametric Speech Synthesis Incorporating Generative Adversarial Networks\\u00a7r\\n\\n\\u00a78\\u00a7oYuki Saito\\nShinnosuke Takamichi\\nHiroshi Saruwatari\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1709.08041\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 23 Sep 2017 12:10:32 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oPreprint manuscript of IEEE/ACMTransactions on Audio, Speech and Language Processing\\u00a7r"}']}
{title:'Solewicz et al. (§72017§r)', author: 'Yosef Solewicz; Chagay Orenshtein; Avital Friedland', display:{Lore:['[{"text": "arXiv:1709.08344", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lPredicting interviewee attitude and body language from speech descriptors\\u00a7r\\n\\n\\u00a78\\u00a7oYosef Solewicz\\nChagay Orenshtein\\nAvital Friedland\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1709.08344\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 25 Sep 2017 06:52:42 GMT)\\u00a7r"}']}
{title:'Huang (§72017§r)', author: 'Chengwei Huang', display:{Lore:['[{"text": "arXiv:1709.09364", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.AI\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lResearch on several key technologies in practical speech emotion recognition\\u00a7r\\n\\n\\u00a78\\u00a7oChengwei Huang\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1709.09364\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 27 Sep 2017 07:21:26 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oin Chinese\\u00a7r"}']}
{title:'Ferretti (§72017§r)', author: 'Stefano Ferretti', display:{Lore:['[{"text": "arXiv:1709.09708", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.MM\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lOn the Complex Network Structure of Musical Pieces: Analysis of Some Use Cases from Different Music Genres\\u00a7r\\n\\n\\u00a78\\u00a7oStefano Ferretti\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1709.09708\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1007/s11042-017-5175-y\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 13 Sep 2017 15:04:30 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oaccepted to Multimedia Tools and Applications, Springer\\u00a7r"}']}
{title:'Rhodes (§72017§r)', author: 'Anthony D. Rhodes', display:{Lore:['[{"text": "arXiv:1710.00082", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lReal-Time Wind Noise Detection and Suppression with Neural-Based Signal Reconstruction for Mult-Channel, Low-Power Devices\\u00a7r\\n\\n\\u00a78\\u00a7oAnthony D. Rhodes\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1710.00082\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 29 Sep 2017 20:33:38 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 8 figures\\u00a7r"}']}
{title:'Xu et al. (§72017§r)', author: 'Yong Xu; Qiuqiang Kong; Wenwu Wang; Mark D. Plumbley', display:{Lore:['[{"text": "arXiv:1710.00343", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lLarge-scale weakly supervised audio classification using gated convolutional neural network\\u00a7r\\n\\n\\u00a78\\u00a7oYong Xu\\nQiuqiang Kong\\nWenwu Wang\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1710.00343\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 1 Oct 2017 12:57:45 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7osubmitted to ICASSP2018, summary on the 1st place systemin DCASE2017 task4 challenge\\u00a7r"}']}
{title:'Takamoto et al. (§72017§r)', author: 'Ayaka Takamoto; Mayu Umemura; Mitsuo Yoshida; Kyoji Umemura', display:{Lore:['[{"text": "arXiv:1710.01446", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.OH\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lImproving Compression Based Dissimilarity Measure for Music Score Analysis\\u00a7r\\n\\n\\u00a78\\u00a7oAyaka Takamoto\\nMayu Umemura\\nMitsuo Yoshida\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1710.01446\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 4 Oct 2017 03:11:31 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oThe 2016 International Conference On Advanced Informatics: Concepts, Theory And Application (ICAICTA2016)\\u00a7r"}']}
{title:'Mitsui et al. (§72017§r)', author: 'Yoshiki Mitsui; Daichi Kitamura; Norihiro Takamune; Hiroshi Saruwatari; Yu Takahashi; Kazunobu Kondo', display:{Lore:['[{"text": "arXiv:1710.01589", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lIndependent Low-Rank Matrix Analysis Based on Parametric Majorization-Equalization Algorithm\\u00a7r\\n\\n\\u00a78\\u00a7oYoshiki Mitsui\\nDaichi Kitamura\\nNorihiro Takamune\\n+ 2 others\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1710.01589\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 4 Oct 2017 13:12:44 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oPreprint Manuscript of 2017 IEEE International Workshop on Computational Advances in Multi-Sensor Adaptive Processing (CAMSAP 2017)\\u00a7r"}']}
{title:'Teng et al. (§72017§r)', author: 'Yifei Teng; An Zhao; Camille Goudeseune', display:{Lore:['[{"text": "arXiv:1710.02280", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.AI\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lGenerating Nontrivial Melodies for Music as a Service\\u00a7r\\n\\n\\u00a78\\u00a7oYifei Teng\\nAn Zhao\\nCamille Goudeseune\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1710.02280\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 6 Oct 2017 05:53:20 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oISMIR 2017 Conference\\u00a7r"}']}
{title:'Adavanne et al. (§72017§r)', author: 'Sharath Adavanne; Tuomas Virtanen', display:{Lore:['[{"text": "arXiv:1710.02997", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA report on sound event detection with different binaural features\\u00a7r\\n\\n\\u00a78\\u00a7oSharath Adavanne\\nTuomas Virtanen\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1710.02997\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 9 Oct 2017 09:12:01 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oTechnical reportfor the top performing method in Task 3: Real life sound event detection challenge, at Detection and classification of acoustic scene and events (DCASE) 2017\\u00a7r"}']}
{title:'Adavanne et al. (§72017§r)', author: 'Sharath Adavanne; Tuomas Virtanen', display:{Lore:['[{"text": "arXiv:1710.02998", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSound event detection using weakly labeled dataset with stacked convolutional and recurrent neural network\\u00a7r\\n\\n\\u00a78\\u00a7oSharath Adavanne\\nTuomas Virtanen\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1710.02998\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 9 Oct 2017 09:14:24 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted in Detection and Classification of Acoustic Scenes and Events (DCASE 2017)\\u00a7r"}']}
{title:'Scheibler et al. (§72017§r)', author: 'Robin Scheibler; Eric Bezzam; Ivan Dokmanić', display:{Lore:['[{"text": "arXiv:1710.04196", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lPyroomacoustics: A Python package for audio room simulations and array processing algorithms\\u00a7r\\n\\n\\u00a78\\u00a7oRobin Scheibler\\nEric Bezzam\\nIvan Dokmani\\u0107\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1710.04196\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/ICASSP.2018.8461310\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 11 Oct 2017 17:44:41 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 5 figures, describes a software package\\u00a7r"}']}
{title:'Yadav et al. (§72017§r)', author: 'Mohit Yadav; Vivek Tyagi', display:{Lore:['[{"text": "arXiv:1710.07868", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDeep Triphone Embedding Improves Phoneme Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oMohit Yadav\\nVivek Tyagi\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1710.07868\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 24 Oct 2017 14:59:30 GMT)\\u00a7r"}']}
{title:'McMahan et al. (§72017§r)', author: 'Brian McMahan; Delip Rao', display:{Lore:['[{"text": "arXiv:1710.08377", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.AI\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lListening to the World Improves Speech Command Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oBrian McMahan\\nDelip Rao\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1710.08377\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 23 Oct 2017 16:47:05 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o8 pages\\u00a7r"}']}
{title:'Shah et al. (§72017§r)', author: 'Muhammad A. Shah; Bhiksha Raj; Khaled A. Harras', display:{Lore:['[{"text": "arXiv:1710.08684", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lInferring Room Semantics Using Acoustic Monitoring\\u00a7r\\n\\n\\u00a78\\u00a7oMuhammad A. Shah\\nBhiksha Raj\\nKhaled A. Harras\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1710.08684\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/MLSP.2017.8168153\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nIEEE International Workshop on Machine Learning for Signal\\n  Processing (MLSP) 27 (2017) 1-6\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 24 Oct 2017 09:59:21 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o2017 IEEE International Workshop on Machine Learning for Signal Processing, Sept. 25\\u201328, 2017, Tokyo, Japan\\u00a7r"}']}
{title:'Wang et al. (§72017§r)', author: 'Ziteng Wang; Emmanuel Vincent; Yonghong Yan', display:{Lore:['[{"text": "arXiv:1710.09091", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lRelative Transfer Function Inverse Regression from Low Dimensional Manifold\\u00a7r\\n\\n\\u00a78\\u00a7oZiteng Wang\\nEmmanuel Vincent\\nYonghong Yan\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1710.09091\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 25 Oct 2017 07:02:02 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, in preparation for Signal Processing Letters\\u00a7r"}']}
{title:'Nikunen et al. (§72017§r)', author: 'Joonas Nikunen; Aleksandr Diment; Tuomas Virtanen', display:{Lore:['[{"text": "arXiv:1710.10005", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSeparation of Moving Sound Sources Using Multichannel NMF and Acoustic Tracking\\u00a7r\\n\\n\\u00a78\\u00a7oJoonas Nikunen\\nAleksandr Diment\\nTuomas Virtanen\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1710.10005\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 27 Oct 2017 06:49:04 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oPreprint of manuscript submitted toIEEE/ACM Transactionson Audio Speech and Language processing (R1)\\u00a7r"}']}
{title:'Subakan et al. (§72017§r)', author: 'Cem Subakan; Paris Smaragdis', display:{Lore:['[{"text": "arXiv:1710.10779", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.NE\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lGenerative Adversarial Source Separation\\u00a7r\\n\\n\\u00a78\\u00a7oCem Subakan\\nParis Smaragdis\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1710.10779\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 30 Oct 2017 05:42:25 GMT)\\u00a7r"}']}
{title:'Ferguson et al. (§72017§r)', author: 'Eric L. Ferguson; Stefan B. Williams; Craig T. Jin', display:{Lore:['[{"text": "arXiv:1710.10948", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CV\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSound Source Localization in a Multipath Environment Using Convolutional Neural Networks\\u00a7r\\n\\n\\u00a78\\u00a7oEric L. Ferguson\\nStefan B. Williams\\nCraig T. Jin\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1710.10948\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 27 Oct 2017 01:14:51 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 5 figures, Final draft of paper submitted to 2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) 15-20 April 2018 in Calgary, Alberta, Canada. arXiv admin note: text overlap"}','{"text": "with arXiv:1612.03505\\u00a7r"}']}
{title:'Fan et al. (§72017§r)', author: 'Zhe-Cheng Fan; Yen-Lin Lai; Jyh-Shing Roger Jang', display:{Lore:['[{"text": "arXiv:1710.11428", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSVSGAN: Singing Voice Separation via Generative Adversarial Network\\u00a7r\\n\\n\\u00a78\\u00a7oZhe-Cheng Fan\\nYen-Lin Lai\\nJyh-Shing Roger Jang\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1710.11428\\u00a7r\\n\\nVersion:\\u00a77v2 (Mon, 13 Nov 2017 13:29:58 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 4 figures, 1 table. Demo website: http://mirlab.org/demo/svsgan\\u00a7r"}']}
{title:'Grais et al. (§72017§r)', author: 'Emad M. Grais; Hagen Wierstorf; Dominic Ward; Mark D. Plumbley', display:{Lore:['[{"text": "arXiv:1710.11473", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CV\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMulti-Resolution Fully Convolutional Neural Networks for Monaural Audio Source Separation\\u00a7r\\n\\n\\u00a78\\u00a7oEmad M. Grais\\nHagen Wierstorf\\nDominic Ward\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1710.11473\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 28 Oct 2017 22:12:08 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oarXiv admin note: text overlapwith arXiv:1703.08019\\u00a7r"}']}
{title:'Shin et al. (§72017§r)', author: 'Andrew Shin; Leopold Crestel; Hiroharu Kato; Kuniaki Saito; Katsunori Ohnishi; Masataka Yamaguchi; Masahiro Nakawaki; Yoshitaka Ushiku; Tatsuya Harada', display:{Lore:['[{"text": "arXiv:1710.11549", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.MM\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMelody Generation for Pop Music via Word Representation of Musical Properties\\u00a7r\\n\\n\\u00a78\\u00a7oAndrew Shin\\nLeopold Crestel\\nHiroharu Kato\\n+ 5 others\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1710.11549\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 31 Oct 2017 16:04:23 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7osubmitted to ICLR2018\\u00a7r"}']}
{title:'Pires et al. (§72017§r)', author: 'Ivan Miguel Pires; Nuno M. Garcia; Nuno Pombo; Francisco Flórez-Revuelta', display:{Lore:['[{"text": "arXiv:1711.00124", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r, \\u00a75physics.data-an\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lUser Environment Detection with Acoustic Sensors Embedded on Mobile Devices for the Recognition of Activities of Daily Living\\u00a7r\\n\\n\\u00a78\\u00a7oIvan Miguel Pires\\nNuno M. Garcia\\nNuno Pombo\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1711.00124\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 31 Oct 2017 22:00:25 GMT)\\u00a7r"}']}
{title:'Dubey et al. (§72017§r)', author: 'Mohit Dubey; Garrett Kenyon; Nils Carlson; Austin Thresher', display:{Lore:['[{"text": "arXiv:1711.00913", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.NE\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDoes Phase Matter For Monaural Source Separation?\\u00a7r\\n\\n\\u00a78\\u00a7oMohit Dubey\\nGarrett Kenyon\\nNils Carlson\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1711.00913\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 2 Nov 2017 20:10:00 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o4 pages, 2 figures, NIPS format\\u00a7r"}']}
{title:'Huang et al. (§72017§r)', author: 'Hao Huang; Ying Hu; Haihua Xu', display:{Lore:['[{"text": "arXiv:1711.01946", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMandarin tone modeling using recurrent neural networks\\u00a7r\\n\\n\\u00a78\\u00a7oHao Huang\\nYing Hu\\nHaihua Xu\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1711.01946\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 6 Nov 2017 15:17:47 GMT)\\u00a7r"}']}
{title:'Jansen et al. (§72017§r)', author: 'Aren Jansen; Manoj Plakal; Ratheet Pandya; Daniel P. W. Ellis; Shawn Hershey; Jiayang Liu; R. Channing Moore; Rif A. Saurous', display:{Lore:['[{"text": "arXiv:1711.02209", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lUnsupervised Learning of Semantic Audio Representations\\u00a7r\\n\\n\\u00a78\\u00a7oAren Jansen\\nManoj Plakal\\nRatheet Pandya\\n+ 4 others\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1711.02209\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 6 Nov 2017 22:54:01 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to ICASSP 2018\\u00a7r"}']}
{title:'Viraraghavan et al. (§72017§r)', author: 'Venkata Subramanian Viraraghavan; Arpan Pal; R Aravind; Hema Murthy', display:{Lore:['[{"text": "arXiv:1711.02318", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lNon-uniform time-scaling of Carnatic music transients\\u00a7r\\n\\n\\u00a78\\u00a7oVenkata Subramanian Viraraghavan\\nArpan Pal\\nR Aravind\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1711.02318\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 7 Nov 2017 07:11:34 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oThe non-uniform time-scaling of CP-notes and transients in Carnatic concert renditions is new; it has not been reported earlier in the literature, but a reviewer pointed out that the proposed algorithm is previously "}','{"text": "known\\u00a7r"}']}
{title:'Cancino-Chacón et al. (§72017§r)', author: 'Carlos Cancino-Chacón; Martin Bonev; Amaury Durand; Maarten Grachten; Andreas Arzt; Laura Bishop; Werner Goebl; Gerhard Widmer', display:{Lore:['[{"text": "arXiv:1711.02427", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.HC\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lThe ACCompanion v0.1: An Expressive Accompaniment System\\u00a7r\\n\\n\\u00a78\\u00a7oCarlos Cancino-Chac\\u00f3n\\nMartin Bonev\\nAmaury Durand\\n+ 4 others\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1711.02427\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 7 Nov 2017 12:13:30 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oPresented at theLate-Breaking Demo Session of the 18th International Society for Music Information Retrieval Conference (ISMIR 2017), Suzhou, China, 2017\\u00a7r"}']}
{title:'Kwon et al. (§72017§r)', author: 'Taegyun Kwon; Dasaem Jeong; Juhan Nam', display:{Lore:['[{"text": "arXiv:1711.04480", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAudio-to-score alignment of piano music using RNN-based automatic music transcription\\u00a7r\\n\\n\\u00a78\\u00a7oTaegyun Kwon\\nDasaem Jeong\\nJuhan Nam\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1711.04480\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 13 Nov 2017 09:15:19 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o6 pages, 5 figures, The paper was published in SMC 2017 proceedings, Proceedings of 14th Sound and Music Computing Conference (SMC). 2017\\u00a7r"}']}
{title:'Bannerman et al. (§72017§r)', author: 'Aricca Bannerman; James Emington; Anil Venkatesh', display:{Lore:['[{"text": "arXiv:1711.05260", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lOptimal Tuning of Two-Dimensional Keyboards\\u00a7r\\n\\n\\u00a78\\u00a7oAricca Bannerman\\nJames Emington\\nAnil Venkatesh\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1711.05260\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 14 Nov 2017 16:47:23 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o14 page, 3 figures\\u00a7r"}']}
{title:'Lee et al. (§72017§r)', author: 'Younggun Lee; Azam Rabiee; Soo-Young Lee', display:{Lore:['[{"text": "arXiv:1711.05447", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lEmotional End-to-End Neural Speech Synthesizer\\u00a7r\\n\\n\\u00a78\\u00a7oYounggun Lee\\nAzam Rabiee\\nSoo-Young Lee\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1711.05447\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 28 Nov 2017 02:07:43 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 3 figures\\u00a7r"}']}
{title:'Santos et al. (§72017§r)', author: 'Joao Felipe Santos; Tiago H. Falk', display:{Lore:['[{"text": "arXiv:1711.06309", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSpeech Dereverberation with Context-aware Recurrent Neural Networks\\u00a7r\\n\\n\\u00a78\\u00a7oJoao Felipe Santos\\nTiago H. Falk\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1711.06309\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 16 Nov 2017 20:18:44 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to IEEE/ACM Transactionson Audio, Speech, and Language Processing\\u00a7r"}']}
{title:'Shi et al. (§72017§r)', author: 'Ziqiang Shi; Mengjiao Wang; Liu Liu; Huibin Lin; Rujie Liu', display:{Lore:['[{"text": "arXiv:1711.06434", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.MM\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Double Joint Bayesian Approach for J-Vector Based Text-dependent Speaker Verification\\u00a7r\\n\\n\\u00a78\\u00a7oZiqiang Shi\\nMengjiao Wang\\nLiu Liu\\nHuibin Lin\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1711.06434\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 17 Nov 2017 07:19:03 GMT)\\u00a7r"}']}
{title:'Scheibler et al. (§72017§r)', author: 'Robin Scheibler; Diego Di Carlo; Antoine Deleforge; Ivan Dokmanić', display:{Lore:['[{"text": "arXiv:1711.06805", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSeparake: Source Separation with a Little Help From Echoes\\u00a7r\\n\\n\\u00a78\\u00a7oRobin Scheibler\\nDiego Di Carlo\\nAntoine Deleforge\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1711.06805\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/ICASSP.2018.8461345\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 18 Nov 2017 03:35:45 GMT)\\u00a7r"}']}
{title:'Brunner et al. (§72017§r)', author: 'Gino Brunner; Yuyi Wang; Roger Wattenhofer; Jonas Wiesendanger', display:{Lore:['[{"text": "arXiv:1711.07682", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.AI\\u00a7r, \\u00a7acs.IT\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r, \\u00a72math.IT\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lJamBot: Music Theory Aware Chord Based Generation of Polyphonic Music with LSTMs\\u00a7r\\n\\n\\u00a78\\u00a7oGino Brunner\\nYuyi Wang\\nRoger Wattenhofer\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1711.07682\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 21 Nov 2017 09:19:16 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oPaper presented at the 29th International Conference on Tools with Artificial Intelligence, ICTAI 2017, Boston, MA, USA\\u00a7r"}']}
{title:'An et al. (§72017§r)', author: 'Inkyu An; Myungbae Son; Dinesh Manocha; Sung-eui Yoon', display:{Lore:['[{"text": "arXiv:1711.07791", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.RO\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lReflection-Aware Sound Source Localization\\u00a7r\\n\\n\\u00a78\\u00a7oInkyu An\\nMyungbae Son\\nDinesh Manocha\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1711.07791\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 21 Nov 2017 14:05:03 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to ICRA2018. The working videois available at (https://youtu.be/TkQ36lMEC-M)\\u00a7r"}']}
{title:'Tarzan et al. (§72017§r)', author: 'Ali Tarzan; Marco Alunno; Paolo Bientinesi', display:{Lore:['[{"text": "arXiv:1711.09234", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAssessment of sound spatialisation algorithms for sonic rendering with headsets\\u00a7r\\n\\n\\u00a78\\u00a7oAli Tarzan\\nMarco Alunno\\nPaolo Bientinesi\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1711.09234\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 25 Nov 2017 12:33:13 GMT)\\u00a7r"}']}
{title:'Paraschiv et al. (§72017§r)', author: 'Marius Paraschiv; Lasse Borgholt; Tycho Max Sylvester Tax; Marco Singh; Lars Maaløe', display:{Lore:['[{"text": "arXiv:1711.10271", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lExploiting Nontrivial Connectivity for Automatic Speech Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oMarius Paraschiv\\nLasse Borgholt\\nTycho Max Sylvester Tax\\nMarco Singh\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1711.10271\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 28 Nov 2017 13:13:41 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted at the ML4Audio workshop at the NIPS 2017\\u00a7r"}']}
{title:'Arcas et al. (§72017§r)', author: 'Blaise Agüera y Arcas; Beat Gfeller; Ruiqi Guo; Kevin Kilgour; Sanjiv Kumar; James Lyon; Julian Odell; Marvin Ritter; Dominik Roblek; Matthew Sharifi; Mihajlo Velimirović', display:{Lore:['[{"text": "arXiv:1711.10958", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.AI\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lNow Playing: Continuous low-power music recognition\\u00a7r\\n\\n\\u00a78\\u00a7oBlaise Ag\\u00fcera y Arcas\\nBeat Gfeller\\nRuiqi Guo\\n+ 7 others\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1711.10958\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 29 Nov 2017 16:42:52 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAuthors are listed in alphabetical order by last name\\u00a7r"}']}
{title:'Wang et al. (§72017§r)', author: 'Xiaofei Wang; Yonghong Yan; Hynek Hermansky', display:{Lore:['[{"text": "arXiv:1711.11141", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.HC\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lStream Attention for far-field multi-microphone ASR\\u00a7r\\n\\n\\u00a78\\u00a7oXiaofei Wang\\nYonghong Yan\\nHynek Hermansky\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1711.11141\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 29 Nov 2017 22:45:05 GMT)\\u00a7r"}']}
{title:'Mital (§72017§r)', author: 'Parag K. Mital', display:{Lore:['[{"text": "arXiv:1711.11160", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lTime Domain Neural Audio Style Transfer\\u00a7r\\n\\n\\u00a78\\u00a7oParag K. Mital\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1711.11160\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 29 Nov 2017 23:53:52 GMT)\\u00a7r"}']}
{title:'Gaultier et al. (§72017§r)', author: 'Clément Gaultier; Nancy Bertin; Srđan Kitić; Rémi Gribonval', display:{Lore:['[{"text": "arXiv:1711.11259", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA modeling and algorithmic framework for (non)social (co)sparse audio restoration\\u00a7r\\n\\n\\u00a78\\u00a7oCl\\u00e9ment Gaultier\\nNancy Bertin\\nSr\\u0111an Kiti\\u0107\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1711.11259\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 30 Nov 2017 07:38:18 GMT)\\u00a7r"}']}
{title:'Zhao et al. (§72017§r)', author: 'Wenbo Zhao; Yang Gao; Rita Singh', display:{Lore:['[{"text": "arXiv:1712.00171", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSpeaker identification from the sound of the human breath\\u00a7r\\n\\n\\u00a78\\u00a7oWenbo Zhao\\nYang Gao\\nRita Singh\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1712.00171\\u00a7r\\n\\nVersion:\\u00a77v2 (Mon, 4 Dec 2017 17:30:42 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 3 figures\\u00a7r"}']}
{title:'Tax et al. (§72017§r)', author: 'Tycho Max Sylvester Tax; Jose Luis Diez Antich; Hendrik Purwins; Lars Maaløe', display:{Lore:['[{"text": "arXiv:1712.00254", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lUtilizing Domain Knowledge in End-to-End Audio Processing\\u00a7r\\n\\n\\u00a78\\u00a7oTycho Max Sylvester Tax\\nJose Luis Diez Antich\\nHendrik Purwins\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1712.00254\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 1 Dec 2017 09:49:21 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted at the ML4Audio workshop at the NIPS 2017\\u00a7r"}']}
{title:'Lee et al. (§72017§r)', author: 'Jongpil Lee; Taejun Kim; Jiyoung Park; Juhan Nam', display:{Lore:['[{"text": "arXiv:1712.00866", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.MM\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lRaw Waveform-based Audio Classification Using Sample-level CNN Architectures\\u00a7r\\n\\n\\u00a78\\u00a7oJongpil Lee\\nTaejun Kim\\nJiyoung Park\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1712.00866\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 4 Dec 2017 00:58:58 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oNIPS, Machine Learning for Audio Signal ProcessingWorkshop (ML4Audio), 2017\\u00a7r"}']}
{title:'Charan et al. (§72017§r)', author: 'Rishi Charan; Manisha. A; Karthik. R; Rajesh Kumar M', display:{Lore:['[{"text": "arXiv:1712.00917", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA text-independent speaker verification model: A comparative analysis\\u00a7r\\n\\n\\u00a78\\u00a7oRishi Charan\\nManisha. A\\nKarthik. R\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1712.00917\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 4 Dec 2017 06:09:02 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7opresented and accepted by 2017 International Conference on Intelligent Computing and Control (I2C2)\\u00a7r"}']}
{title:'Lim et al. (§72017§r)', author: 'Hyungui Lim; Seungyeon Rhyu; Kyogu Lee', display:{Lore:['[{"text": "arXiv:1712.01011", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lChord Generation from Symbolic Melody Using BLSTM Networks\\u00a7r\\n\\n\\u00a78\\u00a7oHyungui Lim\\nSeungyeon Rhyu\\nKyogu Lee\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1712.01011\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 4 Dec 2017 11:18:08 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o18th International Society for Music Information Retrieval Conference (ISMIR 2017)\\u00a7r"}']}
{title:'Shuvaev et al. (§72017§r)', author: 'Sergey Shuvaev; Hamza Giaffar; Alexei A. Koulakov', display:{Lore:['[{"text": "arXiv:1712.02898", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CV\\u00a7r, \\u00a7eeess.AS\\u00a7r, \\u00a7bq-bio.NC\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lRepresentations of Sound in Deep Learning of Audio Features from Music\\u00a7r\\n\\n\\u00a78\\u00a7oSergey Shuvaev\\nHamza Giaffar\\nAlexei A. Koulakov\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1712.02898\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 8 Dec 2017 00:37:23 GMT)\\u00a7r"}']}
{title:'Sarnatskyi et al. (§72017§r)', author: 'Vladyslav Sarnatskyi; Vadym Ovcharenko; Mariia Tkachenko; Sergii Stirenko; Yuri Gordienko; Anis Rojbi', display:{Lore:['[{"text": "arXiv:1712.03228", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMusic Transcription by Deep Learning with Data and \\"Artificial Semantic\\" Augmentation\\u00a7r\\n\\n\\u00a78\\u00a7oVladyslav Sarnatskyi\\nVadym Ovcharenko\\nMariia Tkachenko\\n+ 2 others\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1712.03228\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nInternational Journal of Systems Applications Engineering and\\n  Development, 11, 212-215 (2017)\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 8 Dec 2017 11:18:22 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o4 pages, 3 figures\\u00a7r"}']}
{title:'Burskii (§72017§r)', author: 'Vladimir P. Burskii', display:{Lore:['[{"text": "arXiv:1712.03569", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lThe organization of a three-manual keyboard for 53-tone tempered and other tempered systems\\u00a7r\\n\\n\\u00a78\\u00a7oVladimir P. Burskii\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1712.03569\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 10 Dec 2017 18:24:23 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o16 pages, in Russian, 10 tables\\u00a7r"}']}
{title:'Reza et al. (§72017§r)', author: 'Mohi Reza; Warida Rashid; Moin Mostakim', display:{Lore:['[{"text": "arXiv:1712.03579", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.HC\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lProdorshok I: A Bengali Isolated Speech Dataset for Voice-Based Assistive Technologies - A comparative analysis of the effects of data augmentation on HMM-GMM and DNN classifiers\\u00a7r\\n\\n\\u00a78\\u00a7oMohi Reza\\nWarida Rashid\\nMoin Mostakim\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1712.03579\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 10 Dec 2017 19:52:51 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o4 pages, accepted for oral presentation at the 5th IEEE R10 HTC 2017\\u00a7r"}']}
{title:'Gruenstein et al. (§72017§r)', author: 'Alexander Gruenstein; Raziel Alvarez; Chris Thornton; Mohammadali Ghodrat', display:{Lore:['[{"text": "arXiv:1712.03603", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Cascade Architecture for Keyword Spotting on Mobile Devices\\u00a7r\\n\\n\\u00a78\\u00a7oAlexander Gruenstein\\nRaziel Alvarez\\nChris Thornton\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1712.03603\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 10 Dec 2017 22:47:29 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o31st Conference on Neural Information ProcessingSystems (NIPS 2017), Long Beach, CA, USA\\u00a7r"}']}
{title:'Chakrabarty et al. (§72017§r)', author: 'Soumitro Chakrabarty; Emanuël A. P. Habets', display:{Lore:['[{"text": "arXiv:1712.04276", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMulti-Speaker Localization Using Convolutional Neural Network Trained with Noise\\u00a7r\\n\\n\\u00a78\\u00a7oSoumitro Chakrabarty\\nEmanu\\u00ebl A. P. Habets\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1712.04276\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 12 Dec 2017 13:17:30 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oPresented at Machine Learning for Audio Processing (ML4Audio) Workshop atNIPS 2017\\u00a7r"}']}
{title:'Freitag et al. (§72017§r)', author: 'Michael Freitag; Shahin Amiriparian; Sergey Pugachevskiy; Nicholas Cummins; Björn Schuller', display:{Lore:['[{"text": "arXiv:1712.04382", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lauDeep: Unsupervised Learning of Representations from Audio with Deep Recurrent Neural Networks\\u00a7r\\n\\n\\u00a78\\u00a7oMichael Freitag\\nShahin Amiriparian\\nSergey Pugachevskiy\\nNicholas Cummins\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1712.04382\\u00a7r\\n\\nVersion:\\u00a77v2 (Fri, 22 Dec 2017 17:33:47 GMT)\\u00a7r"}']}
{title:'Jeong et al. (§72017§r)', author: 'Yeonwoo Jeong; Keunwoo Choi; Hosan Jeong', display:{Lore:['[{"text": "arXiv:1712.05119", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDLR : Toward a deep learned rhythmic representation for music content analysis\\u00a7r\\n\\n\\u00a78\\u00a7oYeonwoo Jeong\\nKeunwoo Choi\\nHosan Jeong\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1712.05119\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 14 Dec 2017 08:13:02 GMT)\\u00a7r"}']}
{title:'Pascual et al. (§72017§r)', author: 'Santiago Pascual; Maruchan Park; Joan Serrà; Antonio Bonafonte; Kang-Hun Ahn', display:{Lore:['[{"text": "arXiv:1712.06340", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lLanguage and Noise Transfer in Speech Enhancement Generative Adversarial Network\\u00a7r\\n\\n\\u00a78\\u00a7oSantiago Pascual\\nMaruchan Park\\nJoan Serr\\u00e0\\nAntonio Bonafonte\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1712.06340\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 18 Dec 2017 11:16:08 GMT)\\u00a7r"}']}
{title:'Chakraborty et al. (§72017§r)', author: 'Rupayan Chakraborty; Climent Nadeu', display:{Lore:['[{"text": "arXiv:1712.07065", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lJoint model-based recognition and localization of overlapped acoustic events using a set of distributed small microphone arrays\\u00a7r\\n\\n\\u00a78\\u00a7oRupayan Chakraborty\\nCliment Nadeu\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1712.07065\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 19 Dec 2017 17:30:19 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oComputational acoustic scene analysis, microphone array signal processing, acoustic event detection\\u00a7r"}']}
{title:'Dean et al. (§72017§r)', author: 'Roger T. Dean; Jamie Forth', display:{Lore:['[{"text": "arXiv:1712.07799", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lTowards a Deep Improviser: a prototype deep learning post-tonal free music generator\\u00a7r\\n\\n\\u00a78\\u00a7oRoger T. Dean\\nJamie Forth\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1712.07799\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 21 Dec 2017 05:28:15 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o13 pages, 1 Figure, 3 Tables\\u00a7r"}']}
{title:'Sun et al. (§72017§r)', author: 'Yingxiang Sun; Jiajia Chen; Chau Yuen; Susanto Rahardja', display:{Lore:['[{"text": "arXiv:1712.07814", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lIndoor Sound Source Localization with Probabilistic Neural Network\\u00a7r\\n\\n\\u00a78\\u00a7oYingxiang Sun\\nJiajia Chen\\nChau Yuen\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1712.07814\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/TIE.2017.2786219\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nIEEE Transactions on Industrial Electronics, vol. 65, no. 8, pp.\\n  6403-6413, Aug. 2018\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 21 Dec 2017 07:26:53 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o10 pages, accepted by IEEE Transactions on Industrial Electronics\\u00a7r"}']}
{title:'Zhang et al. (§72017§r)', author: 'Jie Zhang; Richard Heusdens; Richard C. Hendriks', display:{Lore:['[{"text": "arXiv:1712.07941", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lRate-Distributed Spatial Filtering Based Noise Reduction in Wireless Acoustic Sensor Networks\\u00a7r\\n\\n\\u00a78\\u00a7oJie Zhang\\nRichard Heusdens\\nRichard C. Hendriks\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1712.07941\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 21 Dec 2017 13:54:45 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7osubmitted to IEEETransactions on Audio, Speech and Language Processing\\u00a7r"}']}
{title:'Feng et al. (§72017§r)', author: 'Lin Feng; Shenlan Liu; Jianing Yao', display:{Lore:['[{"text": "arXiv:1712.08370", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.IR\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMusic Genre Classification with Paralleling Recurrent Convolutional Neural Network\\u00a7r\\n\\n\\u00a78\\u00a7oLin Feng\\nShenlan Liu\\nJianing Yao\\u00a7r\\n\\n\\u00a772017\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1712.08370\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 22 Dec 2017 09:49:26 GMT)\\u00a7r"}']}
