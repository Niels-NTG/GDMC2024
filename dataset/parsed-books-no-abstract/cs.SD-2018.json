{title:'Stolzenburg (§72018§r)', author: 'Frieder Stolzenburg', display:{Lore:['[{"text": "arXiv:1306.6458", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lHarmony Perception by Periodicity Detection\\u00a7r\\n\\n\\u00a78\\u00a7oFrieder Stolzenburg\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1306.6458\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1080/17459737.2015.1033024\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nJournal of Mathematics and Music, 9(3):215-238, 2015\\u00a7r\\n\\nVersion:\\u00a77v6 (Tue, 20 Nov 2018 07:40:42 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oextended, revised, and correctedversion, 33 pages, 8 figures, 9 tables\\u00a7r"}']}
{title:'Salvati et al. (§72018§r)', author: 'Daniele Salvati; Carlo Drioli; Gian Luca Foresti', display:{Lore:['[{"text": "arXiv:1512.03261", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lExploiting a Geometrically Sampled Grid in the SRP-PHAT for Localization Improvement and Power Response Sensitivity Analysis\\u00a7r\\n\\n\\u00a78\\u00a7oDaniele Salvati\\nCarlo Drioli\\nGian Luca Foresti\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1512.03261\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1121/1.4974289\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nJournal of the Acoustical Society of America, Volume 141, Issue 1,\\n  Pages 586-601 (2017)\\u00a7r\\n\\nVersion:\\u00a77v4 (Wed, 7 Mar 2018 07:47:58 GMT)\\u00a7r"}']}
{title:'Sager et al. (§72018§r)', author: 'Sebastian Sager; Benjamin Elizalde; Damian Borth; Christian Schulze; Bhiksha Raj; Ian Lane', display:{Lore:['[{"text": "arXiv:1607.03766", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAudioPairBank: Towards A Large-Scale Tag-Pair-Based Audio Content Analysis\\u00a7r\\n\\n\\u00a78\\u00a7oSebastian Sager\\nBenjamin Elizalde\\nDamian Borth\\n+ 2 others\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1607.03766\\u00a7r\\n\\nVersion:\\u00a77v3 (Mon, 8 Jan 2018 21:36:04 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oThis paper is a revised version of \\"AudioSentibank: Large-scale Semantic Ontology of Acoustic Concepts for Audio Content Analysis\\"\\u00a7r"}']}
{title:'Perraudin et al. (§72018§r)', author: 'Nathanael Perraudin; Nicki Holighaus; Piotr Majdak; Peter Balazs', display:{Lore:['[{"text": "arXiv:1607.06667", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.AI\\u00a7r, \\u00a7acs.MM\\u00a7r, \\u00a7acs.SE\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lInpainting of long audio segments with similarity graphs\\u00a7r\\n\\n\\u00a78\\u00a7oNathanael Perraudin\\nNicki Holighaus\\nPiotr Majdak\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1607.06667\\u00a7r\\n\\nVersion:\\u00a77v4 (Fri, 23 Feb 2018 10:15:47 GMT)\\u00a7r"}']}
{title:'Magron et al. (§72018§r)', author: 'Paul Magron; Roland Badeau; Bertrand David', display:{Lore:['[{"text": "arXiv:1608.01953", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lModel-based STFT phase recovery for audio source separation\\u00a7r\\n\\n\\u00a78\\u00a7oPaul Magron\\nRoland Badeau\\nBertrand David\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1608.01953\\u00a7r\\n\\nVersion:\\u00a77v4 (Tue, 27 Feb 2018 09:09:03 GMT)\\u00a7r"}']}
{title:'Bhaduri et al. (§72018§r)', author: 'Susmita Bhaduri; Anirban Bhaduri; Dipak Ghosh', display:{Lore:['[{"text": "arXiv:1611.05182", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDetecting tala Computationally in Polyphonic Context - A Novel Approach\\u00a7r\\n\\n\\u00a78\\u00a7oSusmita Bhaduri\\nAnirban Bhaduri\\nDipak Ghosh\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1611.05182\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.21767/2349-3917.100030\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nAmerican Journal of Computer Science and Information\\n  Technology(2018)\\u00a7r\\n\\nVersion:\\u00a77v2 (Mon, 24 Sep 2018 08:37:49 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oIt is a 20 page document with 8figures, essentially portrays a pattern recognition novel approach to detect talafrom a polyphonic song having table content and of North-Indian-Music-System(NIMS) genre\\u00a7r"}']}
{title:'Lattner et al. (§72018§r)', author: 'Stefan Lattner; Maarten Grachten; Gerhard Widmer', display:{Lore:['[{"text": "arXiv:1612.04742", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.AI\\u00a7r, \\u00a7acs.NE\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lImposing higher-level Structure in Polyphonic Music Generation using Convolutional Restricted Boltzmann Machines and Constraints\\u00a7r\\n\\n\\u00a78\\u00a7oStefan Lattner\\nMaarten Grachten\\nGerhard Widmer\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1612.04742\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.5920/jcms.2018.01\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nJournal of Creative Music Systems, Volume 2, Issue 1, March 2018\\u00a7r\\n\\nVersion:\\u00a77v4 (Sat, 14 Apr 2018 12:43:15 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o31 pages, 11 figures\\u00a7r"}']}
{title:'Phan et al. (§72018§r)', author: 'Huy Phan; Philipp Koch; Fabrice Katzberg; Marco Maass; Radoslaw Mazur; Ian McLoughlin; Alfred Mertins', display:{Lore:['[{"text": "arXiv:1612.09089", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lWhat Makes Audio Event Detection Harder than Classification?\\u00a7r\\n\\n\\u00a78\\u00a7oHuy Phan\\nPhilipp Koch\\nFabrice Katzberg\\n+ 3 others\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1612.09089\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.23919/EUSIPCO.2017.8081709\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nPublished in Proceedings of the 25th European Signal Processing\\n  Conference (EUSIPCO), pp. 2739-2743, 2017\\u00a7r\\n\\nVersion:\\u00a77v4 (Thu, 17 May 2018 13:51:52 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oPublished version available at https://ieeexplore.ieee.org/document/8081709/\\u00a7r"}']}
{title:'Swarna et al. (§72018§r)', author: 'Sadia Tasnim Swarna; Shamim Ehsan; Md. Saiful Islam; Marium E Jannat', display:{Lore:['[{"text": "arXiv:1701.08156", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Comprehensive Survey on Bengali Phoneme Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oSadia Tasnim Swarna\\nShamim Ehsan\\nMd. Saiful Islam\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1701.08156\\u00a7r\\n\\nVersion:\\u00a77v2 (Thu, 26 Apr 2018 18:17:00 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o7 pages, reference added in phoneme recognition methods\\u00a7r"}']}
{title:'Rehr et al. (§72018§r)', author: 'Robert Rehr; Timo Gerkmann', display:{Lore:['[{"text": "arXiv:1703.05003", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lOn the Importance of Super-Gaussian Speech Priors for Machine-Learning Based Speech Enhancement\\u00a7r\\n\\n\\u00a78\\u00a7oRobert Rehr\\nTimo Gerkmann\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1703.05003\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/TASLP.2017.2778151\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nIEEE/ACM Transactions on Audio, Speech, and Language Processing,\\n  vol. 26, no. 2, pp. 357-366, Feb. 2018\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 16 Jan 2018 11:16:40 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o10 pages, 9 figures\\u00a7r"}']}
{title:'Jarne (§72018§r)', author: 'Cecilia Jarne', display:{Lore:['[{"text": "arXiv:1703.06812", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA heuristic approach to obtain signal envelope with a simple software implementation\\u00a7r\\n\\n\\u00a78\\u00a7oCecilia Jarne\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1703.06812\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7n2018 Anales AFA,\\n  https://anales.fisica.org.ar/journal/index.php/analesafa/article/view/2173/2174\\u00a7r\\n\\nVersion:\\u00a77v3 (Wed, 4 Jul 2018 11:30:51 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o9 pages, 5 Figures\\u00a7r"}']}
{title:'Hou et al. (§72018§r)', author: 'Jen-Cheng Hou; Syu-Siang Wang; Ying-Hui Lai; Yu Tsao; Hsiu-Wen Chang; Hsin-Min Wang', display:{Lore:['[{"text": "arXiv:1703.10893", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.MM\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAudio-Visual Speech Enhancement Using Multimodal Deep Convolutional Neural Networks\\u00a7r\\n\\n\\u00a78\\u00a7oJen-Cheng Hou\\nSyu-Siang Wang\\nYing-Hui Lai\\n+ 2 others\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1703.10893\\u00a7r\\n\\nVersion:\\u00a77v6 (Wed, 24 Jan 2018 17:54:39 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oTo appear in IEEE Transactions on Emerging Topics in Computational Intelligence. Some audiosamples can be reached in this link: https://sites.google.com/view/avse2017\\u00a7r"}']}
{title:'Yamshchikov et al. (§72018§r)', author: 'Ivan P. Yamshchikov; Alexey Tikhonov', display:{Lore:['[{"text": "arXiv:1705.05458", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMusic generation with variational recurrent autoencoder supported by history\\u00a7r\\n\\n\\u00a78\\u00a7oIvan P. Yamshchikov\\nAlexey Tikhonov\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1705.05458\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1007/s42452-020-03715-w\\u00a7r\\n\\nVersion:\\u00a77v4 (Mon, 12 Nov 2018 22:27:43 GMT)\\u00a7r"}']}
{title:'Zhang et al. (§72018§r)', author: 'Zixing Zhang; Jürgen Geiger; Jouni Pohjalainen; Amr El-Desoky Mousa; Wenyu Jin; Björn Schuller', display:{Lore:['[{"text": "arXiv:1705.10874", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDeep Learning for Environmentally Robust Speech Recognition: An Overview of Recent Developments\\u00a7r\\n\\n\\u00a78\\u00a7oZixing Zhang\\nJ\\u00fcrgen Geiger\\nJouni Pohjalainen\\n+ 2 others\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1705.10874\\u00a7r\\n\\nVersion:\\u00a77v3 (Fri, 21 Sep 2018 09:05:57 GMT)\\u00a7r"}']}
{title:'Rethage et al. (§72018§r)', author: 'Dario Rethage; Jordi Pons; Xavier Serra', display:{Lore:['[{"text": "arXiv:1706.07162", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Wavenet for Speech Denoising\\u00a7r\\n\\n\\u00a78\\u00a7oDario Rethage\\nJordi Pons\\nXavier Serra\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1706.07162\\u00a7r\\n\\nVersion:\\u00a77v3 (Wed, 31 Jan 2018 09:38:44 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oIn proceedings of the 43rd IEEE InternationalConference on Acoustics, Speech and Signal Processing (ICASSP2018). Code: https://github.com/drethage/speech-denoising-wavenet - Audio examples: http://jordipons.me/apps/speech"}','{"text": "-denoising-wavenet/\\u00a7r"}']}
{title:'Nagrani et al. (§72018§r)', author: 'Arsha Nagrani; Joon Son Chung; Andrew Zisserman', display:{Lore:['[{"text": "arXiv:1706.08612", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lVoxCeleb: a large-scale speaker identification dataset\\u00a7r\\n\\n\\u00a78\\u00a7oArsha Nagrani\\nJoon Son Chung\\nAndrew Zisserman\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1706.08612\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.21437/Interspeech.2017-950\\u00a7r\\n\\nVersion:\\u00a77v2 (Wed, 30 May 2018 06:52:06 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oThe dataset can be downloaded from http://www.robots.ox.ac.uk/ vgg/data/voxceleb . 1706.08612v2: minor fixes; 6 pages\\u00a7r"}']}
{title:'Narendra et al. (§72018§r)', author: 'K. C. Narendra; R. Kumaraswamy; S. Gurugopinath', display:{Lore:['[{"text": "arXiv:1706.09386", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lOn a Novel Speech Representation Using Multitapered Modified Group Delay Function\\u00a7r\\n\\n\\u00a78\\u00a7oK. C. Narendra\\nR. Kumaraswamy\\nS. Gurugopinath\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1706.09386\\u00a7r\\n\\nVersion:\\u00a77v3 (Tue, 3 Jul 2018 14:31:29 GMT)\\u00a7r"}']}
{title:'Wang et al. (§72018§r)', author: 'Yu Wang; Mike Brookes', display:{Lore:['[{"text": "arXiv:1707.02651", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lModel-Based Speech Enhancement in the Modulation Domain\\u00a7r\\n\\n\\u00a78\\u00a7oYu Wang\\nMike Brookes\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1707.02651\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/TASLP.2017.2786863\\u00a7r\\n\\nVersion:\\u00a77v3 (Wed, 31 Jan 2018 04:25:19 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o15 pages, 18 figures; IEEE/ACM Transactionson Audio, Speech and Language Processing, Vol. 26, No. 3, Mar. 2018\\u00a7r"}']}
{title:'Luo et al. (§72018§r)', author: 'Yi Luo; Zhuo Chen; Nima Mesgarani', display:{Lore:['[{"text": "arXiv:1707.03634", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSpeaker-independent Speech Separation with Deep Attractor Network\\u00a7r\\n\\n\\u00a78\\u00a7oYi Luo\\nZhuo Chen\\nNima Mesgarani\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1707.03634\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/TASLP.2018.2795749\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nIEEE/ACM Transactions on Audio, Speech and Language Processing\\n  (TASLP), Volume 26 Issue 4, April 2018, Page 787-796\\u00a7r\\n\\nVersion:\\u00a77v3 (Wed, 18 Apr 2018 02:31:09 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oIEEE/ACM Transactions on Audio, Speech and Language Processing (TASLP), Volume 26 Issue 4, April 2018, Page 787-796\\u00a7r"}']}
{title:'Yanchenko et al. (§72018§r)', author: 'Anna K. Yanchenko; Sayan Mukherjee', display:{Lore:['[{"text": "arXiv:1708.03822", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lClassical Music Composition Using State Space Models\\u00a7r\\n\\n\\u00a78\\u00a7oAnna K. Yanchenko\\nSayan Mukherjee\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1708.03822\\u00a7r\\n\\nVersion:\\u00a77v2 (Fri, 28 Sep 2018 21:44:01 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAdded case studies section and increased discussion of interpretation of results in terms of music theory\\u00a7r"}']}
{title:'Van Kuyk et al. (§72018§r)', author: 'Steven Van Kuyk; W. Bastiaan Kleijn; Richard C. Hendriks', display:{Lore:['[{"text": "arXiv:1708.05132", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAn instrumental intelligibility metric based on information theory\\u00a7r\\n\\n\\u00a78\\u00a7oSteven Van Kuyk\\nW. Bastiaan Kleijn\\nRichard C. Hendriks\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1708.05132\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/LSP.2017.2774250\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nIEEE Signal Processing Letters, vol. 25, no. 1, pp. 115-119, Jan.\\n  2018\\u00a7r\\n\\nVersion:\\u00a77v2 (Sun, 14 Jan 2018 21:05:59 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oPublished in IEEESignal Processing Letters\\u00a7r"}']}
{title:'Van Kuyk et al. (§72018§r)', author: 'Steven Van Kuyk; W. Bastiaan Kleijn; Richard C. Hendriks', display:{Lore:['[{"text": "arXiv:1708.06027", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAn evaluation of intrusive instrumental intelligibility metrics\\u00a7r\\n\\n\\u00a78\\u00a7oSteven Van Kuyk\\nW. Bastiaan Kleijn\\nRichard C. Hendriks\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1708.06027\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/TASLP.2018.2856374\\u00a7r\\n\\nVersion:\\u00a77v4 (Sun, 29 Jul 2018 00:56:02 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oPublished in IEEE/ACM Transactionson Audio, Speech, and Language Processing, 2018\\u00a7r"}']}
{title:'Mimilakis et al. (§72018§r)', author: 'Stylianos Ioannis Mimilakis; Konstantinos Drossos; Tuomas Virtanen; Gerald Schuller', display:{Lore:['[{"text": "arXiv:1709.00611", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Recurrent Encoder-Decoder Approach with Skip-filtering Connections for Monaural Singing Voice Separation\\u00a7r\\n\\n\\u00a78\\u00a7oStylianos Ioannis Mimilakis\\nKonstantinos Drossos\\nTuomas Virtanen\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1709.00611\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 24 Apr 2018 09:17:13 GMT)\\u00a7r"}']}
{title:'Rehr et al. (§72018§r)', author: 'Robert Rehr; Timo Gerkmann', display:{Lore:['[{"text": "arXiv:1709.02175", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lNormalized Features for Improving the Generalization of DNN Based Speech Enhancement\\u00a7r\\n\\n\\u00a78\\u00a7oRobert Rehr\\nTimo Gerkmann\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1709.02175\\u00a7r\\n\\nVersion:\\u00a77v2 (Mon, 15 Jan 2018 14:45:56 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o10 pages, 4 figures, Journal\\u00a7r"}']}
{title:'Valin (§72018§r)', author: 'Jean-Marc Valin', display:{Lore:['[{"text": "arXiv:1709.08243", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Hybrid DSP/Deep Learning Approach to Real-Time Full-Band Speech Enhancement\\u00a7r\\n\\n\\u00a78\\u00a7oJean-Marc Valin\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1709.08243\\u00a7r\\n\\nVersion:\\u00a77v3 (Thu, 31 May 2018 21:39:13 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, MMSP 2018\\u00a7r"}']}
{title:'Park et al. (§72018§r)', author: 'Jiyoung Park; Jongpil Lee; Jangyeon Park; Jung-Woo Ha; Juhan Nam', display:{Lore:['[{"text": "arXiv:1710.06648", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lRepresentation Learning of Music Using Artist Labels\\u00a7r\\n\\n\\u00a78\\u00a7oJiyoung Park\\nJongpil Lee\\nJangyeon Park\\nJung-Woo Ha\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1710.06648\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 19 Jun 2018 01:58:09 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o19th International Society for Music Information Retrieval Conference (ISMIR), 2018\\u00a7r"}']}
{title:'Ping et al. (§72018§r)', author: 'Wei Ping; Kainan Peng; Andrew Gibiansky; Sercan O. Arik; Ajay Kannan; Sharan Narang; Jonathan Raiman; John Miller', display:{Lore:['[{"text": "arXiv:1710.07654", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.AI\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDeep Voice 3: Scaling Text-to-Speech with Convolutional Sequence Learning\\u00a7r\\n\\n\\u00a78\\u00a7oWei Ping\\nKainan Peng\\nAndrew Gibiansky\\n+ 4 others\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1710.07654\\u00a7r\\n\\nVersion:\\u00a77v3 (Thu, 22 Feb 2018 06:23:45 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oPublished as a conference paper at ICLR 2018. (v3 changed paper title)\\u00a7r"}']}
{title:'Adavanne et al. (§72018§r)', author: 'Sharath Adavanne; Archontis Politis; Tuomas Virtanen', display:{Lore:['[{"text": "arXiv:1710.10059", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDirection of arrival estimation for multiple sound sources using convolutional recurrent neural network\\u00a7r\\n\\n\\u00a78\\u00a7oSharath Adavanne\\nArchontis Politis\\nTuomas Virtanen\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1710.10059\\u00a7r\\n\\nVersion:\\u00a77v2 (Sun, 5 Aug 2018 19:54:58 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oEUSIPCO 2018\\u00a7r"}']}
{title:'Liu et al. (§72018§r)', author: 'Yi Liu; Liang He; Weiqiang Zhang; Jia Liu; Michael T. Johnson', display:{Lore:['[{"text": "arXiv:1710.10436", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lInvestigation of Frame Alignments for GMM-based Digit-prompted Speaker Verification\\u00a7r\\n\\n\\u00a78\\u00a7oYi Liu\\nLiang He\\nWeiqiang Zhang\\nJia Liu\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1710.10436\\u00a7r\\n\\nVersion:\\u00a77v4 (Sun, 2 Sep 2018 12:54:23 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oaccepted by APSIPA ASC 2018\\u00a7r"}']}
{title:'Kim et al. (§72018§r)', author: 'Taejun Kim; Jongpil Lee; Juhan Nam', display:{Lore:['[{"text": "arXiv:1710.10451", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.MM\\u00a7r, \\u00a7acs.NE\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSample-level CNN Architectures for Music Auto-tagging Using Raw Waveforms\\u00a7r\\n\\n\\u00a78\\u00a7oTaejun Kim\\nJongpil Lee\\nJuhan Nam\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1710.10451\\u00a7r\\n\\nVersion:\\u00a77v2 (Wed, 14 Feb 2018 04:39:50 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted for publication at ICASSP 2018\\u00a7r"}']}
{title:'Manocha et al. (§72018§r)', author: 'Pranay Manocha; Rohan Badlani; Anurag Kumar; Ankit Shah; Benjamin Elizalde; Bhiksha Raj', display:{Lore:['[{"text": "arXiv:1710.10974", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.IR\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lContent-based Representations of audio using Siamese neural networks\\u00a7r\\n\\n\\u00a78\\u00a7oPranay Manocha\\nRohan Badlani\\nAnurag Kumar\\n+ 2 others\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1710.10974\\u00a7r\\n\\nVersion:\\u00a77v3 (Thu, 15 Feb 2018 15:05:30 GMT)\\u00a7r"}']}
{title:'Hawthorne et al. (§72018§r)', author: 'Curtis Hawthorne; Erich Elsen; Jialin Song; Adam Roberts; Ian Simon; Colin Raffel; Jesse Engel; Sageev Oore; Douglas Eck', display:{Lore:['[{"text": "arXiv:1710.11153", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lOnsets and Frames: Dual-Objective Piano Transcription\\u00a7r\\n\\n\\u00a78\\u00a7oCurtis Hawthorne\\nErich Elsen\\nJialin Song\\n+ 5 others\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1710.11153\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 5 Jun 2018 04:20:28 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oExamples available at https://goo.gl/magenta/onsets-frames-examples\\u00a7r"}']}
{title:'Grinstein et al. (§72018§r)', author: 'Eric Grinstein; Ngoc Duong; Alexey Ozerov; Patrick Pérez', display:{Lore:['[{"text": "arXiv:1710.11385", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r, \\u00a75physics.class-ph\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAudio style transfer\\u00a7r\\n\\n\\u00a78\\u00a7oEric Grinstein\\nNgoc Duong\\nAlexey Ozerov\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1710.11385\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/ICASSP.2018.8461711\\u00a7r\\n\\nVersion:\\u00a77v3 (Wed, 7 Nov 2018 10:04:59 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oICASSP 2018 - 2018 IEEE InternationalConference on Acoustics, Speech and Signal Processing (ICASSP), Apr 2018, Calgary, France. IEEE\\u00a7r"}']}
{title:'Lee et al. (§72018§r)', author: 'Sang-gil Lee; Uiwon Hwang; Seonwoo Min; Sungroh Yoon', display:{Lore:['[{"text": "arXiv:1710.11418", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lPolyphonic Music Generation with Sequence Generative Adversarial Networks\\u00a7r\\n\\n\\u00a78\\u00a7oSang-gil Lee\\nUiwon Hwang\\nSeonwoo Min\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1710.11418\\u00a7r\\n\\nVersion:\\u00a77v2 (Mon, 2 Jul 2018 04:44:03 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o8 pages, 3 figures, 3 tables\\u00a7r"}']}
{title:'Bando et al. (§72018§r)', author: 'Yoshiaki Bando; Masato Mimura; Katsutoshi Itoyama; Kazuyoshi Yoshii; Tatsuya Kawahara', display:{Lore:['[{"text": "arXiv:1710.11439", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lStatistical Speech Enhancement Based on Probabilistic Integration of Variational Autoencoder and Non-Negative Matrix Factorization\\u00a7r\\n\\n\\u00a78\\u00a7oYoshiaki Bando\\nMasato Mimura\\nKatsutoshi Itoyama\\nKazuyoshi Yoshii\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1710.11439\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/ICASSP.2018.8461530\\u00a7r\\n\\nVersion:\\u00a77v4 (Mon, 19 Mar 2018 07:04:46 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 3 figures, version that Eqs. (9), (19), and (20) in v2 (submitted to ICASSP 2018) are corrected. Samples available here:http://sap.ist.i.kyoto-u.ac.jp/members/yoshiaki/demo/vae-nmf/\\u00a7r"}']}
{title:'Wu et al. (§72018§r)', author: 'Yuzhong Wu; Tan Lee', display:{Lore:['[{"text": "arXiv:1711.00229", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lReducing Model Complexity for DNN Based Large-Scale Audio Classification\\u00a7r\\n\\n\\u00a78\\u00a7oYuzhong Wu\\nTan Lee\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1711.00229\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 30 Oct 2018 14:15:52 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted by ICASSP 2018\\u00a7r"}']}
{title:'Yela et al. (§72018§r)', author: "Delia Fano Yela; Sebastian Ewert; Ken O'Hanlon; Mark B. Sandler", display:{Lore:['[{"text": "arXiv:1711.00351", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lShift-Invariant Kernel Additive Modelling for Audio Source Separation\\u00a7r\\n\\n\\u00a78\\u00a7oDelia Fano Yela\\nSebastian Ewert\\nKen O\'Hanlon\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1711.00351\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nIEEE International Conference on Acoustics, Speech and Signal\\n  Processing (ICASSP), Calgary, 2018\\u00a7r\\n\\nVersion:\\u00a77v2 (Fri, 16 Feb 2018 13:27:12 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oFeedback is welcome\\u00a7r"}']}
{title:'Li et al. (§72018§r)', author: 'Lantian Li; Zhiyuan Tang; Dong Wang; Thomas Fang Zheng', display:{Lore:['[{"text": "arXiv:1711.00366", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lFull-info Training for Deep Speaker Feature Learning\\u00a7r\\n\\n\\u00a78\\u00a7oLantian Li\\nZhiyuan Tang\\nDong Wang\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1711.00366\\u00a7r\\n\\nVersion:\\u00a77v3 (Tue, 27 Feb 2018 09:57:22 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted by ICASSP 2018\\u00a7r"}']}
{title:'Luo et al. (§72018§r)', author: 'Yi Luo; Nima Mesgarani', display:{Lore:['[{"text": "arXiv:1711.00541", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.MM\\u00a7r, \\u00a7acs.NE\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lTasNet: time-domain audio separation network for real-time, single-channel speech separation\\u00a7r\\n\\n\\u00a78\\u00a7oYi Luo\\nNima Mesgarani\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1711.00541\\u00a7r\\n\\nVersion:\\u00a77v2 (Wed, 18 Apr 2018 02:25:29 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oCamera ready version for ICASSP 2018, Calgary, Canada\\u00a7r"}']}
{title:'Badlani et al. (§72018§r)', author: 'Rohan Badlani; Ankit Shah; Benjamin Elizalde; Anurag Kumar; Bhiksha Raj', display:{Lore:['[{"text": "arXiv:1711.00804", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.AI\\u00a7r, \\u00a7acs.IR\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lFramework for evaluation of sound event detection in web videos\\u00a7r\\n\\n\\u00a78\\u00a7oRohan Badlani\\nAnkit Shah\\nBenjamin Elizalde\\nAnurag Kumar\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1711.00804\\u00a7r\\n\\nVersion:\\u00a77v2 (Wed, 4 Apr 2018 15:05:37 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oCamera Ready Version of Paper accepted at International Conference on Acoustics, Speech, and Signal Processing (ICASSP) 2018. First twoAuthors - Rohan Badlani and Ankit Shah contributed equally\\u00a7r"}']}
{title:'Kong et al. (§72018§r)', author: 'Qiuqiang Kong; Yong Xu; Wenwu Wang; Mark D. Plumbley', display:{Lore:['[{"text": "arXiv:1711.00927", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAudio Set classification with attention model: A probabilistic perspective\\u00a7r\\n\\n\\u00a78\\u00a7oQiuqiang Kong\\nYong Xu\\nWenwu Wang\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1711.00927\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nIEEE International Conference on Acoustics, Speech and Signal\\n  Processing (ICASSP), 2018, pp. 316-320\\u00a7r\\n\\nVersion:\\u00a77v2 (Wed, 7 Feb 2018 22:02:38 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted by ICASSP 2018\\u00a7r"}']}
{title:'Kumar et al. (§72018§r)', author: 'Anurag Kumar; Maksim Khadkevich; Christian Fugen', display:{Lore:['[{"text": "arXiv:1711.01369", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.MM\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lKnowledge Transfer from Weakly Labeled Audio using Convolutional Neural Network for Sound Events and Scenes\\u00a7r\\n\\n\\u00a78\\u00a7oAnurag Kumar\\nMaksim Khadkevich\\nChristian Fugen\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1711.01369\\u00a7r\\n\\nVersion:\\u00a77v4 (Fri, 7 Sep 2018 05:22:27 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oICASSP 2018\\u00a7r"}']}
{title:'Mimilakis et al. (§72018§r)', author: 'Stylianos Ioannis Mimilakis; Konstantinos Drossos; João F. Santos; Gerald Schuller; Tuomas Virtanen; Yoshua Bengio', display:{Lore:['[{"text": "arXiv:1711.01437", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMonaural Singing Voice Separation with Skip-Filtering Connections and Recurrent Inference of Time-Frequency Mask\\u00a7r\\n\\n\\u00a78\\u00a7oStylianos Ioannis Mimilakis\\nKonstantinos Drossos\\nJo\\u00e3o F. Santos\\n+ 2 others\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1711.01437\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 13 Feb 2018 10:26:50 GMT)\\u00a7r"}']}
{title:'Pons et al. (§72018§r)', author: 'Jordi Pons; Oriol Nieto; Matthew Prockup; Erik Schmidt; Andreas Ehmann; Xavier Serra', display:{Lore:['[{"text": "arXiv:1711.02520", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lEnd-to-end learning for music audio tagging at scale\\u00a7r\\n\\n\\u00a78\\u00a7oJordi Pons\\nOriol Nieto\\nMatthew Prockup\\n+ 2 others\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1711.02520\\u00a7r\\n\\nVersion:\\u00a77v4 (Fri, 15 Jun 2018 08:04:37 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oPresented at theWorkshop on Machine Learning for Audio Signal Processing (ML4Audio) at NIPS 2017, and in proceedings of the 19th International Society for Music Information Retrieval Conference (ISMIR2018). Code: http"}','{"text": "s://github.com/jordipons/music-audio-tagging-at-scale-models. Demo: http://www.jordipons.me/apps/music-audio-tagging-at-scale-demo/\\u00a7r"}']}
{title:'Kong et al. (§72018§r)', author: 'Qiuqiang Kong; Yong Xu; Wenwu Wang; Mark D. Plumbley', display:{Lore:['[{"text": "arXiv:1711.03037", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA joint separation-classification model for sound event detection of weakly labelled data\\u00a7r\\n\\n\\u00a78\\u00a7oQiuqiang Kong\\nYong Xu\\nWenwu Wang\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1711.03037\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nIEEE International Conference on Acoustics, Speech and Signal\\n  Processing (ICASSP), 2018, pp. 321-325\\u00a7r\\n\\nVersion:\\u00a77v2 (Wed, 7 Feb 2018 21:57:10 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted by ICASSP 2018\\u00a7r"}']}
{title:'Zhang et al. (§72018§r)', author: 'Ning Zhang; Junchi Yan; Yuchen Zhou', display:{Lore:['[{"text": "arXiv:1711.04121", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lWeakly Supervised Audio Source Separation via Spectrum Energy Preserved Wasserstein Learning\\u00a7r\\n\\n\\u00a78\\u00a7oNing Zhang\\nJunchi Yan\\nYuchen Zhou\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1711.04121\\u00a7r\\n\\nVersion:\\u00a77v3 (Thu, 17 May 2018 06:50:15 GMT)\\u00a7r"}']}
{title:'Zhang et al. (§72018§r)', author: 'Miao Zhang; Xiaofei Kang; Yanqing Wang; Lantian Li; Zhiyuan Tang; Haisheng Dai; Dong Wang', display:{Lore:['[{"text": "arXiv:1711.05443", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.NE\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lHuman and Machine Speaker Recognition Based on Short Trivial Events\\u00a7r\\n\\n\\u00a78\\u00a7oMiao Zhang\\nXiaofei Kang\\nYanqing Wang\\n+ 3 others\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1711.05443\\u00a7r\\n\\nVersion:\\u00a77v3 (Tue, 6 Feb 2018 04:13:27 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oICASSP 2018\\u00a7r"}']}
{title:'Donahue et al. (§72018§r)', author: 'Chris Donahue; Bo Li; Rohit Prabhavalkar', display:{Lore:['[{"text": "arXiv:1711.05747", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.NE\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lExploring Speech Enhancement with Generative Adversarial Networks for Robust Speech Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oChris Donahue\\nBo Li\\nRohit Prabhavalkar\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1711.05747\\u00a7r\\n\\nVersion:\\u00a77v2 (Wed, 31 Oct 2018 00:48:59 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oPublished as a conference paper at ICASSP 2018\\u00a7r"}']}
{title:'Zhang et al. (§72018§r)', author: 'Yundong Zhang; Naveen Suda; Liangzhen Lai; Vikas Chandra', display:{Lore:['[{"text": "arXiv:1711.07128", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.NE\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lHello Edge: Keyword Spotting on Microcontrollers\\u00a7r\\n\\n\\u00a78\\u00a7oYundong Zhang\\nNaveen Suda\\nLiangzhen Lai\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1711.07128\\u00a7r\\n\\nVersion:\\u00a77v3 (Wed, 14 Feb 2018 19:24:55 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oCode available in github at https://github.com/ARM-software/ML-KWS-for-MCU\\u00a7r"}']}
{title:'Li et al. (§72018§r)', author: 'Xiaofei Li; Laurent Girin; Sharon Gannot; Radu Horaud', display:{Lore:['[{"text": "arXiv:1711.07911", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMultichannel Speech Separation and Enhancement Using the Convolutive Transfer Function\\u00a7r\\n\\n\\u00a78\\u00a7oXiaofei Li\\nLaurent Girin\\nSharon Gannot\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1711.07911\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/TASLP.2019.2892412\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nIEEE/ACM Transactions on Audio Speech and Language Processing\\n  27(3), 645-659, 2019\\u00a7r\\n\\nVersion:\\u00a77v2 (Mon, 26 Feb 2018 10:00:40 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to IEEE/ACM Transactionson Audio, Speech and Language Processing\\u00a7r"}']}
{title:'He et al. (§72018§r)', author: 'Weipeng He; Petr Motlicek; Jean-Marc Odobez', display:{Lore:['[{"text": "arXiv:1711.11565", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.AI\\u00a7r, \\u00a7acs.MM\\u00a7r, \\u00a7acs.RO\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDeep Neural Networks for Multiple Speaker Detection and Localization\\u00a7r\\n\\n\\u00a78\\u00a7oWeipeng He\\nPetr Motlicek\\nJean-Marc Odobez\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1711.11565\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/ICRA.2018.8461267\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7n2018 IEEE International Conference on Robotics and Automation\\n  (ICRA), Brisbane, Australia, 2018, pp. 74-79\\u00a7r\\n\\nVersion:\\u00a77v3 (Mon, 26 Feb 2018 09:04:36 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted for ICRA 2018\\u00a7r"}']}
{title:'Briot et al. (§72018§r)', author: 'Jean-Pierre Briot; François Pachet', display:{Lore:['[{"text": "arXiv:1712.04371", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMusic Generation by Deep Learning - Challenges and Directions\\u00a7r\\n\\n\\u00a78\\u00a7oJean-Pierre Briot\\nFran\\u00e7ois Pachet\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1712.04371\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1007/s00521-018-3813-6\\u00a7r\\n\\nVersion:\\u00a77v2 (Sun, 30 Sep 2018 15:06:19 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o17 pages. arXiv admin note:substantial text overlap with arXiv:1709.01620. Accepted for publication in Special Issue on Deep learning for music and audio, Neural Computing Applications, Springer Nature, 2018\\u00a7r"}']}
{title:'Wu et al. (§72018§r)', author: 'Jian Wu; Changran Hu; Yulong Wang; Xiaolin Hu; Jun Zhu', display:{Lore:['[{"text": "arXiv:1712.05274", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.MM\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Hierarchical Recurrent Neural Network for Symbolic Melody Generation\\u00a7r\\n\\n\\u00a78\\u00a7oJian Wu\\nChangran Hu\\nYulong Wang\\nXiaolin Hu\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1712.05274\\u00a7r\\n\\nVersion:\\u00a77v2 (Wed, 5 Sep 2018 03:25:40 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o9 pages\\u00a7r"}']}
{title:'Chorowski et al. (§72018§r)', author: 'Jan Chorowski; Ron J. Weiss; Rif A. Saurous; Samy Bengio', display:{Lore:['[{"text": "arXiv:1712.08363", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lOn Using Backpropagation for Speech Texture Generation and Voice Conversion\\u00a7r\\n\\n\\u00a78\\u00a7oJan Chorowski\\nRon J. Weiss\\nRif A. Saurous\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1712.08363\\u00a7r\\n\\nVersion:\\u00a77v2 (Thu, 8 Mar 2018 09:17:27 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted to ICASSP 2018\\u00a7r"}']}
{title:'Pham et al. (§72018§r)', author: 'Phuong Pham; Juncheng Li; Joseph Szurley; Samarjit Das', display:{Lore:['[{"text": "arXiv:1712.09668", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lEventness: Object Detection on Spectrograms for Temporal Localization of Audio Events\\u00a7r\\n\\n\\u00a78\\u00a7oPhuong Pham\\nJuncheng Li\\nJoseph Szurley\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1712.09668\\u00a7r\\n\\nVersion:\\u00a77v2 (Mon, 19 Feb 2018 13:50:35 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 3 figures, accepted to ICASSP 2018\\u00a7r"}']}
{title:'Tseng et al. (§72018§r)', author: 'Shao-Yen Tseng; Juncheng Li; Yun Wang; Joseph Szurley; Florian Metze; Samarjit Das', display:{Lore:['[{"text": "arXiv:1712.09673", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMultiple Instance Deep Learning for Weakly Supervised Small-Footprint Audio Event Detection\\u00a7r\\n\\n\\u00a78\\u00a7oShao-Yen Tseng\\nJuncheng Li\\nYun Wang\\n+ 2 others\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1712.09673\\u00a7r\\n\\nVersion:\\u00a77v2 (Mon, 26 Mar 2018 12:56:57 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 3 figures\\u00a7r"}']}
{title:'Li et al. (§72018§r)', author: 'Juncheng Li; Yun Wang; Joseph Szurley; Florian Metze; Samarjit Das', display:{Lore:['[{"text": "arXiv:1712.09680", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Light-Weight Multimodal Framework for Improved Environmental Audio Tagging\\u00a7r\\n\\n\\u00a78\\u00a7oJuncheng Li\\nYun Wang\\nJoseph Szurley\\nFlorian Metze\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1712.09680\\u00a7r\\n\\nVersion:\\u00a77v2 (Thu, 1 Mar 2018 18:03:00 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 3 figures, Accepted and to appear at ICASSP 2018\\u00a7r"}']}
{title:'Mao et al. (§72018§r)', author: 'Huanru Henry Mao; Taylor Shin; Garrison W. Cottrell', display:{Lore:['[{"text": "arXiv:1801.00887", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDeepJ: Style-Specific Music Generation\\u00a7r\\n\\n\\u00a78\\u00a7oHuanru Henry Mao\\nTaylor Shin\\nGarrison W. Cottrell\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1801.00887\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/ICSC.2018.00077\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 3 Jan 2018 02:54:08 GMT)\\u00a7r"}']}
{title:'Verma et al. (§72018§r)', author: 'Prateek Verma; Julius O. Smith', display:{Lore:['[{"text": "arXiv:1801.01589", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.MM\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lNeural Style Transfer for Audio Spectograms\\u00a7r\\n\\n\\u00a78\\u00a7oPrateek Verma\\nJulius O. Smith\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1801.01589\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 4 Jan 2018 23:59:07 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAppeared in 31stConference on Neural Information ProcessingSystems (NIPS 2017), Long Beach, CA, USA at the workshop for Machine Learning for Creativity and Design\\u00a7r"}']}
{title:'Deolekar et al. (§72018§r)', author: 'Subodh Deolekar; Siby Abraham', display:{Lore:['[{"text": "arXiv:1801.01712", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.IR\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lTree based classification of tabla strokes\\u00a7r\\n\\n\\u00a78\\u00a7oSubodh Deolekar\\nSiby Abraham\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1801.01712\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 5 Jan 2018 11:09:31 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o14 pages, 11 figures, current science\\u00a7r"}']}
{title:'Singh (§72018§r)', author: 'Malvika Singh', display:{Lore:['[{"text": "arXiv:1801.02155", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lBinning based algorithm for Pitch Detection in Hindustani Classical Music\\u00a7r\\n\\n\\u00a78\\u00a7oMalvika Singh\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1801.02155\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 7 Jan 2018 08:09:52 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 11 figures, 1 Table\\u00a7r"}']}
{title:'Cai et al. (§72018§r)', author: 'Wilson Cai; Anish Doshi; Rafael Valle', display:{Lore:['[{"text": "arXiv:1801.02384", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAttacking Speaker Recognition With Deep Generative Models\\u00a7r\\n\\n\\u00a78\\u00a7oWilson Cai\\nAnish Doshi\\nRafael Valle\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1801.02384\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 8 Jan 2018 11:17:56 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 3 Figures, 1 table\\u00a7r"}']}
{title:'Jimenez et al. (§72018§r)', author: 'Abelino Jimenez; Benjamin Elizalde; Bhiksha Raj', display:{Lore:['[{"text": "arXiv:1801.02690", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDCASE 2017 Task 1: Acoustic Scene Classification Using Shift-Invariant Kernels and Random Features\\u00a7r\\n\\n\\u00a78\\u00a7oAbelino Jimenez\\nBenjamin Elizalde\\nBhiksha Raj\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1801.02690\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 8 Jan 2018 21:12:49 GMT)\\u00a7r"}']}
{title:'Lee et al. (§72018§r)', author: 'Wei-Jen Lee; Syu-Siang Wang; Fei Chen; Xugang Lu; Shao-Yi Chien; Yu Tsao', display:{Lore:['[{"text": "arXiv:1801.04052", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSpeech Dereverberation Based on Integrated Deep and Ensemble Learning Algorithm\\u00a7r\\n\\n\\u00a78\\u00a7oWei-Jen Lee\\nSyu-Siang Wang\\nFei Chen\\n+ 2 others\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1801.04052\\u00a7r\\n\\nVersion:\\u00a77v2 (Sat, 17 Feb 2018 03:53:00 GMT)\\u00a7r"}']}
{title:'Park et al. (§72018§r)', author: 'Jeongsoo Park; Jaeyoung Shin; Kyogu Lee', display:{Lore:['[{"text": "arXiv:1801.04081", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.MM\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSeparation of Instrument Sounds using Non-negative Matrix Factorization with Spectral Envelope Constraints\\u00a7r\\n\\n\\u00a78\\u00a7oJeongsoo Park\\nJaeyoung Shin\\nKyogu Lee\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1801.04081\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 12 Jan 2018 08:10:53 GMT)\\u00a7r"}']}
{title:'Shahin (§72018§r)', author: 'Ismail Shahin', display:{Lore:['[{"text": "arXiv:1801.06657", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lGender-dependent emotion recognition based on HMMs and SPHMMs\\u00a7r\\n\\n\\u00a78\\u00a7oIsmail Shahin\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1801.06657\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1007/s10772-012-9170-4.\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nInternational Journal of Speech Technology, Vol. 16, issue 2, June\\n  2013, pp. 133-141\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 20 Jan 2018 11:05:52 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o9 pages. arXiv admin note:text overlap with arXiv:1706.09760, arXiv:1707.00137\\u00a7r"}']}
{title:'Shahin (§72018§r)', author: 'Ismail Shahin', display:{Lore:['[{"text": "arXiv:1801.07054", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lIdentifying Speakers Using Their Emotion Cues\\u00a7r\\n\\n\\u00a78\\u00a7oIsmail Shahin\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1801.07054\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1007/s10772-011-9089-1.\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nIdentifying speakers using their emotion cues, International\\n  Journal of Speech Technology, Vol. 14, No. 2, June 2011\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 22 Jan 2018 11:33:50 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o10 pages. arXiv admin note:text overlap with arXiv:1707.00137\\u00a7r"}']}
{title:'Ling et al. (§72018§r)', author: 'Zhen-Hua Ling; Yang Ai; Yu Gu; Li-Rong Dai', display:{Lore:['[{"text": "arXiv:1801.07910", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lWaveform Modeling and Generation Using Hierarchical Recurrent Neural Networks for Speech Bandwidth Extension\\u00a7r\\n\\n\\u00a78\\u00a7oZhen-Hua Ling\\nYang Ai\\nYu Gu\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1801.07910\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/TASLP.2018.2798811\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 24 Jan 2018 08:53:55 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted by IEEE Transactions on Audio, Speech and Language Processing\\u00a7r"}']}
{title:'Adavanne et al. (§72018§r)', author: 'Sharath Adavanne; Archontis Politis; Tuomas Virtanen', display:{Lore:['[{"text": "arXiv:1801.09522", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMultichannel Sound Event Detection Using 3D Convolutional Neural Networks for Learning Inter-channel Features\\u00a7r\\n\\n\\u00a78\\u00a7oSharath Adavanne\\nArchontis Politis\\nTuomas Virtanen\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1801.09522\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 29 Jan 2018 14:24:39 GMT)\\u00a7r"}']}
{title:'Zhen et al. (§72018§r)', author: 'Kai Zhen; Aswin Sivaraman; Jongmo Sung; Minje Kim', display:{Lore:['[{"text": "arXiv:1801.09774", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lOn Psychoacoustically Weighted Cost Functions Towards Resource-Efficient Deep Neural Networks for Speech Denoising\\u00a7r\\n\\n\\u00a78\\u00a7oKai Zhen\\nAswin Sivaraman\\nJongmo Sung\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1801.09774\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 29 Jan 2018 21:45:05 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 4 figures\\u00a7r"}']}
{title:'Martin et al. (§72018§r)', author: 'Charles P. Martin; Kai Olav Ellefsen; Jim Torresen', display:{Lore:['[{"text": "arXiv:1801.10492", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.AI\\u00a7r, \\u00a7acs.HC\\u00a7r, \\u00a7acs.NE\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDeep Predictive Models in Interactive Music\\u00a7r\\n\\n\\u00a78\\u00a7oCharles P. Martin\\nKai Olav Ellefsen\\nJim Torresen\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1801.10492\\u00a7r\\n\\nVersion:\\u00a77v3 (Wed, 19 Dec 2018 22:16:26 GMT)\\u00a7r"}']}
{title:'Wang et al. (§72018§r)', author: 'Yu Wang; Xie Chen; Mark Gales; Anton Ragni; Jeremy Wong', display:{Lore:['[{"text": "arXiv:1802.00254", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lPhonetic and Graphemic Systems for Multi-Genre Broadcast Transcription\\u00a7r\\n\\n\\u00a78\\u00a7oYu Wang\\nXie Chen\\nMark Gales\\nAnton Ragni\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1802.00254\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 1 Feb 2018 12:00:45 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 6 tables, to appear in 2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP 2018)\\u00a7r"}']}
{title:'Drossos et al. (§72018§r)', author: 'Konstantinos Drossos; Stylianos Ioannis Mimilakis; Dmitriy Serdyuk; Gerald Schuller; Tuomas Virtanen; Yoshua Bengio', display:{Lore:['[{"text": "arXiv:1802.00300", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMaD TwinNet: Masker-Denoiser Architecture with Twin Networks for Monaural Sound Source Separation\\u00a7r\\n\\n\\u00a78\\u00a7oKonstantinos Drossos\\nStylianos Ioannis Mimilakis\\nDmitriy Serdyuk\\n+ 2 others\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1802.00300\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 1 Feb 2018 14:31:36 GMT)\\u00a7r"}']}
{title:'Iqbal et al. (§72018§r)', author: 'Turab Iqbal; Wenwu Wang', display:{Lore:['[{"text": "arXiv:1802.00380", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lApproximate Message Passing for Underdetermined Audio Source Separation\\u00a7r\\n\\n\\u00a78\\u00a7oTurab Iqbal\\nWenwu Wang\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1802.00380\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 1 Feb 2018 16:41:09 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oPaper accepted for 3rd International Conference on Intelligent Signal Processing (ISP 2017)\\u00a7r"}']}
{title:'Kolbæk et al. (§72018§r)', author: 'Morten Kolbæk; Zheng-Hua Tan; Jesper Jensen', display:{Lore:['[{"text": "arXiv:1802.00604", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMonaural Speech Enhancement using Deep Neural Networks by Maximizing a Short-Time Objective Intelligibility Measure\\u00a7r\\n\\n\\u00a78\\u00a7oMorten Kolb\\u00e6k\\nZheng-Hua Tan\\nJesper Jensen\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1802.00604\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 2 Feb 2018 09:00:39 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oTo appear in ICASSP 2018\\u00a7r"}']}
{title:'An et al. (§72018§r)', author: 'Guozhen An; Rivka Levitan', display:{Lore:['[{"text": "arXiv:1802.01405", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lComparing approaches for mitigating intergroup variability in personality recognition\\u00a7r\\n\\n\\u00a78\\u00a7oGuozhen An\\nRivka Levitan\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1802.01405\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 31 Jan 2018 22:18:56 GMT)\\u00a7r"}']}
{title:'Magron et al. (§72018§r)', author: 'Paul Magron; Tuomas Virtanen', display:{Lore:['[{"text": "arXiv:1802.03156", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lComplex ISNMF: a Phase-Aware Model for Monaural Audio Source Separation\\u00a7r\\n\\n\\u00a78\\u00a7oPaul Magron\\nTuomas Virtanen\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1802.03156\\u00a7r\\n\\nVersion:\\u00a77v3 (Sun, 30 Sep 2018 15:05:11 GMT)\\u00a7r"}']}
{title:'Ko et al. (§72018§r)', author: 'Kyung Pyo Ko; Kwang Hee Lee; Mi So Jang; Gun Hong Park', display:{Lore:['[{"text": "arXiv:1802.03581", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CV\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7l2-gram-based Phonetic Feature Generation for Convolutional Neural Network in Assessment of Trademark Similarity\\u00a7r\\n\\n\\u00a78\\u00a7oKyung Pyo Ko\\nKwang Hee Lee\\nMi So Jang\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1802.03581\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 10 Feb 2018 12:50:34 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o10 pages, 6 figures, 10 tables\\u00a7r"}']}
{title:'Zhang (§72018§r)', author: 'Xiao-Lei Zhang', display:{Lore:['[{"text": "arXiv:1802.04113", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lLinear Regression for Speaker Verification\\u00a7r\\n\\n\\u00a78\\u00a7oXiao-Lei Zhang\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1802.04113\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 12 Feb 2018 15:23:35 GMT)\\u00a7r"}']}
{title:'Colombo et al. (§72018§r)', author: 'Florian Colombo; Wulfram Gerstner', display:{Lore:['[{"text": "arXiv:1802.05162", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lBachProp: Learning to Compose Music in Multiple Styles\\u00a7r\\n\\n\\u00a78\\u00a7oFlorian Colombo\\nWulfram Gerstner\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1802.05162\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 20 Feb 2018 12:45:51 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oPreliminary work.Under review by the 2018 International Conference on MachineLearning (ICML)\\u00a7r"}']}
{title:'Rolet et al. (§72018§r)', author: 'Antoine Rolet; Vivien Seguy; Mathieu Blondel; Hiroshi Sawada', display:{Lore:['[{"text": "arXiv:1802.05429", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lBlind Source Separation with Optimal Transport Non-negative Matrix Factorization\\u00a7r\\n\\n\\u00a78\\u00a7oAntoine Rolet\\nVivien Seguy\\nMathieu Blondel\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1802.05429\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1186/s13634-018-0576-2\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 15 Feb 2018 08:01:48 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o22 pages, 7 figures, 2 additional files\\u00a7r"}']}
{title:'Etienne et al. (§72018§r)', author: 'Caroline Etienne; Guillaume Fidanza; Andrei Petrovskii; Laurence Devillers; Benoit Schmauch', display:{Lore:['[{"text": "arXiv:1802.05630", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lCNN+LSTM Architecture for Speech Emotion Recognition with Data Augmentation\\u00a7r\\n\\n\\u00a78\\u00a7oCaroline Etienne\\nGuillaume Fidanza\\nAndrei Petrovskii\\nLaurence Devillers\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1802.05630\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.21437/SMM.2018-5\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nWorkshop on Speech, Music and Mind 2018\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 11 Sep 2018 18:05:16 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 3 figures\\u00a7r"}']}
{title:'Gao et al. (§72018§r)', author: 'Yang Gao; Rita Singh; Bhiksha Raj', display:{Lore:['[{"text": "arXiv:1802.06840", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lVoice Impersonation using Generative Adversarial Networks\\u00a7r\\n\\n\\u00a78\\u00a7oYang Gao\\nRita Singh\\nBhiksha Raj\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1802.06840\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 19 Feb 2018 20:41:47 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted by 2018 International Conference on Acoustics, Speech, and Signal Processing (ICASSP 2018)\\u00a7r"}']}
{title:'Sinclair (§72018§r)', author: 'Stephen Sinclair', display:{Lore:['[{"text": "arXiv:1802.08008", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSounderfeit: Cloning a Physical Model with Conditional Adversarial Autoencoders\\u00a7r\\n\\n\\u00a78\\u00a7oStephen Sinclair\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1802.08008\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nProc. Brazilian Symp. on Comp. Music., 2017. p. 67--74\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 22 Feb 2018 12:24:24 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oPublished in the Brazilian Symposium on Computer Music (SBCM 2017)\\u00a7r"}']}
{title:'Hua (§72018§r)', author: 'Kanru Hua', display:{Lore:['[{"text": "arXiv:1802.08370", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.NE\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDo WaveNets Dream of Acoustic Waves?\\u00a7r\\n\\n\\u00a78\\u00a7oKanru Hua\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1802.08370\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 23 Feb 2018 02:45:50 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages with 7 figures; submitted to Interspeech 2018\\u00a7r"}']}
{title:'Kalchbrenner et al. (§72018§r)', author: 'Nal Kalchbrenner; Erich Elsen; Karen Simonyan; Seb Noury; Norman Casagrande; Edward Lockhart; Florian Stimberg; Aaron van den Oord; Sander Dieleman; Koray Kavukcuoglu', display:{Lore:['[{"text": "arXiv:1802.08435", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lEfficient Neural Audio Synthesis\\u00a7r\\n\\n\\u00a78\\u00a7oNal Kalchbrenner\\nErich Elsen\\nKaren Simonyan\\n+ 6 others\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1802.08435\\u00a7r\\n\\nVersion:\\u00a77v2 (Mon, 25 Jun 2018 19:45:25 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o10 pages\\u00a7r"}']}
{title:'Dong (§72018§r)', author: 'Mingwen Dong', display:{Lore:['[{"text": "arXiv:1802.09697", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lConvolutional Neural Network Achieves Human-level Accuracy in Music Genre Classification\\u00a7r\\n\\n\\u00a78\\u00a7oMingwen Dong\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1802.09697\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 27 Feb 2018 03:08:55 GMT)\\u00a7r"}']}
{title:'Sajil et al. (§72018§r)', author: 'C. K. Sajil; C. L. Biji; S. Nair Achuthsankar', display:{Lore:['[{"text": "arXiv:1802.10058", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lEffect of Transducer Positioning in Active Noise Control\\u00a7r\\n\\n\\u00a78\\u00a7oC. K. Sajil\\nC. L. Biji\\nS. Nair Achuthsankar\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1802.10058\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 27 Feb 2018 18:29:14 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o6 pages, 11 figures. To appear in the Proceedings of the 5th International Conference on Signal Processing and Integrated Networks(SPIN 2018), 22-23 February 2018, Delhi, India\\u00a7r"}']}
{title:'Useche et al. (§72018§r)', author: 'Jorge Useche; Rafael Hurtado; Federico Demmer', display:{Lore:['[{"text": "arXiv:1802.10162", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lInterplay between musical practices and tuning in the marimba de chonta music\\u00a7r\\n\\n\\u00a78\\u00a7oJorge Useche\\nRafael Hurtado\\nFederico Demmer\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1802.10162\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 27 Feb 2018 21:03:37 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oTotal number of pages: 52, main manuscript: 18 pages, supplemental material: 34 pages, the main manuscript contains 6 tables and 9 figures\\u00a7r"}']}
{title:'Maeno et al. (§72018§r)', author: 'Yu Maeno; Yuki Mitsufuji; Thushara D. Abhayapala', display:{Lore:['[{"text": "arXiv:1803.00187", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r, \\u00a7eeess.SP\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMode Domain Spatial Active Noise Control Using Sparse Signal Representation\\u00a7r\\n\\n\\u00a78\\u00a7oYu Maeno\\nYuki Mitsufuji\\nThushara D. Abhayapala\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1803.00187\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 1 Mar 2018 03:12:15 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oto appear at ICASSP 2018\\u00a7r"}']}
{title:'Grais et al. (§72018§r)', author: 'Emad M. Grais; Dominic Ward; Mark D. Plumbley', display:{Lore:['[{"text": "arXiv:1803.00702", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CV\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.MM\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lRaw Multi-Channel Audio Source Separation using Multi-Resolution Convolutional Auto-Encoders\\u00a7r\\n\\n\\u00a78\\u00a7oEmad M. Grais\\nDominic Ward\\nMark D. Plumbley\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1803.00702\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 2 Mar 2018 03:47:47 GMT)\\u00a7r"}']}
{title:'Torfi (§72018§r)', author: 'Amirsina Torfi', display:{Lore:['[{"text": "arXiv:1803.01094", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSpeechPy - A Library for Speech Processing and Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oAmirsina Torfi\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1803.01094\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.21105/joss.00749\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nJournal of Open Source Software, 3(27), 749, 2018\\u00a7r\\n\\nVersion:\\u00a77v3 (Fri, 25 May 2018 21:22:19 GMT)\\u00a7r"}']}
{title:'Xie et al. (§72018§r)', author: 'Jiang-jian Xie; Chang-qing Ding; Wen-bin Li; Cheng-hao Cai', display:{Lore:['[{"text": "arXiv:1803.01107", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAudio-only Bird Species Automated Identification Method with Limited Training Data Based on Multi-Channel Deep Convolutional Neural Networks\\u00a7r\\n\\n\\u00a78\\u00a7oJiang-jian Xie\\nChang-qing Ding\\nWen-bin Li\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1803.01107\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 3 Mar 2018 05:12:06 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o11 pages,11 figures\\u00a7r"}']}
{title:'Coteli et al. (§72018§r)', author: 'Mert Burkay Coteli; Orhun Olgun; Huseyin Hacihabiboglu', display:{Lore:['[{"text": "arXiv:1803.01339", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.MM\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMultiple Sound Source Localisation with Steered Response Power Density and Hierarchical Grid Refinement\\u00a7r\\n\\n\\u00a78\\u00a7oMert Burkay Coteli\\nOrhun Olgun\\nHuseyin Hacihabiboglu\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1803.01339\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 4 Mar 2018 11:32:21 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o14 pages, 10 figures, 4 tables, submitted to IEEE/ACM Transactionson Audio, Speech and Language Processing (03 March 2018)\\u00a7r"}']}
{title:'Shon et al. (§72018§r)', author: 'Suwon Shon; Ahmed Ali; James Glass', display:{Lore:['[{"text": "arXiv:1803.04567", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lConvolutional Neural Networks and Language Embeddings for End-to-End Dialect Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oSuwon Shon\\nAhmed Ali\\nJames Glass\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1803.04567\\u00a7r\\n\\nVersion:\\u00a77v2 (Sat, 21 Apr 2018 23:35:48 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSpeaker Odyssey 2018, The Speaker and Language Recognition Workshop\\u00a7r"}']}
{title:'Banitalebi-Dehkordi et al… (§72018§r)', author: 'Mehdi Banitalebi-Dehkordi; Amin Banitalebi-Dehkordi', display:{Lore:['[{"text": "arXiv:1803.04652", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMusic Genre Classification Using Spectral Analysis and Sparse Representation of the Signals\\u00a7r\\n\\n\\u00a78\\u00a7oMehdi Banitalebi-Dehkordi\\nAmin Banitalebi-Dehkordi\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1803.04652\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nJournal of Signal Processing Systems, 2014\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 13 Mar 2018 06:39:49 GMT)\\u00a7r"}']}
{title:'Scharenborg et al. (§72018§r)', author: 'Odette Scharenborg; Martha Larson', display:{Lore:['[{"text": "arXiv:1803.05058", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lInvestigating the Effect of Music and Lyrics on Spoken-Word Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oOdette Scharenborg\\nMartha Larson\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1803.05058\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 13 Mar 2018 21:40:59 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oPreliminary study\\u00a7r"}']}
{title:'Defferrard et al. (§72018§r)', author: 'Michaël Defferrard; Sharada P. Mohanty; Sean F. Carroll; Marcel Salathé', display:{Lore:['[{"text": "arXiv:1803.05337", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.IR\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lLearning to Recognize Musical Genre from Audio\\u00a7r\\n\\n\\u00a78\\u00a7oMicha\\u00ebl Defferrard\\nSharada P. Mohanty\\nSean F. Carroll\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1803.05337\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 13 Mar 2018 15:58:58 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7osubmitted to WWW\'18 after challenge round-1\\u00a7r"}']}
{title:'Dai et al. (§72018§r)', author: 'Shuqi Dai; Zheng Zhang; Gus G. Xia', display:{Lore:['[{"text": "arXiv:1803.06841", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMusic Style Transfer: A Position Paper\\u00a7r\\n\\n\\u00a78\\u00a7oShuqi Dai\\nZheng Zhang\\nGus G. Xia\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1803.06841\\u00a7r\\n\\nVersion:\\u00a77v4 (Thu, 19 Jul 2018 08:17:38 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oIn Proceeding of International Workshopon Musical Metacreation(MUME), 2018, Salamanca, Spain\\u00a7r"}']}
{title:'Jumelle et al. (§72018§r)', author: 'Maxime Jumelle; Taqiyeddine Sakmeche', display:{Lore:['[{"text": "arXiv:1803.08276", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSpeaker Clustering With Neural Networks And Audio Processing\\u00a7r\\n\\n\\u00a78\\u00a7oMaxime Jumelle\\nTaqiyeddine Sakmeche\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1803.08276\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 22 Mar 2018 09:21:56 GMT)\\u00a7r"}']}
{title:'Mobin et al. (§72018§r)', author: 'Shariq Mobin; Brian Cheung; Bruno Olshausen', display:{Lore:['[{"text": "arXiv:1803.08629", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.SP\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lGeneralization Challenges for Neural Architectures in Audio Source Separation\\u00a7r\\n\\n\\u00a78\\u00a7oShariq Mobin\\nBrian Cheung\\nBruno Olshausen\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1803.08629\\u00a7r\\n\\nVersion:\\u00a77v2 (Sun, 27 May 2018 17:03:09 GMT)\\u00a7r"}']}
{title:'Rao et al. (§72018§r)', author: 'Anyi Rao; Francis Lau', display:{Lore:['[{"text": "arXiv:1803.09033", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.MM\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAutomatic Music Accompanist\\u00a7r\\n\\n\\u00a78\\u00a7oAnyi Rao\\nFrancis Lau\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1803.09033\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 24 Mar 2018 02:06:11 GMT)\\u00a7r"}']}
{title:'Ding et al. (§72018§r)', author: 'Wenhao Ding; Liang He', display:{Lore:['[{"text": "arXiv:1803.09059", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMTGAN: Speaker Verification through Multitasking Triplet Generative Adversarial Networks\\u00a7r\\n\\n\\u00a78\\u00a7oWenhao Ding\\nLiang He\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1803.09059\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 24 Mar 2018 05:49:07 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7osubmitted to Interspeech 2018\\u00a7r"}']}
{title:'Bagchi et al. (§72018§r)', author: 'Deblin Bagchi; Peter Plantinga; Adam Stiff; Eric Fosler-Lussier', display:{Lore:['[{"text": "arXiv:1803.09816", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSpectral feature mapping with mimic loss for robust speech recognition\\u00a7r\\n\\n\\u00a78\\u00a7oDeblin Bagchi\\nPeter Plantinga\\nAdam Stiff\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1803.09816\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 26 Mar 2018 19:56:21 GMT)\\u00a7r"}']}
{title:'Chen et al. (§72018§r)', author: 'Szu-Jui Chen; Aswin Shanmugam Subramanian; Hainan Xu; Shinji Watanabe', display:{Lore:['[{"text": "arXiv:1803.10109", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lBuilding state-of-the-art distant speech recognition using the CHiME-4 challenge with a setup of speech enhancement baseline\\u00a7r\\n\\n\\u00a78\\u00a7oSzu-Jui Chen\\nAswin Shanmugam Subramanian\\nHainan Xu\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1803.10109\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 27 Mar 2018 14:33:53 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted for Interspeech 2018\\u00a7r"}']}
{title:'Wang et al. (§72018§r)', author: 'Ke Wang; Junbo Zhang; Sining Sun; Yujun Wang; Fei Xiang; Lei Xie', display:{Lore:['[{"text": "arXiv:1803.10132", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lInvestigating Generative Adversarial Networks based Speech Dereverberation for Robust Speech Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oKe Wang\\nJunbo Zhang\\nSining Sun\\n+ 2 others\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1803.10132\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.21437/Interspeech.2018-1780\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nProceedings of Interspeech, 2018, pp. 1581-1585\\u00a7r\\n\\nVersion:\\u00a77v3 (Thu, 25 Oct 2018 07:01:25 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oInterspeech 2018\\u00a7r"}']}
{title:'Wang et al. (§72018§r)', author: 'Ke Wang; Junbo Zhang; Yujun Wang; Lei Xie', display:{Lore:['[{"text": "arXiv:1803.10146", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lEmpirical Evaluation of Speaker Adaptation on DNN based Acoustic Model\\u00a7r\\n\\n\\u00a78\\u00a7oKe Wang\\nJunbo Zhang\\nYujun Wang\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1803.10146\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.21437/Interspeech.2018-1897\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nProceedings of Interspeech, 2018, pp. 2429-2433\\u00a7r\\n\\nVersion:\\u00a77v3 (Thu, 25 Oct 2018 07:11:54 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oInterspeech 2018\\u00a7r"}']}
{title:'Zhu et al. (§72018§r)', author: 'Boqing Zhu; Changjian Wang; Feng Liu; Jin Lei; Zengquan Lu; Yuxing Peng', display:{Lore:['[{"text": "arXiv:1803.10219", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lLearning Environmental Sounds with Multi-scale Convolutional Neural Network\\u00a7r\\n\\n\\u00a78\\u00a7oBoqing Zhu\\nChangjian Wang\\nFeng Liu\\n+ 2 others\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1803.10219\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 25 Mar 2018 04:46:17 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oaccepted by IJCNN 2018\\u00a7r"}']}
{title:'Barker et al. (§72018§r)', author: 'Jon Barker; Shinji Watanabe; Emmanuel Vincent; Jan Trmal', display:{Lore:['[{"text": "arXiv:1803.10609", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.AI\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lThe fifth \'CHiME\' Speech Separation and Recognition Challenge: Dataset, task and baselines\\u00a7r\\n\\n\\u00a78\\u00a7oJon Barker\\nShinji Watanabe\\nEmmanuel Vincent\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1803.10609\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 28 Mar 2018 13:51:09 GMT)\\u00a7r"}']}
{title:'Shan et al. (§72018§r)', author: 'Changhao Shan; Junbo Zhang; Yujun Wang; Lei Xie', display:{Lore:['[{"text": "arXiv:1803.10916", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAttention-based End-to-End Models for Small-Footprint Keyword Spotting\\u00a7r\\n\\n\\u00a78\\u00a7oChanghao Shan\\nJunbo Zhang\\nYujun Wang\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1803.10916\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 29 Mar 2018 03:32:59 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oattention-based model, end-to-end keyword spotting, convolutional neural networks, recurrent neural networks\\u00a7r"}']}
{title:'Chen et al. (§72018§r)', author: 'Zhuo Chen; Jinyu Li; Xiong Xiao; Takuya Yoshioka; Huaming Wang; Zhenghao Wang; Yifan Gong', display:{Lore:['[{"text": "arXiv:1803.10924", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lCracking the cocktail party problem by multi-beam deep attractor network\\u00a7r\\n\\n\\u00a78\\u00a7oZhuo Chen\\nJinyu Li\\nXiong Xiao\\n+ 3 others\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1803.10924\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 29 Mar 2018 04:42:26 GMT)\\u00a7r"}']}
{title:'Haque et al. (§72018§r)', author: 'Albert Haque; Michelle Guo; Prateek Verma', display:{Lore:['[{"text": "arXiv:1804.00047", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lConditional End-to-End Audio Transforms\\u00a7r\\n\\n\\u00a78\\u00a7oAlbert Haque\\nMichelle Guo\\nPrateek Verma\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1804.00047\\u00a7r\\n\\nVersion:\\u00a77v2 (Thu, 7 Jun 2018 06:37:44 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oInterspeech 2018\\u00a7r"}']}
{title:'Shahin (§72018§r)', author: 'Ismail Shahin', display:{Lore:['[{"text": "arXiv:1804.00155", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSpeaker Verification in Emotional Talking Environments based on Three-Stage Framework\\u00a7r\\n\\n\\u00a78\\u00a7oIsmail Shahin\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1804.00155\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 31 Mar 2018 10:49:43 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 1 figure, conference\\u00a7r"}']}
{title:'Shahin et al. (§72018§r)', author: 'Ismail Shahin; Ali Bou Nassif; Mohammed Bahutair', display:{Lore:['[{"text": "arXiv:1804.00981", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lEmirati-Accented Speaker Identification in each of Neutral and Shouted Talking Environments\\u00a7r\\n\\n\\u00a78\\u00a7oIsmail Shahin\\nAli Bou Nassif\\nMohammed Bahutair\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1804.00981\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1007/s10772-018-9502-0\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 31 Mar 2018 10:46:38 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o14 pages, 3 figures. arXiv admin note: text overlapwith arXiv:1707.00686\\u00a7r"}']}
{title:'Wang et al. (§72018§r)', author: 'Yun Wang; Juncheng Li; Florian Metze', display:{Lore:['[{"text": "arXiv:1804.01146", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lComparing the Max and Noisy-Or Pooling Functions in Multiple Instance Learning for Weakly Supervised Sequence Learning Tasks\\u00a7r\\n\\n\\u00a78\\u00a7oYun Wang\\nJuncheng Li\\nFlorian Metze\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1804.01146\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 3 Apr 2018 19:53:08 GMT)\\u00a7r"}']}
{title:'Bahuleyan (§72018§r)', author: 'Hareesh Bahuleyan', display:{Lore:['[{"text": "arXiv:1804.01149", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMusic Genre Classification using Machine Learning Techniques\\u00a7r\\n\\n\\u00a78\\u00a7oHareesh Bahuleyan\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1804.01149\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 3 Apr 2018 20:04:04 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o12 Pages, 6 figures, 4 tables\\u00a7r"}']}
{title:'Dalir et al. (§72018§r)', author: 'Ali Dalir; Ali Asghar Beheshti; Morteza Hoseini Masoom', display:{Lore:['[{"text": "arXiv:1804.01212", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lClassification of Vehicles Based on Audio Signals using Quadratic Discriminant Analysis and High Energy Feature Vectors\\u00a7r\\n\\n\\u00a78\\u00a7oAli Dalir\\nAli Asghar Beheshti\\nMorteza Hoseini Masoom\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1804.01212\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.5121/ijsc.2015.6105\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nInternational Journal on Soft Computing (IJSC) Vol.6, No. 1,\\n  February 2015\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 4 Apr 2018 02:19:27 GMT)\\u00a7r"}']}
{title:'Stoller et al. (§72018§r)', author: 'Daniel Stoller; Sebastian Ewert; Simon Dixon', display:{Lore:['[{"text": "arXiv:1804.01650", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lJointly Detecting and Separating Singing Voice: A Multi-Task Approach\\u00a7r\\n\\n\\u00a78\\u00a7oDaniel Stoller\\nSebastian Ewert\\nSimon Dixon\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1804.01650\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 5 Apr 2018 01:55:39 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o10 pages, 2 figures, accepted for the 14th International Conference on Latent Variable Analysis and Signal Separation\\u00a7r"}']}
{title:'Yela et al. (§72018§r)', author: 'Delia Fano Yela; Dan Stowell; Mark Sandler', display:{Lore:['[{"text": "arXiv:1804.02325", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDoes k Matter? k-NN Hubness Analysis for Kernel Additive Modelling Vocal Separation\\u00a7r\\n\\n\\u00a78\\u00a7oDelia Fano Yela\\nDan Stowell\\nMark Sandler\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1804.02325\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 6 Apr 2018 15:33:29 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oLVA-ICA 2018 - Feedback always welcome\\u00a7r"}']}
{title:'Gala et al. (§72018§r)', author: 'Deepak Gala; Nathan Lindsay; Liang Sun', display:{Lore:['[{"text": "arXiv:1804.03372", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.RO\\u00a7r, \\u00a7eeess.AS\\u00a7r, \\u00a7eeess.SP\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lRealtime Active Sound Source Localization for Unmanned Ground Robots Using a Self-Rotational Bi-Microphone Array\\u00a7r\\n\\n\\u00a78\\u00a7oDeepak Gala\\nNathan Lindsay\\nLiang Sun\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1804.03372\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 10 Apr 2018 07:04:33 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oThe paper is under revisionfor \'Journal of Intelligent Robotic Systems\'\\u00a7r"}']}
{title:'Ephrat et al. (§72018§r)', author: 'Ariel Ephrat; Inbar Mosseri; Oran Lang; Tali Dekel; Kevin Wilson; Avinatan Hassidim; William T. Freeman; Michael Rubinstein', display:{Lore:['[{"text": "arXiv:1804.03619", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CV\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lLooking to Listen at the Cocktail Party: A Speaker-Independent Audio-Visual Model for Speech Separation\\u00a7r\\n\\n\\u00a78\\u00a7oAriel Ephrat\\nInbar Mosseri\\nOran Lang\\n+ 4 others\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1804.03619\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1145/3197517.3201357\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nACM Trans. Graph. 37(4): 112:1-112:11 (2018)\\u00a7r\\n\\nVersion:\\u00a77v2 (Thu, 9 Aug 2018 21:22:37 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted to SIGGRAPH 2018. Project webpage: https://looking-to-listen.github.io\\u00a7r"}']}
{title:'Liu et al. (§72018§r)', author: 'Yi Liu; Liang He; Jia Liu; Michael T. Johnson', display:{Lore:['[{"text": "arXiv:1804.04862", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSpeaker Embedding Extraction with Phonetic Information\\u00a7r\\n\\n\\u00a78\\u00a7oYi Liu\\nLiang He\\nJia Liu\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1804.04862\\u00a7r\\n\\nVersion:\\u00a77v2 (Thu, 14 Jun 2018 13:17:27 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7osubmitted to Interspeech 2018 (accepted) and open-sourced. Please refer to Interspeech for the final version\\u00a7r"}']}
{title:'Richey et al. (§72018§r)', author: 'Colleen Richey; Maria A. Barrios; Zeb Armstrong; Chris Bartels; Horacio Franco; Martin Graciarena; Aaron Lawson; Mahesh Kumar Nandwana; Allen Stauffer; Julien van Hout; Paul Gamble; Jeff Hetherly; Cory Stephenson; Karl Ni', display:{Lore:['[{"text": "arXiv:1804.05053", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lVoices Obscured in Complex Environmental Settings (VOICES) corpus\\u00a7r\\n\\n\\u00a78\\u00a7oColleen Richey\\nMaria A. Barrios\\nZeb Armstrong\\n+ 10 others\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1804.05053\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 15 May 2018 23:52:22 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to Interspeech 2018\\u00a7r"}']}
{title:'Tsai et al. (§72018§r)', author: 'Che-Ping Tsai; Yi-Lin Tuan; Lin-shan Lee', display:{Lore:['[{"text": "arXiv:1804.05306", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lTranscribing Lyrics From Commercial Song Audio: The First Step Towards Singing Content Processing\\u00a7r\\n\\n\\u00a78\\u00a7oChe-Ping Tsai\\nYi-Lin Tuan\\nLin-shan Lee\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1804.05306\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 15 Apr 2018 05:50:27 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted as a conference paper at ICASSP 2018\\u00a7r"}']}
{title:'Takamoto et al. (§72018§r)', author: 'Ayaka Takamoto; Mitsuo Yoshida; Kyoji Umemura; Yuko Ichikawa', display:{Lore:['[{"text": "arXiv:1804.05486", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lComputing Information Quantity as Similarity Measure for Music Classification Task\\u00a7r\\n\\n\\u00a78\\u00a7oAyaka Takamoto\\nMitsuo Yoshida\\nKyoji Umemura\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1804.05486\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/ICAICTA.2017.8090990\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 16 Apr 2018 02:59:25 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oThe 2017 International Conference On Advanced Informatics: Concepts, Theory And Application (ICAICTA2017)\\u00a7r"}']}
{title:'Brown et al. (§72018§r)', author: 'Alexander Brown; Saurabh Garg; James Montgomery', display:{Lore:['[{"text": "arXiv:1804.05502", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAutomatic Rain and Cicada Chorus Filtering of Bird Acoustic Data\\u00a7r\\n\\n\\u00a78\\u00a7oAlexander Brown\\nSaurabh Garg\\nJames Montgomery\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1804.05502\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 16 Apr 2018 04:21:20 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o18 pages, 10 figures\\u00a7r"}']}
{title:'Milde et al. (§72018§r)', author: 'Benjamin Milde; Chris Biemann', display:{Lore:['[{"text": "arXiv:1804.06775", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lUnspeech: Unsupervised Speech Context Embeddings\\u00a7r\\n\\n\\u00a78\\u00a7oBenjamin Milde\\nChris Biemann\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1804.06775\\u00a7r\\n\\nVersion:\\u00a77v2 (Thu, 23 Aug 2018 10:33:44 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted at Interspeech 2018, Hyderabad, India. This version matches the final version submitted to the conference\\u00a7r"}']}
{title:'Huang et al. (§72018§r)', author: 'Che-Wei Huang; Shrikanth Narayanan', display:{Lore:['[{"text": "arXiv:1804.06779", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lShaking Acoustic Spectral Sub-bands Can Better Regularize Learning in Affective Computing\\u00a7r\\n\\n\\u00a78\\u00a7oChe-Wei Huang\\nShrikanth Narayanan\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1804.06779\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 18 Apr 2018 15:11:19 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oICASSP paper with follow-up exps\\u00a7r"}']}
{title:'Elowsson (§72018§r)', author: 'Anders Elowsson', display:{Lore:['[{"text": "arXiv:1804.07297", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDeep Layered Learning in MIR\\u00a7r\\n\\n\\u00a78\\u00a7oAnders Elowsson\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1804.07297\\u00a7r\\n\\nVersion:\\u00a77v3 (Mon, 10 Dec 2018 01:17:52 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted for publication. Feedback always welcome\\u00a7r"}']}
{title:'Kotecha et al. (§72018§r)', author: 'Nikhil Kotecha; Paul Young', display:{Lore:['[{"text": "arXiv:1804.07300", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lGenerating Music using an LSTM Network\\u00a7r\\n\\n\\u00a78\\u00a7oNikhil Kotecha\\nPaul Young\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1804.07300\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 18 Apr 2018 21:14:00 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o8 pages, 11 figures\\u00a7r"}']}
{title:'Elowsson (§72018§r)', author: 'Anders Elowsson', display:{Lore:['[{"text": "arXiv:1804.08167", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lTempo-Invariant Processing of Rhythm with Convolutional Neural Networks\\u00a7r\\n\\n\\u00a78\\u00a7oAnders Elowsson\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1804.08167\\u00a7r\\n\\nVersion:\\u00a77v2 (Sat, 28 Apr 2018 21:31:48 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oIncluded in doctoral dissertation \\"Modeling Music: Studiesof Music Transcription, Music Perception and Music Production\\". 26 pages, G5 format. Feedback always welcome\\u00a7r"}']}
{title:'Rafii et al. (§72018§r)', author: 'Zafar Rafii; Antoine Liutkus; Fabian-Robert Stöter; Stylianos Ioannis Mimilakis; Derry FitzGerald; Bryan Pardo', display:{Lore:['[{"text": "arXiv:1804.08300", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAn Overview of Lead and Accompaniment Separation in Music\\u00a7r\\n\\n\\u00a78\\u00a7oZafar Rafii\\nAntoine Liutkus\\nFabian-Robert St\\u00f6ter\\n+ 2 others\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1804.08300\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 23 Apr 2018 09:08:03 GMT)\\u00a7r"}']}
{title:'Hautamäki et al. (§72018§r)', author: 'Rosa González Hautamäki; Anssi Kanervisto; Ville Hautamäki; Tomi Kinnunen', display:{Lore:['[{"text": "arXiv:1804.08910", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CY\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lPerceptual Evaluation of the Effectiveness of Voice Disguise by Age Modification\\u00a7r\\n\\n\\u00a78\\u00a7oRosa Gonz\\u00e1lez Hautam\\u00e4ki\\nAnssi Kanervisto\\nVille Hautam\\u00e4ki\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1804.08910\\u00a7r\\n\\nVersion:\\u00a77v2 (Mon, 28 May 2018 09:04:08 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted to Speaker Odyssey 2018:The Speaker and Language Recognition Workshop\\u00a7r"}']}
{title:'Su (§72018§r)', author: 'Li Su', display:{Lore:['[{"text": "arXiv:1804.09202", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lVocal melody extraction using patch-based CNN\\u00a7r\\n\\n\\u00a78\\u00a7oLi Su\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1804.09202\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nProc. Int. Conf. Acoustic, Speech and Signal Processing (ICASSP),\\n  2018\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 24 Apr 2018 18:28:48 GMT)\\u00a7r"}']}
{title:'Shah et al. (§72018§r)', author: 'Ankit Shah; Anurag Kumar; Alexander G. Hauptmann; Bhiksha Raj', display:{Lore:['[{"text": "arXiv:1804.09288", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.MM\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Closer Look at Weak Label Learning for Audio Events\\u00a7r\\n\\n\\u00a78\\u00a7oAnkit Shah\\nAnurag Kumar\\nAlexander G. Hauptmann\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1804.09288\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 24 Apr 2018 23:04:35 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o10 pages\\u00a7r"}']}
{title:'Borghuis et al. (§72018§r)', author: 'Tijn Borghuis; Alessandro Tibo; Simone Conforti; Luca Canciello; Lorenzo Brusci; Paolo Frasconi', display:{Lore:['[{"text": "arXiv:1804.09808", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.MM\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lOff the Beaten Track: Using Deep Learning to Interpolate Between Music Genres\\u00a7r\\n\\n\\u00a78\\u00a7oTijn Borghuis\\nAlessandro Tibo\\nSimone Conforti\\n+ 2 others\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1804.09808\\u00a7r\\n\\nVersion:\\u00a77v2 (Wed, 2 May 2018 16:56:08 GMT)\\u00a7r"}']}
{title:'McFee et al. (§72018§r)', author: 'Brian McFee; Justin Salamon; Juan Pablo Bello', display:{Lore:['[{"text": "arXiv:1804.10070", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAdaptive pooling operators for weakly labeled sound event detection\\u00a7r\\n\\n\\u00a78\\u00a7oBrian McFee\\nJustin Salamon\\nJuan Pablo Bello\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1804.10070\\u00a7r\\n\\nVersion:\\u00a77v2 (Fri, 10 Aug 2018 16:35:17 GMT)\\u00a7r"}']}
{title:'Novoselov et al. (§72018§r)', author: 'Sergey Novoselov; Andrey Shulipa; Ivan Kremnev; Alexandr Kozlov; Vadim Shchemelinin', display:{Lore:['[{"text": "arXiv:1804.10080", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7eeess.AS\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lOn deep speaker embeddings for text-independent speaker recognition\\u00a7r\\n\\n\\u00a78\\u00a7oSergey Novoselov\\nAndrey Shulipa\\nIvan Kremnev\\nAlexandr Kozlov\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1804.10080\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 26 Apr 2018 14:22:01 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to Odyssey 2018\\u00a7r"}']}
{title:'Wang et al. (§72018§r)', author: 'Zhong-Qiu Wang; Jonathan Le Roux; DeLiang Wang; John R. Hershey', display:{Lore:['[{"text": "arXiv:1804.10204", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lEnd-to-End Speech Separation with Unfolded Iterative Phase Reconstruction\\u00a7r\\n\\n\\u00a78\\u00a7oZhong-Qiu Wang\\nJonathan Le Roux\\nDeLiang Wang\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1804.10204\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 26 Apr 2018 13:14:22 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to Interspeech 2018\\u00a7r"}']}
{title:'Hetherly et al. (§72018§r)', author: 'Jeff Hetherly; Paul Gamble; Maria Barrios; Cory Stephenson; Karl Ni', display:{Lore:['[{"text": "arXiv:1804.10669", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.AI\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDeep Speech Denoising with Vector Space Projections\\u00a7r\\n\\n\\u00a78\\u00a7oJeff Hetherly\\nPaul Gamble\\nMaria Barrios\\nCory Stephenson\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1804.10669\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 27 Apr 2018 20:08:38 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oarXiv admin note: text overlapwith arXiv:1705.04662\\u00a7r"}']}
{title:'Haque et al. (§72018§r)', author: 'Albert Haque; Corinna Fukushima', display:{Lore:['[{"text": "arXiv:1804.11046", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAutomatic Documentation of ICD Codes with Far-Field Speech Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oAlbert Haque\\nCorinna Fukushima\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1804.11046\\u00a7r\\n\\nVersion:\\u00a77v4 (Tue, 27 Nov 2018 01:51:13 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oMachine Learning for Health (ML4H) Workshop at NeurIPS 2018 arXiv:1811.07216\\u00a7r"}']}
{title:'Yi et al. (§72018§r)', author: 'Steven Yi; Victor Lazzarini; Edward Costello', display:{Lore:['[{"text": "arXiv:1804.11120", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lWAAW Csound\\u00a7r\\n\\n\\u00a78\\u00a7oSteven Yi\\nVictor Lazzarini\\nEdward Costello\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1804.11120\\u00a7r\\n\\nVersion:\\u00a77v2 (Wed, 2 May 2018 22:28:27 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o6 pages, 1 figure\\u00a7r"}']}
{title:'Grimm et al. (§72018§r)', author: 'Giso Grimm; Joanna Luberadzka; Volker Hohmann', display:{Lore:['[{"text": "arXiv:1804.11300", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA toolbox for rendering virtual acoustic environments in the context of audiology\\u00a7r\\n\\n\\u00a78\\u00a7oGiso Grimm\\nJoanna Luberadzka\\nVolker Hohmann\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1804.11300\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 30 Apr 2018 16:26:45 GMT)\\u00a7r"}']}
{title:'Zhao et al. (§72018§r)', author: 'Han Zhao; Shuayb Zarar; Ivan Tashev; Chin-Hui Lee', display:{Lore:['[{"text": "arXiv:1805.00579", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lConvolutional-Recurrent Neural Networks for Speech Enhancement\\u00a7r\\n\\n\\u00a78\\u00a7oHan Zhao\\nShuayb Zarar\\nIvan Tashev\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1805.00579\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 2 May 2018 00:06:53 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oICASSP 2018\\u00a7r"}']}
{title:'Shi et al. (§72018§r)', author: 'Xuan Shi; Xingjian Du; Mengyao Zhu', display:{Lore:['[{"text": "arXiv:1805.00645", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lEnd-to-End Residual CNN with L-GM Loss Speaker Verification System\\u00a7r\\n\\n\\u00a78\\u00a7oXuan Shi\\nXingjian Du\\nMengyao Zhu\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1805.00645\\u00a7r\\n\\nVersion:\\u00a77v2 (Sat, 1 Sep 2018 10:23:21 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages. arXiv admin note:text overlap with arXiv:1803.02988, arXiv:1705.02304, arXiv:1706.08612 by other authors\\u00a7r"}']}
{title:'Bello et al. (§72018§r)', author: 'Juan Pablo Bello; Claudio Silva; Oded Nov; R. Luke DuBois; Anish Arora; Justin Salamon; Charles Mydlarz; Harish Doraiswamy', display:{Lore:['[{"text": "arXiv:1805.00889", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CY\\u00a7r, \\u00a7acs.HC\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSONYC: A System for the Monitoring, Analysis and Mitigation of Urban Noise Pollution\\u00a7r\\n\\n\\u00a78\\u00a7oJuan Pablo Bello\\nClaudio Silva\\nOded Nov\\n+ 4 others\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1805.00889\\u00a7r\\n\\nVersion:\\u00a77v2 (Fri, 18 May 2018 19:23:01 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted May 2018, Communications ofthe ACM. This is the author\'s version of thework. It is posted here for your personal use. Not for redistribution. The definitive Version of Record will be published in Communications"}','{"text": "of the ACM\\u00a7r"}']}
{title:'Fourer et al. (§72018§r)', author: 'Dominique Fourer; Geoffroy Peeters', display:{Lore:['[{"text": "arXiv:1805.01201", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSingle-Channel Blind Source Separation for Singing Voice Detection: A Comparative Study\\u00a7r\\n\\n\\u00a78\\u00a7oDominique Fourer\\nGeoffroy Peeters\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1805.01201\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 3 May 2018 10:10:33 GMT)\\u00a7r"}']}
{title:'Song et al. (§72018§r)', author: 'Siyang Song; Shuimei Zhang; Björn Schuller; Linlin Shen; Michel Valstar', display:{Lore:['[{"text": "arXiv:1805.01259", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CV\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lNoise Invariant Frame Selection: A Simple Method to Address the Background Noise Problem for Text-independent Speaker Verification\\u00a7r\\n\\n\\u00a78\\u00a7oSiyang Song\\nShuimei Zhang\\nBj\\u00f6rn Schuller\\nLinlin Shen\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1805.01259\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 3 May 2018 12:35:06 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oPaper accepted in IJCNN 2018\\u00a7r"}']}
{title:'Mann et al. (§72018§r)', author: 'Richard Mann; William Mann', display:{Lore:['[{"text": "arXiv:1805.01297", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r, \\u00a75physics.med-ph\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lGeneration of Infra sound to replicate a wind turbine\\u00a7r\\n\\n\\u00a78\\u00a7oRichard Mann\\nWilliam Mann\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1805.01297\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 2 May 2018 16:53:07 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oKeywords: Infra sound, wind turbines, acoustics, sound measurement, sound generation\\u00a7r"}']}
{title:'Wang et al. (§72018§r)', author: 'Shuai Wang; Zili Huang; Yanmin Qian; Kai Yu', display:{Lore:['[{"text": "arXiv:1805.01344", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDeep Discriminant Analysis for i-vector Based Robust Speaker Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oShuai Wang\\nZili Huang\\nYanmin Qian\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1805.01344\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 3 May 2018 14:55:56 GMT)\\u00a7r"}']}
{title:'Liu et al. (§72018§r)', author: 'Bin Liu; Shuai Nie; Yaping Zhang; Dengfeng Ke; Shan Liang; Wenju Liu1', display:{Lore:['[{"text": "arXiv:1805.01357", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lBoosting Noise Robustness of Acoustic Model via Deep Adversarial Training\\u00a7r\\n\\n\\u00a78\\u00a7oBin Liu\\nShuai Nie\\nYaping Zhang\\n+ 2 others\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1805.01357\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 2 May 2018 06:06:24 GMT)\\u00a7r"}']}
{title:'Pereira et al. (§72018§r)', author: 'Ingryd Pereira; Diego Santos', display:{Lore:['[{"text": "arXiv:1805.01576", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lOMG Emotion Challenge - ExCouple Team\\u00a7r\\n\\n\\u00a78\\u00a7oIngryd Pereira\\nDiego Santos\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1805.01576\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 2 May 2018 21:53:23 GMT)\\u00a7r"}']}
{title:'Koutrouvelis et al. (§72018§r)', author: 'Andreas I. Koutrouvelis; Richard C. Hendriks; Richard Heusdens; Jesper Jensen', display:{Lore:['[{"text": "arXiv:1805.01692", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.IT\\u00a7r, \\u00a7eeess.AS\\u00a7r, \\u00a72math.IT\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Convex Approximation of the Relaxed Binaural Beamforming Optimization Problem\\u00a7r\\n\\n\\u00a78\\u00a7oAndreas I. Koutrouvelis\\nRichard C. Hendriks\\nRichard Heusdens\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1805.01692\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/TASLP.2018.2878618\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nIEEE/ACM Transactions on Audio, Speech and Language Processing,\\n  27(2), 321-331, 2019\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 4 May 2018 10:01:56 GMT)\\u00a7r"}']}
{title:'Takahashi et al. (§72018§r)', author: 'Naoya Takahashi; Nabarun Goswami; Yuki Mitsufuji', display:{Lore:['[{"text": "arXiv:1805.02410", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMMDenseLSTM: An efficient combination of convolutional and recurrent neural networks for audio source separation\\u00a7r\\n\\n\\u00a78\\u00a7oNaoya Takahashi\\nNabarun Goswami\\nYuki Mitsufuji\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1805.02410\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 29 May 2018 09:09:29 GMT)\\u00a7r"}']}
{title:'Wager et al. (§72018§r)', author: 'Sanna Wager; Lijiang Guo; Aswin Sivaraman; Minje Kim', display:{Lore:['[{"text": "arXiv:1805.02603", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Data-Driven Approach to Smooth Pitch Correction for Singing Voice in Pop Music\\u00a7r\\n\\n\\u00a78\\u00a7oSanna Wager\\nLijiang Guo\\nAswin Sivaraman\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1805.02603\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 7 May 2018 16:32:39 GMT)\\u00a7r"}']}
{title:'Çakır et al. (§72018§r)', author: 'Emre Çakır; Tuomas Virtanen', display:{Lore:['[{"text": "arXiv:1805.03647", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lEnd-to-End Polyphonic Sound Event Detection Using Convolutional Recurrent Neural Networks with Learned Time-Frequency Representation Input\\u00a7r\\n\\n\\u00a78\\u00a7oEmre \\u00c7ak\\u0131r\\nTuomas Virtanen\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1805.03647\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 9 May 2018 15:10:57 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oaccepted to IJCNN 2018\\u00a7r"}']}
{title:'Raissi et al. (§72018§r)', author: 'Tina Raissi; Alessandro Tibo; Paolo Bientinesi', display:{Lore:['[{"text": "arXiv:1805.05324", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lExtended pipeline for content-based feature engineering in music genre recognition\\u00a7r\\n\\n\\u00a78\\u00a7oTina Raissi\\nAlessandro Tibo\\nPaolo Bientinesi\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1805.05324\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/ICASSP.2018.8461807\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 12 May 2018 16:47:01 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oICASSP 2018\\u00a7r"}']}
{title:'Seki et al. (§72018§r)', author: 'Hiroshi Seki; Takaaki Hori; Shinji Watanabe; Jonathan Le Roux; John R. Hershey', display:{Lore:['[{"text": "arXiv:1805.05826", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7eeess.AS\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Purely End-to-end System for Multi-speaker Speech Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oHiroshi Seki\\nTakaaki Hori\\nShinji Watanabe\\nJonathan Le Roux\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1805.05826\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 15 May 2018 14:45:33 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oACL 2018\\u00a7r"}']}
{title:'Fahim et al. (§72018§r)', author: 'Abdullah Fahim; Prasanga N. Samarasinghe; Thushara D. Abhayapala', display:{Lore:['[{"text": "arXiv:1805.06234", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lPSD Estimation and Source Separation in a Noisy Reverberant Environment using a Spherical Microphone Array\\u00a7r\\n\\n\\u00a78\\u00a7oAbdullah Fahim\\nPrasanga N. Samarasinghe\\nThushara D. Abhayapala\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1805.06234\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/TASLP.2018.2835723\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 16 May 2018 10:30:31 GMT)\\u00a7r"}']}
{title:'Ito et al. (§72018§r)', author: 'Nobutaka Ito; Shoko Araki; Tomohiro Nakatani', display:{Lore:['[{"text": "arXiv:1805.06572", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lFastFCA: A Joint Diagonalization Based Fast Algorithm for Audio Source Separation Using A Full-Rank Spatial Covariance Model\\u00a7r\\n\\n\\u00a78\\u00a7oNobutaka Ito\\nShoko Araki\\nTomohiro Nakatani\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1805.06572\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 17 May 2018 01:47:14 GMT)\\u00a7r"}']}
{title:'Sedighi et al. (§72018§r)', author: 'Sara Sedighi; Shayan Ramhormozi', display:{Lore:['[{"text": "arXiv:1805.07628", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSparse Architectures for Text-Independent Speaker Verification Using Deep Neural Networks\\u00a7r\\n\\n\\u00a78\\u00a7oSara Sedighi\\nShayan Ramhormozi\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1805.07628\\u00a7r\\n\\nVersion:\\u00a77v2 (Thu, 9 Aug 2018 22:42:24 GMT)\\u00a7r"}']}
{title:'Mor et al. (§72018§r)', author: 'Noam Mor; Lior Wolf; Adam Polyak; Yaniv Taigman', display:{Lore:['[{"text": "arXiv:1805.07848", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.AI\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Universal Music Translation Network\\u00a7r\\n\\n\\u00a78\\u00a7oNoam Mor\\nLior Wolf\\nAdam Polyak\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1805.07848\\u00a7r\\n\\nVersion:\\u00a77v2 (Wed, 23 May 2018 17:23:54 GMT)\\u00a7r"}']}
{title:'Esling et al. (§72018§r)', author: 'Philippe Esling; Axel Chemla--Romeu-Santos; Adrien Bitton', display:{Lore:['[{"text": "arXiv:1805.08501", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lGenerative timbre spaces: regularizing variational auto-encoders with perceptual metrics\\u00a7r\\n\\n\\u00a78\\u00a7oPhilippe Esling\\nAxel Chemla--Romeu-Santos\\nAdrien Bitton\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1805.08501\\u00a7r\\n\\nVersion:\\u00a77v3 (Mon, 1 Oct 2018 14:07:04 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oDigital Audio Conference (DaFX 2018)\\u00a7r"}']}
{title:'Park et al. (§72018§r)', author: 'Sungheon Park; Taehoon Kim; Kyogu Lee; Nojun Kwak', display:{Lore:['[{"text": "arXiv:1805.08559", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMusic Source Separation Using Stacked Hourglass Networks\\u00a7r\\n\\n\\u00a78\\u00a7oSungheon Park\\nTaehoon Kim\\nKyogu Lee\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1805.08559\\u00a7r\\n\\nVersion:\\u00a77v2 (Fri, 22 Jun 2018 04:09:58 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oISMIR 2018, source code: https://github.com/sungheonpark/music_source_sepearation_SH_net\\u00a7r"}']}
{title:'Hibraj et al. (§72018§r)', author: 'Feliks Hibraj; Sebastiano Vascon; Thilo Stadelmann; Marcello Pelillo', display:{Lore:['[{"text": "arXiv:1805.08641", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSpeaker Clustering Using Dominant Sets\\u00a7r\\n\\n\\u00a78\\u00a7oFeliks Hibraj\\nSebastiano Vascon\\nThilo Stadelmann\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1805.08641\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 21 May 2018 16:11:52 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oICPR 2018\\u00a7r"}']}
{title:'Ito et al. (§72018§r)', author: 'Nobutaka Ito; Tomohiro Nakatani', display:{Lore:['[{"text": "arXiv:1805.09498", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lFastFCA-AS: Joint Diagonalization Based Acceleration of Full-Rank Spatial Covariance Analysis for Separating Any Number of Sources\\u00a7r\\n\\n\\u00a78\\u00a7oNobutaka Ito\\nTomohiro Nakatani\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1805.09498\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 24 May 2018 03:46:20 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to IWAENC2018\\u00a7r"}']}
{title:'Zhu et al. (§72018§r)', author: 'Boqing Zhu; Kele Xu; Dezhi Wang; Lilun Zhang; Bo Li; Yuxing Peng', display:{Lore:['[{"text": "arXiv:1805.09752", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lEnvironmental Sound Classification Based on Multi-temporal Resolution Convolutional Neural Network Combining with Multi-level Features\\u00a7r\\n\\n\\u00a78\\u00a7oBoqing Zhu\\nKele Xu\\nDezhi Wang\\n+ 2 others\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1805.09752\\u00a7r\\n\\nVersion:\\u00a77v2 (Thu, 14 Jun 2018 02:34:13 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmit to PCM 2018\\u00a7r"}']}
{title:'Wyse (§72018§r)', author: 'Lonce Wyse', display:{Lore:['[{"text": "arXiv:1805.10808", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lReal-valued parametric conditioning of an RNN for interactive sound synthesis\\u00a7r\\n\\n\\u00a78\\u00a7oLonce Wyse\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1805.10808\\u00a7r\\n\\nVersion:\\u00a77v2 (Wed, 30 May 2018 00:06:29 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oWyse, Lonce. (2018), Real-valued parametric conditioningof an RNN for real-time interactive sound synthesis. 6th International Workshopon Musical Metacreation, International Conference on Computational Creativity "}','{"text": "(ICCC) June 25-26, 2018, Salamanca, Spain\\u00a7r"}']}
{title:'Kelz et al. (§72018§r)', author: 'Rainer Kelz; Gerhard Widmer', display:{Lore:['[{"text": "arXiv:1805.10880", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lInvestigating Label Noise Sensitivity of Convolutional Neural Networks for Fine Grained Audio Signal Labelling\\u00a7r\\n\\n\\u00a78\\u00a7oRainer Kelz\\nGerhard Widmer\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1805.10880\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 28 May 2018 12:02:26 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oaccepted at ICASSP 2018\\u00a7r"}']}
{title:'Kelz et al. (§72018§r)', author: 'Rainer Kelz; Gerhard Widmer', display:{Lore:['[{"text": "arXiv:1805.11526", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lLearning to Transcribe by Ear\\u00a7r\\n\\n\\u00a78\\u00a7oRainer Kelz\\nGerhard Widmer\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1805.11526\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 29 May 2018 14:58:35 GMT)\\u00a7r"}']}
{title:'Morales et al. (§72018§r)', author: 'Nicolas Morales; Zhenyu Tang; Dinesh Manocha', display:{Lore:['[{"text": "arXiv:1805.11533", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lReceiver Placement for Speech Enhancement using Sound Propagation Optimization\\u00a7r\\n\\n\\u00a78\\u00a7oNicolas Morales\\nZhenyu Tang\\nDinesh Manocha\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1805.11533\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1016/j.apacoust.2019.04.037\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nApplied Acoustics Volume 155, 1 December 2019, Pages 53-62\\u00a7r\\n\\nVersion:\\u00a77v3 (Sat, 24 Nov 2018 22:26:40 GMT)\\u00a7r"}']}
{title:'Imoto (§72018§r)', author: 'Keisuke Imoto', display:{Lore:['[{"text": "arXiv:1805.11782", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAcoustic Scene Analysis Using Partially Connected Microphones Based on Graph Cepstrum\\u00a7r\\n\\n\\u00a78\\u00a7oKeisuke Imoto\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1805.11782\\u00a7r\\n\\nVersion:\\u00a77v2 (Sun, 8 Jul 2018 05:22:54 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted to EUSIPCO 2018\\u00a7r"}']}
{title:'Lee et al. (§72018§r)', author: 'Younggun Lee; Taesu Kim; Soo-Young Lee', display:{Lore:['[{"text": "arXiv:1806.00927", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lVoice Imitating Text-to-Speech Neural Networks\\u00a7r\\n\\n\\u00a78\\u00a7oYounggun Lee\\nTaesu Kim\\nSoo-Young Lee\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1806.00927\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 4 Jun 2018 02:10:48 GMT)\\u00a7r"}']}
{title:'Fahad et al. (§72018§r)', author: 'Md. Shah Fahad; Jainath Yadav; Gyadhar Pradhan; Akshay Deepak', display:{Lore:['[{"text": "arXiv:1806.00984", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.AI\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDNN-HMM based Speaker Adaptive Emotion Recognition using Proposed Epoch and MFCC Features\\u00a7r\\n\\n\\u00a78\\u00a7oMd. Shah Fahad\\nJainath Yadav\\nGyadhar Pradhan\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1806.00984\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1007/s00034-020-01486-8\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nCircuits, Systems, and Signal Processing 2020\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 4 Jun 2018 06:58:45 GMT)\\u00a7r"}']}
{title:'Baby et al. (§72018§r)', author: 'Deepak Baby; Sarah Verhulst', display:{Lore:['[{"text": "arXiv:1806.01145", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMachines hear better when they have ears\\u00a7r\\n\\n\\u00a78\\u00a7oDeepak Baby\\nSarah Verhulst\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1806.01145\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 5 Jun 2018 16:23:09 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o6 pages\\u00a7r"}']}
{title:'Lee et al. (§72018§r)', author: 'Kyungyun Lee; Keunwoo Choi; Juhan Nam', display:{Lore:['[{"text": "arXiv:1806.01180", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.IR\\u00a7r, \\u00a7acs.MM\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lRevisiting Singing Voice Detection: a Quantitative Review and the Future Outlook\\u00a7r\\n\\n\\u00a78\\u00a7oKyungyun Lee\\nKeunwoo Choi\\nJuhan Nam\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1806.01180\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 4 Jun 2018 16:25:37 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted to the 19th International Society of Music Information Retrieval (ISMIR) Conference, Paris, France, 2018\\u00a7r"}']}
{title:'Gong et al. (§72018§r)', author: 'Rong Gong; Xavier Serra', display:{Lore:['[{"text": "arXiv:1806.01665", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.IR\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSinging voice phoneme segmentation by hierarchically inferring syllable and phoneme onset positions\\u00a7r\\n\\n\\u00a78\\u00a7oRong Gong\\nXavier Serra\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1806.01665\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 5 Jun 2018 12:54:19 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oInterspeech 2018\\u00a7r"}']}
{title:'Kameoka et al. (§72018§r)', author: 'Hirokazu Kameoka; Takuhiro Kaneko; Kou Tanaka; Nobukatsu Hojo', display:{Lore:['[{"text": "arXiv:1806.02169", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lStarGAN-VC: Non-parallel many-to-many voice conversion with star generative adversarial networks\\u00a7r\\n\\n\\u00a78\\u00a7oHirokazu Kameoka\\nTakuhiro Kaneko\\nKou Tanaka\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1806.02169\\u00a7r\\n\\nVersion:\\u00a77v2 (Fri, 29 Jun 2018 06:19:34 GMT)\\u00a7r"}']}
{title:'Stoller et al. (§72018§r)', author: 'Daniel Stoller; Sebastian Ewert; Simon Dixon', display:{Lore:['[{"text": "arXiv:1806.03185", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lWave-U-Net: A Multi-Scale Neural Network for End-to-End Audio Source Separation\\u00a7r\\n\\n\\u00a78\\u00a7oDaniel Stoller\\nSebastian Ewert\\nSimon Dixon\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1806.03185\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7n19th International Society for Music Information Retrieval\\n  Conference (ISMIR 2018)\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 8 Jun 2018 14:29:08 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o7 pages (1 for references), 4 figures,3 tables. Appearing in the proceedings of the 19th International Society for Music Information Retrieval Conference (ISMIR 2018) (camera-ready version). Implementation available "}','{"text": "at https://github.com/f90/Wave-U-Net\\u00a7r"}']}
{title:'Donahue et al. (§72018§r)', author: 'Chris Donahue; Huanru Henry Mao; Julian McAuley', display:{Lore:['[{"text": "arXiv:1806.04278", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.NE\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lThe NES Music Database: A multi-instrumental dataset with expressive performance attributes\\u00a7r\\n\\n\\u00a78\\u00a7oChris Donahue\\nHuanru Henry Mao\\nJulian McAuley\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1806.04278\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 12 Jun 2018 00:28:50 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oPublished as a conference paper at ISMIR 2018\\u00a7r"}']}
{title:'Iqbal et al. (§72018§r)', author: 'Turab Iqbal; Yong Xu; Qiuqiang Kong; Wenwu Wang', display:{Lore:['[{"text": "arXiv:1806.04699", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lCapsule Routing for Sound Event Detection\\u00a7r\\n\\n\\u00a78\\u00a7oTurab Iqbal\\nYong Xu\\nQiuqiang Kong\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1806.04699\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 12 Jun 2018 18:22:20 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oPaper accepted for 26th European Signal Processing Conference (EUSIPCO 2018)\\u00a7r"}']}
{title:'Aljanaki et al. (§72018§r)', author: 'Anna Aljanaki; Mohammad Soleymani', display:{Lore:['[{"text": "arXiv:1806.04903", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA data-driven approach to mid-level perceptual musical feature modeling\\u00a7r\\n\\n\\u00a78\\u00a7oAnna Aljanaki\\nMohammad Soleymani\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1806.04903\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 13 Jun 2018 09:10:43 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o7 pages, ISMIR conference paper\\u00a7r"}']}
{title:'Chung et al. (§72018§r)', author: 'Joon Son Chung; Arsha Nagrani; Andrew Zisserman', display:{Lore:['[{"text": "arXiv:1806.05622", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CV\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lVoxCeleb2: Deep Speaker Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oJoon Son Chung\\nArsha Nagrani\\nAndrew Zisserman\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1806.05622\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.21437/Interspeech.2018-1929\\u00a7r\\n\\nVersion:\\u00a77v2 (Wed, 27 Jun 2018 01:49:17 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oTo appear in Interspeech 2018. The audio-visual dataset can be downloaded from http://www.robots.ox.ac.uk/ vgg/data/voxceleb2 . 1806.05622v2: minor fixes; 5 pages\\u00a7r"}']}
{title:'Nakajima et al. (§72018§r)', author: 'Hiroaki Nakajima; Yu Takahashi; Kazunobu Kondo; Yuji Hisaminato', display:{Lore:['[{"text": "arXiv:1806.05791", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMonaural source enhancement maximizing source-to-distortion ratio via automatic differentiation\\u00a7r\\n\\n\\u00a78\\u00a7oHiroaki Nakajima\\nYu Takahashi\\nKazunobu Kondo\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1806.05791\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 15 Jun 2018 02:38:40 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oThis paper is submitted to 16th International Workshop on Acoustic Signal Enhancement (IWAENC)\\u00a7r"}']}
{title:'Tralie (§72018§r)', author: 'Christopher J. Tralie', display:{Lore:['[{"text": "arXiv:1806.06347", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lCover Song Synthesis by Analogy\\u00a7r\\n\\n\\u00a78\\u00a7oChristopher J. Tralie\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1806.06347\\u00a7r\\n\\nVersion:\\u00a77v2 (Fri, 29 Jun 2018 09:58:26 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o11 pages, 5 figures\\u00a7r"}']}
{title:'Vogl et al. (§72018§r)', author: 'Richard Vogl; Gerhard Widmer; Peter Knees', display:{Lore:['[{"text": "arXiv:1806.06676", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.IR\\u00a7r, \\u00a7acs.NE\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lTowards multi-instrument drum transcription\\u00a7r\\n\\n\\u00a78\\u00a7oRichard Vogl\\nGerhard Widmer\\nPeter Knees\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1806.06676\\u00a7r\\n\\nVersion:\\u00a77v2 (Wed, 3 Oct 2018 11:56:38 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oPublished in Proceedings of the 21th International Conference on Digital Audio Effects (DAFx18),4 - 8 September, 2018, Aveiro, Portugal\\u00a7r"}']}
{title:'Gong et al. (§72018§r)', author: 'Rong Gong; Xavier Serra', display:{Lore:['[{"text": "arXiv:1806.06773", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.IR\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lTowards an efficient deep learning model for musical onset detection\\u00a7r\\n\\n\\u00a78\\u00a7oRong Gong\\nXavier Serra\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1806.06773\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 19 Jun 2018 10:12:23 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oPaper rejected by the 19th International Society for Music Information Retrieval Conference\\u00a7r"}']}
{title:'Kawahara et al. (§72018§r)', author: 'Hideki Kawahara; Ken-Ichi Sakakibara; Masanori Morise; Hideki Banno; Tomoki Toda; Toshio Irino', display:{Lore:['[{"text": "arXiv:1806.06812", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r, \\u00a7eeess.SP\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lFrequency domain variants of velvet noise and their application to speech processing and synthesis: with appendices\\u00a7r\\n\\n\\u00a78\\u00a7oHideki Kawahara\\nKen-Ichi Sakakibara\\nMasanori Morise\\n+ 2 others\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1806.06812\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 18 Jun 2018 16:35:47 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o11 pages, 20 figures, and 1table, Interspeech 2018\\u00a7r"}']}
{title:'Fonseca et al. (§72018§r)', author: 'Eduardo Fonseca; Rong Gong; Xavier Serra', display:{Lore:['[{"text": "arXiv:1806.07506", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Simple Fusion of Deep and Shallow Learning for Acoustic Scene Classification\\u00a7r\\n\\n\\u00a78\\u00a7oEduardo Fonseca\\nRong Gong\\nXavier Serra\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1806.07506\\u00a7r\\n\\nVersion:\\u00a77v2 (Wed, 27 Jun 2018 19:29:00 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oaccepted to SMC 2018; updated Figure 7, results unchanged\\u00a7r"}']}
{title:'Parcollet et al. (§72018§r)', author: 'Titouan Parcollet; Ying Zhang; Mohamed Morchid; Chiheb Trabelsi; Georges Linarès; Renato De Mori; Yoshua Bengio', display:{Lore:['[{"text": "arXiv:1806.07789", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lQuaternion Convolutional Neural Networks for End-to-End Automatic Speech Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oTitouan Parcollet\\nYing Zhang\\nMohamed Morchid\\n+ 3 others\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1806.07789\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 20 Jun 2018 15:16:43 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted at INTERSPEECH 2018\\u00a7r"}']}
{title:'Antognini et al. (§72018§r)', author: 'Joseph Antognini; Matt Hoffman; Ron J. Weiss', display:{Lore:['[{"text": "arXiv:1806.08002", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSynthesizing Diverse, High-Quality Audio Textures\\u00a7r\\n\\n\\u00a78\\u00a7oJoseph Antognini\\nMatt Hoffman\\nRon J. Weiss\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1806.08002\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 20 Jun 2018 21:51:32 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o10 pages, submitted to TASLP\\u00a7r"}']}
{title:'Kolbæk et al. (§72018§r)', author: 'Morten Kolbæk; Zheng-Hua Tan; Jesper Jensen', display:{Lore:['[{"text": "arXiv:1806.08404", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lOn the Relationship Between Short-Time Objective Intelligibility and Short-Time Spectral-Amplitude Mean-Square Error for Speech Enhancement\\u00a7r\\n\\n\\u00a78\\u00a7oMorten Kolb\\u00e6k\\nZheng-Hua Tan\\nJesper Jensen\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1806.08404\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/TASLP.2018.2877909\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nPublished in IEEE/ACM Trans. Audio, Speech, Lang. Process., vol.\\n  27, no. 2, pp. 283-295, 2018\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 4 Dec 2018 10:20:49 GMT)\\u00a7r"}']}
{title:'Karu et al. (§72018§r)', author: 'Martin Karu; Tanel Alumäe', display:{Lore:['[{"text": "arXiv:1806.08621", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.HC\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lWeakly Supervised Training of Speaker Identification Models\\u00a7r\\n\\n\\u00a78\\u00a7oMartin Karu\\nTanel Alum\\u00e4e\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1806.08621\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 22 Jun 2018 12:15:35 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oOdyssey 2018 The Speaker and Language Recognition Workshop\\u00a7r"}']}
{title:'Lattner et al. (§72018§r)', author: 'Stefan Lattner; Maarten Grachten; Gerhard Widmer', display:{Lore:['[{"text": "arXiv:1806.08686", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.AI\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Predictive Model for Music Based on Learned Interval Representations\\u00a7r\\n\\n\\u00a78\\u00a7oStefan Lattner\\nMaarten Grachten\\nGerhard Widmer\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1806.08686\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 22 Jun 2018 14:17:04 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oPaper accepted at the 19th International Society for Music Information Retrieval Conference, ISMIR 2018, Paris, France, September 23-27; 8 pages, 3 figures\\u00a7r"}']}
{title:'Sears et al. (§72018§r)', author: 'David R. W. Sears; Filip Korzeniowski; Gerhard Widmer', display:{Lore:['[{"text": "arXiv:1806.08724", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lEvaluating language models of tonal harmony\\u00a7r\\n\\n\\u00a78\\u00a7oDavid R. W. Sears\\nFilip Korzeniowski\\nGerhard Widmer\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1806.08724\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 22 Jun 2018 15:18:54 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o7 pages, 4 figures, 3 tables. To appear in Proceedings of the 19th International Society for Music Information Retrieval Conference (ISMIR), Paris, France\\u00a7r"}']}
{title:'Liu (§72018§r)', author: 'Gabrielle K. Liu', display:{Lore:['[{"text": "arXiv:1806.09010", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lEvaluating Gammatone Frequency Cepstral Coefficients with Neural Networks for Emotion Recognition from Speech\\u00a7r\\n\\n\\u00a78\\u00a7oGabrielle K. Liu\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1806.09010\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 23 Jun 2018 17:42:32 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 1 figure, 3 tables\\u00a7r"}']}
{title:'Dubey et al. (§72018§r)', author: 'Harishchandra Dubey; Abhijeet Sangwan; John H. L. Hansen', display:{Lore:['[{"text": "arXiv:1806.09301", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lRobust Feature Clustering for Unsupervised Speech Activity Detection\\u00a7r\\n\\n\\u00a78\\u00a7oHarishchandra Dubey\\nAbhijeet Sangwan\\nJohn H. L. Hansen\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1806.09301\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 25 Jun 2018 06:53:54 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 Pages, 4 Tables, 1 Figure\\u00a7r"}']}
{title:'Li et al. (§72018§r)', author: 'Chenxing Li; Tieqiang Wang; Shuang Xu; Bo Xu', display:{Lore:['[{"text": "arXiv:1806.09325", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSingle-channel Speech Dereverberation via Generative Adversarial Training\\u00a7r\\n\\n\\u00a78\\u00a7oChenxing Li\\nTieqiang Wang\\nShuang Xu\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1806.09325\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 25 Jun 2018 08:35:56 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages. Accepted by Interspeech 2018\\u00a7r"}']}
{title:'Hung et al. (§72018§r)', author: 'Yun-Ning Hung; Yi-Hsuan Yang', display:{Lore:['[{"text": "arXiv:1806.09587", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lFrame-level Instrument Recognition by Timbre and Pitch\\u00a7r\\n\\n\\u00a78\\u00a7oYun-Ning Hung\\nYi-Hsuan Yang\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1806.09587\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 25 Jun 2018 17:33:04 GMT)\\u00a7r"}']}
{title:'Sinclair (§72018§r)', author: 'Stephen Sinclair', display:{Lore:['[{"text": "arXiv:1806.09617", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.NE\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSounderfeit: Cloning a Physical Model using a Conditional Adversarial Autoencoder\\u00a7r\\n\\n\\u00a78\\u00a7oStephen Sinclair\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1806.09617\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.5216/mh.v18i1.53570\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nRevista M\\\\\'usica Hodie, [S.l.], v. 18, n. 1, p. 44 - 60, jun. 2018\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 25 Jun 2018 14:21:37 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oExtended conference paper published as article in Brazilian open-access journal Musica Hodie. 17 pages, 10 figures. ISSN 1676-3939. Dispon\\u00edvel em: https://www.revistas.ufg.br/musica/article/view/53570. arXiv admin note:"}','{"text": "substantial text overlap with arXiv:1802.08008\\u00a7r"}']}
{title:'Manzelli et al. (§72018§r)', author: 'Rachel Manzelli; Vijay Thakkar; Ali Siahkamari; Brian Kulis', display:{Lore:['[{"text": "arXiv:1806.09905", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lConditioning Deep Generative Raw Audio Models for Structured Automatic Music\\u00a7r\\n\\n\\u00a78\\u00a7oRachel Manzelli\\nVijay Thakkar\\nAli Siahkamari\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1806.09905\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 26 Jun 2018 11:10:19 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oPresented at theISMIR 2018 Conference\\u00a7r"}']}
{title:'Adel et al. (§72018§r)', author: 'Mohamed Adel; Mohamed Afify; Akram Gaballah', display:{Lore:['[{"text": "arXiv:1806.09932", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lText-Independent Speaker Verification Based on Deep Neural Networks and Segmental Dynamic Time Warping\\u00a7r\\n\\n\\u00a78\\u00a7oMohamed Adel\\nMohamed Afify\\nAkram Gaballah\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1806.09932\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 26 Jun 2018 12:05:33 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to SLT 2018\\u00a7r"}']}
{title:'Dieleman et al. (§72018§r)', author: 'Sander Dieleman; Aäron van den Oord; Karen Simonyan', display:{Lore:['[{"text": "arXiv:1806.10474", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lThe challenge of realistic music generation: modelling raw audio at scale\\u00a7r\\n\\n\\u00a78\\u00a7oSander Dieleman\\nA\\u00e4ron van den Oord\\nKaren Simonyan\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1806.10474\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 26 Jun 2018 16:48:59 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o13 pages, 2 figures, submitted to NIPS 2018\\u00a7r"}']}
{title:'Aljanaki et al. (§72018§r)', author: 'Anna Aljanaki; Gerhard Widmer', display:{Lore:['[{"text": "arXiv:1806.10570", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lModeling Majorness as a Perceptual Property in Music from Listener Ratings\\u00a7r\\n\\n\\u00a78\\u00a7oAnna Aljanaki\\nGerhard Widmer\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1806.10570\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 27 Jun 2018 17:05:48 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oshort paper for ICMPC proceedings\\u00a7r"}']}
{title:'Kroher et al. (§72018§r)', author: 'Nadine Kroher; Aggelos Pikrakis', display:{Lore:['[{"text": "arXiv:1807.00069", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lExploratory Analysis of a Large Flamenco Corpus using an Ensemble of Convolutional Neural Networks as a Structural Annotation Backend\\u00a7r\\n\\n\\u00a78\\u00a7oNadine Kroher\\nAggelos Pikrakis\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1807.00069\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 29 Jun 2018 21:05:19 GMT)\\u00a7r"}']}
{title:'Adavanne et al. (§72018§r)', author: 'Sharath Adavanne; Archontis Politis; Joonas Nikunen; Tuomas Virtanen', display:{Lore:['[{"text": "arXiv:1807.00129", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSound Event Localization and Detection of Overlapping Sources Using Convolutional Recurrent Neural Networks\\u00a7r\\n\\n\\u00a78\\u00a7oSharath Adavanne\\nArchontis Politis\\nJoonas Nikunen\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1807.00129\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/JSTSP.2018.2885636\\u00a7r\\n\\nVersion:\\u00a77v3 (Mon, 17 Dec 2018 12:47:10 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oPublished in Journal of Selected Topics in Signal Processing 2018\\u00a7r"}']}
{title:'Kumar et al. (§72018§r)', author: "Yaman Kumar; Mayank Aggarwal; Pratham Nawal; Shin'ichi Satoh; Rajiv Ratn Shah; Roger Zimmerman", display:{Lore:['[{"text": "arXiv:1807.00619", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lHarnessing AI for Speech Reconstruction using Multi-view Silent Video Feed\\u00a7r\\n\\n\\u00a78\\u00a7oYaman Kumar\\nMayank Aggarwal\\nPratham Nawal\\n+ 2 others\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1807.00619\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1145/3240508.3241911\\u00a7r\\n\\nVersion:\\u00a77v2 (Sun, 12 Aug 2018 08:05:04 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o2018 ACM Multimedia Conference (MM \'18), October 22\\u201326, 2018, Seoul, Republic of Korea\\u00a7r"}']}
{title:'Harrison et al. (§72018§r)', author: 'Peter M. C. Harrison; Marcus T. Pearce', display:{Lore:['[{"text": "arXiv:1807.00790", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAn energy-based generative sequence model for testing sensory theories of Western harmony\\u00a7r\\n\\n\\u00a78\\u00a7oPeter M. C. Harrison\\nMarcus T. Pearce\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1807.00790\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 2 Jul 2018 17:23:06 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o8 pages, 2 figures. To appear in Proceedings of the 19th International Society for Music Information Retrieval Conference (ISMIR), Paris, France, 2018\\u00a7r"}']}
{title:'Bataev et al. (§72018§r)', author: 'Vladimir Bataev; Maxim Korenevsky; Ivan Medennikov; Alexander Zatvornitskiy', display:{Lore:['[{"text": "arXiv:1807.00868", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lExploring End-to-End Techniques for Low-Resource Speech Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oVladimir Bataev\\nMaxim Korenevsky\\nIvan Medennikov\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1807.00868\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 2 Jul 2018 19:47:22 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted for Specom 2018, 20th International Conference on Speech and Computer\\u00a7r"}']}
{title:'Cancino-Chacón et al. (§72018§r)', author: 'Carlos Cancino-Chacón; Maarten Grachten', display:{Lore:['[{"text": "arXiv:1807.01080", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Computational Study of the Role of Tonal Tension in Expressive Piano Performance\\u00a7r\\n\\n\\u00a78\\u00a7oCarlos Cancino-Chac\\u00f3n\\nMaarten Grachten\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1807.01080\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 3 Jul 2018 10:59:23 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o6 pages, 2 figures, accepted as poster at the ICMPC15/ESCOM10 in Graz, Austria\\u00a7r"}']}
{title:'Liu et al. (§72018§r)', author: 'Jen-Yu Liu; Yi-Hsuan Yang', display:{Lore:['[{"text": "arXiv:1807.01898", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDenoising Auto-encoder with Recurrent Skip Connections and Residual Regression for Music Source Separation\\u00a7r\\n\\n\\u00a78\\u00a7oJen-Yu Liu\\nYi-Hsuan Yang\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1807.01898\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 5 Jul 2018 08:54:32 GMT)\\u00a7r"}']}
{title:'Wu et al. (§72018§r)', author: 'Cheng-Wei Wu; Jen-Yu Liu; Yi-Hsuan Yang; Jyh-Shing R. Jang', display:{Lore:['[{"text": "arXiv:1807.02254", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.AI\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSinging Style Transfer Using Cycle-Consistent Boundary Equilibrium Generative Adversarial Networks\\u00a7r\\n\\n\\u00a78\\u00a7oCheng-Wei Wu\\nJen-Yu Liu\\nYi-Hsuan Yang\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1807.02254\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nICML Workshop 2018 (Joint Music Workshop)\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 6 Jul 2018 04:32:18 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o3 pages, 3 figures, demo website: http://mirlab.org/users/haley.wu/cybegan\\u00a7r"}']}
{title:'Muth et al. (§72018§r)', author: 'Joachim Muth; Stefan Uhlich; Nathanael Perraudin; Thomas Kemp; Fabien Cardinaux; Yuki Mitsufuji', display:{Lore:['[{"text": "arXiv:1807.02710", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lImproving DNN-based Music Source Separation using Phase Features\\u00a7r\\n\\n\\u00a78\\u00a7oJoachim Muth\\nStefan Uhlich\\nNathanael Perraudin\\n+ 2 others\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1807.02710\\u00a7r\\n\\nVersion:\\u00a77v3 (Mon, 16 Jul 2018 06:09:41 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o7 pages, 9 figures, Joint Workshop on Machine Learning for Music at ICML, IJCAI/ECAI and AAMAS, 2018\\u00a7r"}']}
{title:'Pellegrini (§72018§r)', author: 'Thomas Pellegrini', display:{Lore:['[{"text": "arXiv:1807.02776", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDensely Connected CNNs for Bird Audio Detection\\u00a7r\\n\\n\\u00a78\\u00a7oThomas Pellegrini\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1807.02776\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.23919/EUSIPCO.2017.8081506\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 8 Jul 2018 08:16:33 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oChallenge solution source code available at https://github.com/topel/bird_audio_detection_challenge, Proc. EUSIPCO 2017\\u00a7r"}']}
{title:'Gómez et al. (§72018§r)', author: 'Emilia Gómez; Merlijn Blaauw; Jordi Bonada; Pritish Chandna; Helena Cuesta', display:{Lore:['[{"text": "arXiv:1807.03046", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.IR\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.MM\\u00a7r, \\u00a7eeess.AS\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDeep Learning for Singing Processing: Achievements, Challenges and Impact on Singers and Listeners\\u00a7r\\n\\n\\u00a78\\u00a7oEmilia G\\u00f3mez\\nMerlijn Blaauw\\nJordi Bonada\\nPritish Chandna\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1807.03046\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 9 Jul 2018 11:19:42 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oKeynote speech, 2018 Joint Workshop onMachine Learning for Music. The Federated Artificial Intelligence Meeting (FAIM), a joint workshop program of ICML, IJCAI/ECAI, and AAMAS\\u00a7r"}']}
{title:'Takamichi et al. (§72018§r)', author: 'Shinnosuke Takamichi; Yuki Saito; Norihiro Takamune; Daichi Kitamura; Hiroshi Saruwatari', display:{Lore:['[{"text": "arXiv:1807.03474", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lPhase reconstruction from amplitude spectrograms based on von-Mises-distribution deep neural network\\u00a7r\\n\\n\\u00a78\\u00a7oShinnosuke Takamichi\\nYuki Saito\\nNorihiro Takamune\\nDaichi Kitamura\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1807.03474\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 10 Jul 2018 04:14:55 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oTo appear in the Proc. of IWAENC2018\\u00a7r"}']}
{title:'Kitashov et al. (§72018§r)', author: 'Fedor Kitashov; Elizaveta Svitanko; Debojyoti Dutta', display:{Lore:['[{"text": "arXiv:1807.03625", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lForeign English Accent Adjustment by Learning Phonetic Patterns\\u00a7r\\n\\n\\u00a78\\u00a7oFedor Kitashov\\nElizaveta Svitanko\\nDebojyoti Dutta\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1807.03625\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 9 Jul 2018 17:38:23 GMT)\\u00a7r"}']}
{title:'Sarker et al. (§72018§r)', author: 'Md. Kamruzzaman Sarker; Kazi Md. Rokibul Alam; Md. Arifuzzaman', display:{Lore:['[{"text": "arXiv:1807.03909", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.AI\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lEmotion Recognition from Speech based on Relevant Feature and Majority Voting\\u00a7r\\n\\n\\u00a78\\u00a7oMd. Kamruzzaman Sarker\\nKazi Md. Rokibul Alam\\nMd. Arifuzzaman\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1807.03909\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/ICIEV.2014.6850685\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nInternational Conference on Informatics, Electronics & Vision\\n  (ICIEV) (2014) 1-5\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 11 Jul 2018 00:25:13 GMT)\\u00a7r"}']}
{title:'Park et al. (§72018§r)', author: 'Sangwook Park; Seongkyu Mun; Younglo Lee; David K. Han; Hanseok Ko', display:{Lore:['[{"text": "arXiv:1807.04970", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAnalysis Acoustic Features for Acoustic Scene Classification and Score fusion of multi-classification systems applied to DCASE 2016 challenge\\u00a7r\\n\\n\\u00a78\\u00a7oSangwook Park\\nSeongkyu Mun\\nYounglo Lee\\nDavid K. Han\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1807.04970\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nPark, S., Mun, S., Lee, Y., and Ko, H. (2016). Score fusion of\\n  classification systems for acoustic scene classification. IEEE AASP Challenge\\n  on Detection and Classification of Acoustic Scenes and Events (DCASE)\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 13 Jul 2018 08:26:54 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oThis article is related to a technical report for a challenge named Detection and Classification of Acoustic Scenes and Events 2016\\u00a7r"}']}
{title:'Stowell et al. (§72018§r)', author: 'Dan Stowell; Yannis Stylianou; Mike Wood; Hanna Pamuła; Hervé Glotin', display:{Lore:['[{"text": "arXiv:1807.05812", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAutomatic acoustic detection of birds through deep learning: the first Bird Audio Detection challenge\\u00a7r\\n\\n\\u00a78\\u00a7oDan Stowell\\nYannis Stylianou\\nMike Wood\\nHanna Pamu\\u0142a\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1807.05812\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1111/2041-210X.13103\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 16 Jul 2018 12:06:13 GMT)\\u00a7r"}']}
{title:'Madhavaraj et al. (§72018§r)', author: 'A Madhavaraj; T V Ananthapadmanabha; A G Ramakrishnan', display:{Lore:['[{"text": "arXiv:1807.05813", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSubjective and objective experiments on the influence of speaker\'s gender on the unvoiced segments\\u00a7r\\n\\n\\u00a78\\u00a7oA Madhavaraj\\nT V Ananthapadmanabha\\nA G Ramakrishnan\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1807.05813\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 16 Jul 2018 12:08:39 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o2 Figures, 5 Pages\\u00a7r"}']}
{title:'Sears et al. (§72018§r)', author: 'David R. W. Sears; Gerhard Widmer', display:{Lore:['[{"text": "arXiv:1807.06700", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lPsychological constraints on string-based methods for pattern discovery in polyphonic corpora\\u00a7r\\n\\n\\u00a78\\u00a7oDavid R. W. Sears\\nGerhard Widmer\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1807.06700\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 17 Jul 2018 23:04:17 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oExtended abstract\\u00a7r"}']}
{title:'Naithani et al. (§72018§r)', author: 'Gaurav Naithani; Joonas Nikunen; Lars Bramsløw; Tuomas Virtanen', display:{Lore:['[{"text": "arXiv:1807.06899", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDeep neural network based speech separation optimizing an objective estimator of intelligibility for low latency applications\\u00a7r\\n\\n\\u00a78\\u00a7oGaurav Naithani\\nJoonas Nikunen\\nLars Bramsl\\u00f8w\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1807.06899\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 18 Jul 2018 12:55:59 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oTo appear at InternationalWorkshop on Acoustic Signal Enhancement (IWAENC) 2018\\u00a7r"}']}
{title:'Morfi et al. (§72018§r)', author: 'Veronica Morfi; Dan Stowell', display:{Lore:['[{"text": "arXiv:1807.06972", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lData-Efficient Weakly Supervised Learning for Low-Resource Audio Event Detection Using Deep Learning\\u00a7r\\n\\n\\u00a78\\u00a7oVeronica Morfi\\nDan Stowell\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1807.06972\\u00a7r\\n\\nVersion:\\u00a77v2 (Fri, 26 Oct 2018 15:19:02 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 2 figures. arXiv admin note: substantial text overlap with arXiv:1807.03697\\u00a7r"}']}
{title:'Arzt et al. (§72018§r)', author: 'Andreas Arzt; Stefan Lattner', display:{Lore:['[{"text": "arXiv:1807.07278", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.MM\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAudio-to-Score Alignment using Transposition-invariant Features\\u00a7r\\n\\n\\u00a78\\u00a7oAndreas Arzt\\nStefan Lattner\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1807.07278\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 19 Jul 2018 08:13:34 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o19th International Society for Music Information Retrieval Conference, Paris, France, 2018\\u00a7r"}']}
{title:'Longueira et al. (§72018§r)', author: 'Frank Longueira; Sam Keene', display:{Lore:['[{"text": "arXiv:1807.07959", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Fully Convolutional Neural Network Approach to End-to-End Speech Enhancement\\u00a7r\\n\\n\\u00a78\\u00a7oFrank Longueira\\nSam Keene\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1807.07959\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 20 Jul 2018 01:20:06 GMT)\\u00a7r"}']}
{title:'Grachten et al. (§72018§r)', author: 'Maarten Grachten; Emmanuel Deruty; Alexandre Tanguy', display:{Lore:['[{"text": "arXiv:1807.08636", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAuto-adaptive Resonance Equalization using Dilated Residual Networks\\u00a7r\\n\\n\\u00a78\\u00a7oMaarten Grachten\\nEmmanuel Deruty\\nAlexandre Tanguy\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1807.08636\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 23 Jul 2018 14:18:56 GMT)\\u00a7r"}']}
{title:'Wang et al. (§72018§r)', author: 'Jun Wang; Jie Chen; Dan Su; Lianwu Chen; Meng Yu; Yanmin Qian; Dong Yu', display:{Lore:['[{"text": "arXiv:1807.08974", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDeep Extractor Network for Target Speaker Recovery From Single Channel Speech Mixtures\\u00a7r\\n\\n\\u00a78\\u00a7oJun Wang\\nJie Chen\\nDan Su\\n+ 3 others\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1807.08974\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 24 Jul 2018 09:08:29 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted in Interspeech 2018\\u00a7r"}']}
{title:'Park et al. (§72018§r)', author: 'Jiyoung Park; Donghyun Kim; Jongpil Lee; Sangeun Kum; Juhan Nam', display:{Lore:['[{"text": "arXiv:1807.09208", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Hybrid of Deep Audio Feature and i-vector for Artist Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oJiyoung Park\\nDonghyun Kim\\nJongpil Lee\\nSangeun Kum\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1807.09208\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 24 Jul 2018 16:14:09 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oJoint Workshop on Machine Learning for Music, the 34th International Conference on MachineLearning (ICML), 2018\\u00a7r"}']}
{title:'Fonseca et al. (§72018§r)', author: 'Eduardo Fonseca; Manoj Plakal; Frederic Font; Daniel P. W. Ellis; Xavier Favory; Jordi Pons; Xavier Serra', display:{Lore:['[{"text": "arXiv:1807.09902", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lGeneral-purpose Tagging of Freesound Audio with AudioSet Labels: Task Description, Dataset, and Baseline\\u00a7r\\n\\n\\u00a78\\u00a7oEduardo Fonseca\\nManoj Plakal\\nFrederic Font\\n+ 3 others\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1807.09902\\u00a7r\\n\\nVersion:\\u00a77v3 (Sun, 7 Oct 2018 02:25:28 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oCamera ready for DCASE Workshop 2018\\u00a7r"}']}
{title:'Dionelis et al. (§72018§r)', author: 'Nikolaos Dionelis; Mike Brookes', display:{Lore:['[{"text": "arXiv:1807.10236", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lModulation-Domain Kalman Filtering for Monaural Blind Speech Denoising and Dereverberation\\u00a7r\\n\\n\\u00a78\\u00a7oNikolaos Dionelis\\nMike Brookes\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1807.10236\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 26 Jul 2018 16:40:12 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o13 pages, 13 figures, Submitted to IEEE Transactions on Audio, Speech and Language Processing\\u00a7r"}']}
{title:'Serizel et al. (§72018§r)', author: 'Romain Serizel; Nicolas Turpault; Hamid Eghbal-Zadeh; Ankit Parag Shah', display:{Lore:['[{"text": "arXiv:1807.10501", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lLarge-Scale Weakly Labeled Semi-Supervised Sound Event Detection in Domestic Environments\\u00a7r\\n\\n\\u00a78\\u00a7oRomain Serizel\\nNicolas Turpault\\nHamid Eghbal-Zadeh\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1807.10501\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 27 Jul 2018 09:15:50 GMT)\\u00a7r"}']}
{title:'Saha et al. (§72018§r)', author: 'Pramit Saha; Praneeth Srungarapu; Sidney Fels', display:{Lore:['[{"text": "arXiv:1807.11089", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.CV\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lTowards Automatic Speech Identification from Vocal Tract Shape Dynamics in Real-time MRI\\u00a7r\\n\\n\\u00a78\\u00a7oPramit Saha\\nPraneeth Srungarapu\\nSidney Fels\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1807.11089\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 29 Jul 2018 17:36:08 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oTo appear in the INTERSPEECH 2018 Proceedings\\u00a7r"}']}
{title:'Vera-Diaz et al. (§72018§r)', author: 'Juan Manuel Vera-Diaz; Daniel Pizarro; Javier Macias-Guarasa', display:{Lore:['[{"text": "arXiv:1807.11094", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lTowards End-to-End Acoustic Localization using Deep Learning: from Audio Signal to Source Position Coordinates\\u00a7r\\n\\n\\u00a78\\u00a7oJuan Manuel Vera-Diaz\\nDaniel Pizarro\\nJavier Macias-Guarasa\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1807.11094\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.3390/s18103418\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nSensors 2018, (volume 18(10), 3418)\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 29 Jul 2018 18:22:38 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o18 pages, 3 figures, 8 tables\\u00a7r"}']}
{title:'Vidwans et al. (§72018§r)', author: 'Amruta Vidwans; Nachiket Deo; Preeti Rao', display:{Lore:['[{"text": "arXiv:1807.11138", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAudio segmentation based on melodic style with hand-crafted features and with convolutional neural networks\\u00a7r\\n\\n\\u00a78\\u00a7oAmruta Vidwans\\nNachiket Deo\\nPreeti Rao\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1807.11138\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 30 Jul 2018 01:34:20 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oThis work was done in 2015 at Indian Institute of Technology, Bombay, asa part of the ERC grant agreement 267583 (CompMusic) project\\u00a7r"}']}
{title:'Liu et al. (§72018§r)', author: 'Hao-Min Liu; Yi-Hsuan Yang', display:{Lore:['[{"text": "arXiv:1807.11161", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.AI\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lLead Sheet Generation and Arrangement by Conditional Generative Adversarial Network\\u00a7r\\n\\n\\u00a78\\u00a7oHao-Min Liu\\nYi-Hsuan Yang\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1807.11161\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 30 Jul 2018 03:48:04 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o7 pages, 7 figures and 4 tables\\u00a7r"}']}
{title:'Drossos et al. (§72018§r)', author: 'Konstantinos Drossos; Paul Magron; Stylianos Ioannis Mimilakis; Tuomas Virtanen', display:{Lore:['[{"text": "arXiv:1807.11298", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lHarmonic-Percussive Source Separation with Deep Neural Networks and Phase Recovery\\u00a7r\\n\\n\\u00a78\\u00a7oKonstantinos Drossos\\nPaul Magron\\nStylianos Ioannis Mimilakis\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1807.11298\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 30 Jul 2018 11:51:59 GMT)\\u00a7r"}']}
{title:'Gogate et al. (§72018§r)', author: 'Mandar Gogate; Ahsan Adeel; Ricard Marxer; Jon Barker; Amir Hussain', display:{Lore:['[{"text": "arXiv:1808.00060", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CV\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDNN driven Speaker Independent Audio-Visual Mask Estimation for Speech Separation\\u00a7r\\n\\n\\u00a78\\u00a7oMandar Gogate\\nAhsan Adeel\\nRicard Marxer\\nJon Barker\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1808.00060\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.21437/Interspeech.2018-2516\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 31 Jul 2018 20:12:15 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted for Interspeech 2018, 5 pages, 4 figures\\u00a7r"}']}
{title:'Chaudhuri et al. (§72018§r)', author: 'Sourish Chaudhuri; Joseph Roth; Daniel P. W. Ellis; Andrew Gallagher; Liat Kaver; Radhika Marvin; Caroline Pantofaru; Nathan Reale; Loretta Guarino Reid; Kevin Wilson; Zhonghua Xi', display:{Lore:['[{"text": "arXiv:1808.00606", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAVA-Speech: A Densely Labeled Dataset of Speech Activity in Movies\\u00a7r\\n\\n\\u00a78\\u00a7oSourish Chaudhuri\\nJoseph Roth\\nDaniel P. W. Ellis\\n+ 7 others\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1808.00606\\u00a7r\\n\\nVersion:\\u00a77v2 (Thu, 23 Aug 2018 23:28:38 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oInterspeech, 2018\\u00a7r"}']}
{title:'Kong et al. (§72018§r)', author: 'Qiuqiang Kong; Turab Iqbal; Yong Xu; Wenwu Wang; Mark D. Plumbley', display:{Lore:['[{"text": "arXiv:1808.00773", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDCASE 2018 Challenge Surrey Cross-Task convolutional neural network baseline\\u00a7r\\n\\n\\u00a78\\u00a7oQiuqiang Kong\\nTurab Iqbal\\nYong Xu\\nWenwu Wang\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1808.00773\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nWorkshop on Detection and Classification of Acoustic Scenes and\\n  Events (DCASE), 2018, pp. 217-221\\u00a7r\\n\\nVersion:\\u00a77v4 (Sat, 29 Sep 2018 19:49:54 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted by DCASE 2018 Workshop. 4pages. Source code available\\u00a7r"}']}
{title:'Gosain et al. (§72018§r)', author: 'Devashish Gosain; Soubhik Chakraborty; Mohit Sajwan', display:{Lore:['[{"text": "arXiv:1808.01603", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CE\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSimulating Raga Notes with a Markov Chain of Order 1-2\\u00a7r\\n\\n\\u00a78\\u00a7oDevashish Gosain\\nSoubhik Chakraborty\\nMohit Sajwan\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1808.01603\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 5 Aug 2018 12:13:47 GMT)\\u00a7r"}']}
{title:'Hou et al. (§72018§r)', author: 'Yuanbo Hou; Qiuqiang Kong; Shengchen Li', display:{Lore:['[{"text": "arXiv:1808.01935", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAudio Tagging With Connectionist Temporal Classification Model Using Sequential Labelled Data\\u00a7r\\n\\n\\u00a78\\u00a7oYuanbo Hou\\nQiuqiang Kong\\nShengchen Li\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1808.01935\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 6 Aug 2018 14:40:31 GMT)\\u00a7r"}']}
{title:'Gong et al. (§72018§r)', author: 'Yuan Gong; Christian Poellabauer', display:{Lore:['[{"text": "arXiv:1808.02939", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lTowards Learning Fine-Grained Disentangled Representations from Speech\\u00a7r\\n\\n\\u00a78\\u00a7oYuan Gong\\nChristian Poellabauer\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1808.02939\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 8 Aug 2018 20:59:26 GMT)\\u00a7r"}']}
{title:'Yeh et al. (§72018§r)', author: 'Cheng-chieh Yeh; Po-chun Hsu; Ju-chieh Chou; Hung-yi Lee; Lin-shan Lee', display:{Lore:['[{"text": "arXiv:1808.03113", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lRhythm-Flexible Voice Conversion without Parallel Data Using Cycle-GAN over Phoneme Posteriorgram Sequences\\u00a7r\\n\\n\\u00a78\\u00a7oCheng-chieh Yeh\\nPo-chun Hsu\\nJu-chieh Chou\\nHung-yi Lee\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1808.03113\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 9 Aug 2018 12:32:23 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o8 pages, 6 figures, Submitted to SLT 2018\\u00a7r"}']}
{title:'Oore et al. (§72018§r)', author: 'Sageev Oore; Ian Simon; Sander Dieleman; Douglas Eck; Karen Simonyan', display:{Lore:['[{"text": "arXiv:1808.03715", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lThis Time with Feeling: Learning Expressive Musical Performance\\u00a7r\\n\\n\\u00a78\\u00a7oSageev Oore\\nIan Simon\\nSander Dieleman\\nDouglas Eck\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1808.03715\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 10 Aug 2018 21:53:51 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oIncludes links to urls for audio samples\\u00a7r"}']}
{title:'Wei et al. (§72018§r)', author: 'Shengyun Wei; Kele Xu; Dezhi Wang; Feifan Liao; Huaimin Wang; Qiuqiang Kong', display:{Lore:['[{"text": "arXiv:1808.03883", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSample Mixed-Based Data Augmentation for Domestic Audio Tagging\\u00a7r\\n\\n\\u00a78\\u00a7oShengyun Wei\\nKele Xu\\nDezhi Wang\\n+ 2 others\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1808.03883\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 12 Aug 2018 02:34:55 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7osubmitted to the workshop of Detection and Classification of Acoustic Scenes and Events 2018 (DCASE 2018), 19-20 November 2018, Surrey, UK\\u00a7r"}']}
{title:'Alam et al. (§72018§r)', author: 'Shahnawaz Alam; Rohan Banerjee; Soma Bandyopadhyay', display:{Lore:['[{"text": "arXiv:1808.04411", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMurmur Detection Using Parallel Recurrent     Convolutional Neural Networks\\u00a7r\\n\\n\\u00a78\\u00a7oShahnawaz Alam\\nRohan Banerjee\\nSoma Bandyopadhyay\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1808.04411\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 13 Aug 2018 19:21:41 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o4 pages, Machine Learning for Medicine and Healthcare Workshop, KDD 2018\\u00a7r"}']}
{title:'Mohammadi et al. (§72018§r)', author: 'Seyed Hamidreza Mohammadi; Taehwan Kim', display:{Lore:['[{"text": "arXiv:1808.05294", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lInvestigation of Using Disentangled and Interpretable Representations for One-shot Cross-lingual Voice Conversion\\u00a7r\\n\\n\\u00a78\\u00a7oSeyed Hamidreza Mohammadi\\nTaehwan Kim\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1808.05294\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 15 Aug 2018 22:21:42 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oProceedings of Interspeech 2018\\u00a7r"}']}
{title:'Korzeniowski et al. (§72018§r)', author: 'Filip Korzeniowski; Gerhard Widmer', display:{Lore:['[{"text": "arXiv:1808.05335", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lImproved Chord Recognition by Combining Duration and Harmonic Language Models\\u00a7r\\n\\n\\u00a78\\u00a7oFilip Korzeniowski\\nGerhard Widmer\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1808.05335\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 16 Aug 2018 03:34:27 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oPublished at 19thInternational Society for Music Information Retrieval Conference\\u00a7r"}']}
{title:'Korzeniowski et al. (§72018§r)', author: 'Filip Korzeniowski; Gerhard Widmer', display:{Lore:['[{"text": "arXiv:1808.05340", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lGenre-Agnostic Key Classification With Convolutional Neural Networks\\u00a7r\\n\\n\\u00a78\\u00a7oFilip Korzeniowski\\nGerhard Widmer\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1808.05340\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 16 Aug 2018 03:57:03 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oPublished at the 19th International Society for Music Information Retrieval Conference\\u00a7r"}']}
{title:'Korzeniowski et al. (§72018§r)', author: 'Filip Korzeniowski; Gerhard Widmer', display:{Lore:['[{"text": "arXiv:1808.05341", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAutomatic Chord Recognition with Higher-Order Harmonic Language Modelling\\u00a7r\\n\\n\\u00a78\\u00a7oFilip Korzeniowski\\nGerhard Widmer\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1808.05341\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 16 Aug 2018 04:10:02 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oFirst published in the Proceedings of the 26th European Signal Processing Conference (EUSIPCO-2018) in 2018, published by EURASIP\\u00a7r"}']}
{title:'Fu et al. (§72018§r)', author: 'Szu-Wei Fu; Yu Tsao; Hsin-Te Hwang; Hsin-Min Wang', display:{Lore:['[{"text": "arXiv:1808.05344", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.AI\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lQuality-Net: An End-to-End Non-intrusive Speech Quality Assessment Model based on BLSTM\\u00a7r\\n\\n\\u00a78\\u00a7oSzu-Wei Fu\\nYu Tsao\\nHsin-Te Hwang\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1808.05344\\u00a7r\\n\\nVersion:\\u00a77v2 (Fri, 17 Aug 2018 08:02:30 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted in Interspeech2018\\u00a7r"}']}
{title:'Dubey et al. (§72018§r)', author: 'Harishchandra Dubey; Abhijeet Sangwan; John H. L. Hansen', display:{Lore:['[{"text": "arXiv:1808.06045", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lRobust Speaker Clustering using Mixtures of von Mises-Fisher Distributions for Naturalistic Audio Streams\\u00a7r\\n\\n\\u00a78\\u00a7oHarishchandra Dubey\\nAbhijeet Sangwan\\nJohn H. L. Hansen\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1808.06045\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 18 Aug 2018 05:45:13 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 2 figures\\u00a7r"}']}
{title:'Suvorov et al. (§72018§r)', author: 'Dmitry Suvorov; Ge Dong; Roman Zhukov', display:{Lore:['[{"text": "arXiv:1808.06429", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDeep Residual Network for Sound Source Localization in the Time Domain\\u00a7r\\n\\n\\u00a78\\u00a7oDmitry Suvorov\\nGe Dong\\nRoman Zhukov\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1808.06429\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nJournal of Engineering and Applied Sciences, 2018, vol. 13, no.\\n  13, P. 5096-5104\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 20 Aug 2018 12:54:51 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o8 pages, 8 figures\\u00a7r"}']}
{title:'Kao et al. (§72018§r)', author: 'Chieh-Chi Kao; Weiran Wang; Ming Sun; Chao Wang', display:{Lore:['[{"text": "arXiv:1808.06627", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lR-CRNN: Region-based Convolutional Recurrent Neural Network for Audio Event Detection\\u00a7r\\n\\n\\u00a78\\u00a7oChieh-Chi Kao\\nWeiran Wang\\nMing Sun\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1808.06627\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 20 Aug 2018 18:01:52 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted by Interspeech 2018\\u00a7r"}']}
{title:'Wang et al. (§72018§r)', author: 'Weiran Wang; Chieh-chi Kao; Chao Wang', display:{Lore:['[{"text": "arXiv:1808.06676", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA simple model for detection of rare sound events\\u00a7r\\n\\n\\u00a78\\u00a7oWeiran Wang\\nChieh-chi Kao\\nChao Wang\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1808.06676\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 20 Aug 2018 19:59:09 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted by Interspeech 2018\\u00a7r"}']}
{title:'Arik et al. (§72018§r)', author: 'Sercan O. Arik; Heewoo Jun; Gregory Diamos', display:{Lore:['[{"text": "arXiv:1808.06719", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lFast Spectrogram Inversion using Multi-head Convolutional Neural Networks\\u00a7r\\n\\n\\u00a78\\u00a7oSercan O. Arik\\nHeewoo Jun\\nGregory Diamos\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1808.06719\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/LSP.2018.2880284\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 6 Nov 2018 04:53:41 GMT)\\u00a7r"}']}
{title:'Liu et al. (§72018§r)', author: 'Yi Liu; Liang He; Weiwei Liu; Jia Liu', display:{Lore:['[{"text": "arXiv:1808.07120", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lExploring a Unified Attention-Based Pooling Framework for Speaker Verification\\u00a7r\\n\\n\\u00a78\\u00a7oYi Liu\\nLiang He\\nWeiwei Liu\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1808.07120\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 21 Aug 2018 20:28:46 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted by ISCSLP 2018\\u00a7r"}']}
{title:'Zhou et al. (§72018§r)', author: 'Cong Zhou; Michael Horgan; Vivek Kumar; Cristina Vasco; Dan Darcy', display:{Lore:['[{"text": "arXiv:1808.08311", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lVoice Conversion with Conditional SampleRNN\\u00a7r\\n\\n\\u00a78\\u00a7oCong Zhou\\nMichael Horgan\\nVivek Kumar\\nCristina Vasco\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1808.08311\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.21437/Interspeech.2018-1121\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 24 Aug 2018 21:14:40 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted at Interspeech 2018, Hyderabad, India. This version matches the final version submitted to the conference\\u00a7r"}']}
{title:'He et al. (§72018§r)', author: 'Liang He; Xianhong Chen; Can Xu; Jia Liu', display:{Lore:['[{"text": "arXiv:1808.08344", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMultiobjective Optimization Training of PLDA for Speaker Verification\\u00a7r\\n\\n\\u00a78\\u00a7oLiang He\\nXianhong Chen\\nCan Xu\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1808.08344\\u00a7r\\n\\nVersion:\\u00a77v2 (Sun, 11 Nov 2018 14:41:45 GMT)\\u00a7r"}']}
{title:'Zhang et al. (§72018§r)', author: 'Zhichao Zhang; Shugong Xu; Shan Cao; Shunqing Zhang', display:{Lore:['[{"text": "arXiv:1808.08405", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDeep Convolutional Neural Network with Mixup for Environmental Sound Classification\\u00a7r\\n\\n\\u00a78\\u00a7oZhichao Zhang\\nShugong Xu\\nShan Cao\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1808.08405\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 25 Aug 2018 10:55:04 GMT)\\u00a7r"}']}
{title:'Lee et al. (§72018§r)', author: 'Moa Lee; Joon Hyuk Chang', display:{Lore:['[{"text": "arXiv:1808.08702", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.AI\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAugmenting Bottleneck Features of Deep Neural Network Employing Motor State for Speech Recognition at Humanoid Robots\\u00a7r\\n\\n\\u00a78\\u00a7oMoa Lee\\nJoon Hyuk Chang\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1808.08702\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 27 Aug 2018 06:41:47 GMT)\\u00a7r"}']}
{title:'Lostanlen et al. (§72018§r)', author: 'Vincent Lostanlen; Joakim Andén; Mathieu Lagrange', display:{Lore:['[{"text": "arXiv:1808.09730", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lExtended playing techniques: The next milestone in musical instrument recognition\\u00a7r\\n\\n\\u00a78\\u00a7oVincent Lostanlen\\nJoakim And\\u00e9n\\nMathieu Lagrange\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1808.09730\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nProceedings of the 5th International Workshop on Digital Libraries\\n  for Musicology (DLfM), Paris, France, September 2018. Published by ACM\'s\\n  International Conference Proceedings Series (ICPS)\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 29 Aug 2018 11:16:30 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o10 pages, 9 figures. The source code to reproduce the experiments of this paper is made available at: https://www.github.com/mathieulagrange/dlfm2018\\u00a7r"}']}
{title:'Xiao et al. (§72018§r)', author: 'Zhongzhe Xiao; Ying Chen; Weibei Dou; Zhi Tao; Liming Chen', display:{Lore:['[{"text": "arXiv:1808.10095", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMES-P: an Emotional Tonal Speech Dataset in Mandarin Chinese with Distal and Proximal Labels\\u00a7r\\n\\n\\u00a78\\u00a7oZhongzhe Xiao\\nYing Chen\\nWeibei Dou\\nZhi Tao\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1808.10095\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 16 Oct 2018 08:42:41 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmission to IEEE Transactions\\u00a7r"}']}
{title:'Xiao et al. (§72018§r)', author: 'Zhongzhe Xiao; Ying Chen; Zhi Tao', display:{Lore:['[{"text": "arXiv:1808.10144", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lContribution of Glottal Waveform in Speech Emotion: A Comparative Pairwise Investigation\\u00a7r\\n\\n\\u00a78\\u00a7oZhongzhe Xiao\\nYing Chen\\nZhi Tao\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1808.10144\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 30 Aug 2018 07:09:04 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmission to PIC2018\\u00a7r"}']}
{title:'Kolbæk (§72018§r)', author: 'Morten Kolbæk', display:{Lore:['[{"text": "arXiv:1808.10620", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSingle-Microphone Speech Enhancement and Separation Using Deep Learning\\u00a7r\\n\\n\\u00a78\\u00a7oMorten Kolb\\u00e6k\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1808.10620\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 4 Dec 2018 11:55:07 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oPhD Thesis. 233 pages\\u00a7r"}']}
{title:'Pascual et al. (§72018§r)', author: 'Santiago Pascual; Antonio Bonafonte; Joan Serrà', display:{Lore:['[{"text": "arXiv:1808.10678", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSelf-Attention Linguistic-Acoustic Decoder\\u00a7r\\n\\n\\u00a78\\u00a7oSantiago Pascual\\nAntonio Bonafonte\\nJoan Serr\\u00e0\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1808.10678\\u00a7r\\n\\nVersion:\\u00a77v2 (Mon, 5 Nov 2018 16:43:15 GMT)\\u00a7r"}']}
{title:'Pascual et al. (§72018§r)', author: 'Santiago Pascual; Antonio Bonafonte; Joan Serrà; Jose A. Gonzalez', display:{Lore:['[{"text": "arXiv:1808.10687", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lWhispered-to-voiced Alaryngeal Speech Conversion with Generative Adversarial Networks\\u00a7r\\n\\n\\u00a78\\u00a7oSantiago Pascual\\nAntonio Bonafonte\\nJoan Serr\\u00e0\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1808.10687\\u00a7r\\n\\nVersion:\\u00a77v2 (Mon, 5 Nov 2018 16:34:49 GMT)\\u00a7r"}']}
{title:'Alsouda et al. (§72018§r)', author: 'Yasser Alsouda; Sabri Pllana; Arianit Kurti', display:{Lore:['[{"text": "arXiv:1809.00238", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Machine Learning Driven IoT Solution for Noise Classification in Smart Cities\\u00a7r\\n\\n\\u00a78\\u00a7oYasser Alsouda\\nSabri Pllana\\nArianit Kurti\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1809.00238\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 1 Sep 2018 19:11:53 GMT)\\u00a7r"}']}
{title:'Bittner et al. (§72018§r)', author: 'Rachel M. Bittner; Brian McFee; Juan P. Bello', display:{Lore:['[{"text": "arXiv:1809.00381", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMultitask Learning for Fundamental Frequency Estimation in Music\\u00a7r\\n\\n\\u00a78\\u00a7oRachel M. Bittner\\nBrian McFee\\nJuan P. Bello\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1809.00381\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 2 Sep 2018 20:03:09 GMT)\\u00a7r"}']}
{title:'Yu et al. (§72018§r)', author: 'Yi Yu; Samuel Beuret; Donghuo Zeng; Keizo Oyama', display:{Lore:['[{"text": "arXiv:1809.00502", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.MM\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDeep Learning of Human Perception in Audio Event Classification\\u00a7r\\n\\n\\u00a78\\u00a7oYi Yu\\nSamuel Beuret\\nDonghuo Zeng\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1809.00502\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 3 Sep 2018 08:47:32 GMT)\\u00a7r"}']}
{title:'Song et al. (§72018§r)', author: 'Qun Song; Chaojie Gu; Rui Tan', display:{Lore:['[{"text": "arXiv:1809.00531", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDeep Room Recognition Using Inaudible Echos\\u00a7r\\n\\n\\u00a78\\u00a7oQun Song\\nChaojie Gu\\nRui Tan\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1809.00531\\u00a7r\\n\\nVersion:\\u00a77v2 (Fri, 7 Sep 2018 09:11:05 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o29 pages\\u00a7r"}']}
{title:'Papadopoulos et al. (§72018§r)', author: 'Timos Papadopoulos; Stephen J. Roberts; Katherine J. Willis', display:{Lore:['[{"text": "arXiv:1809.01133", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CY\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAutomated bird sound recognition in realistic settings\\u00a7r\\n\\n\\u00a78\\u00a7oTimos Papadopoulos\\nStephen J. Roberts\\nKatherine J. Willis\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1809.01133\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 4 Sep 2018 10:26:37 GMT)\\u00a7r"}']}
{title:'Shahin et al. (§72018§r)', author: 'Ismail Shahin; Ali Bou Nassif', display:{Lore:['[{"text": "arXiv:1809.01721", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.AI\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lThree-Stage Speaker Verification Architecture in Emotional Talking Environments\\u00a7r\\n\\n\\u00a78\\u00a7oIsmail Shahin\\nAli Bou Nassif\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1809.01721\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1007/s10772-018-9543-4\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nInternational Journal of Speech Technology, 2018\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 3 Sep 2018 09:25:35 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o18 pages. arXiv admin note:substantial text overlap with arXiv:1804.00155, arXiv:1707.00137\\u00a7r"}']}
{title:'Morgado et al. (§72018§r)', author: 'Pedro Morgado; Nuno Vasconcelos; Timothy Langlois; Oliver Wang', display:{Lore:['[{"text": "arXiv:1809.02587", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CV\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.MM\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSelf-Supervised Generation of Spatial Audio for 360 Video\\u00a7r\\n\\n\\u00a78\\u00a7oPedro Morgado\\nNuno Vasconcelos\\nTimothy Langlois\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1809.02587\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 7 Sep 2018 17:25:59 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oTo appear in NIPS 2018\\u00a7r"}']}
{title:'Fang et al. (§72018§r)', author: 'Fuming Fang; Junichi Yamagishi; Isao Echizen; Md Sahidullah; Tomi Kinnunen', display:{Lore:['[{"text": "arXiv:1809.04274", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CR\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lTransforming acoustic characteristics to deceive playback spoofing countermeasures of speaker verification systems\\u00a7r\\n\\n\\u00a78\\u00a7oFuming Fang\\nJunichi Yamagishi\\nIsao Echizen\\nMd Sahidullah\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1809.04274\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nIEEE International Workshop on Information Forensics and Security\\n  (WIFS), 2018\\u00a7r\\n\\nVersion:\\u00a77v2 (Thu, 13 Sep 2018 04:51:55 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted at WIFS2018\\u00a7r"}']}
{title:'Rajaratnam et al. (§72018§r)', author: 'Krishan Rajaratnam; Kunal Shah; Jugal Kalita', display:{Lore:['[{"text": "arXiv:1809.04397", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.CR\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.NE\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lIsolated and Ensemble Audio Preprocessing Methods for Detecting Adversarial Examples against Automatic Speech Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oKrishan Rajaratnam\\nKunal Shah\\nJugal Kalita\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1809.04397\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 11 Sep 2018 05:12:15 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted for oral presentation at the 30th Conference onComputational Linguistics and Speech Processing (ROCLING 2018)\\u00a7r"}']}
{title:'Dorfer et al. (§72018§r)', author: 'Matthias Dorfer; Jr. Jan Hajič; Gerhard Widmer', display:{Lore:['[{"text": "arXiv:1809.05689", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAttention as a Perspective for Learning Tempo-invariant Audio Queries\\u00a7r\\n\\n\\u00a78\\u00a7oMatthias Dorfer\\nJr. Jan Haji\\u010d\\nGerhard Widmer\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1809.05689\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 15 Sep 2018 10:03:15 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oThe 2018 Joint Workshop onMachine Learning for Music\\u00a7r"}']}
{title:'Liu et al. (§72018§r)', author: 'Yu-Jeh Liu; Jonah Casebeer; Ivan Dokmanić', display:{Lore:['[{"text": "arXiv:1809.05862", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lCocktails, but no party: multipath-enabled private audio\\u00a7r\\n\\n\\u00a78\\u00a7oYu-Jeh Liu\\nJonah Casebeer\\nIvan Dokmani\\u0107\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1809.05862\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 16 Sep 2018 12:28:19 GMT)\\u00a7r"}']}
{title:'Ibarrola et al. (§72018§r)', author: 'Francisco Ibarrola; Leandro Di Persia; Ruben Spies', display:{Lore:['[{"text": "arXiv:1809.07375", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSwitching divergences for spectral learning in blind speech dereverberation\\u00a7r\\n\\n\\u00a78\\u00a7oFrancisco Ibarrola\\nLeandro Di Persia\\nRuben Spies\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1809.07375\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 19 Sep 2018 19:09:46 GMT)\\u00a7r"}']}
{title:'Brunner et al. (§72018§r)', author: 'Gino Brunner; Yuyi Wang; Roger Wattenhofer; Sumu Zhao', display:{Lore:['[{"text": "arXiv:1809.07575", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSymbolic Music Genre Transfer with CycleGAN\\u00a7r\\n\\n\\u00a78\\u00a7oGino Brunner\\nYuyi Wang\\nRoger Wattenhofer\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1809.07575\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 20 Sep 2018 11:20:11 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oPaper accepted at the 30th International Conference on Tools with Artificial Intelligence, ICTAI 2018, Volos, Greece\\u00a7r"}']}
{title:'Brunner et al. (§72018§r)', author: 'Gino Brunner; Andres Konrad; Yuyi Wang; Roger Wattenhofer', display:{Lore:['[{"text": "arXiv:1809.07600", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMIDI-VAE: Modeling Dynamics and Instrumentation of Music with Applications to Style Transfer\\u00a7r\\n\\n\\u00a78\\u00a7oGino Brunner\\nAndres Konrad\\nYuyi Wang\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1809.07600\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 20 Sep 2018 13:02:30 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oPaper accepted at the 19th International Society for Music Information Retrieval Conference, ISMIR 2018, Paris, France\\u00a7r"}']}
{title:'Wang et al. (§72018§r)', author: 'Qiongqiong Wang; Koji Okabe; Kong Aik Lee; Hitoshi Yamamoto; Takafumi Koshinaka', display:{Lore:['[{"text": "arXiv:1809.09311", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAttention Mechanism in Speaker Recognition: What Does It Learn in Deep Speaker Embedding?\\u00a7r\\n\\n\\u00a78\\u00a7oQiongqiong Wang\\nKoji Okabe\\nKong Aik Lee\\nHitoshi Yamamoto\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1809.09311\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 25 Sep 2018 04:12:18 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSLT 2018 (Workshop on Spoken Language Technology)\\u00a7r"}']}
{title:'Plantinga et al. (§72018§r)', author: 'Peter Plantinga; Deblin Bagchi; Eric Fosler-Lussier', display:{Lore:['[{"text": "arXiv:1809.09756", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAn Exploration of Mimic Architectures for Residual Network Based Spectral Mapping\\u00a7r\\n\\n\\u00a78\\u00a7oPeter Plantinga\\nDeblin Bagchi\\nEric Fosler-Lussier\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1809.09756\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 25 Sep 2018 23:20:32 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oPublished in the IEEE 2018 Workshop on Spoken Language Technology (SLT 2018)\\u00a7r"}']}
{title:'Bear et al. (§72018§r)', author: 'Helen L Bear; Emmanouil Benetos', display:{Lore:['[{"text": "arXiv:1809.10047", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAn extensible cluster-graph taxonomy for open set sound scene analysis\\u00a7r\\n\\n\\u00a78\\u00a7oHelen L Bear\\nEmmanouil Benetos\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1809.10047\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 26 Sep 2018 15:04:17 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oTo be presented at Detection and Classification of Audio Scenes and Events (DCASE) workshop, November 2018\\u00a7r"}']}
{title:'Zeinali et al. (§72018§r)', author: 'Hossein Zeinali; Lukas Burget; Hossein Sameti; Jan Cernocky', display:{Lore:['[{"text": "arXiv:1809.11068", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSpoken Pass-Phrase Verification in the i-vector Space\\u00a7r\\n\\n\\u00a78\\u00a7oHossein Zeinali\\nLukas Burget\\nHossein Sameti\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1809.11068\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nProc. Odyssey 2018 The Speaker and Language Recognition Workshop\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 28 Sep 2018 14:49:27 GMT)\\u00a7r"}']}
{title:'Bitton et al. (§72018§r)', author: 'Adrien Bitton; Philippe Esling; Axel Chemla-Romeu-Santos', display:{Lore:['[{"text": "arXiv:1810.00222", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lModulated Variational auto-Encoders for many-to-many musical timbre transfer\\u00a7r\\n\\n\\u00a78\\u00a7oAdrien Bitton\\nPhilippe Esling\\nAxel Chemla-Romeu-Santos\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1810.00222\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 29 Sep 2018 15:31:23 GMT)\\u00a7r"}']}
{title:'Lostanlen (§72018§r)', author: 'Vincent Lostanlen', display:{Lore:['[{"text": "arXiv:1810.00790", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lEigentriads and Eigenprogressions on the Tonnetz\\u00a7r\\n\\n\\u00a78\\u00a7oVincent Lostanlen\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1810.00790\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 1 Oct 2018 16:21:55 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oProceedings of the Late-Breaking / Demo session (LBD) of the International Society of Music Information Retrieval (ISMIR). September 2018, Paris, France. Source code at github.com/lostanlen/ismir2018-lbd\\u00a7r"}']}
{title:'Solovyev et al. (§72018§r)', author: 'Roman A. Solovyev; Maxim Vakhrushev; Alexander Radionov; Vladimir Aliev; Alexey A. Shvets', display:{Lore:['[{"text": "arXiv:1810.02364", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.HC\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDeep Learning Approaches for Understanding Simple Speech Commands\\u00a7r\\n\\n\\u00a78\\u00a7oRoman A. Solovyev\\nMaxim Vakhrushev\\nAlexander Radionov\\nVladimir Aliev\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1810.02364\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 4 Oct 2018 17:42:18 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o12 page, 4 figures, 1 table\\u00a7r"}']}
{title:'Koh et al. (§72018§r)', author: 'Eunjeong Stella Koh; Shlomo Dubnov; Dustin Wright', display:{Lore:['[{"text": "arXiv:1810.03226", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.MM\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lRethinking Recurrent Latent Variable Model for Music Composition\\u00a7r\\n\\n\\u00a78\\u00a7oEunjeong Stella Koh\\nShlomo Dubnov\\nDustin Wright\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1810.03226\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 7 Oct 2018 23:22:56 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oPublished as a conference paper at IEEE MMSP 2018\\u00a7r"}']}
{title:'Shen et al. (§72018§r)', author: 'Yu-Han Shen; Ke-Xin He; Wei-Qiang Zhang', display:{Lore:['[{"text": "arXiv:1810.03986", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CV\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSAM-GCNN: A Gated Convolutional Neural Network with Segment-Level Attention Mechanism for Home Activity Monitoring\\u00a7r\\n\\n\\u00a78\\u00a7oYu-Han Shen\\nKe-Xin He\\nWei-Qiang Zhang\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1810.03986\\u00a7r\\n\\nVersion:\\u00a77v2 (Wed, 14 Nov 2018 09:42:40 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o6 pages, accepted by ISSPIT 2018\\u00a7r"}']}
{title:'Kitić et al. (§72018§r)', author: 'Srđan Kitić; Alexandre Guérin', display:{Lore:['[{"text": "arXiv:1810.04080", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lTRAMP: Tracking by a Real-time AMbisonic-based Particle filter\\u00a7r\\n\\n\\u00a78\\u00a7oSr\\u0111an Kiti\\u0107\\nAlexandre Gu\\u00e9rin\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1810.04080\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 4 Dec 2018 21:44:30 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oIn Proceedings of the LOCATA ChallengeWorkshop - a satellite event of IWAENC 2018 (arXiv:1811.08482 )\\u00a7r"}']}
{title:'Toro (§72018§r)', author: 'Mauricio Toro', display:{Lore:['[{"text": "arXiv:1810.04276", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.AI\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lCurrent Trends and Future Research Directions for Interactive Music\\u00a7r\\n\\n\\u00a78\\u00a7oMauricio Toro\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1810.04276\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nJournal of Theoretical & Applied Information Technologies 96(16),\\n  2018\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 5 Oct 2018 02:53:26 GMT)\\u00a7r"}']}
{title:'Shahin et al. (§72018§r)', author: 'Ismail Shahin; Ali Bou Nassif; Shibani Hamsa', display:{Lore:['[{"text": "arXiv:1810.04908", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lNovel Cascaded Gaussian Mixture Model-Deep Neural Network Classifier for Speaker Identification in Emotional Talking Environments\\u00a7r\\n\\n\\u00a78\\u00a7oIsmail Shahin\\nAli Bou Nassif\\nShibani Hamsa\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1810.04908\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1007/s00521-018-3760-2\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 11 Oct 2018 09:09:57 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o15 pages\\u00a7r"}']}
{title:'Harb et al. (§72018§r)', author: 'Robert Harb; Franz Pernkopf', display:{Lore:['[{"text": "arXiv:1810.06897", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSound event detection using weakly-labeled semi-supervised data with GCRNNS, VAT and Self-Adaptive Label Refinement\\u00a7r\\n\\n\\u00a78\\u00a7oRobert Harb\\nFranz Pernkopf\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1810.06897\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 16 Oct 2018 09:36:25 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted at DCASE 2018 Workshop for oral presentation\\u00a7r"}']}
{title:'Chen et al. (§72018§r)', author: 'Xuanda Chen; Ziyu Xiong; Jian Hu', display:{Lore:['[{"text": "arXiv:1810.07030", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lThe Trajectory of Voice Onset Time with Vocal Aging\\u00a7r\\n\\n\\u00a78\\u00a7oXuanda Chen\\nZiyu Xiong\\nJian Hu\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1810.07030\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.21437/Interspeech.2018-60\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nInterspeech 2018\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 15 Oct 2018 08:30:27 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oconference\\u00a7r"}']}
{title:'Crestel et al. (§72018§r)', author: 'Léopold Crestel; Philippe Esling; Lena Heng; Stephen McAdams', display:{Lore:['[{"text": "arXiv:1810.08611", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA database linking piano and orchestral MIDI scores with application to automatic projective orchestration\\u00a7r\\n\\n\\u00a78\\u00a7oL\\u00e9opold Crestel\\nPhilippe Esling\\nLena Heng\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1810.08611\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 19 Oct 2018 12:50:20 GMT)\\u00a7r"}']}
{title:'Du et al. (§72018§r)', author: 'Zhihao Du; Xueliang Zhang; Jiqing Han', display:{Lore:['[{"text": "arXiv:1810.09067", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.MM\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lInvestigation of Monaural Front-End Processing for Robust ASR without Retraining or Joint-Training\\u00a7r\\n\\n\\u00a78\\u00a7oZhihao Du\\nXueliang Zhang\\nJiqing Han\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1810.09067\\u00a7r\\n\\nVersion:\\u00a77v2 (Wed, 24 Oct 2018 14:57:33 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 0 figures, 4 tables, conference\\u00a7r"}']}
{title:'Balemarthy et al. (§72018§r)', author: 'Siddhardha Balemarthy; Atul Sajjanhar; James Xi Zheng', display:{Lore:['[{"text": "arXiv:1810.09078", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lOur Practice Of Using Machine Learning To Recognize Species By Voice\\u00a7r\\n\\n\\u00a78\\u00a7oSiddhardha Balemarthy\\nAtul Sajjanhar\\nJames Xi Zheng\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1810.09078\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 22 Oct 2018 04:23:17 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o16 pages\\u00a7r"}']}
{title:'Stowell et al. (§72018§r)', author: 'Dan Stowell; Tereza Petrusková; Martin Šálek; Pavel Linhart', display:{Lore:['[{"text": "arXiv:1810.09273", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAutomatic acoustic identification of individual animals: Improving generalisation across species and recording conditions\\u00a7r\\n\\n\\u00a78\\u00a7oDan Stowell\\nTereza Petruskov\\u00e1\\nMartin \\u0160\\u00e1lek\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1810.09273\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 22 Oct 2018 13:39:23 GMT)\\u00a7r"}']}
{title:'Défossez et al. (§72018§r)', author: 'Alexandre Défossez; Neil Zeghidour; Nicolas Usunier; Léon Bottou; Francis Bach', display:{Lore:['[{"text": "arXiv:1810.09785", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSING: Symbol-to-Instrument Neural Generator\\u00a7r\\n\\n\\u00a78\\u00a7oAlexandre D\\u00e9fossez\\nNeil Zeghidour\\nNicolas Usunier\\nL\\u00e9on Bottou\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1810.09785\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nConference on Neural Information Processing Systems (NIPS), Dec\\n  2018, Montr{\\\\\'e}al, Canada\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 23 Oct 2018 11:27:06 GMT)\\u00a7r"}']}
{title:'Masada et al. (§72018§r)', author: 'Kristen Masada; Razvan Bunescu', display:{Lore:['[{"text": "arXiv:1810.10002", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lChord Recognition in Symbolic Music: A Segmental CRF Model, Segment-Level Features, and Comparative Evaluations on Classical and Popular Music\\u00a7r\\n\\n\\u00a78\\u00a7oKristen Masada\\nRazvan Bunescu\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1810.10002\\u00a7r\\n\\nVersion:\\u00a77v2 (Fri, 26 Oct 2018 02:05:13 GMT)\\u00a7r"}']}
{title:'Pons et al. (§72018§r)', author: 'Jordi Pons; Joan Serrà; Xavier Serra', display:{Lore:['[{"text": "arXiv:1810.10274", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.AI\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lTraining neural audio classifiers with few data\\u00a7r\\n\\n\\u00a78\\u00a7oJordi Pons\\nJoan Serr\\u00e0\\nXavier Serra\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1810.10274\\u00a7r\\n\\nVersion:\\u00a77v3 (Sat, 3 Nov 2018 16:42:07 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oCode: https://github.com/jordipons/neural-classifiers-with-few-audio/\\u00a7r"}']}
{title:'Zong et al. (§72018§r)', author: 'Zefang Zong; Hao Li; Qi Wang', display:{Lore:['[{"text": "arXiv:1810.10662", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMulti-Channel Auto-Encoder for Speech Emotion Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oZefang Zong\\nHao Li\\nQi Wang\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1810.10662\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 25 Oct 2018 00:22:59 GMT)\\u00a7r"}']}
{title:'Sheng et al. (§72018§r)', author: 'Leyuan Sheng; Evgeniy N. Pavlovskiy', display:{Lore:['[{"text": "arXiv:1810.10989", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lReducing over-smoothness in speech synthesis using Generative Adversarial Networks\\u00a7r\\n\\n\\u00a78\\u00a7oLeyuan Sheng\\nEvgeniy N. Pavlovskiy\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1810.10989\\u00a7r\\n\\nVersion:\\u00a77v3 (Mon, 17 Dec 2018 13:33:40 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted by Siberian Symposium on Data Science and Engineering (SSDSE) 2018\\u00a7r"}']}
{title:'Yang et al. (§72018§r)', author: 'Xuerui Yang; Jiwei Li; Xi Zhou', display:{Lore:['[{"text": "arXiv:1810.11352", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA novel pyramidal-FSMN architecture with lattice-free MMI for speech recognition\\u00a7r\\n\\n\\u00a78\\u00a7oXuerui Yang\\nJiwei Li\\nXi Zhou\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1810.11352\\u00a7r\\n\\nVersion:\\u00a77v2 (Wed, 31 Oct 2018 06:03:17 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 3 figures, 2 tables. 2019 ICASSP submitted\\u00a7r"}']}
{title:'Oh et al. (§72018§r)', author: 'Jaehoon Oh; Duyeon Kim; Se-Young Yun', display:{Lore:['[{"text": "arXiv:1810.11520", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r, \\u00a7eeess.SP\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSpectrogram-channels u-net: a source separation model viewing each channel as the spectrogram of each source\\u00a7r\\n\\n\\u00a78\\u00a7oJaehoon Oh\\nDuyeon Kim\\nSe-Young Yun\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1810.11520\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 30 Oct 2018 15:08:52 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o3 figures\\u00a7r"}']}
{title:'Noman et al. (§72018§r)', author: 'Fuad Noman; Chee-Ming Ting; Sh-Hussain Salleh; Hernando Ombao', display:{Lore:['[{"text": "arXiv:1810.11573", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r, \\u00a7eeess.SP\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lShort-segment heart sound classification using an ensemble of deep convolutional neural networks\\u00a7r\\n\\n\\u00a78\\u00a7oFuad Noman\\nChee-Ming Ting\\nSh-Hussain Salleh\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1810.11573\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/ICASSP.2019.8682668\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 27 Oct 2018 01:32:27 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o8 pages, 1 figure, conference\\u00a7r"}']}
{title:'Shen et al. (§72018§r)', author: 'Yu-Han Shen; Ke-Xin He; Wei-Qiang Zhang', display:{Lore:['[{"text": "arXiv:1810.11939", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lLearning How to Listen: A Temporal-Frequential Attention Model for Sound Event Detection\\u00a7r\\n\\n\\u00a78\\u00a7oYu-Han Shen\\nKe-Xin He\\nWei-Qiang Zhang\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1810.11939\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 29 Oct 2018 03:37:55 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, to be submitted to ICASSP 2019\\u00a7r"}']}
{title:'Ferguson et al. (§72018§r)', author: 'Eric L. Ferguson; Stefan B. Williams; Craig T. Jin', display:{Lore:['[{"text": "arXiv:1810.11990", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lImproved multipath time delay estimation using cepstrum subtraction\\u00a7r\\n\\n\\u00a78\\u00a7oEric L. Ferguson\\nStefan B. Williams\\nCraig T. Jin\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1810.11990\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 29 Oct 2018 07:53:40 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oFinal predraft submitted to 2019 IEEE InternationalConference on Acoustics, Speech and Signal Processing (ICASSP 2019), in Brighton, UK, May 2019. 5 pages, 4 figures\\u00a7r"}']}
{title:'Yuan et al. (§72018§r)', author: 'Zhe Yuan; Zhuoran Lyu; Jiwei Li; Xi Zhou', display:{Lore:['[{"text": "arXiv:1810.12020", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAn improved hybrid CTC-Attention model for speech recognition\\u00a7r\\n\\n\\u00a78\\u00a7oZhe Yuan\\nZhuoran Lyu\\nJiwei Li\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1810.12020\\u00a7r\\n\\nVersion:\\u00a77v3 (Thu, 1 Nov 2018 07:05:44 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to the 2019 IEEE InternationalConference on Acoustics, Speech, and Signal Processing (ICASSP), Brighton, UK, May 2019\\u00a7r"}']}
{title:'Bollepalli et al. (§72018§r)', author: 'Bajibabu Bollepalli; Lauri Juvela; Paavo Alku', display:{Lore:['[{"text": "arXiv:1810.12051", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSpeaking style adaptation in Text-To-Speech synthesis using Sequence-to-sequence models with attention\\u00a7r\\n\\n\\u00a78\\u00a7oBajibabu Bollepalli\\nLauri Juvela\\nPaavo Alku\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1810.12051\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 29 Oct 2018 10:53:31 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 5 figures. Submitted to ICASSP 2019\\u00a7r"}']}
{title:'Lerato et al. (§72018§r)', author: 'Lerato Lerato; Thomas Niesler', display:{Lore:['[{"text": "arXiv:1810.12722", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lFeature Trajectory Dynamic Time Warping for Clustering of Speech Segments\\u00a7r\\n\\n\\u00a78\\u00a7oLerato Lerato\\nThomas Niesler\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1810.12722\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 30 Oct 2018 13:30:19 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o10 pages\\u00a7r"}']}
{title:'Tukuljac et al. (§72018§r)', author: 'Helena Peic Tukuljac; Antoine Deleforge; Rémi Gribonval', display:{Lore:['[{"text": "arXiv:1810.13338", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.AI\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMULAN: A Blind and Off-Grid Method for Multichannel Echo Retrieval\\u00a7r\\n\\n\\u00a78\\u00a7oHelena Peic Tukuljac\\nAntoine Deleforge\\nR\\u00e9mi Gribonval\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1810.13338\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nThirty-second Conference on Neural Information Processing Systems\\n  (NIPS 2018), Dec 2018, Montr{\\\\\'e}al, Canada\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 31 Oct 2018 15:30:00 GMT)\\u00a7r"}']}
{title:'Prenger et al. (§72018§r)', author: 'Ryan Prenger; Rafael Valle; Bryan Catanzaro', display:{Lore:['[{"text": "arXiv:1811.00002", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.AI\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lWaveGlow: A Flow-based Generative Network for Speech Synthesis\\u00a7r\\n\\n\\u00a78\\u00a7oRyan Prenger\\nRafael Valle\\nBryan Catanzaro\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1811.00002\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 31 Oct 2018 03:22:25 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 1 figure, 1 table, 13 equations\\u00a7r"}']}
{title:'Nagarajan et al. (§72018§r)', author: 'Bhalaji Nagarajan; V Ramana Murthy Oruganti', display:{Lore:['[{"text": "arXiv:1811.00003", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDeep Net Features for Complex Emotion Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oBhalaji Nagarajan\\nV Ramana Murthy Oruganti\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1811.00003\\u00a7r\\n\\nVersion:\\u00a77v2 (Fri, 2 Nov 2018 04:46:09 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oConflict of interest\\u00a7r"}']}
{title:'Dionelis (§72018§r)', author: 'Nikolaos Dionelis', display:{Lore:['[{"text": "arXiv:1811.00078", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lOn Single-Channel Speech Enhancement and On Non-Linear Modulation-Domain Kalman Filtering\\u00a7r\\n\\n\\u00a78\\u00a7oNikolaos Dionelis\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1811.00078\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 31 Oct 2018 19:30:39 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o13 pages\\u00a7r"}']}
{title:'Kim et al. (§72018§r)', author: 'Jong Wook Kim; Rachel Bittner; Aparna Kumar; Juan Pablo Bello', display:{Lore:['[{"text": "arXiv:1811.00223", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lNeural Music Synthesis for Flexible Timbre Control\\u00a7r\\n\\n\\u00a78\\u00a7oJong Wook Kim\\nRachel Bittner\\nAparna Kumar\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1811.00223\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 1 Nov 2018 04:41:40 GMT)\\u00a7r"}']}
{title:'Wang et al. (§72018§r)', author: 'Dezhi Wang; Lilun Zhang; Changchun Bao; Kele Xu; Boqing Zhu; Qiuqiang Kong', display:{Lore:['[{"text": "arXiv:1811.00301", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lWeakly supervised CRNN system for sound event detection with large-scale unlabeled in-domain data\\u00a7r\\n\\n\\u00a78\\u00a7oDezhi Wang\\nLilun Zhang\\nChangchun Bao\\n+ 2 others\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1811.00301\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 1 Nov 2018 10:16:41 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to ICASSP 2019\\u00a7r"}']}
{title:'Zhang et al. (§72018§r)', author: 'Haitong Zhang; Junbo Zhang; Yujun Wang', display:{Lore:['[{"text": "arXiv:1811.00348", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSequence-to-sequence Models for Small-Footprint Keyword Spotting\\u00a7r\\n\\n\\u00a78\\u00a7oHaitong Zhang\\nJunbo Zhang\\nYujun Wang\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1811.00348\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 1 Nov 2018 12:53:53 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to ICASSP 2019\\u00a7r"}']}
{title:'Zhang et al. (§72018§r)', author: 'Haitong Zhang; Junbo Zhang; Yujun Wang', display:{Lore:['[{"text": "arXiv:1811.00350", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lEnd-to-end Models with auditory attention in Multi-channel Keyword Spotting\\u00a7r\\n\\n\\u00a78\\u00a7oHaitong Zhang\\nJunbo Zhang\\nYujun Wang\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1811.00350\\u00a7r\\n\\nVersion:\\u00a77v2 (Sat, 3 Nov 2018 08:41:06 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to ICASSP 2019\\u00a7r"}']}
{title:'Grais et al. (§72018§r)', author: 'Emad M. Grais; Hagen Wierstorf; Dominic Ward; Russell Mason; Mark D. Plumbley', display:{Lore:['[{"text": "arXiv:1811.00454", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.MM\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lReferenceless Performance Evaluation of Audio Source Separation using Deep Neural Networks\\u00a7r\\n\\n\\u00a78\\u00a7oEmad M. Grais\\nHagen Wierstorf\\nDominic Ward\\nRussell Mason\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1811.00454\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nThis paper will be presented at EUSIPCO 2019\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 1 Nov 2018 15:50:42 GMT)\\u00a7r"}']}
{title:'Bhatt et al. (§72018§r)', author: 'Gaurav Bhatt; Akshita Gupta; Aditya Arora; Balasubramanian Raman', display:{Lore:['[{"text": "arXiv:1811.00936", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAcoustic Features Fusion using Attentive Multi-channel Deep Architecture\\u00a7r\\n\\n\\u00a78\\u00a7oGaurav Bhatt\\nAkshita Gupta\\nAditya Arora\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1811.00936\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 2 Nov 2018 15:31:22 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted in CHiME\'18 (Interspeech Workshop)\\u00a7r"}']}
{title:'Zeinali et al. (§72018§r)', author: 'Hossein Zeinali; Lukas Burget; Johan Rohdin; Themos Stafylakis; Jan Cernocky', display:{Lore:['[{"text": "arXiv:1811.02066", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lHow to Improve Your Speaker Embeddings Extractor in Generic Toolkits\\u00a7r\\n\\n\\u00a78\\u00a7oHossein Zeinali\\nLukas Burget\\nJohan Rohdin\\nThemos Stafylakis\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1811.02066\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 5 Nov 2018 22:31:00 GMT)\\u00a7r"}']}
{title:'Seetharaman et al. (§72018§r)', author: 'Prem Seetharaman; Gordon Wichern; Jonathan Le Roux; Bryan Pardo', display:{Lore:['[{"text": "arXiv:1811.02130", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.AI\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lBootstrapping single-channel source separation via unsupervised spatial clustering on stereo mixtures\\u00a7r\\n\\n\\u00a78\\u00a7oPrem Seetharaman\\nGordon Wichern\\nJonathan Le Roux\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1811.02130\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 6 Nov 2018 02:20:40 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 2 figures\\u00a7r"}']}
{title:'Morfi et al. (§72018§r)', author: 'Veronica Morfi; Yves Bas; Hanna Pamuła; Hervé Glotin; Dan Stowell', display:{Lore:['[{"text": "arXiv:1811.02275", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.DL\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lNIPS4Bplus: a richly annotated birdsong audio dataset\\u00a7r\\n\\n\\u00a78\\u00a7oVeronica Morfi\\nYves Bas\\nHanna Pamu\\u0142a\\nHerv\\u00e9 Glotin\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1811.02275\\u00a7r\\n\\nVersion:\\u00a77v2 (Wed, 14 Nov 2018 12:25:27 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 5 figures, submitted to ICASSP 2019\\u00a7r"}']}
{title:'Ramires et al. (§72018§r)', author: 'António Ramires; Rui Penha; Matthew E. P. Davies', display:{Lore:['[{"text": "arXiv:1811.02406", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lUser Specific Adaptation in Automatic Transcription of Vocalised Percussion\\u00a7r\\n\\n\\u00a78\\u00a7oAnt\\u00f3nio Ramires\\nRui Penha\\nMatthew E. P. Davies\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1811.02406\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nProc. of RecPad-2017, Amadora, Portugal, pp. 19-20, October, 2017\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 6 Nov 2018 15:23:53 GMT)\\u00a7r"}']}
{title:'Ramires et al. (§72018§r)', author: 'António Ramires; Diogo Cocharro; Matthew E. P. Davies', display:{Lore:['[{"text": "arXiv:1811.02411", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAn audio-only method for advertisement detection in broadcast television content\\u00a7r\\n\\n\\u00a78\\u00a7oAnt\\u00f3nio Ramires\\nDiogo Cocharro\\nMatthew E. P. Davies\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1811.02411\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nProc. of RecPad-2017, Amadora, Portugal, pp. 21-22, October, 2017\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 6 Nov 2018 15:28:26 GMT)\\u00a7r"}']}
{title:'Roux et al. (§72018§r)', author: 'Jonathan Le Roux; Scott Wisdom; Hakan Erdogan; John R. Hershey', display:{Lore:['[{"text": "arXiv:1811.02508", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSDR - half-baked or well done?\\u00a7r\\n\\n\\u00a78\\u00a7oJonathan Le Roux\\nScott Wisdom\\nHakan Erdogan\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1811.02508\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 6 Nov 2018 17:20:05 GMT)\\u00a7r"}']}
{title:'Wang et al. (§72018§r)', author: 'Ran Wang; Yao Wang; Adeen Flinker', display:{Lore:['[{"text": "arXiv:1811.02694", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r, \\u00a7bq-bio.NC\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lReconstructing Speech Stimuli From Human Auditory Cortex Activity Using a WaveNet Approach\\u00a7r\\n\\n\\u00a78\\u00a7oRan Wang\\nYao Wang\\nAdeen Flinker\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1811.02694\\u00a7r\\n\\nVersion:\\u00a77v2 (Thu, 8 Nov 2018 02:17:16 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o6 pages, 3 figures. Conference of 2018 IEEE Signal Processing in Medicine and Biology Symposium (SPMB 2018)\\u00a7r"}']}
{title:'Seetharaman et al. (§72018§r)', author: 'Prem Seetharaman; Gordon Wichern; Shrikant Venkataramani; Jonathan Le Roux', display:{Lore:['[{"text": "arXiv:1811.03076", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lClass-conditional embeddings for music source separation\\u00a7r\\n\\n\\u00a78\\u00a7oPrem Seetharaman\\nGordon Wichern\\nShrikant Venkataramani\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1811.03076\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 7 Nov 2018 18:49:34 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages\\u00a7r"}']}
{title:'Hung et al. (§72018§r)', author: 'Yun-Ning Hung; Yi-An Chen; Yi-Hsuan Yang', display:{Lore:['[{"text": "arXiv:1811.03271", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lLearning Disentangled Representations for Timber and Pitch in Music Audio\\u00a7r\\n\\n\\u00a78\\u00a7oYun-Ning Hung\\nYi-An Chen\\nYi-Hsuan Yang\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1811.03271\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 8 Nov 2018 05:05:50 GMT)\\u00a7r"}']}
{title:'Tzinis et al. (§72018§r)', author: 'Efthymios Tzinis; Georgios Paraskevopoulos; Christos Baziotis; Alexandros Potamianos', display:{Lore:['[{"text": "arXiv:1811.04133", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lIntegrating Recurrence Dynamics for Speech Emotion Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oEfthymios Tzinis\\nGeorgios Paraskevopoulos\\nChristos Baziotis\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1811.04133\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.21437/Interspeech.2018-1377\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nProc. Interspeech 2018, pp. 927-931\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 9 Nov 2018 21:02:52 GMT)\\u00a7r"}']}
{title:'Orife et al. (§72018§r)', author: 'Iroro Orife; Shane Walker; Jason Flaks', display:{Lore:['[{"text": "arXiv:1811.04139", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAudio Spectrogram Factorization for Classification of Telephony Signals below the Auditory Threshold\\u00a7r\\n\\n\\u00a78\\u00a7oIroro Orife\\nShane Walker\\nJason Flaks\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1811.04139\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 9 Nov 2018 21:24:47 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o7 pages, 4 figures. Marchex Technical Report on VoIP SPAM classification\\u00a7r"}']}
{title:'Wang et al. (§72018§r)', author: 'Bryan Wang; Yi-Hsuan Yang', display:{Lore:['[{"text": "arXiv:1811.04357", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.MM\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lPerformanceNet: Score-to-Audio Music Generation with Multi-Band Convolutional Residual Network\\u00a7r\\n\\n\\u00a78\\u00a7oBryan Wang\\nYi-Hsuan Yang\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1811.04357\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 11 Nov 2018 05:55:39 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o8 pages, 6 figures, AAAI 2019 camera-ready version\\u00a7r"}']}
{title:'Schindler et al. (§72018§r)', author: 'Alexander Schindler; Thomas Lidy; Andreas Rauber', display:{Lore:['[{"text": "arXiv:1811.04419", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.MM\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMulti-Temporal Resolution Convolutional Neural Networks for Acoustic Scene Classification\\u00a7r\\n\\n\\u00a78\\u00a7oAlexander Schindler\\nThomas Lidy\\nAndreas Rauber\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1811.04419\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 11 Nov 2018 14:05:52 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oIn Proceedings of the Detection and Classification of Acoustic Scenes and Events 2017 Workshop (DCASE2017), November2017\\u00a7r"}']}
{title:'Fazeka et al. (§72018§r)', author: 'Botond Fazeka; Alexander Schindler; Thomas Lidy; Andreas Rauber', display:{Lore:['[{"text": "arXiv:1811.04448", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Multi-modal Deep Neural Network approach to Bird-song identification\\u00a7r\\n\\n\\u00a78\\u00a7oBotond Fazeka\\nAlexander Schindler\\nThomas Lidy\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1811.04448\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 11 Nov 2018 18:58:30 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oLifeCLEF 2017 working notes, Dublin, Ireland\\u00a7r"}']}
{title:'Seki et al. (§72018§r)', author: 'Hiroshi Seki; Takaaki Hori; Shinji Watanabe', display:{Lore:['[{"text": "arXiv:1811.04568", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7eeess.AS\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lVectorization of hypotheses and speech for faster beam search in encoder decoder-based speech recognition\\u00a7r\\n\\n\\u00a78\\u00a7oHiroshi Seki\\nTakaaki Hori\\nShinji Watanabe\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1811.04568\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 12 Nov 2018 06:02:19 GMT)\\u00a7r"}']}
{title:'Hantrakul et al. (§72018§r)', author: 'Lamtharn Hantrakul; Li-Chia Yang', display:{Lore:['[{"text": "arXiv:1811.05550", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.MM\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lNeural Wavetable: a playable wavetable synthesizer using neural networks\\u00a7r\\n\\n\\u00a78\\u00a7oLamtharn Hantrakul\\nLi-Chia Yang\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1811.05550\\u00a7r\\n\\nVersion:\\u00a77v2 (Fri, 16 Nov 2018 19:54:20 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o2 pages, Accepted by Conference on Neural Information ProcessingSystems (NIPS), Workshop on Machine Learning for Creativityand Design\\u00a7r"}']}
{title:'Carr et al. (§72018§r)', author: 'CJ Carr; Zack Zukowski', display:{Lore:['[{"text": "arXiv:1811.06633", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lGenerating Albums with SampleRNN to Imitate Metal, Rock, and Punk Bands\\u00a7r\\n\\n\\u00a78\\u00a7oCJ Carr\\nZack Zukowski\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1811.06633\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nProceedings of the 6th International Workshop on Musical\\n  Metacreation (MUME 2018)\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 16 Nov 2018 00:04:16 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o3 pages\\u00a7r"}']}
{title:'Zukowski et al. (§72018§r)', author: 'Zack Zukowski; CJ Carr', display:{Lore:['[{"text": "arXiv:1811.06639", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lGenerating Black Metal and Math Rock: Beyond Bach, Beethoven, and Beatles\\u00a7r\\n\\n\\u00a78\\u00a7oZack Zukowski\\nCJ Carr\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1811.06639\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nNIPS Workshop on Machine Learning for Creativity and Design (2017)\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 16 Nov 2018 00:54:05 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o3 pages\\u00a7r"}']}
{title:'Huang et al. (§72018§r)', author: 'Jonathan J Huang; Juan Jose Alvarado Leanos', display:{Lore:['[{"text": "arXiv:1811.06669", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAclNet: efficient end-to-end audio classification CNN\\u00a7r\\n\\n\\u00a78\\u00a7oJonathan J Huang\\nJuan Jose Alvarado Leanos\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1811.06669\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 16 Nov 2018 03:31:35 GMT)\\u00a7r"}']}
{title:'Byker et al. (§72018§r)', author: 'Rudolf Byker; Thomas Niesler', display:{Lore:['[{"text": "arXiv:1811.06756", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDirection of Arrival Estimation of Wide-band Signals with Planar Microphone Arrays\\u00a7r\\n\\n\\u00a78\\u00a7oRudolf Byker\\nThomas Niesler\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1811.06756\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 16 Nov 2018 11:22:00 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o10 pages\\u00a7r"}']}
{title:'Wilson et al. (§72018§r)', author: 'Kevin Wilson; Michael Chinen; Jeremy Thorpe; Brian Patton; John Hershey; Rif A. Saurous; Jan Skoglund; Richard F. Lyon', display:{Lore:['[{"text": "arXiv:1811.07030", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lExploring Tradeoffs in Models for Low-latency Speech Enhancement\\u00a7r\\n\\n\\u00a78\\u00a7oKevin Wilson\\nMichael Chinen\\nJeremy Thorpe\\n+ 4 others\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1811.07030\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 16 Nov 2018 20:49:15 GMT)\\u00a7r"}']}
{title:'Hou et al. (§72018§r)', author: 'Yuanbo Hou; Qiuqiang Kong; Jun Wang; Shengchen Li', display:{Lore:['[{"text": "arXiv:1811.07072", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lPolyphonic audio tagging with sequentially labelled data using CRNN with learnable gated linear units\\u00a7r\\n\\n\\u00a78\\u00a7oYuanbo Hou\\nQiuqiang Kong\\nJun Wang\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1811.07072\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 17 Nov 2018 01:19:25 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oDCASE2018 Workshop. arXiv admin note: text overlap with arXiv:1808.01935\\u00a7r"}']}
{title:'Ramsay et al. (§72018§r)', author: 'David B. Ramsay; Ishwarya Ananthabhotla; Joseph A. Paradiso', display:{Lore:['[{"text": "arXiv:1811.07082", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lThe Intrinsic Memorability of Everyday Sounds\\u00a7r\\n\\n\\u00a78\\u00a7oDavid B. Ramsay\\nIshwarya Ananthabhotla\\nJoseph A. Paradiso\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1811.07082\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 17 Nov 2018 02:46:45 GMT)\\u00a7r"}']}
{title:'Kastner et al. (§72018§r)', author: 'Kyle Kastner; Rithesh Kumar; Tim Cooijmans; Aaron Courville', display:{Lore:['[{"text": "arXiv:1811.07426", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lHarmonic Recomposition using Conditional Autoregressive Modeling\\u00a7r\\n\\n\\u00a78\\u00a7oKyle Kastner\\nRithesh Kumar\\nTim Cooijmans\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1811.07426\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 18 Nov 2018 23:40:53 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o3 pages, 2 figures. In Proceedings of The Joint Workshop on Machine Learning for Music, ICML 2018\\u00a7r"}']}
{title:'Mohapatra et al. (§72018§r)', author: 'Debasish Ray Mohapatra; Sidney Fels', display:{Lore:['[{"text": "arXiv:1811.07435", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lLimitations of Source-Filter Coupling In Phonation\\u00a7r\\n\\n\\u00a78\\u00a7oDebasish Ray Mohapatra\\nSidney Fels\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1811.07435\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1121/1.5068357\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 19 Nov 2018 00:32:50 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o2 pages, 2 figures\\u00a7r"}']}
{title:'Saha et al. (§72018§r)', author: 'Pramit Saha; Debasish Ray Mohapatra; Praneeth SV; Sidney Fels', display:{Lore:['[{"text": "arXiv:1811.08029", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSound-Stream II: Towards Real-Time Gesture Controlled Articulatory Sound Synthesis\\u00a7r\\n\\n\\u00a78\\u00a7oPramit Saha\\nDebasish Ray Mohapatra\\nPraneeth SV\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1811.08029\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 20 Nov 2018 00:23:28 GMT)\\u00a7r"}']}
{title:'Zhang et al. (§72018§r)', author: 'Jing-Xuan Zhang; Zhen-Hua Ling; Yuan Jiang; Li-Juan Liu; Chen Liang; Li-Rong Dai', display:{Lore:['[{"text": "arXiv:1811.08111", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lImproving Sequence-to-Sequence Acoustic Modeling by Adding Text-Supervision\\u00a7r\\n\\n\\u00a78\\u00a7oJing-Xuan Zhang\\nZhen-Hua Ling\\nYuan Jiang\\n+ 2 others\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1811.08111\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/ICASSP.2019.8682380\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nIEEE International Conference on Acoustic, Speech and Signal\\n  Processing (2019) 6785-6789\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 20 Nov 2018 08:02:54 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 4 figures, 2 tables. Submitted to IEEE ICASSP 2019\\u00a7r"}']}
{title:'Wisdom et al. (§72018§r)', author: 'Scott Wisdom; John R. Hershey; Kevin Wilson; Jeremy Thorpe; Michael Chinen; Brian Patton; Rif A. Saurous', display:{Lore:['[{"text": "arXiv:1811.08521", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDifferentiable Consistency Constraints for Improved Deep Speech Enhancement\\u00a7r\\n\\n\\u00a78\\u00a7oScott Wisdom\\nJohn R. Hershey\\nKevin Wilson\\n+ 3 others\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1811.08521\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 20 Nov 2018 22:44:12 GMT)\\u00a7r"}']}
{title:'Wang et al. (§72018§r)', author: 'Zhong-Qiu Wang; Ke Tan; DeLiang Wang', display:{Lore:['[{"text": "arXiv:1811.09010", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDeep Learning Based Phase Reconstruction for Speaker Separation: A Trigonometric Perspective\\u00a7r\\n\\n\\u00a78\\u00a7oZhong-Qiu Wang\\nKe Tan\\nDeLiang Wang\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1811.09010\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 22 Nov 2018 03:46:44 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, in submission to ICASSP-2019\\u00a7r"}']}
{title:'Rodomagoulakis et al. (§72018§r)', author: 'Isidoros Rodomagoulakis; Petros Maragos', display:{Lore:['[{"text": "arXiv:1811.09381", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.HC\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lImproved Frequency Modulation Features for Multichannel Distant Speech Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oIsidoros Rodomagoulakis\\nPetros Maragos\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1811.09381\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/JSTSP.2019.2923372\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 23 Nov 2018 07:54:13 GMT)\\u00a7r"}']}
{title:'Gonzalez-Diaz et al. (§72018§r)', author: 'R. Gonzalez-Diaz; E. Paluzo-Hidalgo; J. F. Quesada', display:{Lore:['[{"text": "arXiv:1811.09607", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lTowards Emotion Recognition: A Persistent Entropy Application\\u00a7r\\n\\n\\u00a78\\u00a7oR. Gonzalez-Diaz\\nE. Paluzo-Hidalgo\\nJ. F. Quesada\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1811.09607\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1007/978-3-030-10828-1_8\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 21 Nov 2018 19:20:43 GMT)\\u00a7r"}']}
{title:'M et al. (§72018§r)', author: 'Gurunath Reddy M; Tanumay Mandal; Krothapalli Sreenivasa Rao', display:{Lore:['[{"text": "arXiv:1811.09956", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lGlottal Closure Instants Detection From Pathological Acoustic Speech Signal Using Deep Learning\\u00a7r\\n\\n\\u00a78\\u00a7oGurunath Reddy M\\nTanumay Mandal\\nKrothapalli Sreenivasa Rao\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1811.09956\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 25 Nov 2018 06:18:24 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oMachine Learning for Health (ML4H) Workshop at NeurIPS 2018 arXiv:1811.07216\\u00a7r"}']}
{title:'Lederle et al. (§72018§r)', author: 'Marcel Lederle; Benjamin Wilhelm', display:{Lore:['[{"text": "arXiv:1811.10708", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lCombining High-Level Features of Raw Audio Waves and Mel-Spectrograms for Audio Tagging\\u00a7r\\n\\n\\u00a78\\u00a7oMarcel Lederle\\nBenjamin Wilhelm\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1811.10708\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 26 Nov 2018 22:02:20 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oDetection and Classification of Acoustic Scenes and Events 2018 (DCASE 2018), 19-20 November 2018, Surrey, UK\\u00a7r"}']}
{title:'Macartney et al. (§72018§r)', author: 'Craig Macartney; Tillman Weyde', display:{Lore:['[{"text": "arXiv:1811.11307", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.NE\\u00a7r, \\u00a7eeess.AS\\u00a7r, \\u00a7eeess.SP\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lImproved Speech Enhancement with the Wave-U-Net\\u00a7r\\n\\n\\u00a78\\u00a7oCraig Macartney\\nTillman Weyde\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1811.11307\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 27 Nov 2018 23:11:05 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages (including 1 for References), 1 figure, 2 tables\\u00a7r"}']}
{title:'Moore (§72018§r)', author: 'Alastair H. Moore', display:{Lore:['[{"text": "arXiv:1811.11663", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMultiple source direction of arrival estimation using subspace pseudointensity vectors\\u00a7r\\n\\n\\u00a78\\u00a7oAlastair H. Moore\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1811.11663\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 28 Nov 2018 16:43:56 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oIn Proceedings of the LOCATA Challenge Workshop - a satellite event of IWAENC 2018 (arXiv:1811.08482 )\\u00a7r"}']}
{title:'Ma et al. (§72018§r)', author: 'Dabiao Ma; Zhiba Su; Yuhao Lu; Wenxuan Wang; Zhen Li', display:{Lore:['[{"text": "arXiv:1811.12208", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lUFANS: U-shaped Fully-Parallel Acoustic Neural Structure For Statistical Parametric Speech Synthesis With 20X Faster\\u00a7r\\n\\n\\u00a78\\u00a7oDabiao Ma\\nZhiba Su\\nYuhao Lu\\nWenxuan Wang\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1811.12208\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 28 Nov 2018 03:53:20 GMT)\\u00a7r"}']}
{title:'Lu et al. (§72018§r)', author: 'Chien-Yu Lu; Min-Xin Xue; Chia-Che Chang; Che-Rung Lee; Li Su', display:{Lore:['[{"text": "arXiv:1811.12214", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lPlay as You Like: Timbre-enhanced Multi-modal Music Style Transfer\\u00a7r\\n\\n\\u00a78\\u00a7oChien-Yu Lu\\nMin-Xin Xue\\nChia-Che Chang\\nChe-Rung Lee\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1811.12214\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 28 Nov 2018 18:42:50 GMT)\\u00a7r"}']}
{title:'Chuan et al. (§72018§r)', author: 'Ching-Hua Chuan; Kat Agres; Dorien Herremans', display:{Lore:['[{"text": "arXiv:1811.12408", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.IR\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lFrom Context to Concept: Exploring Semantic Relationships in Music with Word2Vec\\u00a7r\\n\\n\\u00a78\\u00a7oChing-Hua Chuan\\nKat Agres\\nDorien Herremans\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1811.12408\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nNeural Computing and Applications, Springer. 2019\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 29 Nov 2018 13:52:13 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted for publication in Neural Computing and Applications, Springer. In Press\\u00a7r"}']}
{title:'Kotecha (§72018§r)', author: 'Nikhil Kotecha', display:{Lore:['[{"text": "arXiv:1812.01060", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lBach2Bach: Generating Music Using A Deep Reinforcement Learning Approach\\u00a7r\\n\\n\\u00a78\\u00a7oNikhil Kotecha\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1812.01060\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 3 Dec 2018 20:09:05 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o42 pages\\u00a7r"}']}
{title:'Lin et al. (§72018§r)', author: 'Kin Wah Edward Lin; Balamurali B. T.; Enyan Koh; Simon Lui; Dorien Herremans', display:{Lore:['[{"text": "arXiv:1812.01278", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.AI\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSinging Voice Separation Using a Deep Convolutional Neural Network Trained by Ideal Binary Mask and Cross Entropy\\u00a7r\\n\\n\\u00a78\\u00a7oKin Wah Edward Lin\\nBalamurali B. T.\\nEnyan Koh\\nSimon Lui\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1812.01278\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 4 Dec 2018 08:47:41 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oIn Press, Neural Computing and Applications, Springer. 2019\\u00a7r"}']}
{title:'Salvati et al. (§72018§r)', author: 'Daniele Salvati; Carlo Drioli; Gian Luca Foresti', display:{Lore:['[{"text": "arXiv:1812.01521", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lLocalization and Tracking of an Acoustic Source using a Diagonal Unloading Beamforming and a Kalman Filter\\u00a7r\\n\\n\\u00a78\\u00a7oDaniele Salvati\\nCarlo Drioli\\nGian Luca Foresti\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1812.01521\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 4 Dec 2018 16:48:52 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oIn Proceedings of the LOCATA Challenge Workshop - a satellite event of IWAENC 2018 (arXiv:1811.08482)\\u00a7r"}']}
{title:'Liu et al. (§72018§r)', author: 'Yang Liu; Wenwu Wang; Volkan Kilic', display:{Lore:['[{"text": "arXiv:1812.01570", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lIntensity Particle Flow SMC-PHD Filter For Audio Speaker Tracking\\u00a7r\\n\\n\\u00a78\\u00a7oYang Liu\\nWenwu Wang\\nVolkan Kilic\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1812.01570\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 4 Dec 2018 18:20:27 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oIn Proceedings of the LOCATA Challenge Workshop - a satellite event of IWAENC 2018 (arXiv:1811.08482 )\\u00a7r"}']}
{title:'Mun et al. (§72018§r)', author: 'Seongkyu Mun; Suwon Shon', display:{Lore:['[{"text": "arXiv:1812.01731", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDomain Mismatch Robust Acoustic Scene Classification using Channel Information Conversion\\u00a7r\\n\\n\\u00a78\\u00a7oSeongkyu Mun\\nSuwon Shon\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1812.01731\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 4 Dec 2018 22:43:33 GMT)\\u00a7r"}']}
{title:'Ağcaer et al. (§72018§r)', author: 'Semih Ağcaer; Rainer Martin', display:{Lore:['[{"text": "arXiv:1812.02399", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lBinaural Source Localization based on Modulation-Domain Features and Decision Pooling\\u00a7r\\n\\n\\u00a78\\u00a7oSemih A\\u011fcaer\\nRainer Martin\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1812.02399\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 6 Dec 2018 08:30:56 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oIn Proceedings of the LOCATA Challenge Workshop - a satellite event of IWAENC 2018 (arXiv:1811.08482)\\u00a7r"}']}
{title:'Mejstrik et al. (§72018§r)', author: 'Thomas Mejstrik; Gianpaolo Evangelista', display:{Lore:['[{"text": "arXiv:1812.03279", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r, \\u00a72math.NA\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lEstimates of the Reconstruction Error in Partially Redressed Warped Frames Expansions\\u00a7r\\n\\n\\u00a78\\u00a7oThomas Mejstrik\\nGianpaolo Evangelista\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1812.03279\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nProc. of Digital Audio Effect Conf. (DAFx\'16). Brno, Czech\\n  Republic, September 2016, pp. 9-16\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 8 Dec 2018 07:58:00 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o8 pages, 5 figures, 4 tables, conference paper\\u00a7r"}']}
{title:'Reddy et al. (§72018§r)', author: 'Chandan K A Reddy; Gautam Bhat; Nikhil Shankar; Issa Panahi', display:{Lore:['[{"text": "arXiv:1812.03914", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Computationally Efficient and Practically Feasible Two Microphones Blind Speech Separation Method\\u00a7r\\n\\n\\u00a78\\u00a7oChandan K A Reddy\\nGautam Bhat\\nNikhil Shankar\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1812.03914\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 10 Dec 2018 16:49:47 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages\\u00a7r"}']}
{title:'Reddy et al. (§72018§r)', author: 'Chandan K A Reddy; Nikhil Shankar; Gautam Bhat; Ram Charan; Issa Panahi', display:{Lore:['[{"text": "arXiv:1812.03916", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAn individualized super Gaussian single microphone Speech Enhancement for hearing aid users with smartphone as an assistive device\\u00a7r\\n\\n\\u00a78\\u00a7oChandan K A Reddy\\nNikhil Shankar\\nGautam Bhat\\nRam Charan\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1812.03916\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/LSP.2017.2750979\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 10 Dec 2018 16:50:37 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages\\u00a7r"}']}
{title:'Herremans et al. (§72018§r)', author: 'Dorien Herremans; Ching-Hua Chuan; Elaine Chew', display:{Lore:['[{"text": "arXiv:1812.04186", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Functional Taxonomy of Music Generation Systems\\u00a7r\\n\\n\\u00a78\\u00a7oDorien Herremans\\nChing-Hua Chuan\\nElaine Chew\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1812.04186\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1145/3108242\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nACM Computing Surveys (CSUR), 50(5), 69.\\n  https://dl.acm.org/citation.cfm?id=3145473.3108242\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 11 Dec 2018 02:07:06 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7osurvey, music generation, taxonomy, functional survey, survey, automatic composition, algorithmiccomposition\\u00a7r"}']}
{title:'Li et al. (§72018§r)', author: 'Xiaofei Li; Yutong Ban; Laurent Girin; Xavier Alameda-Pineda; Radu Horaud', display:{Lore:['[{"text": "arXiv:1812.04417", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA cascaded multiple-speaker localization and tracking system\\u00a7r\\n\\n\\u00a78\\u00a7oXiaofei Li\\nYutong Ban\\nLaurent Girin\\nXavier Alameda-Pineda\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1812.04417\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 11 Dec 2018 14:12:10 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oIn Proceedings of the LOCATA Challenge Workshop - a satellite event of IWAENC 2018 (arXiv:1811.08482 )\\u00a7r"}']}
{title:'Herremans et al. (§72018§r)', author: 'Dorien Herremans; Elaine Chew', display:{Lore:['[{"text": "arXiv:1812.04832", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMorpheuS: generating structured music with constrained patterns and tension\\u00a7r\\n\\n\\u00a78\\u00a7oDorien Herremans\\nElaine Chew\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1812.04832\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/TAFFC.2017.2737984\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 12 Dec 2018 07:17:48 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oIEEE Transactions on Affective Computing. PP(99)\\u00a7r"}']}
{title:'Madmoni et al. (§72018§r)', author: 'Lior Madmoni; Hanan Beit-On; Hai Morgenstern; Boaz Rafaely', display:{Lore:['[{"text": "arXiv:1812.04942", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDescription of algorithms for Ben-Gurion University Submission to the LOCATA challenge\\u00a7r\\n\\n\\u00a78\\u00a7oLior Madmoni\\nHanan Beit-On\\nHai Morgenstern\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1812.04942\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 12 Dec 2018 13:55:33 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oIn Proceedings of the LOCATA Challenge Workshop - a satellite event of IWAENC 2018 (arXiv:1811.08482 )\\u00a7r"}']}
{title:'Grzywalski et al. (§72018§r)', author: 'Tomasz Grzywalski; Adam Maciaszek; Adam Biniakowski; Jan Orwat; Szymon Drgas; Mateusz Piecuch; Riccardo Belluzzo; Krzysztof Joachimiak; Dawid Niemiec; Jakub Ptaszynski; Krzysztof Szarzynski', display:{Lore:['[{"text": "arXiv:1812.05888", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lParameterization of Sequence of MFCCs for DNN-based voice disorder detection\\u00a7r\\n\\n\\u00a78\\u00a7oTomasz Grzywalski\\nAdam Maciaszek\\nAdam Biniakowski\\n+ 7 others\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1812.05888\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 14 Dec 2018 12:44:21 GMT)\\u00a7r"}']}
{title:'Lebarbenchon et al. (§72018§r)', author: 'Romain Lebarbenchon; Ewen Camberlein; Diego di Carlo; Clément Gaultier; Antoine Deleforge; Nancy Bertin', display:{Lore:['[{"text": "arXiv:1812.05901", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lEvaluation of an open-source implementation of the SRP-PHAT algorithm within the 2018 LOCATA challenge\\u00a7r\\n\\n\\u00a78\\u00a7oRomain Lebarbenchon\\nEwen Camberlein\\nDiego di Carlo\\n+ 2 others\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1812.05901\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 14 Dec 2018 13:15:45 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oIn Proceedings of the LOCATA Challenge Workshop - a satellite event of IWAENC 2018 (arXiv:1811.08482 )\\u00a7r"}']}
{title:'Xu et al. (§72018§r)', author: 'Zhijing Xu; Juan Wang; Ying Zhang; Xiangjian He', display:{Lore:['[{"text": "arXiv:1812.06613", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CV\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lVoiceprint recognition of Parkinson patients based on deep learning\\u00a7r\\n\\n\\u00a78\\u00a7oZhijing Xu\\nJuan Wang\\nYing Zhang\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1812.06613\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 17 Dec 2018 04:24:46 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o10 pages,4 figures\\u00a7r"}']}
{title:'Mosgaard et al. (§72018§r)', author: 'Lars D. Mosgaard; David Pelegrin-Garcia; Thomas B. Elmedyb; Michael J. Pihl; Pejman Mowlaee', display:{Lore:['[{"text": "arXiv:1812.06697", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lCircular Statistics-based low complexity DOA estimation for hearing aid application\\u00a7r\\n\\n\\u00a78\\u00a7oLars D. Mosgaard\\nDavid Pelegrin-Garcia\\nThomas B. Elmedyb\\nMichael J. Pihl\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1812.06697\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 17 Dec 2018 11:09:30 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oIn Proceedings of the LOCATA Challenge Workshop - a satellite event of IWAENC 2018 (arXiv:1811.08482 )\\u00a7r"}']}
{title:'Malekzadeh et al. (§72018§r)', author: 'Saber Malekzadeh; Mohammad Hossein Gholizadeh; Seyed Naser Razavi', display:{Lore:['[{"text": "arXiv:1812.06953", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lPersian Vowel recognition with MFCC and ANN on PCVC speech dataset\\u00a7r\\n\\n\\u00a78\\u00a7oSaber Malekzadeh\\nMohammad Hossein Gholizadeh\\nSeyed Naser Razavi\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1812.06953\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.13140/RG.2.2.12187.72486\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 17 Dec 2018 18:50:36 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oThe 5th International Conference of Electrical Engineering, Computer Science and Information Technology 2018\\u00a7r"}']}
{title:'Zhou et al. (§72018§r)', author: 'Yichao Zhou; Wei Chu; Sam Young; Xin Chen', display:{Lore:['[{"text": "arXiv:1812.07126", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.MM\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lBandNet: A Neural Network-based, Multi-Instrument Beatles-Style MIDI Music Composition Machine\\u00a7r\\n\\n\\u00a78\\u00a7oYichao Zhou\\nWei Chu\\nSam Young\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1812.07126\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 18 Dec 2018 01:26:13 GMT)\\u00a7r"}']}
{title:'Ramani et al. (§72018§r)', author: 'Dhruv Ramani; Samarjit Karmakar; Anirban Panda; Asad Ahmed; Pratham Tangri', display:{Lore:['[{"text": "arXiv:1812.07159", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAutoencoder Based Architecture For Fast     Real Time Audio Style Transfer\\u00a7r\\n\\n\\u00a78\\u00a7oDhruv Ramani\\nSamarjit Karmakar\\nAnirban Panda\\nAsad Ahmed\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1812.07159\\u00a7r\\n\\nVersion:\\u00a77v2 (Wed, 26 Dec 2018 15:30:16 GMT)\\u00a7r"}']}
{title:'Sanford et al. (§72018§r)', author: 'Clayton Sanford; Cyrus Cousins; Eli Upfal', display:{Lore:['[{"text": "arXiv:1812.07568", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lUniform Convergence Bounds for Codec Selection\\u00a7r\\n\\n\\u00a78\\u00a7oClayton Sanford\\nCyrus Cousins\\nEli Upfal\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1812.07568\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 18 Dec 2018 04:42:34 GMT)\\u00a7r"}']}
{title:'Mingote et al. (§72018§r)', author: 'Victoria Mingote; Antonio Miguel; Alfonso Ortega; Eduardo Lleida', display:{Lore:['[{"text": "arXiv:1812.09484", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDifferentiable Supervector Extraction for Encoding Speaker and Phrase Information in Text Dependent Speaker Verification\\u00a7r\\n\\n\\u00a78\\u00a7oVictoria Mingote\\nAntonio Miguel\\nAlfonso Ortega\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1812.09484\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 22 Dec 2018 09:25:59 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, IberSPEECH 2018\\u00a7r"}']}
{title:'Rajaratnam et al. (§72018§r)', author: 'Krishan Rajaratnam; Jugal Kalita', display:{Lore:['[{"text": "arXiv:1812.10061", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.CR\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lNoise Flooding for Detecting Audio Adversarial Examples Against Automatic Speech Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oKrishan Rajaratnam\\nJugal Kalita\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1812.10061\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/ISSPIT.2018.8642623\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 25 Dec 2018 08:02:01 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oOrally presented at the 18th IEEE International Symposium on Signal Processing and Information Technology (ISSPIT) in Louisville, Kentucky, USA, December 2018. 5 pages, 2 figures\\u00a7r"}']}
{title:'Samui et al. (§72018§r)', author: 'Suman Samui; Indrajit Chakrabarti; Soumya K. Ghosh', display:{Lore:['[{"text": "arXiv:1812.10095", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lTensor-Train Long Short-Term Memory for Monaural Speech Enhancement\\u00a7r\\n\\n\\u00a78\\u00a7oSuman Samui\\nIndrajit Chakrabarti\\nSoumya K. Ghosh\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1812.10095\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 25 Dec 2018 12:21:42 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to IEEESignal Processing Letters\\u00a7r"}']}
{title:'Wang et al. (§72018§r)', author: 'Ziyu Wang; Gus Xia', display:{Lore:['[{"text": "arXiv:1812.10906", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Framework for Automated Pop-song Melody Generation with Piano Accompaniment Arrangement\\u00a7r\\n\\n\\u00a78\\u00a7oZiyu Wang\\nGus Xia\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1812.10906\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 28 Dec 2018 06:32:04 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oIn Proceeding of 6th Conference on Sound and Music Technology, 2018, Xiamen, China\\u00a7r"}']}
