{title:'Tsiang (§72020§r)', author: 'Elaine Y L Tsiang', display:{Lore:['[{"text": "arXiv:1306.2593", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Perceptual Alphabet for the 10-dimensional Phonetic-prosodic Space\\u00a7r\\n\\n\\u00a78\\u00a7oElaine Y L Tsiang\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1306.2593\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 21 Jan 2020 22:54:04 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o4 pages, 11 tables The formulation of the phonetic subspace and the alphabet are now based on the model of speech of oral billiards, thereby reducing the size of theIHA from the previous version. It is now only "}','{"text": "supplemental to the article on oral billiards in providing the detail enumeration of the complete phonetic alphabet\\u00a7r"}']}
{title:'Tachibana et al. (§72020§r)', author: 'Hideyuki Tachibana; Katsuya Uenoyama; Shunsuke Aihara', display:{Lore:['[{"text": "arXiv:1710.08969", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.AI\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lEfficiently Trainable Text-to-Speech System Based on Deep Convolutional Networks with Guided Attention\\u00a7r\\n\\n\\u00a78\\u00a7oHideyuki Tachibana\\nKatsuya Uenoyama\\nShunsuke Aihara\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1710.08969\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/ICASSP.2018.8461829\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nProc. ICASSP (2018) 4784-4788\\u00a7r\\n\\nVersion:\\u00a77v2 (Wed, 30 Sep 2020 05:41:53 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 3figures, IEEE ICASSP 2018\\u00a7r"}']}
{title:'Chang et al. (§72020§r)', author: 'Sungkyun Chang; Juheon Lee; Sang Keun Choe; Kyogu Lee', display:{Lore:['[{"text": "arXiv:1712.00166", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.AI\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAudio Cover Song Identification using Convolutional Neural Network\\u00a7r\\n\\n\\u00a78\\u00a7oSungkyun Chang\\nJuheon Lee\\nSang Keun Choe\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1712.00166\\u00a7r\\n\\nVersion:\\u00a77v2 (Mon, 26 Oct 2020 14:34:40 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oNIPS 2017 Workshop on Machine Learning for Audio (ML4A), Long Beach, CA, USA\\u00a7r"}']}
{title:'Latif et al. (§72020§r)', author: 'Siddique Latif; Rajib Rana; Junaid Qadir; Julien Epps', display:{Lore:['[{"text": "arXiv:1712.08708", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lVariational Autoencoders for Learning Latent Representations of Speech Emotion: A Preliminary Study\\u00a7r\\n\\n\\u00a78\\u00a7oSiddique Latif\\nRajib Rana\\nJunaid Qadir\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1712.08708\\u00a7r\\n\\nVersion:\\u00a77v3 (Tue, 28 Jul 2020 01:35:27 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oProc. Interspeech 2018\\u00a7r"}']}
{title:'Gala et al. (§72020§r)', author: 'Deepak Gala; Nathan Lindsay; Liang Sun', display:{Lore:['[{"text": "arXiv:1804.05111", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.RO\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMulti-Sound-Source Localization Using Machine Learning for Small Autonomous Unmanned Vehicles with a Self-Rotating Bi-Microphone Array\\u00a7r\\n\\n\\u00a78\\u00a7oDeepak Gala\\nNathan Lindsay\\nLiang Sun\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1804.05111\\u00a7r\\n\\nVersion:\\u00a77v2 (Sun, 28 Jun 2020 06:36:07 GMT)\\u00a7r"}']}
{title:'Ma et al. (§72020§r)', author: 'Zhanyu Ma; Hong Yu', display:{Lore:['[{"text": "arXiv:1808.00959", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lHistogram Transform-based Speaker Identification\\u00a7r\\n\\n\\u00a78\\u00a7oZhanyu Ma\\nHong Yu\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1808.00959\\u00a7r\\n\\nVersion:\\u00a77v2 (Sun, 2 Feb 2020 09:21:31 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oTechnical Report\\u00a7r"}']}
{title:'Ma et al. (§72020§r)', author: 'Zhanyu Ma; Arne Leijon', display:{Lore:['[{"text": "arXiv:1808.00960", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lStatistical Speech Model Description with VMF Mixture Model\\u00a7r\\n\\n\\u00a78\\u00a7oZhanyu Ma\\nArne Leijon\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1808.00960\\u00a7r\\n\\nVersion:\\u00a77v2 (Sun, 2 Feb 2020 06:16:57 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oTechnical Report\\u00a7r"}']}
{title:'Zhang et al. (§72020§r)', author: 'Jing-Xuan Zhang; Zhen-Hua Ling; Li-Juan Liu; Yuan Jiang; Li-Rong Dai', display:{Lore:['[{"text": "arXiv:1810.06865", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSequence-to-Sequence Acoustic Modeling for Voice Conversion\\u00a7r\\n\\n\\u00a78\\u00a7oJing-Xuan Zhang\\nZhen-Hua Ling\\nLi-Juan Liu\\nYuan Jiang\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1810.06865\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/TASLP.2019.2892235\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nIEEE/ACM Transactions on Audio, Speech and Language Processing vol\\n  27 no 3 (2019) 631-644\\u00a7r\\n\\nVersion:\\u00a77v5 (Sun, 12 Jan 2020 06:49:21 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oPublished on IEEE/ACM Transactionson Audio, Speech and Language Processing\\u00a7r"}']}
{title:'Pellegrini et al. (§72020§r)', author: 'Thomas Pellegrini; Jérôme Farinas; Estelle Delpech; François Lancelot', display:{Lore:['[{"text": "arXiv:1810.12614", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lThe Airbus Air Traffic Control speech recognition 2018 challenge: towards ATC automatic transcription and call sign detection\\u00a7r\\n\\n\\u00a78\\u00a7oThomas Pellegrini\\nJ\\u00e9r\\u00f4me Farinas\\nEstelle Delpech\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1810.12614\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.21437/Interspeech.2019-1962\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7n20th Annual Conference of the International Speech Communication\\n  Association (INTERSPEECH 2019), 15--19 September 2019 (Graz, Austria)\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 10 Mar 2020 13:07:47 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 4 tables, 1 figure\\u00a7r"}']}
{title:'Kameoka et al. (§72020§r)', author: 'Hirokazu Kameoka; Kou Tanaka; Damian Kwasny; Takuhiro Kaneko; Nobukatsu Hojo', display:{Lore:['[{"text": "arXiv:1811.01609", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lConvS2S-VC: Fully convolutional sequence-to-sequence voice conversion\\u00a7r\\n\\n\\u00a78\\u00a7oHirokazu Kameoka\\nKou Tanaka\\nDamian Kwasny\\nTakuhiro Kaneko\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1811.01609\\u00a7r\\n\\nVersion:\\u00a77v3 (Tue, 6 Oct 2020 19:14:50 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oPublished in IEEE/ACM Trans. ASLP https://ieeexplore.ieee.org/document/9113442\\u00a7r"}']}
{title:'Li et al. (§72020§r)', author: 'Xiaofei Li; Laurent Girin; Sharon Gannot; Radu Horaud', display:{Lore:['[{"text": "arXiv:1812.08471", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMultichannel Online Dereverberation based on Spectral Magnitude Inverse Filtering\\u00a7r\\n\\n\\u00a78\\u00a7oXiaofei Li\\nLaurent Girin\\nSharon Gannot\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1812.08471\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/TASLP.2019.2919183\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nACM/IEEE Transactions on Audio, Speech, and Language Processing,\\n  27(9) 2019\\u00a7r\\n\\nVersion:\\u00a77v3 (Mon, 9 Nov 2020 11:14:58 GMT)\\u00a7r"}']}
{title:'Kreuk et al. (§72020§r)', author: 'Felix Kreuk; Yossi Adi; Bhiksha Raj; Rita Singh; Joseph Keshet', display:{Lore:['[{"text": "arXiv:1902.03083", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CR\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lHide and Speak: Towards Deep Neural Networks for Speech Steganography\\u00a7r\\n\\n\\u00a78\\u00a7oFelix Kreuk\\nYossi Adi\\nBhiksha Raj\\nRita Singh\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1902.03083\\u00a7r\\n\\nVersion:\\u00a77v2 (Mon, 27 Jul 2020 12:20:30 GMT)\\u00a7r"}']}
{title:'Trowitzsch et al. (§72020§r)', author: 'Ivo Trowitzsch; Jalil Taghia; Youssef Kashef; Klaus Obermayer', display:{Lore:['[{"text": "arXiv:1902.08314", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.MM\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lThe NIGENS General Sound Events Database\\u00a7r\\n\\n\\u00a78\\u00a7oIvo Trowitzsch\\nJalil Taghia\\nYoussef Kashef\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1902.08314\\u00a7r\\n\\nVersion:\\u00a77v4 (Wed, 1 Jan 2020 23:22:00 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oupdate to v4: added classification rate table, corrections,updates\\u00a7r"}']}
{title:'Yamamoto et al. (§72020§r)', author: 'Katsuhiko Yamamoto; Toshio Irino; Shoko Araki; Keisuke Kinoshita; Tomohiro Nakatani', display:{Lore:['[{"text": "arXiv:1904.02096", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lGEDI: Gammachirp Envelope Distortion Index for Predicting Intelligibility of Enhanced Speech\\u00a7r\\n\\n\\u00a78\\u00a7oKatsuhiko Yamamoto\\nToshio Irino\\nShoko Araki\\nKeisuke Kinoshita\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1904.02096\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1016/j.specom.2020.06.001\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nSpeech Communication, Vol. 123, pp. 43-58, 2020\\u00a7r\\n\\nVersion:\\u00a77v6 (Sun, 19 Jul 2020 05:32:29 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oPreprint, 37 pages, 6 tables, 9 figures\\u00a7r"}']}
{title:'Leshem et al. (§72020§r)', author: 'Roee Levy Leshem; Raja Giryes', display:{Lore:['[{"text": "arXiv:1904.03522", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lTaco-VC: A Single Speaker Tacotron based Voice Conversion with Limited Data\\u00a7r\\n\\n\\u00a78\\u00a7oRoee Levy Leshem\\nRaja Giryes\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1904.03522\\u00a7r\\n\\nVersion:\\u00a77v4 (Fri, 19 Jun 2020 07:18:11 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted to EUSIPCO 2020\\u00a7r"}']}
{title:'Latif et al. (§72020§r)', author: 'Siddique Latif; Rajib Rana; Sara Khalifa; Raja Jurdak; Julien Epps', display:{Lore:['[{"text": "arXiv:1904.03833", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDirect Modelling of Speech Emotion from Raw Speech\\u00a7r\\n\\n\\u00a78\\u00a7oSiddique Latif\\nRajib Rana\\nSara Khalifa\\nRaja Jurdak\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1904.03833\\u00a7r\\n\\nVersion:\\u00a77v4 (Tue, 28 Jul 2020 01:44:23 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oINTERSPEECH 2019\\u00a7r"}']}
{title:'Dinkel et al. (§72020§r)', author: 'Heinrich Dinkel; Kai Yu', display:{Lore:['[{"text": "arXiv:1904.03841", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDuration robust weakly supervised sound event detection\\u00a7r\\n\\n\\u00a78\\u00a7oHeinrich Dinkel\\nKai Yu\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1904.03841\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/ICASSP40776.2020.9053459\\u00a7r\\n\\nVersion:\\u00a77v3 (Sun, 26 Jan 2020 05:03:09 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted by ICASSP2020\\u00a7r"}']}
{title:'Honda et al. (§72020§r)', author: 'Shiori Honda; Yuri Ishikawa; Rei Konno; Eiko Imai; Natsumi Nomiyama; Kazuki Sakurada; Takuya Koumura; Hirohito M. Kondo; Shigeto Furukawa; Shinya Fujii; Masashi Nakatani', display:{Lore:['[{"text": "arXiv:1904.06851", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.MM\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lProximal binaural sound can induce subjective frisson\\u00a7r\\n\\n\\u00a78\\u00a7oShiori Honda\\nYuri Ishikawa\\nRei Konno\\n+ 7 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1904.06851\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.3389/fpsyg.2020.00316.\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nFront Psychol. 2020 Mar 3;11:316\\u00a7r\\n\\nVersion:\\u00a77v2 (Wed, 8 Apr 2020 07:53:12 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o21 pages, 3 figures, 3 tables, 3 supplemental figures, 3 supplementaltables\\u00a7r"}']}
{title:'Michelashvili et al. (§72020§r)', author: 'Michael Michelashvili; Lior Wolf', display:{Lore:['[{"text": "arXiv:1904.07612", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSpeech Denoising by Accumulating Per-Frequency Modeling Fluctuations\\u00a7r\\n\\n\\u00a78\\u00a7oMichael Michelashvili\\nLior Wolf\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1904.07612\\u00a7r\\n\\nVersion:\\u00a77v3 (Mon, 8 Jun 2020 20:38:08 GMT)\\u00a7r"}']}
{title:'Polyak et al. (§72020§r)', author: 'Adam Polyak; Lior Wolf; Yaniv Taigman', display:{Lore:['[{"text": "arXiv:1904.08983", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lTTS Skins: Speaker Conversion via ASR\\u00a7r\\n\\n\\u00a78\\u00a7oAdam Polyak\\nLior Wolf\\nYaniv Taigman\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1904.08983\\u00a7r\\n\\nVersion:\\u00a77v2 (Sun, 26 Jul 2020 11:18:14 GMT)\\u00a7r"}']}
{title:'Lin et al. (§72020§r)', author: 'Liwei Lin; Xiangdong Wang; Hong Liu; Yueliang Qian', display:{Lore:['[{"text": "arXiv:1905.10091", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSpecialized Decision Surface and Disentangled Feature for Weakly-Supervised Polyphonic Sound Event Detection\\u00a7r\\n\\n\\u00a78\\u00a7oLiwei Lin\\nXiangdong Wang\\nHong Liu\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1905.10091\\u00a7r\\n\\nVersion:\\u00a77v6 (Fri, 10 Apr 2020 17:20:21 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccept by TASLP\\u00a7r"}']}
{title:'Jia et al. (§72020§r)', author: 'Xiaoqi Jia; Jianwei Tai; Hang Zhou; Yakai Li; Weijuan Zhang; Haichao Du; Qingjia Huang', display:{Lore:['[{"text": "arXiv:1905.11173", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lET-GAN: Cross-Language Emotion Transfer Based on Cycle-Consistent Generative Adversarial Networks\\u00a7r\\n\\n\\u00a78\\u00a7oXiaoqi Jia\\nJianwei Tai\\nHang Zhou\\n+ 3 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1905.11173\\u00a7r\\n\\nVersion:\\u00a77v3 (Thu, 5 Mar 2020 13:44:30 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted by ECAI 2020, 8 pages, 4 figures\\u00a7r"}']}
{title:'Xu et al. (§72020§r)', author: 'Xuenan Xu; Heinrich Dinkel; Mengyue Wu; Kai Yu', display:{Lore:['[{"text": "arXiv:1905.13448", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAudio Caption in a Car Setting with a Sentence-Level Loss\\u00a7r\\n\\n\\u00a78\\u00a7oXuenan Xu\\nHeinrich Dinkel\\nMengyue Wu\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1905.13448\\u00a7r\\n\\nVersion:\\u00a77v2 (Fri, 23 Oct 2020 06:58:36 GMT)\\u00a7r"}']}
{title:'Nardelli (§72020§r)', author: 'Marco Buongiorno Nardelli', display:{Lore:['[{"text": "arXiv:1906.01453", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMUSICNTWRK: data tools for music theory, analysis and composition\\u00a7r\\n\\n\\u00a78\\u00a7oMarco Buongiorno Nardelli\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1906.01453\\u00a7r\\n\\nVersion:\\u00a77v4 (Tue, 21 Jul 2020 15:32:41 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oarXiv admin note: substantial text overlap with arXiv:1905.01842\\u00a7r"}']}
{title:'Fonseca et al. (§72020§r)', author: 'Eduardo Fonseca; Manoj Plakal; Frederic Font; Daniel P. W. Ellis; Xavier Serra', display:{Lore:['[{"text": "arXiv:1906.02975", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAudio tagging with noisy labels and minimal supervision\\u00a7r\\n\\n\\u00a78\\u00a7oEduardo Fonseca\\nManoj Plakal\\nFrederic Font\\nDaniel P. W. Ellis\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1906.02975\\u00a7r\\n\\nVersion:\\u00a77v4 (Mon, 20 Jan 2020 00:26:57 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oDCASE2019 Workshop\\u00a7r"}']}
{title:'McBride et al. (§72020§r)', author: 'John M. McBride; Tsvi Tlusty', display:{Lore:['[{"text": "arXiv:1906.06171", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r, \\u00a7bq-bio.NC\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lCross-cultural data shows musical scales evolved to maximise imperfect fifths\\u00a7r\\n\\n\\u00a78\\u00a7oJohn M. McBride\\nTsvi Tlusty\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1906.06171\\u00a7r\\n\\nVersion:\\u00a77v2 (Mon, 1 Jun 2020 11:13:47 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oincluding SI\\u00a7r"}']}
{title:'Ai et al. (§72020§r)', author: 'Yang Ai; Zhen-Hua Ling', display:{Lore:['[{"text": "arXiv:1906.09573", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Neural Vocoder with Hierarchical Generation of Amplitude and Phase Spectra for Statistical Parametric Speech Synthesis\\u00a7r\\n\\n\\u00a78\\u00a7oYang Ai\\nZhen-Hua Ling\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1906.09573\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/TASLP.2020.2970241\\u00a7r\\n\\nVersion:\\u00a77v2 (Wed, 5 Feb 2020 11:05:33 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oPublished in IEEETransactions on Audio, Speech and Language Processing\\u00a7r"}']}
{title:'Tang et al. (§72020§r)', author: 'Zhenyu Tang; Lianwu Chen; Bo Wu; Dong Yu; Dinesh Manocha', display:{Lore:['[{"text": "arXiv:1907.03988", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lImproving Reverberant Speech Training Using Diffuse Acoustic Simulation\\u00a7r\\n\\n\\u00a78\\u00a7oZhenyu Tang\\nLianwu Chen\\nBo Wu\\nDong Yu\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1907.03988\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/ICASSP40776.2020.9052932\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7n2020 IEEE International Conference on Acoustics, Speech and Signal\\n  Processing (ICASSP) (pp. 6969-6973)\\u00a7r\\n\\nVersion:\\u00a77v5 (Thu, 2 Apr 2020 18:25:46 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted to ICASSP 2020, impulse response generation code at https://github.com/RoyJames/pygsound\\u00a7r"}']}
{title:'Latif et al. (§72020§r)', author: 'Siddique Latif; Rajib Rana; Sara Khalifa; Raja Jurdak; Julien Epps; Björn W. Schuller', display:{Lore:['[{"text": "arXiv:1907.06078", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMulti-Task Semi-Supervised Adversarial Autoencoding for Speech Emotion Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oSiddique Latif\\nRajib Rana\\nSara Khalifa\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1907.06078\\u00a7r\\n\\nVersion:\\u00a77v5 (Sun, 22 Mar 2020 04:30:29 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted in IEEE Transactions on Affective Computing\\u00a7r"}']}
{title:'Latif et al. (§72020§r)', author: 'Siddique Latif; Junaid Qadir; Muhammad Bilal', display:{Lore:['[{"text": "arXiv:1907.06083", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lUnsupervised Adversarial Domain Adaptation for Cross-Lingual Speech Emotion Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oSiddique Latif\\nJunaid Qadir\\nMuhammad Bilal\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1907.06083\\u00a7r\\n\\nVersion:\\u00a77v4 (Tue, 28 Jul 2020 01:38:34 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted in Affective Computing Intelligent Interaction (ACII 2019)\\u00a7r"}']}
{title:'Sadeghi et al. (§72020§r)', author: 'Mostafa Sadeghi; Simon Leglaive; Xavier Alameda-PIneda; Laurent Girin; Radu Horaud', display:{Lore:['[{"text": "arXiv:1908.02590", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAudio-visual Speech Enhancement Using Conditional Variational Auto-Encoders\\u00a7r\\n\\n\\u00a78\\u00a7oMostafa Sadeghi\\nSimon Leglaive\\nXavier Alameda-PIneda\\nLaurent Girin\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1908.02590\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/TASLP.2020.3000593\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nIEEE/ACM Transactions on Audio, Speech and Language Processing,\\n  28, 2020\\u00a7r\\n\\nVersion:\\u00a77v3 (Tue, 26 May 2020 09:38:39 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to IEEE/ACM Transactionson Audio, Speech, and Language Processing\\u00a7r"}']}
{title:'Zhen et al. (§72020§r)', author: 'Kai Zhen; Mi Suk Lee; Minje Kim', display:{Lore:['[{"text": "arXiv:1908.06468", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Dual-Staged Context Aggregation Method Towards Efficient End-To-End Speech Enhancement\\u00a7r\\n\\n\\u00a78\\u00a7oKai Zhen\\nMi Suk Lee\\nMinje Kim\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1908.06468\\u00a7r\\n\\nVersion:\\u00a77v4 (Thu, 6 Feb 2020 23:28:51 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted in Proceedings of the ICASSP, Barcelona, Spain, May 4-8, 2020\\u00a7r"}']}
{title:'Sudharsan et al. (§72020§r)', author: 'Bharath Sudharsan; Manigandan Chockalingam', display:{Lore:['[{"text": "arXiv:1908.07324", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Microphone Array and Voice Algorithm based Smart Hearing Aid\\u00a7r\\n\\n\\u00a78\\u00a7oBharath Sudharsan\\nManigandan Chockalingam\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1908.07324\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.5120/ijca2019919295\\u00a7r\\n\\nVersion:\\u00a77v4 (Fri, 5 Jun 2020 21:55:22 GMT)\\u00a7r"}']}
{title:'Li et al. (§72020§r)', author: 'Andong Li; Minmin Yuan; Chengshi Zheng; Xiaodong Li', display:{Lore:['[{"text": "arXiv:1908.10768", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lConvolutional Recurrent Neural Network Based Progressive Learning for Monaural Speech Enhancement\\u00a7r\\n\\n\\u00a78\\u00a7oAndong Li\\nMinmin Yuan\\nChengshi Zheng\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1908.10768\\u00a7r\\n\\nVersion:\\u00a77v3 (Sat, 11 Jan 2020 14:06:29 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o23 pages,5 figures, Submitted to Applied Acoustics\\u00a7r"}']}
{title:'Sharma et al. (§72020§r)', author: 'Jivitesh Sharma; Ole-Christoffer Granmo; Morten Goodwin', display:{Lore:['[{"text": "arXiv:1908.11219", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lEnvironment Sound Classification using Multiple Feature Channels and Attention based Deep Convolutional Neural Network\\u00a7r\\n\\n\\u00a78\\u00a7oJivitesh Sharma\\nOle-Christoffer Granmo\\nMorten Goodwin\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1908.11219\\u00a7r\\n\\nVersion:\\u00a77v9 (Tue, 8 Dec 2020 12:55:29 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oRe-checking results\\u00a7r"}']}
{title:'Kolbæk et al. (§72020§r)', author: 'Morten Kolbæk; Zheng-Hua Tan; Søren Holdt Jensen; Jesper Jensen', display:{Lore:['[{"text": "arXiv:1909.01019", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lOn Loss Functions for Supervised Monaural Time-Domain Speech Enhancement\\u00a7r\\n\\n\\u00a78\\u00a7oMorten Kolb\\u00e6k\\nZheng-Hua Tan\\nS\\u00f8ren Holdt Jensen\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1909.01019\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/TASLP.2020.2968738\\u00a7r\\n\\nVersion:\\u00a77v2 (Thu, 30 Jan 2020 10:58:32 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oPublished in the IEEE Transactions on Audio, Speech and Language Processing\\u00a7r"}']}
{title:'Liu et al. (§72020§r)', author: 'Chang-Le Liu; Sze-Wei Fu; You-Jin Li; Jen-Wei Huang; Hsin-Min Wang; Yu Tsao', display:{Lore:['[{"text": "arXiv:1909.11909", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMultichannel Speech Enhancement by Raw Waveform-mapping using Fully Convolutional Networks\\u00a7r\\n\\n\\u00a78\\u00a7oChang-Le Liu\\nSze-Wei Fu\\nYou-Jin Li\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1909.11909\\u00a7r\\n\\nVersion:\\u00a77v3 (Mon, 24 Feb 2020 08:47:23 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted to IEEE/ACM Transactionson Audio, Speech and Language Processing\\u00a7r"}']}
{title:'Tseng et al. (§72020§r)', author: 'Rung-Yu Tseng; Tao-Wei Wang; Szu-Wei Fu; Chia-Ying Lee; Yu Tsao', display:{Lore:['[{"text": "arXiv:1909.11919", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Study of Joint Effect on Denoising Techniques and Visual Cues to Improve Speech Intelligibility in Cochlear Implant Simulation\\u00a7r\\n\\n\\u00a78\\u00a7oRung-Yu Tseng\\nTao-Wei Wang\\nSzu-Wei Fu\\nChia-Ying Lee\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1909.11919\\u00a7r\\n\\nVersion:\\u00a77v2 (Fri, 18 Dec 2020 07:00:11 GMT)\\u00a7r"}']}
{title:'Guo et al. (§72020§r)', author: 'Rui Guo; Dorien Herremans; Thor Magnusson', display:{Lore:['[{"text": "arXiv:1910.02049", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.IR\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMidi Miner \\u2013 A Python library for tonal tension and track classification\\u00a7r\\n\\n\\u00a78\\u00a7oRui Guo\\nDorien Herremans\\nThor Magnusson\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1910.02049\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 26 May 2020 08:35:20 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o2 pages. ISMIR - Late Breaking Demo, Delft, The Netherlands. November 2019\\u00a7r"}']}
{title:'Zhao et al. (§72020§r)', author: 'Wenbo Zhao; Rita Singh', display:{Lore:['[{"text": "arXiv:1910.08886", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSpeech-Based Parameter Estimation of an Asymmetric Vocal Fold Oscillation Model and Its Application in Discriminating Vocal Fold Pathologies\\u00a7r\\n\\n\\u00a78\\u00a7oWenbo Zhao\\nRita Singh\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1910.08886\\u00a7r\\n\\nVersion:\\u00a77v3 (Wed, 12 Feb 2020 16:18:41 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted by ICASSP 2020. Copyright 2020 IEEE. 6 pages, 4 figures\\u00a7r"}']}
{title:'Li et al. (§72020§r)', author: 'Bai Li; Jing Yi Xie; Frank Rudzicz', display:{Lore:['[{"text": "arXiv:1910.08987", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lRepresentation Learning for Discovering Phonemic Tone Contours\\u00a7r\\n\\n\\u00a78\\u00a7oBai Li\\nJing Yi Xie\\nFrank Rudzicz\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1910.08987\\u00a7r\\n\\nVersion:\\u00a77v2 (Thu, 14 May 2020 22:23:28 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted by SIGMORPHON 2020: 17th SIGMORPHON Workshop on Computational Research in Phonetics, Phonology, and Morphology\\u00a7r"}']}
{title:'Kegler et al. (§72020§r)', author: 'Mikolaj Kegler; Pierre Beckmann; Milos Cernak', display:{Lore:['[{"text": "arXiv:1910.09058", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDeep speech inpainting of time-frequency masks\\u00a7r\\n\\n\\u00a78\\u00a7oMikolaj Kegler\\nPierre Beckmann\\nMilos Cernak\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1910.09058\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.21437/Interspeech.2020-1532\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nProc. Interspeech 2020, 3276-3280\\u00a7r\\n\\nVersion:\\u00a77v5 (Sat, 29 Aug 2020 18:13:04 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted to InterSpeech2020\\u00a7r"}']}
{title:'Zhang et al. (§72020§r)', author: 'Ruixiong Zhang; Wei Zou; Xiangang Li', display:{Lore:['[{"text": "arXiv:1910.09935", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lCross-task pre-training for on-device acoustic scene classification\\u00a7r\\n\\n\\u00a78\\u00a7oRuixiong Zhang\\nWei Zou\\nXiangang Li\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1910.09935\\u00a7r\\n\\nVersion:\\u00a77v2 (Sat, 24 Oct 2020 05:19:12 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7opresented at Interspeech workshop 2020\\u00a7r"}']}
{title:'Blaauw et al. (§72020§r)', author: 'Merlijn Blaauw; Jordi Bonada', display:{Lore:['[{"text": "arXiv:1910.09989", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSequence-to-sequence Singing Synthesis Using the Feed-forward Transformer\\u00a7r\\n\\n\\u00a78\\u00a7oMerlijn Blaauw\\nJordi Bonada\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1910.09989\\u00a7r\\n\\nVersion:\\u00a77v2 (Thu, 20 Feb 2020 11:42:15 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 1 figure, accepted at ICASSP 2020\\u00a7r"}']}
{title:'Koerich et al. (§72020§r)', author: 'Karl Michel Koerich; Mohammad Esmaeilpour; Sajjad Abdoli; Jr. Alceu de Souza Britto; Alessandro Lameiras Koerich', display:{Lore:['[{"text": "arXiv:1910.10106", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.MM\\u00a7r, \\u00a7eeess.AS\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lCross-Representation Transferability of Adversarial Attacks: From Spectrograms to Audio Waveforms\\u00a7r\\n\\n\\u00a78\\u00a7oKarl Michel Koerich\\nMohammad Esmaeilpour\\nSajjad Abdoli\\nJr. Alceu de Souza Britto\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1910.10106\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nIEEE International Joint Conference on Neural Networks (IJCNN\\n  2020), Glasgow, UK\\u00a7r\\n\\nVersion:\\u00a77v4 (Wed, 29 Jul 2020 11:16:58 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o8 pages\\u00a7r"}']}
{title:'Lostanlen et al. (§72020§r)', author: 'Vincent Lostanlen; Sripathi Sridhar; Brian McFee; Andrew Farnsworth; Juan Pablo Bello', display:{Lore:['[{"text": "arXiv:1910.10246", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lLearning the helix topology of musical pitch\\u00a7r\\n\\n\\u00a78\\u00a7oVincent Lostanlen\\nSripathi Sridhar\\nBrian McFee\\nAndrew Farnsworth\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1910.10246\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 4 Feb 2020 19:49:35 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 6 figures. To appear in the Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP). Barcelona, Spain, May 2020\\u00a7r"}']}
{title:'Maciejewski et al. (§72020§r)', author: 'Matthew Maciejewski; Gordon Wichern; Emmett McQuinn; Jonathan Le Roux', display:{Lore:['[{"text": "arXiv:1910.10279", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lWHAMR!: Noisy and Reverberant Single-Channel Speech Separation\\u00a7r\\n\\n\\u00a78\\u00a7oMatthew Maciejewski\\nGordon Wichern\\nEmmett McQuinn\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1910.10279\\u00a7r\\n\\nVersion:\\u00a77v2 (Fri, 14 Feb 2020 16:41:31 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted for publication at ICASSP 2020\\u00a7r"}']}
{title:'Pariente et al. (§72020§r)', author: 'Manuel Pariente; Samuele Cornell; Antoine Deleforge; Emmanuel Vincent', display:{Lore:['[{"text": "arXiv:1910.10400", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r, \\u00a7eeess.SP\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lFilterbank design for end-to-end speech separation\\u00a7r\\n\\n\\u00a78\\u00a7oManuel Pariente\\nSamuele Cornell\\nAntoine Deleforge\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1910.10400\\u00a7r\\n\\nVersion:\\u00a77v2 (Fri, 28 Feb 2020 11:48:11 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oICASSP 2020\\u00a7r"}']}
{title:'Kitić et al. (§72020§r)', author: 'Srđan Kitić; Clément Gaultier; Grégory Pallone', display:{Lore:['[{"text": "arXiv:1910.10661", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r, \\u00a7eeess.SP\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Comparative Study of Multilateration Methods for Single-Source Localization in Distributed Audio\\u00a7r\\n\\n\\u00a78\\u00a7oSr\\u0111an Kiti\\u0107\\nCl\\u00e9ment Gaultier\\nGr\\u00e9gory Pallone\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1910.10661\\u00a7r\\n\\nVersion:\\u00a77v4 (Tue, 28 Jul 2020 16:17:02 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oTo appear at IWIS - The 1st International Workshop on the Internet of Sounds\\u00a7r"}']}
{title:'Kim et al. (§72020§r)', author: 'Jaeyoung Kim; Mostafa El-Khamy; Jungwon Lee', display:{Lore:['[{"text": "arXiv:1910.10707", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lEnd-to-End Multi-Task Denoising for the Joint Optimization of Perceptual Speech Metrics\\u00a7r\\n\\n\\u00a78\\u00a7oJaeyoung Kim\\nMostafa El-Khamy\\nJungwon Lee\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1910.10707\\u00a7r\\n\\nVersion:\\u00a77v2 (Wed, 6 May 2020 00:17:38 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, submitted to Interspeech 2020. arXiv admin note: substantial text overlap with arXiv:1901.09146\\u00a7r"}']}
{title:'Tang et al. (§72020§r)', author: 'Zhenyu Tang; Hsien-Yu Meng; Dinesh Manocha', display:{Lore:['[{"text": "arXiv:1910.10815", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lLow-frequency Compensated Synthetic Impulse Responses for Improved Far-field Speech Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oZhenyu Tang\\nHsien-Yu Meng\\nDinesh Manocha\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1910.10815\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/ICASSP40776.2020.9054454\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7n2020 IEEE International Conference on Acoustics, Speech and Signal\\n  Processing (ICASSP) (pp. 6974-6978)\\u00a7r\\n\\nVersion:\\u00a77v3 (Tue, 11 Feb 2020 02:05:46 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted to ICASSP 2020\\u00a7r"}']}
{title:'Costa et al. (§72020§r)', author: 'Luciano da Fontoura Costa; Henrique Ferraz de Arruda', display:{Lore:['[{"text": "arXiv:1910.11047", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSyntonets: Toward A Harmony-Inspired General Model of Complex Networks\\u00a7r\\n\\n\\u00a78\\u00a7oLuciano da Fontoura Costa\\nHenrique Ferraz de Arruda\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1910.11047\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1140/epjb/e2020-10357-1\\u00a7r\\n\\nVersion:\\u00a77v2 (Mon, 11 May 2020 18:17:47 GMT)\\u00a7r"}']}
{title:'Chung et al. (§72020§r)', author: 'Joon Son Chung; Jaesung Huh; Seongkyu Mun', display:{Lore:['[{"text": "arXiv:1910.11238", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDelving into VoxCeleb: environment invariant speaker recognition\\u00a7r\\n\\n\\u00a78\\u00a7oJoon Son Chung\\nJaesung Huh\\nSeongkyu Mun\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1910.11238\\u00a7r\\n\\nVersion:\\u00a77v2 (Mon, 3 Feb 2020 07:02:23 GMT)\\u00a7r"}']}
{title:'Lian et al. (§72020§r)', author: 'Zheng Lian; Zhengqi Wen', display:{Lore:['[{"text": "arXiv:1910.11269", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lTowards Fine-Grained Prosody Control for Voice Conversion\\u00a7r\\n\\n\\u00a78\\u00a7oZheng Lian\\nZhengqi Wen\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1910.11269\\u00a7r\\n\\nVersion:\\u00a77v2 (Wed, 27 May 2020 07:29:38 GMT)\\u00a7r"}']}
{title:'Kumar et al. (§72020§r)', author: 'Anurag Kumar; Vamsi Krishna Ithapu', display:{Lore:['[{"text": "arXiv:1910.11789", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSecost: Sequential co-supervision for large scale weakly labeled audio event detection\\u00a7r\\n\\n\\u00a78\\u00a7oAnurag Kumar\\nVamsi Krishna Ithapu\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1910.11789\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/ICASSP40776.2020.9053613\\u00a7r\\n\\nVersion:\\u00a77v3 (Mon, 4 May 2020 06:48:15 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted IEEE ICASSP 2020\\u00a7r"}']}
{title:'Spadini et al. (§72020§r)', author: 'Tito Spadini; Dimitri Leandro de Oliveira Silva; Ricardo Suyama', display:{Lore:['[{"text": "arXiv:1910.12369", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSound Event Recognition in a Smart City Surveillance Context\\u00a7r\\n\\n\\u00a78\\u00a7oTito Spadini\\nDimitri Leandro de Oliveira Silva\\nRicardo Suyama\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1910.12369\\u00a7r\\n\\nVersion:\\u00a77v2 (Sat, 1 Feb 2020 20:36:20 GMT)\\u00a7r"}']}
{title:'Fan et al. (§72020§r)', author: 'Zhiyun Fan; Shiyu Zhou; Bo Xu', display:{Lore:['[{"text": "arXiv:1910.12418", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lUnsupervised pre-training for sequence to sequence speech recognition\\u00a7r\\n\\n\\u00a78\\u00a7oZhiyun Fan\\nShiyu Zhou\\nBo Xu\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1910.12418\\u00a7r\\n\\nVersion:\\u00a77v2 (Thu, 2 Jan 2020 01:45:28 GMT)\\u00a7r"}']}
{title:'Yesiler et al. (§72020§r)', author: 'Furkan Yesiler; Joan Serrà; Emilia Gómez', display:{Lore:['[{"text": "arXiv:1910.12551", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAccurate and Scalable Version Identification Using Musically-Motivated Embeddings\\u00a7r\\n\\n\\u00a78\\u00a7oFurkan Yesiler\\nJoan Serr\\u00e0\\nEmilia G\\u00f3mez\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1910.12551\\u00a7r\\n\\nVersion:\\u00a77v2 (Mon, 13 Apr 2020 12:40:10 GMT)\\u00a7r"}']}
{title:'Koyama et al. (§72020§r)', author: 'Yuichiro Koyama; Bhiksha Raj', display:{Lore:['[{"text": "arXiv:1910.14262", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lW-Net BF: DNN-based Beamformer Using Joint Training Approach\\u00a7r\\n\\n\\u00a78\\u00a7oYuichiro Koyama\\nBhiksha Raj\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1910.14262\\u00a7r\\n\\nVersion:\\u00a77v2 (Sat, 29 Feb 2020 19:59:23 GMT)\\u00a7r"}']}
{title:'Pishdadian et al. (§72020§r)', author: 'Fatemeh Pishdadian; Gordon Wichern; Jonathan Le Roux', display:{Lore:['[{"text": "arXiv:1911.02182", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lFinding Strength in Weakness: Learning to Separate Sounds with Weak Supervision\\u00a7r\\n\\n\\u00a78\\u00a7oFatemeh Pishdadian\\nGordon Wichern\\nJonathan Le Roux\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1911.02182\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/TASLP.2020.3013105\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nIEEE/ACM Transactions on Audio, Speech and Language Processing vol\\n  28 (2020) 2386-2399\\u00a7r\\n\\nVersion:\\u00a77v2 (Fri, 28 Aug 2020 18:53:04 GMT)\\u00a7r"}']}
{title:'Mun et al. (§72020§r)', author: 'Seongkyu Mun; Soyeon Choe; Jaesung Huh; Joon Son Chung', display:{Lore:['[{"text": "arXiv:1911.02411", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lThe sound of my voice: speaker representation loss for target voice separation\\u00a7r\\n\\n\\u00a78\\u00a7oSeongkyu Mun\\nSoyeon Choe\\nJaesung Huh\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1911.02411\\u00a7r\\n\\nVersion:\\u00a77v2 (Thu, 27 Feb 2020 11:45:32 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oTo appear in ICASSP 2020. The first two authors contributed equally to this work\\u00a7r"}']}
{title:'Magron et al. (§72020§r)', author: 'Paul Magron; Tuomas Virtanen', display:{Lore:['[{"text": "arXiv:1911.03128", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lOnline Spectrogram Inversion for Low-Latency Audio Source Separation\\u00a7r\\n\\n\\u00a78\\u00a7oPaul Magron\\nTuomas Virtanen\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1911.03128\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/LSP.2020.2970310\\u00a7r\\n\\nVersion:\\u00a77v3 (Mon, 24 Feb 2020 11:15:25 GMT)\\u00a7r"}']}
{title:'Krishna et al. (§72020§r)', author: 'Gautam Krishna; Co Tran; Mason Carnahan; Yan Han; Ahmed H Tewfik', display:{Lore:['[{"text": "arXiv:1911.04261", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r, \\u00a7eeess.SP\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lVoice Activity Detection in presence of background noise using EEG\\u00a7r\\n\\n\\u00a78\\u00a7oGautam Krishna\\nCo Tran\\nMason Carnahan\\nYan Han\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1911.04261\\u00a7r\\n\\nVersion:\\u00a77v5 (Sat, 14 Mar 2020 04:51:06 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oOn preparation for submission to EUSIPCO 2020. arXiv admin note: text overlap with arXiv:1906.08871, arXiv:1909.09132\\u00a7r"}']}
{title:'Tang et al. (§72020§r)', author: 'Zhenyu Tang; Nicholas J. Bryan; Dingzeyu Li; Timothy R. Langlois; Dinesh Manocha', display:{Lore:['[{"text": "arXiv:1911.06245", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.GR\\u00a7r, \\u00a7acs.MM\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lScene-Aware Audio Rendering via Deep Acoustic Analysis\\u00a7r\\n\\n\\u00a78\\u00a7oZhenyu Tang\\nNicholas J. Bryan\\nDingzeyu Li\\nTimothy R. Langlois\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1911.06245\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/TVCG.2020.2973058\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nIEEE Transactions on Visualization and Computer Graphics ( Volume:\\n  26, Issue: 5, May 2020)\\u00a7r\\n\\nVersion:\\u00a77v2 (Sun, 9 Feb 2020 19:20:58 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted to IEEEVR 2020 Journal Track (TVCG)\\u00a7r"}']}
{title:'Wang et al. (§72020§r)', author: 'Zhong-Qiu Wang; Hakan Erdogan; Scott Wisdom; Kevin Wilson; Desh Raj; Shinji Watanabe; Zhuo Chen; John R. Hershey', display:{Lore:['[{"text": "arXiv:1911.07953", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSequential Multi-Frame Neural Beamforming for Speech Separation and Enhancement\\u00a7r\\n\\n\\u00a78\\u00a7oZhong-Qiu Wang\\nHakan Erdogan\\nScott Wisdom\\n+ 4 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1911.07953\\u00a7r\\n\\nVersion:\\u00a77v3 (Tue, 3 Nov 2020 19:35:49 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o7 pages, 7 figures, IEEE SLT 2021 (slt2020.org)\\u00a7r"}']}
{title:'Heitkaemper et al. (§72020§r)', author: 'Jens Heitkaemper; Darius Jakobeit; Christoph Boeddeker; Lukas Drude; Reinhold Haeb-Umbach', display:{Lore:['[{"text": "arXiv:1911.08895", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDemystifying TasNet: A Dissecting Approach\\u00a7r\\n\\n\\u00a78\\u00a7oJens Heitkaemper\\nDarius Jakobeit\\nChristoph Boeddeker\\nLukas Drude\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1911.08895\\u00a7r\\n\\nVersion:\\u00a77v2 (Wed, 5 Feb 2020 11:46:57 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted to ICASSP 2020\\u00a7r"}']}
{title:'Carbajal et al. (§72020§r)', author: 'Guillaume Carbajal; Romain Serizel; Emmanuel Vincent; Eric Humbert', display:{Lore:['[{"text": "arXiv:1911.08934", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lJoint NN-Supported Multichannel Reduction of Acoustic Echo, Reverberation and Noise\\u00a7r\\n\\n\\u00a78\\u00a7oGuillaume Carbajal\\nRomain Serizel\\nEmmanuel Vincent\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1911.08934\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/TASLP.2020.3008974\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nIEEE/ACM Transactions on Audio, Speech and Language Processing\\n  2020\\u00a7r\\n\\nVersion:\\u00a77v4 (Mon, 27 Jul 2020 09:13:04 GMT)\\u00a7r"}']}
{title:'Gururani et al. (§72020§r)', author: 'Siddharth Gururani; Kilol Gupta; Dhaval Shah; Zahra Shakeri; Jervis Pinto', display:{Lore:['[{"text": "arXiv:1911.09645", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lProsody Transfer in Neural Text to Speech Using Global Pitch and Loudness Features\\u00a7r\\n\\n\\u00a78\\u00a7oSiddharth Gururani\\nKilol Gupta\\nDhaval Shah\\nZahra Shakeri\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1911.09645\\u00a7r\\n\\nVersion:\\u00a77v2 (Fri, 15 May 2020 20:46:24 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, in review for conference publication\\u00a7r"}']}
{title:'LI et al. (§72020§r)', author: 'Xiaofei LI; Radu Horaud', display:{Lore:['[{"text": "arXiv:1911.10791", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lNarrow-band Deep Filtering for Multichannel Speech Enhancement\\u00a7r\\n\\n\\u00a78\\u00a7oXiaofei LI\\nRadu Horaud\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1911.10791\\u00a7r\\n\\nVersion:\\u00a77v2 (Wed, 23 Sep 2020 09:07:45 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to IEEE/ACM Transactionson Audio, Speech and Language Processing\\u00a7r"}']}
{title:'Peracha (§72020§r)', author: 'Omar Peracha', display:{Lore:['[{"text": "arXiv:1911.11775", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lImproving Polyphonic Music Models with Feature-Rich Encoding\\u00a7r\\n\\n\\u00a78\\u00a7oOmar Peracha\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1911.11775\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.5281/zenodo.4245396\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nProceedings of the 21st International Society for Music\\n  Information Retrieval Conference, ISMIR 2020\\u00a7r\\n\\nVersion:\\u00a77v3 (Mon, 14 Sep 2020 22:18:36 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oProceedings of the 21st International Society for Music Information Retrieval Conference, ISMIR 2020\\u00a7r"}']}
{title:'Takahashi et al. (§72020§r)', author: 'Naoya Takahashi; Mayank Kumar Singh; Sakya Basak; Parthasaarathy Sudarsanam; Sriram Ganapathy; Yuki Mitsufuji', display:{Lore:['[{"text": "arXiv:1911.12928", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lImproving Voice Separation by Incorporating End-to-end Speech Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oNaoya Takahashi\\nMayank Kumar Singh\\nSakya Basak\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1911.12928\\u00a7r\\n\\nVersion:\\u00a77v2 (Mon, 4 May 2020 00:03:27 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted in ICASSP 2020\\u00a7r"}']}
{title:'Ping et al. (§72020§r)', author: 'Wei Ping; Kainan Peng; Kexin Zhao; Zhao Song', display:{Lore:['[{"text": "arXiv:1912.01219", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lWaveFlow: A Compact Flow-based Model for Raw Audio\\u00a7r\\n\\n\\u00a78\\u00a7oWei Ping\\nKainan Peng\\nKexin Zhao\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1912.01219\\u00a7r\\n\\nVersion:\\u00a77v4 (Wed, 24 Jun 2020 20:10:12 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oPublished at ICML2020. Code and pre-trained models: https://github.com/PaddlePaddle/Parakeet\\u00a7r"}']}
{title:'Qin et al. (§72020§r)', author: 'Xiaoyi Qin; Hui Bu; Ming Li', display:{Lore:['[{"text": "arXiv:1912.01231", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lHI-MIA : A Far-field Text-Dependent Speaker Verification Database and the Baselines\\u00a7r\\n\\n\\u00a78\\u00a7oXiaoyi Qin\\nHui Bu\\nMing Li\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1912.01231\\u00a7r\\n\\nVersion:\\u00a77v3 (Sat, 1 Feb 2020 09:53:49 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted at ICASSP 2020\\u00a7r"}']}
{title:'Deng et al. (§72020§r)', author: 'Chengqi Deng; Chengzhu Yu; Heng Lu; Chao Weng; Dong Yu', display:{Lore:['[{"text": "arXiv:1912.01852", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lPitchNet: Unsupervised Singing Voice Conversion with Pitch Adversarial Network\\u00a7r\\n\\n\\u00a78\\u00a7oChengqi Deng\\nChengzhu Yu\\nHeng Lu\\nChao Weng\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1912.01852\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 18 Feb 2020 07:20:24 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted by ICASSP 2020\\u00a7r"}']}
{title:'Hsu et al. (§72020§r)', author: 'Po-chun Hsu; Chun-hsuan Wang; Andy T. Liu; Hung-yi Lee', display:{Lore:['[{"text": "arXiv:1912.02461", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lTowards Robust Neural Vocoding for Speech Generation: A Survey\\u00a7r\\n\\n\\u00a78\\u00a7oPo-chun Hsu\\nChun-hsuan Wang\\nAndy T. Liu\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1912.02461\\u00a7r\\n\\nVersion:\\u00a77v3 (Thu, 20 Aug 2020 10:19:48 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to INTERSPEECH 2020\\u00a7r"}']}
{title:'Kong et al. (§72020§r)', author: 'Qiuqiang Kong; Yong Xu; Wenwu Wang; Mark D. Plumbley', display:{Lore:['[{"text": "arXiv:1912.04761", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSound Event Detection of Weakly Labelled Data with CNN-Transformer and Automatic Threshold Optimization\\u00a7r\\n\\n\\u00a78\\u00a7oQiuqiang Kong\\nYong Xu\\nWenwu Wang\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1912.04761\\u00a7r\\n\\nVersion:\\u00a77v2 (Sun, 23 Aug 2020 10:30:01 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o11 pages\\u00a7r"}']}
{title:'Cotescu et al. (§72020§r)', author: 'Marius Cotescu; Thomas Drugman; Goeric Huybrechts; Jaime Lorenzo-Trueba; Alexis Moinet', display:{Lore:['[{"text": "arXiv:1912.05289", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lVoice Conversion for Whispered Speech Synthesis\\u00a7r\\n\\n\\u00a78\\u00a7oMarius Cotescu\\nThomas Drugman\\nGoeric Huybrechts\\nJaime Lorenzo-Trueba\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1912.05289\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/LSP.2019.2961213\\u00a7r\\n\\nVersion:\\u00a77v2 (Fri, 17 Jan 2020 20:43:49 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to IEEESignal Processing Letters\\u00a7r"}']}
{title:'Choi et al. (§72020§r)', author: 'Kristy Choi; Curtis Hawthorne; Ian Simon; Monica Dinculescu; Jesse Engel', display:{Lore:['[{"text": "arXiv:1912.05537", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lEncoding Musical Style with Transformer Autoencoders\\u00a7r\\n\\n\\u00a78\\u00a7oKristy Choi\\nCurtis Hawthorne\\nIan Simon\\nMonica Dinculescu\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1912.05537\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 30 Jun 2020 05:00:40 GMT)\\u00a7r"}']}
{title:'Wang et al. (§72020§r)', author: 'Helin Wang; Yuexian Zou; Dading Chong; Wenwu Wang', display:{Lore:['[{"text": "arXiv:1912.06808", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lEnvironmental Sound Classification with Parallel Temporal-spectral Attention\\u00a7r\\n\\n\\u00a78\\u00a7oHelin Wang\\nYuexian Zou\\nDading Chong\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1912.06808\\u00a7r\\n\\nVersion:\\u00a77v3 (Thu, 21 May 2020 02:38:05 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7osubmitted to INTERSPEECH2020\\u00a7r"}']}
{title:'Schlecht et al. (§72020§r)', author: 'Sebastian J. Schlecht; Emanuël A. P. Habets', display:{Lore:['[{"text": "arXiv:1912.08888", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lScattering in Feedback Delay Networks\\u00a7r\\n\\n\\u00a78\\u00a7oSebastian J. Schlecht\\nEmanu\\u00ebl A. P. Habets\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1912.08888\\u00a7r\\n\\nVersion:\\u00a77v2 (Sat, 6 Jun 2020 14:08:39 GMT)\\u00a7r"}']}
{title:'Kong et al. (§72020§r)', author: 'Qiuqiang Kong; Yin Cao; Turab Iqbal; Yuxuan Wang; Wenwu Wang; Mark D. Plumbley', display:{Lore:['[{"text": "arXiv:1912.10211", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lPANNs: Large-Scale Pretrained Audio Neural Networks for Audio Pattern Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oQiuqiang Kong\\nYin Cao\\nTurab Iqbal\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1912.10211\\u00a7r\\n\\nVersion:\\u00a77v5 (Sun, 23 Aug 2020 11:35:41 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o14 pages\\u00a7r"}']}
{title:'Yan et al. (§72020§r)', author: 'WeiRan Yan; MaoLin Tang; Qijun Zhao; Peng Chen; Dunwu Qi; Rong Hou; Zhihe Zhang', display:{Lore:['[{"text": "arXiv:1912.11333", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAudio-based automatic mating success prediction of giant pandas\\u00a7r\\n\\n\\u00a78\\u00a7oWeiRan Yan\\nMaoLin Tang\\nQijun Zhao\\n+ 3 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1912.11333\\u00a7r\\n\\nVersion:\\u00a77v3 (Wed, 3 Jun 2020 06:30:54 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oThe manuscript needs further revision\\u00a7r"}']}
{title:'Liu et al. (§72020§r)', author: 'Jen-Yu Liu; Yu-Hua Chen; Yin-Cheng Yeh; Yi-Hsuan Yang', display:{Lore:['[{"text": "arXiv:1912.11747", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lScore and Lyrics-Free Singing Voice Generation\\u00a7r\\n\\n\\u00a78\\u00a7oJen-Yu Liu\\nYu-Hua Chen\\nYin-Cheng Yeh\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1912.11747\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 21 Jul 2020 06:48:42 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted by International Conference on Computational Creativity (ICCC) 2020\\u00a7r"}']}
{title:'Lu et al. (§72020§r)', author: 'Xugang Lu; Peng Shen; Sheng Li; Yu Tsao; Hisashi Kawai', display:{Lore:['[{"text": "arXiv:1912.12011", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lCross-scale Attention Model for Acoustic Event Classification\\u00a7r\\n\\n\\u00a78\\u00a7oXugang Lu\\nPeng Shen\\nSheng Li\\nYu Tsao\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1912.12011\\u00a7r\\n\\nVersion:\\u00a77v2 (Mon, 15 Jun 2020 21:10:38 GMT)\\u00a7r"}']}
{title:'Cheuk et al. (§72020§r)', author: 'Kin Wai Cheuk; Hans Anderson; Kat Agres; Dorien Herremans', display:{Lore:['[{"text": "arXiv:1912.12055", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lnnAudio: An on-the-fly GPU Audio to Spectrogram Conversion Toolbox Using 1D Convolution Neural Networks\\u00a7r\\n\\n\\u00a78\\u00a7oKin Wai Cheuk\\nHans Anderson\\nKat Agres\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1912.12055\\u00a7r\\n\\nVersion:\\u00a77v3 (Sat, 22 Aug 2020 03:17:35 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted In IEEEAccess\\u00a7r"}']}
{title:'Li et al. (§72020§r)', author: 'Jixiang Li; Chuming Liang; Bo Zhang; Zhao Wang; Fei Xiang; Xiangxiang Chu', display:{Lore:['[{"text": "arXiv:1912.12825", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lNeural Architecture Search on Acoustic Scene Classification\\u00a7r\\n\\n\\u00a78\\u00a7oJixiang Li\\nChuming Liang\\nBo Zhang\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1912.12825\\u00a7r\\n\\nVersion:\\u00a77v2 (Wed, 5 Aug 2020 04:58:06 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted to Interspeech 2020\\u00a7r"}']}
{title:'Drugman et al. (§72020§r)', author: 'Thomas Drugman; Thomas Dubuisson; Thierry Dutoit', display:{Lore:['[{"text": "arXiv:2001.00372", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lPhase-based Information for Voice Pathology Detection\\u00a7r\\n\\n\\u00a78\\u00a7oThomas Drugman\\nThomas Dubuisson\\nThierry Dutoit\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2001.00372\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 2 Jan 2020 09:51:51 GMT)\\u00a7r"}']}
{title:'Gu et al. (§72020§r)', author: 'Rongzhi Gu; Yuexian Zou', display:{Lore:['[{"text": "arXiv:2001.00391", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lTemporal-Spatial Neural Filter: Direction Informed End-to-End Multi-channel Target Speech Separation\\u00a7r\\n\\n\\u00a78\\u00a7oRongzhi Gu\\nYuexian Zou\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2001.00391\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 2 Jan 2020 11:12:50 GMT)\\u00a7r"}']}
{title:'Drugman et al. (§72020§r)', author: 'Thomas Drugman; Thierry Dutoit', display:{Lore:['[{"text": "arXiv:2001.00579", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Comparative Evaluation of Pitch Modification Techniques\\u00a7r\\n\\n\\u00a78\\u00a7oThomas Drugman\\nThierry Dutoit\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2001.00579\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 2 Jan 2020 09:25:30 GMT)\\u00a7r"}']}
{title:'Drugman et al. (§72020§r)', author: 'Thomas Drugman; Jerome Urbain; Thierry Dutoit', display:{Lore:['[{"text": "arXiv:2001.00580", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.HC\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAssessment of Audio Features for Automatic Cough Detection\\u00a7r\\n\\n\\u00a78\\u00a7oThomas Drugman\\nJerome Urbain\\nThierry Dutoit\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2001.00580\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 2 Jan 2020 09:30:23 GMT)\\u00a7r"}']}
{title:'Drugman et al. (§72020§r)', author: 'Thomas Drugman; Geoffrey Wilfart; Thierry Dutoit', display:{Lore:['[{"text": "arXiv:2001.00581", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lEigenresiduals for improved Parametric Speech Synthesis\\u00a7r\\n\\n\\u00a78\\u00a7oThomas Drugman\\nGeoffrey Wilfart\\nThierry Dutoit\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2001.00581\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 2 Jan 2020 09:39:07 GMT)\\u00a7r"}']}
{title:'Drugman et al. (§72020§r)', author: 'Thomas Drugman; Thierry Dutoit; Baris Bozkurt', display:{Lore:['[{"text": "arXiv:2001.00582", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lExcitation-based Voice Quality Analysis and Modification\\u00a7r\\n\\n\\u00a78\\u00a7oThomas Drugman\\nThierry Dutoit\\nBaris Bozkurt\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2001.00582\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 2 Jan 2020 09:44:52 GMT)\\u00a7r"}']}
{title:'Drugman et al. (§72020§r)', author: 'Thomas Drugman; Thomas Dubuisson; Thierry Dutoit', display:{Lore:['[{"text": "arXiv:2001.00583", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lOn the Mutual Information between Source and Filter Contributions for Voice Pathology Detection\\u00a7r\\n\\n\\u00a78\\u00a7oThomas Drugman\\nThomas Dubuisson\\nThierry Dutoit\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2001.00583\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 2 Jan 2020 10:04:37 GMT)\\u00a7r"}']}
{title:'Lattner (§72020§r)', author: 'Stefan Lattner', display:{Lore:['[{"text": "arXiv:2001.01720", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.MM\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lModeling Musical Structure with Artificial Neural Networks\\u00a7r\\n\\n\\u00a78\\u00a7oStefan Lattner\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2001.01720\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 6 Jan 2020 18:35:57 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o152 pages, 28 figures, 10 tables. PhD thesis, Johannes Kepler University Linz, October 2019. Includesresults from https://www.ijcai.org/Proceedings/15/Papers/348.pdf, arXiv:1612.04742, arXiv:1708.05325, "}','{"text": "arXiv:1806.08236, and arXiv:1806.08686 (see Section 1.2 for detailed information)\\u00a7r"}']}
{title:'Moritz et al. (§72020§r)', author: 'Niko Moritz; Takaaki Hori; Jonathan Le Roux', display:{Lore:['[{"text": "arXiv:2001.02674", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lStreaming automatic speech recognition with the transformer model\\u00a7r\\n\\n\\u00a78\\u00a7oNiko Moritz\\nTakaaki Hori\\nJonathan Le Roux\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2001.02674\\u00a7r\\n\\nVersion:\\u00a77v5 (Tue, 30 Jun 2020 18:29:07 GMT)\\u00a7r"}']}
{title:'Dubey et al. (§72020§r)', author: 'Harishchandra Dubey; Dimitra Emmanouilidou; Ivan J. Tashev', display:{Lore:['[{"text": "arXiv:2001.03896", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lCURE Dataset: Ladder Networks for Audio Event Classification\\u00a7r\\n\\n\\u00a78\\u00a7oHarishchandra Dubey\\nDimitra Emmanouilidou\\nIvan J. Tashev\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2001.03896\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 12 Jan 2020 09:35:30 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o6 pages, 2 Figures\\u00a7r"}']}
{title:'Valenti et al. (§72020§r)', author: 'Andrea Valenti; Antonio Carta; Davide Bacciu', display:{Lore:['[{"text": "arXiv:2001.05494", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lLearning Style-Aware Symbolic Music Representations by Adversarial Autoencoders\\u00a7r\\n\\n\\u00a78\\u00a7oAndrea Valenti\\nAntonio Carta\\nDavide Bacciu\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2001.05494\\u00a7r\\n\\nVersion:\\u00a77v2 (Thu, 20 Feb 2020 14:44:50 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted for publication at the 24th European Conference on Artificial Intelligence (ECAI2020)\\u00a7r"}']}
{title:'Zhai et al. (§72020§r)', author: 'Bohan Zhai; Tianren Gao; Flora Xue; Daniel Rothchild; Bichen Wu; Joseph E. Gonzalez; Kurt Keutzer', display:{Lore:['[{"text": "arXiv:2001.05685", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSqueezeWave: Extremely Lightweight Vocoders for On-device Speech Synthesis\\u00a7r\\n\\n\\u00a78\\u00a7oBohan Zhai\\nTianren Gao\\nFlora Xue\\n+ 3 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2001.05685\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 16 Jan 2020 07:26:19 GMT)\\u00a7r"}']}
{title:'Tamaru et al. (§72020§r)', author: 'Hiroki Tamaru; Shinnosuke Takamichi; Naoko Tanji; Hiroshi Saruwatari', display:{Lore:['[{"text": "arXiv:2001.07044", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lJVS-MuSiC: Japanese multispeaker singing-voice corpus\\u00a7r\\n\\n\\u00a78\\u00a7oHiroki Tamaru\\nShinnosuke Takamichi\\nNaoko Tanji\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2001.07044\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 20 Jan 2020 10:20:56 GMT)\\u00a7r"}']}
{title:'Chan et al. (§72020§r)', author: 'Teck Kai Chan; Cheng Siong Chin; Ye Li', display:{Lore:['[{"text": "arXiv:2001.07874", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lNon-Negative Matrix Factorization-Convolutional Neural Network (NMF-CNN) For Sound Event Detection\\u00a7r\\n\\n\\u00a78\\u00a7oTeck Kai Chan\\nCheng Siong Chin\\nYe Li\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2001.07874\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 22 Jan 2020 04:24:08 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 1 figure, 2 tables\\u00a7r"}']}
{title:'Reddy et al. (§72020§r)', author: 'Chandan K. A. Reddy; Ebrahim Beyrami; Harishchandra Dubey; Vishak Gopal; Roger Cheng; Ross Cutler; Sergiy Matusevych; Robert Aichner; Ashkan Aazami; Sebastian Braun; Puneet Rana; Sriram Srinivasan; Johannes Gehrke', display:{Lore:['[{"text": "arXiv:2001.08662", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lThe INTERSPEECH 2020 Deep Noise Suppression Challenge: Datasets, Subjective Speech Quality and Testing Framework\\u00a7r\\n\\n\\u00a78\\u00a7oChandan K. A. Reddy\\nEbrahim Beyrami\\nHarishchandra Dubey\\n+ 9 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2001.08662\\u00a7r\\n\\nVersion:\\u00a77v2 (Sun, 19 Apr 2020 16:16:08 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oDetailsabout Deep Noise Suppression Challenge\\u00a7r"}']}
{title:'Kitić et al. (§72020§r)', author: 'Srđan Kitić; Gilles Puy; Patrick Pérez; Philippe Gilberton', display:{Lore:['[{"text": "arXiv:2001.08830", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r, \\u00a7eeess.SP\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lScattering Features for Multimodal Gait Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oSr\\u0111an Kiti\\u0107\\nGilles Puy\\nPatrick P\\u00e9rez\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2001.08830\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 23 Jan 2020 22:11:38 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oPublished at IEEEGlobalSIP 2017\\u00a7r"}']}
{title:'Anhari (§72020§r)', author: 'Amir Kenarsari Anhari', display:{Lore:['[{"text": "arXiv:2001.08864", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lLearning Multi-instrument Classification with Partial Labels\\u00a7r\\n\\n\\u00a78\\u00a7oAmir Kenarsari Anhari\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2001.08864\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 24 Jan 2020 02:34:31 GMT)\\u00a7r"}']}
{title:'Shi et al. (§72020§r)', author: 'Ziqiang Shi; Rujie Liu; Jiqing Han', display:{Lore:['[{"text": "arXiv:2001.08998", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lLaFurca: Iterative Refined Speech Separation Based on Context-Aware Dual-Path Parallel Bi-LSTM\\u00a7r\\n\\n\\u00a78\\u00a7oZiqiang Shi\\nRujie Liu\\nJiqing Han\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2001.08998\\u00a7r\\n\\nVersion:\\u00a77v4 (Tue, 27 Oct 2020 00:49:42 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oarXiv admin note: substantial text overlap with arXiv:1902.04891, arXiv:1902.00651\\u00a7r"}']}
{title:'Cheuk et al. (§72020§r)', author: 'Kin Wai Cheuk; Yin-Jyun Luo; Balamurali B; T; Gemma Roig; Dorien Herremans', display:{Lore:['[{"text": "arXiv:2001.09988", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lRegression-based music emotion prediction using triplet neural networks\\u00a7r\\n\\n\\u00a78\\u00a7oKin Wai Cheuk\\nYin-Jyun Luo\\nBalamurali B\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2001.09988\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nIJCNN 2020\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 21 Jul 2020 04:10:39 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oPaper Accepted i nIJCNN 2020\\u00a7r"}']}
{title:'Cheuk et al. (§72020§r)', author: 'Kin Wai Cheuk; Kat Agres; Dorien Herremans', display:{Lore:['[{"text": "arXiv:2001.09989", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lThe impact of Audio input representations on neural network based music transcription\\u00a7r\\n\\n\\u00a78\\u00a7oKin Wai Cheuk\\nKat Agres\\nDorien Herremans\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2001.09989\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nIJCNN 2020\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 21 Jul 2020 04:17:11 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oPaper accepted in IJCNN 2020\\u00a7r"}']}
{title:'Nakamura et al. (§72020§r)', author: 'Tomohiko Nakamura; Hiroshi Saruwatari', display:{Lore:['[{"text": "arXiv:2001.10190", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.MM\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lTime-Domain Audio Source Separation Based on Wave-U-Net Combined with Discrete Wavelet Transform\\u00a7r\\n\\n\\u00a78\\u00a7oTomohiko Nakamura\\nHiroshi Saruwatari\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2001.10190\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/ICASSP40776.2020.9053934\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nICASSP 2020 - 2020 IEEE International Conference on Acoustics,\\n  Speech and Signal Processing (ICASSP)\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 28 Jan 2020 06:43:21 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, to appear in IEEE International Conference on Acoustics, Speech, and Signal Processing 2020(ICASSP 2020)\\u00a7r"}']}
{title:'Lluís et al. (§72020§r)', author: 'Francesc Lluís; Pablo Martínez-Nuevo; Martin Bo Møller; Sven Ewan Shepstone', display:{Lore:['[{"text": "arXiv:2001.11263", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSound field reconstruction in rooms: inpainting meets super-resolution\\u00a7r\\n\\n\\u00a78\\u00a7oFrancesc Llu\\u00eds\\nPablo Mart\\u00ednez-Nuevo\\nMartin Bo M\\u00f8ller\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2001.11263\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1121/10.0001687\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nThe Journal of the Acoustical Society of America 148, 649 (2020)\\u00a7r\\n\\nVersion:\\u00a77v2 (Thu, 6 Aug 2020 16:14:24 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oCode: https://github.com/francesclluis/sound-field-neural-network\\u00a7r"}']}
{title:'Chen et al. (§72020§r)', author: 'Zhuo Chen; Takuya Yoshioka; Liang Lu; Tianyan Zhou; Zhong Meng; Yi Luo; Jian Wu; Xiong Xiao; Jinyu Li', display:{Lore:['[{"text": "arXiv:2001.11482", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lContinuous speech separation: dataset and analysis\\u00a7r\\n\\n\\u00a78\\u00a7oZhuo Chen\\nTakuya Yoshioka\\nLiang Lu\\n+ 5 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2001.11482\\u00a7r\\n\\nVersion:\\u00a77v3 (Thu, 7 May 2020 09:13:27 GMT)\\u00a7r"}']}
{title:'Tolooshams et al. (§72020§r)', author: 'Bahareh Tolooshams; Ritwik Giri; Andrew H. Song; Umut Isik; Arvindh Krishnaswamy', display:{Lore:['[{"text": "arXiv:2001.11542", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lChannel-Attention Dense U-Net for Multichannel Speech Enhancement\\u00a7r\\n\\n\\u00a78\\u00a7oBahareh Tolooshams\\nRitwik Giri\\nAndrew H. Song\\nUmut Isik\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2001.11542\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 30 Jan 2020 19:56:52 GMT)\\u00a7r"}']}
{title:'Khare et al. (§72020§r)', author: 'Aparna Khare; Shiva Sundaram; Minhua Wu', display:{Lore:['[{"text": "arXiv:2002.00122", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMulti-channel Acoustic Modeling using Mixed Bitrate OPUS Compression\\u00a7r\\n\\n\\u00a78\\u00a7oAparna Khare\\nShiva Sundaram\\nMinhua Wu\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2002.00122\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 1 Feb 2020 01:46:28 GMT)\\u00a7r"}']}
{title:'Wager et al. (§72020§r)', author: 'Sanna Wager; Aparna Khare; Minhua Wu; Kenichi Kumatani; Shiva Sundaram', display:{Lore:['[{"text": "arXiv:2002.00125", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lFully Learnable Front-End for Multi-Channel Acoustic Modeling using Semi-Supervised Learning\\u00a7r\\n\\n\\u00a78\\u00a7oSanna Wager\\nAparna Khare\\nMinhua Wu\\nKenichi Kumatani\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2002.00125\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/ICASSP40776.2020.9053367\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 1 Feb 2020 02:06:05 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oTo appear in ICASSP 2020\\u00a7r"}']}
{title:'Huang et al. (§72020§r)', author: 'Yu-Siang Huang; Yi-Hsuan Yang', display:{Lore:['[{"text": "arXiv:2002.00212", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.AI\\u00a7r, \\u00a7eeess.AS\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lPop Music Transformer: Beat-based Modeling and Generation of Expressive Pop Piano Compositions\\u00a7r\\n\\n\\u00a78\\u00a7oYu-Siang Huang\\nYi-Hsuan Yang\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2002.00212\\u00a7r\\n\\nVersion:\\u00a77v3 (Mon, 10 Aug 2020 07:27:05 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted at ACM Multimedia 2020\\u00a7r"}']}
{title:'Li et al. (§72020§r)', author: 'Jingdong Li; Hui Zhang; Xueliang Zhang; Changliang Li', display:{Lore:['[{"text": "arXiv:2002.00319", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSingle Channel Speech Enhancement Using Temporal Convolutional Recurrent Neural Networks\\u00a7r\\n\\n\\u00a78\\u00a7oJingdong Li\\nHui Zhang\\nXueliang Zhang\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2002.00319\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 2 Feb 2020 04:26:50 GMT)\\u00a7r"}']}
{title:'Qin et al. (§72020§r)', author: 'Xiaoyi Qin; Ming Li; Hui Bu; Rohan Kumar Das; Wei Rao; Shrikanth Narayanan; Haizhou Li', display:{Lore:['[{"text": "arXiv:2002.00387", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lThe FFSVC 2020 Evaluation Plan\\u00a7r\\n\\n\\u00a78\\u00a7oXiaoyi Qin\\nMing Li\\nHui Bu\\n+ 3 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2002.00387\\u00a7r\\n\\nVersion:\\u00a77v2 (Wed, 5 Feb 2020 03:52:32 GMT)\\u00a7r"}']}
{title:'Luu et al. (§72020§r)', author: 'Chau Luu; Peter Bell; Steve Renals', display:{Lore:['[{"text": "arXiv:2002.00453", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDropClass and DropAdapt: Dropping classes for deep speaker representation learning\\u00a7r\\n\\n\\u00a78\\u00a7oChau Luu\\nPeter Bell\\nSteve Renals\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2002.00453\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 2 Feb 2020 18:43:50 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to Speaker Odyssey 2020\\u00a7r"}']}
{title:'Drossos et al. (§72020§r)', author: 'Konstantinos Drossos; Stylianos I. Mimilakis; Shayan Gharib; Yanxiong Li; Tuomas Virtanen', display:{Lore:['[{"text": "arXiv:2002.00476", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSound Event Detection with Depthwise Separable and Dilated Convolutions\\u00a7r\\n\\n\\u00a78\\u00a7oKonstantinos Drossos\\nStylianos I. Mimilakis\\nShayan Gharib\\nYanxiong Li\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2002.00476\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 2 Feb 2020 19:50:51 GMT)\\u00a7r"}']}
{title:'Kamo et al. (§72020§r)', author: 'Keigo Kamo; Yuki Kubo; Norihiro Takamune; Daichi Kitamura; Hiroshi Saruwatari; Yu Takahashi; Kazunobu Kondo', display:{Lore:['[{"text": "arXiv:2002.00579", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lRegularized Fast Multichannel Nonnegative Matrix Factorization with ILRMA-based Prior Distribution of Joint-Diagonalization Process\\u00a7r\\n\\n\\u00a78\\u00a7oKeigo Kamo\\nYuki Kubo\\nNorihiro Takamune\\n+ 3 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2002.00579\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 3 Feb 2020 06:55:37 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 3 figures, To appear in the Proceedings of International Conference on Acoustics, Speech, and Signal Processing (ICASSP) 2020\\u00a7r"}']}
{title:'Turpault et al. (§72020§r)', author: 'Nicolas Turpault; Romain Serizel; Emmanuel Vincent', display:{Lore:['[{"text": "arXiv:2002.01687", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.AI\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lLimitations of weak labels for embedding and tagging\\u00a7r\\n\\n\\u00a78\\u00a7oNicolas Turpault\\nRomain Serizel\\nEmmanuel Vincent\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2002.01687\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nICASSP 2020 - 45th International Conference on Acoustics, Speech,\\n  and Signal Processing, May 2020, Barcelona, Spain\\u00a7r\\n\\nVersion:\\u00a77v4 (Mon, 7 Dec 2020 13:13:51 GMT)\\u00a7r"}']}
{title:'Kong et al. (§72020§r)', author: 'Qiuqiang Kong; Yuxuan Wang; Xuchen Song; Yin Cao; Wenwu Wang; Mark D. Plumbley', display:{Lore:['[{"text": "arXiv:2002.02065", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSource separation with weakly labelled data: An approach to computational auditory scene analysis\\u00a7r\\n\\n\\u00a78\\u00a7oQiuqiang Kong\\nYuxuan Wang\\nXuchen Song\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2002.02065\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 6 Feb 2020 02:00:05 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages\\u00a7r"}']}
{title:'Chen et al. (§72020§r)', author: 'Ke Chen; Gus Xia; Shlomo Dubnov', display:{Lore:['[{"text": "arXiv:2002.02393", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.AI\\u00a7r, \\u00a7acs.LG\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lContinuous Melody Generation via Disentangled Short-Term Representations and Structural Conditions\\u00a7r\\n\\n\\u00a78\\u00a7oKe Chen\\nGus Xia\\nShlomo Dubnov\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2002.02393\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/ICSC.2020.00025\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7n2020 IEEE 14th International Conference on Semantic Computing\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 5 Feb 2020 06:23:44 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o9 pages, 12 figures, 4 tables. in 14th international conference on semantic computing, ICSC 2020\\u00a7r"}']}
{title:'Park et al. (§72020§r)', author: 'Taejin Park; Kenichi Kumatani; Minhua Wu; Shiva Sundaram', display:{Lore:['[{"text": "arXiv:2002.02520", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lRobust Multi-channel Speech Recognition using Frequency Aligned Network\\u00a7r\\n\\n\\u00a78\\u00a7oTaejin Park\\nKenichi Kumatani\\nMinhua Wu\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2002.02520\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 6 Feb 2020 21:47:39 GMT)\\u00a7r"}']}
{title:'Huh et al. (§72020§r)', author: 'Jaesung Huh; Egil Martinsson; Adrian Kim; Jung-Woo Ha', display:{Lore:['[{"text": "arXiv:2002.03559", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lModeling Musical Onset Probabilities via Neural Distribution Learning\\u00a7r\\n\\n\\u00a78\\u00a7oJaesung Huh\\nEgil Martinsson\\nAdrian Kim\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2002.03559\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 10 Feb 2020 05:38:51 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o2 pages, 2 figures, 2 tables\\u00a7r"}']}
{title:'Pham et al. (§72020§r)', author: 'Lam Pham; Ian McLoughlin; Huy Phan; Minh Tran; Truc Nguyen; Ramaswamy Palaniappan', display:{Lore:['[{"text": "arXiv:2002.03894", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lRobust Deep Learning Framework For Predicting Respiratory Anomalies and Diseases\\u00a7r\\n\\n\\u00a78\\u00a7oLam Pham\\nIan McLoughlin\\nHuy Phan\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2002.03894\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 21 Jan 2020 15:26:52 GMT)\\u00a7r"}']}
{title:'Pandey et al. (§72020§r)', author: 'Ashutosh Pandey; DeLiang Wang', display:{Lore:['[{"text": "arXiv:2002.04027", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lOn Cross-Corpus Generalization of Deep Learning Based Speech Enhancement\\u00a7r\\n\\n\\u00a78\\u00a7oAshutosh Pandey\\nDeLiang Wang\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2002.04027\\u00a7r\\n\\nVersion:\\u00a77v2 (Mon, 10 Aug 2020 16:15:56 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted for publication in IEEE Transactions on Audio, Speech and Language Processing\\u00a7r"}']}
{title:'Verma et al. (§72020§r)', author: 'Prateek Verma; Kenneth Salisbury', display:{Lore:['[{"text": "arXiv:2002.04076", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.RO\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lUnsupervised Learning of Audio Perception for Robotics Applications: Learning to Project Data to T-SNE/UMAP space\\u00a7r\\n\\n\\u00a78\\u00a7oPrateek Verma\\nKenneth Salisbury\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2002.04076\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 10 Feb 2020 20:33:25 GMT)\\u00a7r"}']}
{title:'Pham et al. (§72020§r)', author: 'Lam Pham; Huy Phan; Truc Nguyen; Ramaswamy Palaniappan; Alfred Mertins; Ian McLoughlin', display:{Lore:['[{"text": "arXiv:2002.04502", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lRobust Acoustic Scene Classification using a Multi-Spectrogram Encoder-Decoder Framework\\u00a7r\\n\\n\\u00a78\\u00a7oLam Pham\\nHuy Phan\\nTruc Nguyen\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2002.04502\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 11 Feb 2020 16:02:43 GMT)\\u00a7r"}']}
{title:'Noé et al. (§72020§r)', author: 'Paul-Gauthier Noé; Titouan Parcollet; Mohamed Morchid', display:{Lore:['[{"text": "arXiv:2002.04569", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lCGCNN: Complex Gabor Convolutional Neural Network on raw speech\\u00a7r\\n\\n\\u00a78\\u00a7oPaul-Gauthier No\\u00e9\\nTitouan Parcollet\\nMohamed Morchid\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2002.04569\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 11 Feb 2020 17:48:17 GMT)\\u00a7r"}']}
{title:'Iqbal et al. (§72020§r)', author: 'Turab Iqbal; Yin Cao; Qiuqiang Kong; Mark D. Plumbley; Wenwu Wang', display:{Lore:['[{"text": "arXiv:2002.04683", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lLearning with Out-of-Distribution Data for Audio Classification\\u00a7r\\n\\n\\u00a78\\u00a7oTurab Iqbal\\nYin Cao\\nQiuqiang Kong\\nMark D. Plumbley\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2002.04683\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 11 Feb 2020 21:08:06 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oPaper accepted for 45th International Conference on Acoustics, Speech, and Signal Processing (ICASSP 2020)\\u00a7r"}']}
{title:'Heinze et al. (§72020§r)', author: 'Maria Heinze; Lars Hausfeld; Rainer Goebel; Frieder Stolzenburg', display:{Lore:['[{"text": "arXiv:2002.04990", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lPeriodicity Pitch Detection in Complex Harmonies on EEG Timeline Data\\u00a7r\\n\\n\\u00a78\\u00a7oMaria Heinze\\nLars Hausfeld\\nRainer Goebel\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2002.04990\\u00a7r\\n\\nVersion:\\u00a77v2 (Fri, 18 Dec 2020 16:08:15 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o10 pages, 4 figures, 2 tables\\u00a7r"}']}
{title:'Wager et al. (§72020§r)', author: 'Sanna Wager; George Tzanetakis; Cheng-i Wang; Minje Kim', display:{Lore:['[{"text": "arXiv:2002.05511", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDeep Autotuner: a Pitch Correcting Network for Singing Performances\\u00a7r\\n\\n\\u00a78\\u00a7oSanna Wager\\nGeorge Tzanetakis\\nCheng-i Wang\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2002.05511\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nIEEE International Conference on Acoustics, Speech, and Signal\\n  Processing (ICASSP), 2020\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 12 Feb 2020 01:33:56 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oarXiv admin note: text overlapwith arXiv:1902.00956\\u00a7r"}']}
{title:'Imoto et al. (§72020§r)', author: 'Keisuke Imoto; Noriyuki Tonami; Yuma Koizumi; Masahiro Yasuda; Ryosuke Yamanishi; Yoichi Yamashita', display:{Lore:['[{"text": "arXiv:2002.05848", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSound Event Detection by Multitask Learning of Sound Events and Scenes with Soft Scene Labels\\u00a7r\\n\\n\\u00a78\\u00a7oKeisuke Imoto\\nNoriyuki Tonami\\nYuma Koizumi\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2002.05848\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 14 Feb 2020 02:24:06 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted to ICASSP 2020\\u00a7r"}']}
{title:'Furnon et al. (§72020§r)', author: 'Nicolas Furnon; Romain Serizel; Irina Illina; Slim Essid', display:{Lore:['[{"text": "arXiv:2002.06016", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.AI\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDNN-Based Distributed Multichannel Mask Estimation for Speech Enhancement in Microphone Arrays\\u00a7r\\n\\n\\u00a78\\u00a7oNicolas Furnon\\nRomain Serizel\\nIrina Illina\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2002.06016\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nInternational Conference on Audio, Signal and Speech Processing\\n  (ICASSP), May 2020, Barcelone, Spain\\u00a7r\\n\\nVersion:\\u00a77v2 (Mon, 16 Mar 2020 15:58:55 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to ICASSP2020\\u00a7r"}']}
{title:'Shi et al. (§72020§r)', author: 'Ziqiang Shi; Liu Liu; Huibin Lin; Rujie Liu', display:{Lore:['[{"text": "arXiv:2002.06021", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lHodge and Podge: Hybrid Supervised Sound Event Detection with Multi-Hot MixMatch and Composition Consistence Training\\u00a7r\\n\\n\\u00a78\\u00a7oZiqiang Shi\\nLiu Liu\\nHuibin Lin\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2002.06021\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 13 Feb 2020 06:44:03 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oarXiv admin note: substantial text overlap with arXiv:1907.07398\\u00a7r"}']}
{title:'Gusev et al. (§72020§r)', author: 'Aleksei Gusev; Vladimir Volokhov; Tseren Andzhukaev; Sergey Novoselov; Galina Lavrentyeva; Marina Volkova; Alice Gazizullina; Andrey Shulipa; Artem Gorlanov; Anastasia Avdeeva; Artem Ivanov; Alexander Kozlov; Timur Pekhovsky; Yuri Matveev', display:{Lore:['[{"text": "arXiv:2002.06033", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7eeess.AS\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDeep Speaker Embeddings for Far-Field Speaker Recognition on Short Utterances\\u00a7r\\n\\n\\u00a78\\u00a7oAleksei Gusev\\nVladimir Volokhov\\nTseren Andzhukaev\\n+ 10 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2002.06033\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 14 Feb 2020 13:34:33 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to Odyssey 2020\\u00a7r"}']}
{title:'Lee et al. (§72020§r)', author: 'Shindong Lee; BongGu Ko; Keonnyeong Lee; In-Chul Yoo; Dongsuk Yook', display:{Lore:['[{"text": "arXiv:2002.06328", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMany-to-Many Voice Conversion using Conditional Cycle-Consistent Adversarial Networks\\u00a7r\\n\\n\\u00a78\\u00a7oShindong Lee\\nBongGu Ko\\nKeonnyeong Lee\\nIn-Chul Yoo\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2002.06328\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 15 Feb 2020 06:03:36 GMT)\\u00a7r"}']}
{title:'Gao et al. (§72020§r)', author: 'Yang Gao; Weiyi Zheng; Zhaojun Yang; Thilo Kohler; Christian Fuegen; Qing He', display:{Lore:['[{"text": "arXiv:2002.06758", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lInteractive Text-to-Speech System via Joint Style Analysis\\u00a7r\\n\\n\\u00a78\\u00a7oYang Gao\\nWeiyi Zheng\\nZhaojun Yang\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2002.06758\\u00a7r\\n\\nVersion:\\u00a77v2 (Mon, 21 Sep 2020 22:10:48 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted by Interspeech 2020\\u00a7r"}']}
{title:'Saeki et al. (§72020§r)', author: 'Takaaki Saeki; Yuki Saito; Shinnosuke Takamichi; Hiroshi Saruwatari', display:{Lore:['[{"text": "arXiv:2002.06778", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lLifter Training and Sub-band Modeling for Computationally Efficient and High-Quality Voice Conversion Using Spectral Differentials\\u00a7r\\n\\n\\u00a78\\u00a7oTakaaki Saeki\\nYuki Saito\\nShinnosuke Takamichi\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2002.06778\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 17 Feb 2020 05:41:54 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, to appear in IEEE International Conference on Acoustics, Speech, and Signal Processing 2020(ICASSP 2020)\\u00a7r"}']}
{title:'Hsieh et al. (§72020§r)', author: 'Tsung-Han Hsieh; Kai-Hsiang Cheng; Zhe-Cheng Fan; Yu-Ching Yang; Yi-Hsuan Yang', display:{Lore:['[{"text": "arXiv:2002.06817", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.MM\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAddressing the confounds of accompaniments in singer identification\\u00a7r\\n\\n\\u00a78\\u00a7oTsung-Han Hsieh\\nKai-Hsiang Cheng\\nZhe-Cheng Fan\\nYu-Ching Yang\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2002.06817\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 17 Feb 2020 07:49:21 GMT)\\u00a7r"}']}
{title:'Samuel et al. (§72020§r)', author: 'David Samuel; Aditya Ganeshan; Jason Naradowsky', display:{Lore:['[{"text": "arXiv:2002.07016", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMeta-learning Extractors for Music Source Separation\\u00a7r\\n\\n\\u00a78\\u00a7oDavid Samuel\\nAditya Ganeshan\\nJason Naradowsky\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2002.07016\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 17 Feb 2020 16:00:03 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oCamera-ready version for ICASSP 2020; the source files are published at https://github.com/pfnet-research/meta-tasnet\\u00a7r"}']}
{title:'Balaji et al. (§72020§r)', author: 'Pratibha Balaji; Shruthi Narayan; Durga Sraddha; Bharath K P; Karthik R; Rajesh Kumar Muthu', display:{Lore:['[{"text": "arXiv:2002.07677", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.MM\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lPerformance Analysis of Adaptive Noise Cancellation for Speech Signal\\u00a7r\\n\\n\\u00a78\\u00a7oPratibha Balaji\\nShruthi Narayan\\nDurga Sraddha\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2002.07677\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 3 Feb 2020 10:01:14 GMT)\\u00a7r"}']}
{title:'Kondo et al. (§72020§r)', author: 'Tatsuki Kondo; Kanta Fukushige; Norihiro Takamune; Daichi Kitamura; Hiroshi Saruwatari; Rintaro Ikeshita; Tomohiro Nakatani', display:{Lore:['[{"text": "arXiv:2002.08582", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r, \\u00a7eeess.SP\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lConvergence-guaranteed Independent Positive Semidefinite Tensor Analysis Based on Student\'s t Distribution\\u00a7r\\n\\n\\u00a78\\u00a7oTatsuki Kondo\\nKanta Fukushige\\nNorihiro Takamune\\n+ 3 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2002.08582\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 20 Feb 2020 06:24:02 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 3 figures, to appear in IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP) 2020\\u00a7r"}']}
{title:'Fan et al. (§72020§r)', author: 'Jianyu Fan; Yi-Hsuan Yang; Kui Dong; Philippe Pasquier', display:{Lore:['[{"text": "arXiv:2002.09021", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Comparative Study of Western and Chinese Classical Music based on Soundscape Models\\u00a7r\\n\\n\\u00a78\\u00a7oJianyu Fan\\nYi-Hsuan Yang\\nKui Dong\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2002.09021\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 20 Feb 2020 21:16:27 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oPaper accepted for 45th International Conference on Acoustics, Speech, and Signal Processing (ICASSP 2020)\\u00a7r"}']}
{title:'Odekerken et al. (§72020§r)', author: 'Daphne Odekerken; Hendrik Vincent Koops; Anja Volk', display:{Lore:['[{"text": "arXiv:2002.09748", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.MM\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDECIBEL: Improving Audio Chord Estimation for Popular Music by Alignment and Integration of Crowd-Sourced Symbolic Representations\\u00a7r\\n\\n\\u00a78\\u00a7oDaphne Odekerken\\nHendrik Vincent Koops\\nAnja Volk\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2002.09748\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 22 Feb 2020 18:42:00 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o81 pages, 47 figures\\u00a7r"}']}
{title:'De Boom et al. (§72020§r)', author: 'Cedric De Boom; Stephanie Van Laere; Tim Verbelen; Bart Dhoedt', display:{Lore:['[{"text": "arXiv:2002.10266", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lRhythm, Chord and Melody Generation for Lead Sheets using Recurrent Neural Networks\\u00a7r\\n\\n\\u00a78\\u00a7oCedric De Boom\\nStephanie Van Laere\\nTim Verbelen\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2002.10266\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 21 Feb 2020 09:36:24 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o8 pages, 2 figures, 3 tables, 2 appendices\\u00a7r"}']}
{title:'Ghose et al. (§72020§r)', author: 'Sanchita Ghose; John J. Prevost', display:{Lore:['[{"text": "arXiv:2002.10981", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CV\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAutoFoley: Artificial Synthesis of Synchronized Sound Tracks for Silent Videos with Deep Learning\\u00a7r\\n\\n\\u00a78\\u00a7oSanchita Ghose\\nJohn J. Prevost\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2002.10981\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/TMM.2020.3005033\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nIEEE TRANSACTIONS ON MULTIMEDIA, 2020\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 21 Feb 2020 09:08:28 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o14 pages, 14 figures\\u00a7r"}']}
{title:'Dong et al. (§72020§r)', author: 'Peiyan Dong; Siyue Wang; Wei Niu; Chengming Zhang; Sheng Lin; Zhengang Li; Yifan Gong; Bin Ren; Xue Lin; Yanzhi Wang; Dingwen Tao', display:{Lore:['[{"text": "arXiv:2002.11474", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lRTMobile: Beyond Real-Time Mobile Acceleration of RNNs for Speech Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oPeiyan Dong\\nSiyue Wang\\nWei Niu\\n+ 7 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2002.11474\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 19 Feb 2020 00:07:32 GMT)\\u00a7r"}']}
{title:'Wang et al. (§72020§r)', author: 'Yixin Wang; Xiaohong Guan; Youtian Du; Nan Nan', display:{Lore:['[{"text": "arXiv:2003.00414", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.MM\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lHarmonics Based Representation in Clarinet Tone Quality Evaluation\\u00a7r\\n\\n\\u00a78\\u00a7oYixin Wang\\nXiaohong Guan\\nYoutian Du\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2003.00414\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 1 Mar 2020 06:06:32 GMT)\\u00a7r"}']}
{title:'Lostanlen et al. (§72020§r)', author: 'Vincent Lostanlen; Alice Cohen-Hadria; Juan Pablo Bello', display:{Lore:['[{"text": "arXiv:2003.01037", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lOne or Two Components? The Scattering Transform Answers\\u00a7r\\n\\n\\u00a78\\u00a7oVincent Lostanlen\\nAlice Cohen-Hadria\\nJuan Pablo Bello\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2003.01037\\u00a7r\\n\\nVersion:\\u00a77v2 (Thu, 25 Jun 2020 10:51:12 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 4 figures, in English. Proceedings ofthe European Signal Processing Conference (EUSIPCO 2020)\\u00a7r"}']}
{title:'Guizzo et al. (§72020§r)', author: 'Eric Guizzo; Alberto Novello', display:{Lore:['[{"text": "arXiv:2003.03160", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Neural Network Based Framework for Archetypical Sound Synthesis\\u00a7r\\n\\n\\u00a78\\u00a7oEric Guizzo\\nAlberto Novello\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2003.03160\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 10 Mar 2020 13:00:27 GMT)\\u00a7r"}']}
{title:'Scaini (§72020§r)', author: 'Davide Scaini', display:{Lore:['[{"text": "arXiv:2003.03287", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lWavelet-based spatial audio framework\\u00a7r\\n\\n\\u00a78\\u00a7oDavide Scaini\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2003.03287\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 6 Mar 2020 15:48:26 GMT)\\u00a7r"}']}
{title:'Grumiaux et al. (§72020§r)', author: 'Pierre-Amaury Grumiaux; Srdjan Kitic; Laurent Girin; Alexandre Guérin', display:{Lore:['[{"text": "arXiv:2003.07839", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lHigh-Resolution Speaker Counting In Reverberant Rooms Using CRNN With Ambisonics Features\\u00a7r\\n\\n\\u00a78\\u00a7oPierre-Amaury Grumiaux\\nSrdjan Kitic\\nLaurent Girin\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2003.07839\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 17 Mar 2020 17:42:22 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 1 figure\\u00a7r"}']}
{title:'Goel et al. (§72020§r)', author: 'Shivali Goel; Homayoon Beigi', display:{Lore:['[{"text": "arXiv:2003.07996", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lCross Lingual Cross Corpus Speech Emotion Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oShivali Goel\\nHomayoon Beigi\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2003.07996\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 18 Mar 2020 00:23:08 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o7 pages, 2 figures\\u00a7r"}']}
{title:'Fahim et al. (§72020§r)', author: 'A. Fahim; P. N. Samarasinghe; T. D. Abhayapala', display:{Lore:['[{"text": "arXiv:2003.08050", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMulti-Source DOA Estimation through Pattern Recognition of the Modal Coherence of a Reverberant Soundfield\\u00a7r\\n\\n\\u00a78\\u00a7oA. Fahim\\nP. N. Samarasinghe\\nT. D. Abhayapala\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2003.08050\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/TASLP.2019.2960734\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nIEEE/ACM Transactions on Audio, Speech, and Language Processing 28\\n  (2019) 605 - 618\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 18 Mar 2020 05:24:00 GMT)\\u00a7r"}']}
{title:'Gong et al. (§72020§r)', author: 'Yuan Gong; Jian Yang; Christian Poellabauer', display:{Lore:['[{"text": "arXiv:2003.08225", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CR\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDetecting Replay Attacks Using Multi-Channel Audio: A Neural Network-Based Method\\u00a7r\\n\\n\\u00a78\\u00a7oYuan Gong\\nJian Yang\\nChristian Poellabauer\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2003.08225\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/LSP.2020.2996908\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nin IEEE Signal Processing Letters, vol. 27, pp. 920-924, 2020\\u00a7r\\n\\nVersion:\\u00a77v3 (Fri, 3 Jul 2020 19:37:34 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oCode of this work is available here: https://github.com/YuanGongND/multichannel-antispoof\\u00a7r"}']}
{title:'Naranjo-Alcazar et al. (§72020§r)', author: 'Javier Naranjo-Alcazar; Sergi Perez-Castanos; Pedro Zuccarello; Maximo Cobos', display:{Lore:['[{"text": "arXiv:2003.09284", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAcoustic Scene Classification with Squeeze-Excitation Residual Networks\\u00a7r\\n\\n\\u00a78\\u00a7oJavier Naranjo-Alcazar\\nSergi Perez-Castanos\\nPedro Zuccarello\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2003.09284\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/ACCESS.2020.3002761\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nIEEEAccess 2020\\u00a7r\\n\\nVersion:\\u00a77v3 (Fri, 26 Jun 2020 09:10:47 GMT)\\u00a7r"}']}
{title:'Wang et al. (§72020§r)', author: 'Zehao Wang; Shicheng Zhang; Xiaoou Chen', display:{Lore:['[{"text": "arXiv:2003.09287", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.AI\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lExploring Inherent Properties of the Monophonic Melody of Songs\\u00a7r\\n\\n\\u00a78\\u00a7oZehao Wang\\nShicheng Zhang\\nXiaoou Chen\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2003.09287\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 20 Mar 2020 14:13:16 GMT)\\u00a7r"}']}
{title:'Rocchesso et al. (§72020§r)', author: 'Davide Rocchesso; Maria Mannone', display:{Lore:['[{"text": "arXiv:2003.09632", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Quantum Vocal Theory of Sound\\u00a7r\\n\\n\\u00a78\\u00a7oDavide Rocchesso\\nMaria Mannone\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2003.09632\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 21 Mar 2020 11:14:05 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o32 pages, 11 figures\\u00a7r"}']}
{title:'Li et al. (§72020§r)', author: 'Andong Li; Chengshi Zheng; Linjuan Cheng; Renhua Peng; Xiaodong Li', display:{Lore:['[{"text": "arXiv:2003.09815", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Time-domain Monaural Speech Enhancement with Feedback Learning\\u00a7r\\n\\n\\u00a78\\u00a7oAndong Li\\nChengshi Zheng\\nLinjuan Cheng\\nRenhua Peng\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2003.09815\\u00a7r\\n\\nVersion:\\u00a77v3 (Thu, 5 Nov 2020 12:47:25 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted by APSIPA 2020\\u00a7r"}']}
{title:'Kadandale et al. (§72020§r)', author: 'Venkatesh S. Kadandale; Juan F. Montesinos; Gloria Haro; Emilia Gómez', display:{Lore:['[{"text": "arXiv:2003.10414", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.IR\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.MM\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMulti-channel U-Net for Music Source Separation\\u00a7r\\n\\n\\u00a78\\u00a7oVenkatesh S. Kadandale\\nJuan F. Montesinos\\nGloria Haro\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2003.10414\\u00a7r\\n\\nVersion:\\u00a77v3 (Fri, 4 Sep 2020 13:37:58 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oThe paper has been accepted at IEEE MMSP2020. Project Page: https://vskadandale.github.io/multi-channel-unet\\u00a7r"}']}
{title:'Vashkevich et al. (§72020§r)', author: 'Maxim Vashkevich; Alexander Petrovsky; Yuliya Rushkevich', display:{Lore:['[{"text": "arXiv:2003.10806", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lBulbar ALS Detection Based on Analysis of Voice Perturbation and Vibrato\\u00a7r\\n\\n\\u00a78\\u00a7oMaxim Vashkevich\\nAlexander Petrovsky\\nYuliya Rushkevich\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2003.10806\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.23919/SPA.2019.8936657\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 24 Mar 2020 12:49:25 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oProc. of International Conference Signal Processing Algorithms, Architectures, Arrangements, and Applications (SPA 2019)\\u00a7r"}']}
{title:'Schuller et al. (§72020§r)', author: 'Björn W. Schuller; Dagmar M. Schuller; Kun Qian; Juan Liu; Huaiyuan Zheng; Xiao Li', display:{Lore:['[{"text": "arXiv:2003.11117", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lCOVID-19 and Computer Audition: An Overview on What Speech     Sound Analysis Could Contribute in the SARS-CoV-2 Corona Crisis\\u00a7r\\n\\n\\u00a78\\u00a7oBj\\u00f6rn W. Schuller\\nDagmar M. Schuller\\nKun Qian\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2003.11117\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 24 Mar 2020 21:17:44 GMT)\\u00a7r"}']}
{title:'Dinkel et al. (§72020§r)', author: 'Heinrich Dinkel; Yefei Chen; Mengyue Wu; Kai Yu', display:{Lore:['[{"text": "arXiv:2003.12222", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lVoice activity detection in the wild via weakly supervised sound event detection\\u00a7r\\n\\n\\u00a78\\u00a7oHeinrich Dinkel\\nYefei Chen\\nMengyue Wu\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2003.12222\\u00a7r\\n\\nVersion:\\u00a77v6 (Sun, 16 Aug 2020 16:17:15 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted in Interspeech 2020\\u00a7r"}']}
{title:'Li et al. (§72020§r)', author: 'Andong Li; Chengshi Zheng; Cunhang Fan; Renhua Peng; Xiaodong Li', display:{Lore:['[{"text": "arXiv:2003.12973", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Recursive Network with Dynamic Attention for Monaural Speech Enhancement\\u00a7r\\n\\n\\u00a78\\u00a7oAndong Li\\nChengshi Zheng\\nCunhang Fan\\nRenhua Peng\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2003.12973\\u00a7r\\n\\nVersion:\\u00a77v3 (Wed, 1 Apr 2020 03:59:01 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 3 figures\\u00a7r"}']}
{title:'Nunes et al. (§72020§r)', author: 'João Antônio Chagas Nunes; David Macêdo; Cleber Zanchettin', display:{Lore:['[{"text": "arXiv:2004.00132", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAM-MobileNet1D: A Portable Model for Speaker Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oJo\\u00e3o Ant\\u00f4nio Chagas Nunes\\nDavid Mac\\u00eado\\nCleber Zanchettin\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2004.00132\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/IJCNN48605.2020.9207519\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7n2020 International Joint Conference on Neural Networks (IJCNN)\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 31 Mar 2020 21:42:59 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o2020 International Joint Conference on Neural Networks (IJCNN)\\u00a7r"}']}
{title:'Callender et al. (§72020§r)', author: 'Lee Callender; Curtis Hawthorne; Jesse Engel', display:{Lore:['[{"text": "arXiv:2004.00188", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lImproving Perceptual Quality of Drum Transcription with the Expanded Groove MIDI Dataset\\u00a7r\\n\\n\\u00a78\\u00a7oLee Callender\\nCurtis Hawthorne\\nJesse Engel\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2004.00188\\u00a7r\\n\\nVersion:\\u00a77v5 (Tue, 1 Dec 2020 18:11:04 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oExamples available at https://goo.gl/magenta/e-gmd-examples\\u00a7r"}']}
{title:'Sergio et al. (§72020§r)', author: 'Gwenaelle Cunha Sergio; Minho Lee', display:{Lore:['[{"text": "arXiv:2004.02113", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CV\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lEmotional Video to Audio Transformation Using Deep Recurrent Neural Networks and a Neuro-Fuzzy System\\u00a7r\\n\\n\\u00a78\\u00a7oGwenaelle Cunha Sergio\\nMinho Lee\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2004.02113\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1155/2020/8478527\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nMathematical Problems in Engineering 2020 (2020) 1-15\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 5 Apr 2020 07:18:28 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oPublished (https://www.hindawi.com/journals/mpe/2020/8478527/)\\u00a7r"}']}
{title:'Farzaneh et al. (§72020§r)', author: 'Majid Farzaneh; Rahil Mahdian Toroghi', display:{Lore:['[{"text": "arXiv:2004.04687", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.AI\\u00a7r, \\u00a7acs.NE\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lGGA-MG: Generative Genetic Algorithm for Music Generation\\u00a7r\\n\\n\\u00a78\\u00a7oMajid Farzaneh\\nRahil Mahdian Toroghi\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2004.04687\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.13140/RG.2.2.16677.24805\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 7 Apr 2020 22:45:42 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o14 pages, Submitted to Journal of Evolutionary Intelligence\\u00a7r"}']}
{title:'Ycart et al. (§72020§r)', author: 'Adrien Ycart; Lele Liu; Emmanouil Benetos; Marcus T. Pearce', display:{Lore:['[{"text": "arXiv:2004.07171", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.IR\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMusical Features for Automatic Music Transcription Evaluation\\u00a7r\\n\\n\\u00a78\\u00a7oAdrien Ycart\\nLele Liu\\nEmmanouil Benetos\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2004.07171\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 15 Apr 2020 15:56:45 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oTechnical report\\u00a7r"}']}
{title:'Sarkar et al. (§72020§r)', author: 'Uddalok Sarkar; Soumyadeep Pal; Sayan Nag; Chirayata Bhattacharya; Shankha Sanyal; Archi Banerjee; Ranjan Sengupta; Dipak Ghosh', display:{Lore:['[{"text": "arXiv:2004.07820", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSpeaker Recognition in Bengali Language from Nonlinear Features\\u00a7r\\n\\n\\u00a78\\u00a7oUddalok Sarkar\\nSoumyadeep Pal\\nSayan Nag\\n+ 4 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2004.07820\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 15 Apr 2020 22:38:54 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oarXiv admin note: text overlapwith arXiv:1612.00171, arXiv:1601.07709\\u00a7r"}']}
{title:'Mallick et al. (§72020§r)', author: 'Tanwi Mallick; Partha Pratim Das; Arun Kumar Majumdar', display:{Lore:['[{"text": "arXiv:2004.08269", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lBeat Detection and Automatic Annotation of the Music of Bharatanatyam Dance using Speech Recognition Techniques\\u00a7r\\n\\n\\u00a78\\u00a7oTanwi Mallick\\nPartha Pratim Das\\nArun Kumar Majumdar\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2004.08269\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 17 Apr 2020 14:33:57 GMT)\\u00a7r"}']}
{title:'Watanabe et al. (§72020§r)', author: 'Shinji Watanabe; Michael Mandel; Jon Barker; Emmanuel Vincent; Ashish Arora; Xuankai Chang; Sanjeev Khudanpur; Vimal Manohar; Daniel Povey; Desh Raj; David Snyder; Aswin Shanmugam Subramanian; Jan Trmal; Bar Ben Yair; Christoph Boeddeker; Zhaoheng Ni; Yusuke Fujita; Shota Horiguchi; Naoyuki Kanda; Takuya Yoshioka; Neville Ryant', display:{Lore:['[{"text": "arXiv:2004.09249", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lCHiME-6 Challenge:Tackling Multispeaker Speech Recognition for Unsegmented Recordings\\u00a7r\\n\\n\\u00a78\\u00a7oShinji Watanabe\\nMichael Mandel\\nJon Barker\\n+ 17 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2004.09249\\u00a7r\\n\\nVersion:\\u00a77v2 (Sat, 2 May 2020 11:04:49 GMT)\\u00a7r"}']}
{title:'Dang et al. (§72020§r)', author: 'Viet-Trung Dang; Tianyu Zhao; Sei Ueno; Hirofumi Inaguma; Tatsuya Kawahara', display:{Lore:['[{"text": "arXiv:2004.11419", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lEnd-to-end speech-to-dialog-act recognition\\u00a7r\\n\\n\\u00a78\\u00a7oViet-Trung Dang\\nTianyu Zhao\\nSei Ueno\\nHirofumi Inaguma\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2004.11419\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 28 Jul 2020 22:12:17 GMT)\\u00a7r"}']}
{title:'Vydana et al. (§72020§r)', author: "Hari Krishna Vydana; Martin Karafi'at; Katerina Zmolikova; Luk'as Burget; Honza Cernocky", display:{Lore:['[{"text": "arXiv:2004.12111", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lJointly Trained Transformers models for Spoken Language Translation\\u00a7r\\n\\n\\u00a78\\u00a7oHari Krishna Vydana\\nMartin Karafi\'at\\nKaterina Zmolikova\\nLuk\'as Burget\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2004.12111\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 25 Apr 2020 11:28:39 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o7-pages,3 figures\\u00a7r"}']}
{title:'Yang et al. (§72020§r)', author: 'Shan Yang; Yuxuan Wang; Lei Xie', display:{Lore:['[{"text": "arXiv:2004.13595", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAdversarial Feature Learning and Unsupervised Clustering based Speech Synthesis for Found Data with Acoustic and Textual Noise\\u00a7r\\n\\n\\u00a78\\u00a7oShan Yang\\nYuxuan Wang\\nLei Xie\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2004.13595\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/LSP.2020.3025410\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 28 Apr 2020 15:32:45 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7osubmitted to IEEESPL\\u00a7r"}']}
{title:'Chung et al. (§72020§r)', author: 'Soo-Whan Chung; Hong Goo Kang; Joon Son Chung', display:{Lore:['[{"text": "arXiv:2004.14326", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CV\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSeeing voices and hearing voices: learning discriminative embeddings using cross-modal self-supervision\\u00a7r\\n\\n\\u00a78\\u00a7oSoo-Whan Chung\\nHong Goo Kang\\nJoon Son Chung\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2004.14326\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.21437/Interspeech.2020-1113\\u00a7r\\n\\nVersion:\\u00a77v2 (Wed, 6 May 2020 14:56:36 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oUnder submission as a conference paper\\u00a7r"}']}
{title:'Fonseca et al. (§72020§r)', author: 'Eduardo Fonseca; Shawn Hershey; Manoj Plakal; Daniel P. W. Ellis; Aren Jansen; R. Channing Moore; Xavier Serra', display:{Lore:['[{"text": "arXiv:2005.00878", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAddressing Missing Labels in Large-Scale Sound Event Recognition Using a Teacher-Student Framework With Loss Masking\\u00a7r\\n\\n\\u00a78\\u00a7oEduardo Fonseca\\nShawn Hershey\\nManoj Plakal\\n+ 3 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.00878\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/LSP.2020.3006378\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nIEEE Signal Processing Letters, Vol. 27, 2020, pages 1235-1239\\u00a7r\\n\\nVersion:\\u00a77v2 (Sat, 25 Jul 2020 14:50:11 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted in IEEE Signal Processing Letters, openly accessible at https://ieeexplore.ieee.org/document/9130823\\u00a7r"}']}
{title:'Lyu et al. (§72020§r)', author: 'Sudi Lyu; Anxiang Zhang; Rong Song', display:{Lore:['[{"text": "arXiv:2005.04353", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDual-track Music Generation using Deep Learning\\u00a7r\\n\\n\\u00a78\\u00a7oSudi Lyu\\nAnxiang Zhang\\nRong Song\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.04353\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 9 May 2020 02:34:39 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o8 pages, 7 figures\\u00a7r"}']}
{title:'Aroudi et al. (§72020§r)', author: 'Ali Aroudi; Marc Delcroix; Tomohiro Nakatani; Keisuke Kinoshita; Shoko Araki; Simon Doclo', display:{Lore:['[{"text": "arXiv:2005.04669", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r, \\u00a7eeess.SP\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lCognitive-driven convolutional beamforming using EEG-based auditory attention decoding\\u00a7r\\n\\n\\u00a78\\u00a7oAli Aroudi\\nMarc Delcroix\\nTomohiro Nakatani\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.04669\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 10 May 2020 13:56:31 GMT)\\u00a7r"}']}
{title:'Drugman et al. (§72020§r)', author: 'Thomas Drugman; Thierry Dutoit', display:{Lore:['[{"text": "arXiv:2005.04724", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lChirp Complex Cepstrum-based Decomposition for Asynchronous Glottal Analysis\\u00a7r\\n\\n\\u00a78\\u00a7oThomas Drugman\\nThierry Dutoit\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.04724\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 10 May 2020 17:33:48 GMT)\\u00a7r"}']}
{title:'Marafioti et al. (§72020§r)', author: 'Andres Marafioti; Piotr Majdak; Nicki Holighaus; Nathanaël Perraudin', display:{Lore:['[{"text": "arXiv:2005.05032", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lGACELA \\u2013 A generative adversarial context encoder for long audio inpainting\\u00a7r\\n\\n\\u00a78\\u00a7oAndres Marafioti\\nPiotr Majdak\\nNicki Holighaus\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.05032\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/JSTSP.2020.3037506\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nIEEE Journal of Selected Topics in Signal Processing, vol. 15, no.\\n  1, pp. 120-131, Jan. 2021\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 11 May 2020 12:17:26 GMT)\\u00a7r"}']}
{title:'Li et al. (§72020§r)', author: 'Xiaofei Li; Radu Horaud', display:{Lore:['[{"text": "arXiv:2005.05037", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lOnline Monaural Speech Enhancement Using Delayed Subband LSTM\\u00a7r\\n\\n\\u00a78\\u00a7oXiaofei Li\\nRadu Horaud\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.05037\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.21437/Interspeech.2020-2091\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 11 May 2020 12:33:43 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oPaper submitted to Interspeech 2020\\u00a7r"}']}
{title:'Yang et al. (§72020§r)', author: 'Geng Yang; Shan Yang; Kai Liu; Peng Fang; Wei Chen; Lei Xie', display:{Lore:['[{"text": "arXiv:2005.05106", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMulti-band MelGAN: Faster Waveform Generation for High-Quality Text-to-Speech\\u00a7r\\n\\n\\u00a78\\u00a7oGeng Yang\\nShan Yang\\nKai Liu\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.05106\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 17 Nov 2020 07:07:23 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to Interspeech2020\\u00a7r"}']}
{title:'Tian et al. (§72020§r)', author: 'Qiao Tian; Zewang Zhang; Heng Lu; Ling-Hui Chen; Shan Liu', display:{Lore:['[{"text": "arXiv:2005.05551", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lFeatherWave: An efficient high-fidelity neural vocoder with multi-band linear prediction\\u00a7r\\n\\n\\u00a78\\u00a7oQiao Tian\\nZewang Zhang\\nHeng Lu\\nLing-Hui Chen\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.05551\\u00a7r\\n\\nVersion:\\u00a77v2 (Thu, 3 Sep 2020 06:53:41 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted by INTERSPEECH 2020\\u00a7r"}']}
{title:'Zhang et al. (§72020§r)', author: 'Zewang Zhang; Qiao Tian; Heng Lu; Ling-Hui Chen; Shan Liu', display:{Lore:['[{"text": "arXiv:2005.05642", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAdaDurIAN: Few-shot Adaptation for Neural Text-to-Speech with DurIAN\\u00a7r\\n\\n\\u00a78\\u00a7oZewang Zhang\\nQiao Tian\\nHeng Lu\\nLing-Hui Chen\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.05642\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 12 May 2020 09:41:03 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to InterSpeech 2020\\u00a7r"}']}
{title:'Li et al. (§72020§r)', author: 'Andong Li; Chengshi Zheng; Renhua Peng; Linjuan Cheng; Xiaodong Li', display:{Lore:['[{"text": "arXiv:2005.05855", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lThe IOA System for Deep Noise Suppression Challenge using a Framework Combining Dynamic Attention and Recursive Learning\\u00a7r\\n\\n\\u00a78\\u00a7oAndong Li\\nChengshi Zheng\\nRenhua Peng\\nLinjuan Cheng\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.05855\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 12 May 2020 15:23:25 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o4 pages, 2 figures\\u00a7r"}']}
{title:'Valle et al. (§72020§r)', author: 'Rafael Valle; Kevin Shih; Ryan Prenger; Bryan Catanzaro', display:{Lore:['[{"text": "arXiv:2005.05957", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lFlowtron: an Autoregressive Flow-based Generative Network for Text-to-Speech Synthesis\\u00a7r\\n\\n\\u00a78\\u00a7oRafael Valle\\nKevin Shih\\nRyan Prenger\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.05957\\u00a7r\\n\\nVersion:\\u00a77v3 (Thu, 16 Jul 2020 15:10:18 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o10 pages, 7 pictures\\u00a7r"}']}
{title:'Zhou et al. (§72020§r)', author: 'Kun Zhou; Berrak Sisman; Mingyang Zhang; Haizhou Li', display:{Lore:['[{"text": "arXiv:2005.07025", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.AI\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lConverting Anyone\'s Emotion: Towards Speaker-Independent Emotional Voice Conversion\\u00a7r\\n\\n\\u00a78\\u00a7oKun Zhou\\nBerrak Sisman\\nMingyang Zhang\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.07025\\u00a7r\\n\\nVersion:\\u00a77v3 (Tue, 13 Oct 2020 06:07:16 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted by Interspeech 2020\\u00a7r"}']}
{title:'Chung et al. (§72020§r)', author: 'Soo-Whan Chung; Soyeon Choe; Joon Son Chung; Hong-Goo Kang', display:{Lore:['[{"text": "arXiv:2005.07074", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CV\\u00a7r, \\u00a7acs.MM\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lFaceFilter: Audio-visual speech separation using still images\\u00a7r\\n\\n\\u00a78\\u00a7oSoo-Whan Chung\\nSoyeon Choe\\nJoon Son Chung\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.07074\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.21437/Interspeech.2020-1065\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 14 May 2020 15:42:31 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oUnder submission as a conference paper. Video examples: https://youtu.be/ku9xoLh62E\\u00a7r"}']}
{title:'Wu et al. (§72020§r)', author: 'Yiming Wu; Tristan Carsault; Eita Nakamura; Kazuyoshi Yoshii', display:{Lore:['[{"text": "arXiv:2005.07091", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSemi-supervised Neural Chord Estimation Based on a Variational Autoencoder with Latent Chord Labels and Features\\u00a7r\\n\\n\\u00a78\\u00a7oYiming Wu\\nTristan Carsault\\nEita Nakamura\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.07091\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 8 Sep 2020 04:31:08 GMT)\\u00a7r"}']}
{title:'Ai et al. (§72020§r)', author: 'Yang Ai; Xin Wang; Junichi Yamagishi; Zhen-Hua Ling', display:{Lore:['[{"text": "arXiv:2005.07379", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lReverberation Modeling for Source-Filter-based Neural Vocoder\\u00a7r\\n\\n\\u00a78\\u00a7oYang Ai\\nXin Wang\\nJunichi Yamagishi\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.07379\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 15 May 2020 07:05:06 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to Interspeech 2020\\u00a7r"}']}
{title:'Drugman et al. (§72020§r)', author: 'Thomas Drugman; Baris Bozkurt; Thierry Dutoit', display:{Lore:['[{"text": "arXiv:2005.07897", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lGlottal Source Estimation using an Automatic Chirp Decomposition\\u00a7r\\n\\n\\u00a78\\u00a7oThomas Drugman\\nBaris Bozkurt\\nThierry Dutoit\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.07897\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 16 May 2020 08:10:38 GMT)\\u00a7r"}']}
{title:'Drugman et al. (§72020§r)', author: 'Thomas Drugman; Thierry Dutoit', display:{Lore:['[{"text": "arXiv:2005.07901", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lOscillating Statistical Moments for Speech Polarity Detection\\u00a7r\\n\\n\\u00a78\\u00a7oThomas Drugman\\nThierry Dutoit\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.07901\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 16 May 2020 08:16:43 GMT)\\u00a7r"}']}
{title:'Ma et al. (§72020§r)', author: 'Lu Ma; Xiaomeng Zhang; Pei Zhao; Tengrong Su', display:{Lore:['[{"text": "arXiv:2005.08184", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lVoice Activity Detection Scheme by Combining DNN Model with GMM Model\\u00a7r\\n\\n\\u00a78\\u00a7oLu Ma\\nXiaomeng Zhang\\nPei Zhao\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.08184\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 17 May 2020 08:01:27 GMT)\\u00a7r"}']}
{title:'Latif et al. (§72020§r)', author: 'Siddique Latif; Muhammad Asim; Rajib Rana; Sara Khalifa; Raja Jurdak; Björn W. Schuller', display:{Lore:['[{"text": "arXiv:2005.08447", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAugmenting Generative Adversarial Networks for Speech Emotion Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oSiddique Latif\\nMuhammad Asim\\nRajib Rana\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.08447\\u00a7r\\n\\nVersion:\\u00a77v3 (Sun, 26 Jul 2020 02:45:43 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted in INTERSPEECH 2020\\u00a7r"}']}
{title:'Latif et al. (§72020§r)', author: 'Siddique Latif; Rajib Rana; Sara Khalifa; Raja Jurdak; Björn W. Schuller', display:{Lore:['[{"text": "arXiv:2005.08453", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDeep Architecture Enhancing Robustness to Noise, Adversarial Attacks, and Cross-corpus Setting for Speech Emotion Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oSiddique Latif\\nRajib Rana\\nSara Khalifa\\nRaja Jurdak\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.08453\\u00a7r\\n\\nVersion:\\u00a77v3 (Sun, 26 Jul 2020 02:44:44 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted in INTERSPEECH 2020\\u00a7r"}']}
{title:'Lenain et al. (§72020§r)', author: 'Raphael Lenain; Jack Weston; Abhishek Shivkumar; Emil Fristed', display:{Lore:['[{"text": "arXiv:2005.08848", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSurfboard: Audio Feature Extraction for Modern Machine Learning\\u00a7r\\n\\n\\u00a78\\u00a7oRaphael Lenain\\nJack Weston\\nAbhishek Shivkumar\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.08848\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 18 May 2020 16:20:20 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages. 0 figures. Underreview\\u00a7r"}']}
{title:'Feng (§72020§r)', author: 'Kevin Feng', display:{Lore:['[{"text": "arXiv:2005.08944", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CV\\u00a7r, \\u00a7acs.GR\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSaving the Sonorine: Photovisual Audio Recovery Using Image Processing and Computer Vision Techniques\\u00a7r\\n\\n\\u00a78\\u00a7oKevin Feng\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.08944\\u00a7r\\n\\nVersion:\\u00a77v3 (Fri, 22 May 2020 20:08:01 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oThis version has been removed by arXiv administrators because the submitter did not have the right toagree to the license applied at the time of submission\\u00a7r"}']}
{title:'Ma et al. (§72020§r)', author: 'Lu Ma; Hua Huang; Pei Zhao; Tengrong Su', display:{Lore:['[{"text": "arXiv:2005.09237", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAcoustic Echo Cancellation by Combining Adaptive Digital Filter and Recurrent Neural Network\\u00a7r\\n\\n\\u00a78\\u00a7oLu Ma\\nHua Huang\\nPei Zhao\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.09237\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 19 May 2020 06:25:52 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7osubmitted to INTERSPEECH2020\\u00a7r"}']}
{title:'Ma et al. (§72020§r)', author: 'Lu Ma; Xin Zhao; Pei Zhao; Tengrong Su', display:{Lore:['[{"text": "arXiv:2005.09238", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Lite Microphone Array Beamforming Scheme with Maximum Signal-to-Noise Ratio Filter\\u00a7r\\n\\n\\u00a78\\u00a7oLu Ma\\nXin Zhao\\nPei Zhao\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.09238\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 19 May 2020 06:35:41 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7osubmitted to INTERSPEECH2020\\u00a7r"}']}
{title:'Ma et al. (§72020§r)', author: 'Lu Ma; Haiping Zhang; Pei Zhao; Tengrong Su', display:{Lore:['[{"text": "arXiv:2005.09242", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lCompetitive Wakeup Scheme for Distributed Devices\\u00a7r\\n\\n\\u00a78\\u00a7oLu Ma\\nHaiping Zhang\\nPei Zhao\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.09242\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 19 May 2020 06:46:02 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7osumbitted to INTERSPEECH2020\\u00a7r"}']}
{title:'Wu et al. (§72020§r)', author: 'Yuan-Kuei Wu; Chao-I Tuan; Hung-yi Lee; Yu Tsao', display:{Lore:['[{"text": "arXiv:2005.09966", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSADDEL: Joint Speech Separation and Denoising Model based on Multitask Learning\\u00a7r\\n\\n\\u00a78\\u00a7oYuan-Kuei Wu\\nChao-I Tuan\\nHung-yi Lee\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.09966\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 20 May 2020 11:13:35 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oThe two first authors made equal contributions\\u00a7r"}']}
{title:'Gaultier et al. (§72020§r)', author: 'Clément Gaultier; Srđan Kitić; Rémi Gribonval; Nancy Bertin', display:{Lore:['[{"text": "arXiv:2005.10228", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r, \\u00a7eeess.SP\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSparsity-based audio declipping methods: selected overview, new algorithms, and large-scale evaluation\\u00a7r\\n\\n\\u00a78\\u00a7oCl\\u00e9ment Gaultier\\nSr\\u0111an Kiti\\u0107\\nR\\u00e9mi Gribonval\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.10228\\u00a7r\\n\\nVersion:\\u00a77v2 (Mon, 30 Nov 2020 14:28:07 GMT)\\u00a7r"}']}
{title:'Guo et al. (§72020§r)', author: 'Haohan Guo; Shaofei Zhang; Frank K. Soong; Lei He; Lei Xie', display:{Lore:['[{"text": "arXiv:2005.10438", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lConversational End-to-End TTS for Voice Agent\\u00a7r\\n\\n\\u00a78\\u00a7oHaohan Guo\\nShaofei Zhang\\nFrank K. Soong\\nLei He\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.10438\\u00a7r\\n\\nVersion:\\u00a77v2 (Mon, 16 Nov 2020 10:02:10 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted by SLT 2021; 7 pages\\u00a7r"}']}
{title:'Luo et al. (§72020§r)', author: 'Haoneng Luo; Shiliang Zhang; Ming Lei; Lei Xie', display:{Lore:['[{"text": "arXiv:2005.10463", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSimplified Self-Attention for Transformer-based End-to-End Speech Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oHaoneng Luo\\nShiliang Zhang\\nMing Lei\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.10463\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 17 Nov 2020 09:58:44 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted to SLT 2021\\u00a7r"}']}
{title:'Dissanayake et al. (§72020§r)', author: 'Theekshana Dissanayake; Tharindu Fernando; Simon Denman; Sridha Sridharan; Houman Ghaemmaghami; Clinton Fookes', display:{Lore:['[{"text": "arXiv:2005.10480", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r, \\u00a7bq-bio.QM\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Robust Interpretable Deep Learning Classifier for Heart Anomaly Detection Without Segmentation\\u00a7r\\n\\n\\u00a78\\u00a7oTheekshana Dissanayake\\nTharindu Fernando\\nSimon Denman\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.10480\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 29 Sep 2020 06:42:51 GMT)\\u00a7r"}']}
{title:'Muñoz-Lago et al. (§72020§r)', author: 'Paula Muñoz-Lago; Gonzalo Méndez', display:{Lore:['[{"text": "arXiv:2005.10539", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.AI\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAn approach to Beethoven\'s 10th Symphony\\u00a7r\\n\\n\\u00a78\\u00a7oPaula Mu\\u00f1oz-Lago\\nGonzalo M\\u00e9ndez\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.10539\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 21 May 2020 09:36:24 GMT)\\u00a7r"}']}
{title:'Wang et al. (§72020§r)', author: 'Qing Wang; Pengcheng Guo; Lei Xie', display:{Lore:['[{"text": "arXiv:2005.10637", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lInaudible Adversarial Perturbations for Targeted Attack in Speaker Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oQing Wang\\nPengcheng Guo\\nLei Xie\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.10637\\u00a7r\\n\\nVersion:\\u00a77v2 (Fri, 22 May 2020 03:50:48 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 2 figures\\u00a7r"}']}
{title:'Trinh et al. (§72020§r)', author: 'Viet Anh Trinh; Michael I Mandel', display:{Lore:['[{"text": "arXiv:2005.10929", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CV\\u00a7r, \\u00a7acs.LG\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lLarge scale evaluation of importance maps in automatic speech recognition\\u00a7r\\n\\n\\u00a78\\u00a7oViet Anh Trinh\\nMichael I Mandel\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.10929\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.21437/Interspeech.2020-2883\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nProceedings of Interspeech 2020\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 21 May 2020 22:39:51 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7osubmitted to INTERSPEECH 2020\\u00a7r"}']}
{title:'Liu et al. (§72020§r)', author: 'Yuzhuo Liu; Hangting Chen; Pengyuan Zhang', display:{Lore:['[{"text": "arXiv:2005.11459", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lPower Pooling Operators and Confidence Learning for Semi-Supervised Sound Event Detection\\u00a7r\\n\\n\\u00a78\\u00a7oYuzhuo Liu\\nHangting Chen\\nPengyuan Zhang\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.11459\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 23 May 2020 04:02:21 GMT)\\u00a7r"}']}
{title:'Ebrahimpour et al. (§72020§r)', author: 'Mohammad K. Ebrahimpour; Timothy Shea; Andreea Danielescu; David C. Noelle; Christopher T. Kello', display:{Lore:['[{"text": "arXiv:2005.12195", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lEnd-to-End Auditory Object Recognition via Inception Nucleus\\u00a7r\\n\\n\\u00a78\\u00a7oMohammad K. Ebrahimpour\\nTimothy Shea\\nAndreea Danielescu\\nDavid C. Noelle\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.12195\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 25 May 2020 16:08:41 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oPublished In proceedings of ICASSP 2020\\u00a7r"}']}
{title:'İlerialkan et al. (§72020§r)', author: 'Atıl İlerialkan; Alptekin Temizel; Hüseyin Hacıhabiboğlu', display:{Lore:['[{"text": "arXiv:2005.12230", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSpeaker and Posture Classification using Instantaneous Intraspeech Breathing Features\\u00a7r\\n\\n\\u00a78\\u00a7oAt\\u0131l \\u0130lerialkan\\nAlptekin Temizel\\nH\\u00fcseyin Hac\\u0131habibo\\u011flu\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.12230\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 25 May 2020 17:00:26 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 3 figures\\u00a7r"}']}
{title:'Ebrahimpour et al. (§72020§r)', author: 'Mohammad K. Ebrahimpour; Sara Schneider; David C. Noelle; Christopher T. Kello', display:{Lore:['[{"text": "arXiv:2005.12412", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lInfantNet: A Deep Neural Network for Analyzing Infant Vocalizations\\u00a7r\\n\\n\\u00a78\\u00a7oMohammad K. Ebrahimpour\\nSara Schneider\\nDavid C. Noelle\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.12412\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 25 May 2020 21:24:01 GMT)\\u00a7r"}']}
{title:'Ngo et al. (§72020§r)', author: 'Dat Ngo; Hao Hoang; Anh Nguyen; Tien Ly; Lam Pham', display:{Lore:['[{"text": "arXiv:2005.12779", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSound Context Classification Basing on Join Learning Model and Multi-Spectrogram Features\\u00a7r\\n\\n\\u00a78\\u00a7oDat Ngo\\nHao Hoang\\nAnh Nguyen\\nTien Ly\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.12779\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 26 May 2020 15:01:25 GMT)\\u00a7r"}']}
{title:'Baby et al. (§72020§r)', author: 'Arun Baby; Saranya Vinnaitherthan; Nagaraj Adiga; Pranav Jawale; Sumukh Badam; Sharath Adavanne; Srikanth Konjeti', display:{Lore:['[{"text": "arXiv:2006.01463", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAn ASR Guided Speech Intelligibility Measure for TTS Model Selection\\u00a7r\\n\\n\\u00a78\\u00a7oArun Baby\\nSaranya Vinnaitherthan\\nNagaraj Adiga\\n+ 3 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.01463\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 2 Jun 2020 09:06:41 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to INTERSPEECH 2020\\u00a7r"}']}
{title:'Zhang et al. (§72020§r)', author: 'Shiliang Zhang; Zhifu Gao; Haoneng Luo; Ming Lei; Jie Gao; Zhijie Yan; Lei Xie', display:{Lore:['[{"text": "arXiv:2006.01712", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lStreaming Chunk-Aware Multihead Attention for Online End-to-End Speech Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oShiliang Zhang\\nZhifu Gao\\nHaoneng Luo\\n+ 3 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.01712\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 21 May 2020 03:35:15 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7osubmitted to INTERSPEECH2020\\u00a7r"}']}
{title:'Gao et al. (§72020§r)', author: 'Zhifu Gao; Shiliang Zhang; Ming Lei; Ian McLoughlin', display:{Lore:['[{"text": "arXiv:2006.01713", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSAN-M: Memory Equipped Self-Attention for End-to-End Speech Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oZhifu Gao\\nShiliang Zhang\\nMing Lei\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.01713\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 21 May 2020 03:33:09 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7osubmitted to INTERSPEECH2020\\u00a7r"}']}
{title:'Garcia-Valencia (§72020§r)', author: 'Sebastian Garcia-Valencia', display:{Lore:['[{"text": "arXiv:2006.02217", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lCross entropy as objective function for music generative models\\u00a7r\\n\\n\\u00a78\\u00a7oSebastian Garcia-Valencia\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.02217\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 2 Jun 2020 16:11:04 GMT)\\u00a7r"}']}
{title:'Bezzam et al. (§72020§r)', author: 'Eric Bezzam; Robin Scheibler; Cyril Cadoux; Thibault Gisselbrecht', display:{Lore:['[{"text": "arXiv:2006.02774", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA study on more realistic room simulation for far-field keyword spotting\\u00a7r\\n\\n\\u00a78\\u00a7oEric Bezzam\\nRobin Scheibler\\nCyril Cadoux\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.02774\\u00a7r\\n\\nVersion:\\u00a77v3 (Wed, 18 Nov 2020 16:31:34 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o7 pages, 4 figures, accepted at APSIPA 2020, room impulse response generation code can be found at https://github.com/ebezzam/room-simulation\\u00a7r"}']}
{title:'Koguchi et al. (§72020§r)', author: 'Junya Koguchi; Shinnosuke Takamichi', display:{Lore:['[{"text": "arXiv:2006.02959", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lPJS: phoneme-balanced Japanese singing voice corpus\\u00a7r\\n\\n\\u00a78\\u00a7oJunya Koguchi\\nShinnosuke Takamichi\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.02959\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 4 Jun 2020 15:41:00 GMT)\\u00a7r"}']}
{title:'Latypov et al. (§72020§r)', author: 'Rustam Latypov; Evgeni Stolov', display:{Lore:['[{"text": "arXiv:2006.03388", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA New Method Towards Speech Files Local Features Investigation\\u00a7r\\n\\n\\u00a78\\u00a7oRustam Latypov\\nEvgeni Stolov\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.03388\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 5 Jun 2020 11:53:56 GMT)\\u00a7r"}']}
{title:'Kirke et al. (§72020§r)', author: 'Alexis Kirke; Greg B. Davies; Joel Eaton', display:{Lore:['[{"text": "arXiv:2006.03471", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lApplication of Optimization and Simulation to Musical Composition that Emerges Dynamically during Ensemble Singing Performance\\u00a7r\\n\\n\\u00a78\\u00a7oAlexis Kirke\\nGreg B. Davies\\nJoel Eaton\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.03471\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 4 Jun 2020 15:29:56 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o31 pages, 11 Figures\\u00a7r"}']}
{title:'Kim et al. (§72020§r)', author: 'Hyeongju Kim; Hyeonseung Lee; Woo Hyun Kang; Sung Jun Cheon; Byoung Jin Choi; Nam Soo Kim', display:{Lore:['[{"text": "arXiv:2006.04598", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lWaveNODE: A Continuous Normalizing Flow for Speech Synthesis\\u00a7r\\n\\n\\u00a78\\u00a7oHyeongju Kim\\nHyeonseung Lee\\nWoo Hyun Kang\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.04598\\u00a7r\\n\\nVersion:\\u00a77v4 (Thu, 2 Jul 2020 23:12:56 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o8 pages, 4 figures, Second workshop on Invertible Neural Networks, Normalizing Flows, and Explicit Likelihood Models (ICML 2020)\\u00a7r"}']}
{title:'Nardelli (§72020§r)', author: 'Marco Buongiorno Nardelli', display:{Lore:['[{"text": "arXiv:2006.05007", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.SI\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lThe Hitchhiker\'s Guide to the All-Interval 12-Tone Rows\\u00a7r\\n\\n\\u00a78\\u00a7oMarco Buongiorno Nardelli\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.05007\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 9 Jun 2020 01:40:57 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o15 pages\\u00a7r"}']}
{title:'Mirbagheri et al. (§72020§r)', author: 'Majid Mirbagheri; Bardia Doosti', display:{Lore:['[{"text": "arXiv:2006.05071", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lC-SL: Contrastive Sound Localization with Inertial-Acoustic Sensors\\u00a7r\\n\\n\\u00a78\\u00a7oMajid Mirbagheri\\nBardia Doosti\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.05071\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 9 Jun 2020 06:36:44 GMT)\\u00a7r"}']}
{title:'Li et al. (§72020§r)', author: 'Andong Li; Chengshi Zheng; Renhua Peng; Cunhang Fan; Xiaodong Li', display:{Lore:['[{"text": "arXiv:2006.07530", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDynamic Attention Based Generative Adversarial Network with Phase Post-Processing for Speech Enhancement\\u00a7r\\n\\n\\u00a78\\u00a7oAndong Li\\nChengshi Zheng\\nRenhua Peng\\nCunhang Fan\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.07530\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 13 Jun 2020 01:38:43 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 3 figures\\u00a7r"}']}
{title:'Lartillot et al. (§72020§r)', author: 'Olivier Lartillot; Carlos Cancino-Chacón; Charles Brazier', display:{Lore:['[{"text": "arXiv:2006.10168", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lReal-time visualisation of fugue played by a string quartet\\u00a7r\\n\\n\\u00a78\\u00a7oOlivier Lartillot\\nCarlos Cancino-Chac\\u00f3n\\nCharles Brazier\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.10168\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 17 Jun 2020 21:31:54 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o8 pages, 4 figures, Accepted at the SMC Sound and Music Conference 2020\\u00a7r"}']}
{title:'Liebman et al. (§72020§r)', author: 'Elad Liebman; Peter Stone', display:{Lore:['[{"text": "arXiv:2006.10553", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.AI\\u00a7r, \\u00a7acs.MM\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lArtificial Musical Intelligence: A Survey\\u00a7r\\n\\n\\u00a78\\u00a7oElad Liebman\\nPeter Stone\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.10553\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 17 Jun 2020 04:46:32 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o99 pages, 5 figures, preprint: currently under review\\u00a7r"}']}
{title:'Sarmento et al. (§72020§r)', author: 'Pedro Sarmento; Ove Holmqvist; Mathieu Barthet', display:{Lore:['[{"text": "arXiv:2006.12305", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMusical Smart City: Perspectives on Ubiquitous Sonification\\u00a7r\\n\\n\\u00a78\\u00a7oPedro Sarmento\\nOve Holmqvist\\nMathieu Barthet\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.12305\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nUbiquitous Music Workshop 2020\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 22 Jun 2020 14:37:43 GMT)\\u00a7r"}']}
{title:'Fang et al. (§72020§r)', author: 'Alexander Fang; Alisa Liu; Prem Seetharaman; Bryan Pardo', display:{Lore:['[{"text": "arXiv:2006.13329", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lBach or Mock? A Grading Function for Chorales in the Style of J.S. Bach\\u00a7r\\n\\n\\u00a78\\u00a7oAlexander Fang\\nAlisa Liu\\nPrem Seetharaman\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.13329\\u00a7r\\n\\nVersion:\\u00a77v3 (Fri, 17 Jul 2020 16:25:28 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o2 pages, 3 figures, Machine Learning for Media Discovery (ML4MD) Workshop at ICML 2020\\u00a7r"}']}
{title:'Liu et al. (§72020§r)', author: 'Alisa Liu; Alexander Fang; Gaëtan Hadjeres; Prem Seetharaman; Bryan Pardo', display:{Lore:['[{"text": "arXiv:2006.13331", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lIncorporating Music Knowledge in Continual Dataset Augmentation for Music Generation\\u00a7r\\n\\n\\u00a78\\u00a7oAlisa Liu\\nAlexander Fang\\nGa\\u00ebtan Hadjeres\\nPrem Seetharaman\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.13331\\u00a7r\\n\\nVersion:\\u00a77v4 (Mon, 20 Jul 2020 20:56:59 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o2 pages, 2 figures, Machine Learning for Media Discovery (ML4MD) Workshop at ICML 2020\\u00a7r"}']}
{title:'Akiyama et al. (§72020§r)', author: 'Daichi Akiyama; Keisuke Imoto; Noriyuki Tonami; Yuki Okamoto; Ryosuke Yamanishi; Takahiro Fukumori; Yoichi Yamashita', display:{Lore:['[{"text": "arXiv:2006.15253", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSound Event Detection Using Duration Robust Loss Function\\u00a7r\\n\\n\\u00a78\\u00a7oDaichi Akiyama\\nKeisuke Imoto\\nNoriyuki Tonami\\n+ 3 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.15253\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 27 Jun 2020 01:49:25 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to DCASE2020 Workshop\\u00a7r"}']}
{title:'Sears et al. (§72020§r)', author: 'David R. W. Sears; Gerhard Widmer', display:{Lore:['[{"text": "arXiv:2006.15399", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.IR\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lBeneath (or beyond) the surface: Discovering voice-leading patterns with skip-grams\\u00a7r\\n\\n\\u00a78\\u00a7oDavid R. W. Sears\\nGerhard Widmer\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.15399\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1080/17459737.2020.1785568\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 27 Jun 2020 16:21:18 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oThis is an original manuscript /preprint of an article published by Taylor Francis in the Journal of Mathematics and Music, available online: https://doi.org/10.1080/17459737.2020.1785568. 26 pages, 8 figures, 3 tables\\u00a7r"}','{"text": ""}']}
{title:'Mohammadamini et al. (§72020§r)', author: 'Mohammad Mohammadamini; Driss Matrouf', display:{Lore:['[{"text": "arXiv:2006.15903", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lData augmentation versus noise compensation for x- vector speaker recognition systems in noisy environments\\u00a7r\\n\\n\\u00a78\\u00a7oMohammad Mohammadamini\\nDriss Matrouf\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.15903\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 29 Jun 2020 09:50:45 GMT)\\u00a7r"}']}
{title:'Kumar et al. (§72020§r)', author: 'Anurag Kumar; Vamsi Krishna Ithapu', display:{Lore:['[{"text": "arXiv:2007.00144", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Sequential Self Teaching Approach for Improving Generalization in Sound Event Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oAnurag Kumar\\nVamsi Krishna Ithapu\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2007.00144\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 30 Jun 2020 22:53:43 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted International Conference on MachineLearning (ICML) 2020. 14 pages\\u00a7r"}']}
{title:'Kitamura et al. (§72020§r)', author: 'Daichi Kitamura; Kohei Yatabe', display:{Lore:['[{"text": "arXiv:2007.00274", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lConsistent Independent Low-Rank Matrix Analysis for Determined Blind Source Separation\\u00a7r\\n\\n\\u00a78\\u00a7oDaichi Kitamura\\nKohei Yatabe\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2007.00274\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1186/s13634-020-00704-4\\u00a7r\\n\\nVersion:\\u00a77v2 (Sun, 1 Nov 2020 05:11:02 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to EURASIP J. Adv. Signal. Process. Accepted on Oct. 30, 2020\\u00a7r"}']}
{title:'Kamo et al. (§72020§r)', author: 'Keigo Kamo; Yuki Kubo; Norihiro Takamune; Daichi Kitamura; Hiroshi Saruwatari; Yu Takahashi; Kazunobu Kondo', display:{Lore:['[{"text": "arXiv:2007.00416", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lJoint-Diagonalizability-Constrained Multichannel Nonnegative Matrix Factorization Based on Multivariate Complex Sub-Gaussian Distribution\\u00a7r\\n\\n\\u00a78\\u00a7oKeigo Kamo\\nYuki Kubo\\nNorihiro Takamune\\n+ 3 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2007.00416\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 30 Jun 2020 11:37:03 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 3 figures, To appear in the Proceedings of the 28th European Signal Processing Conference (EUSIPCO 2020). arXiv admin note: text overlap with arXiv:2002.00579\\u00a7r"}']}
{title:'Cella et al. (§72020§r)', author: 'Carmine Emanuele Cella; Daniele Ghisi; Vincent Lostanlen; Fabien Lévy; Joshua Fineberg; Yan Maresz', display:{Lore:['[{"text": "arXiv:2007.00763", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lOrchideaSOL: a dataset of extended instrumental techniques for computer-aided orchestration\\u00a7r\\n\\n\\u00a78\\u00a7oCarmine Emanuele Cella\\nDaniele Ghisi\\nVincent Lostanlen\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2007.00763\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 1 Jul 2020 21:15:42 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o6 pages, 6 figures, in English. To appear in the proceedings of the International ComputerMusic Conference (ICMC2020). Please visit: https://icmc2020.org/\\u00a7r"}']}
{title:'Wang et al. (§72020§r)', author: 'Helin Wang; Yuexian Zou; Dading Chong', display:{Lore:['[{"text": "arXiv:2007.03781", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAcoustic Scene Classification with Spectrogram Processing Strategies\\u00a7r\\n\\n\\u00a78\\u00a7oHelin Wang\\nYuexian Zou\\nDading Chong\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2007.03781\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 6 Jul 2020 15:18:47 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to DCASE 2020 Workshop\\u00a7r"}']}
{title:'Turpault et al. (§72020§r)', author: 'Nicolas Turpault; Romain Serizel', display:{Lore:['[{"text": "arXiv:2007.03931", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r, \\u00a7eeess.SP\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lTraining Sound Event Detection On A Heterogeneous Dataset\\u00a7r\\n\\n\\u00a78\\u00a7oNicolas Turpault\\nRomain Serizel\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2007.03931\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 8 Jul 2020 07:29:35 GMT)\\u00a7r"}']}
{title:'Turpault et al. (§72020§r)', author: 'Nicolas Turpault; Scott Wisdom; Hakan Erdogan; John Hershey; Romain Serizel; Eduardo Fonseca; Prem Seetharaman; Justin Salamon', display:{Lore:['[{"text": "arXiv:2007.03932", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r, \\u00a7eeess.SP\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lImproving Sound Event Detection In Domestic Environments Using Sound Separation\\u00a7r\\n\\n\\u00a78\\u00a7oNicolas Turpault\\nScott Wisdom\\nHakan Erdogan\\n+ 4 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2007.03932\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 8 Jul 2020 07:31:30 GMT)\\u00a7r"}']}
{title:'Przyczyna et al. (§72020§r)', author: 'Dawid Przyczyna; Maria Szaciłowska; Marek Przybylski; Marcin Strzelecki; Konrad Szaciłowski', display:{Lore:['[{"text": "arXiv:2007.04360", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lInformation, communication and music: Recognition of musical dissonance and consonance in a simple reservoir computing system\\u00a7r\\n\\n\\u00a78\\u00a7oDawid Przyczyna\\nMaria Szaci\\u0142owska\\nMarek Przybylski\\nMarcin Strzelecki\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2007.04360\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 8 Jul 2020 18:39:58 GMT)\\u00a7r"}']}
{title:'Çakır et al. (§72020§r)', author: 'Emre Çakır; Konstantinos Drossos; Tuomas Virtanen', display:{Lore:['[{"text": "arXiv:2007.04660", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.MM\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMulti-task Regularization Based on Infrequent Classes for Audio Captioning\\u00a7r\\n\\n\\u00a78\\u00a7oEmre \\u00c7ak\\u0131r\\nKonstantinos Drossos\\nTuomas Virtanen\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2007.04660\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 9 Jul 2020 09:38:54 GMT)\\u00a7r"}']}
{title:'Okamoto et al. (§72020§r)', author: 'Yuki Okamoto; Keisuke Imoto; Shinnosuke Takamichi; Ryosuke Yamanishi; Takahiro Fukumori; Yoichi Yamashita', display:{Lore:['[{"text": "arXiv:2007.04719", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lRWCP-SSD-Onomatopoeia: Onomatopoeic Word Dataset for Environmental Sound Synthesis\\u00a7r\\n\\n\\u00a78\\u00a7oYuki Okamoto\\nKeisuke Imoto\\nShinnosuke Takamichi\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2007.04719\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 9 Jul 2020 11:41:40 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to DCASE2020 workshop\\u00a7r"}']}
{title:'Drossos et al. (§72020§r)', author: 'Konstantinos Drossos; Stylianos I. Mimilakis; Tuomas Virtanen', display:{Lore:['[{"text": "arXiv:2007.05183", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lConditioned Time-Dilated Convolutions for Sound Event Detection\\u00a7r\\n\\n\\u00a78\\u00a7oKonstantinos Drossos\\nStylianos I. Mimilakis\\nTuomas Virtanen\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2007.05183\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 10 Jul 2020 06:05:23 GMT)\\u00a7r"}']}
{title:'Kim et al. (§72020§r)', author: 'Jae-Bin Kim; Seongkyu Mun; Myungwoo Oh; Soyeon Choe; Yong-Hyeok Lee; Hyung-Min Park', display:{Lore:['[{"text": "arXiv:2007.05191", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lOvercoming label noise in audio event detection using sequential labeling\\u00a7r\\n\\n\\u00a78\\u00a7oJae-Bin Kim\\nSeongkyu Mun\\nMyungwoo Oh\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2007.05191\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 10 Jul 2020 06:33:12 GMT)\\u00a7r"}']}
{title:'Ranadive et al. (§72020§r)', author: 'Omkar Ranadive; Grant Gasser; David Terpay; Prem Seetharaman', display:{Lore:['[{"text": "arXiv:2007.06123", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lOtoWorld: Towards Learning to Separate by Learning to Move\\u00a7r\\n\\n\\u00a78\\u00a7oOmkar Ranadive\\nGrant Gasser\\nDavid Terpay\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2007.06123\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 12 Jul 2020 22:53:24 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oPublished in Self Supervision in Audio and Speech Workshop, 37th International Conference on MachineLearning, Vienna, Austria (ICML 2020)\\u00a7r"}']}
{title:'Verma et al. (§72020§r)', author: 'Prateek Verma; Alessandro Ilic Mezza; Chris Chafe; Cristina Rottondi', display:{Lore:['[{"text": "arXiv:2007.07132", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.NI\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Deep Learning Approach for Low-Latency Packet Loss Concealment of Audio Signals in Networked Music Performance Applications\\u00a7r\\n\\n\\u00a78\\u00a7oPrateek Verma\\nAlessandro Ilic Mezza\\nChris Chafe\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2007.07132\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 14 Jul 2020 15:51:52 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o8 pages, 2 figures\\u00a7r"}']}
{title:'Zhang et al. (§72020§r)', author: 'Zhichao Zhang; Shugong Xu; Shunqing Zhang; Tianhao Qiao; Shan Cao', display:{Lore:['[{"text": "arXiv:2007.07241", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lLearning Frame Level Attention for Environmental Sound Classification\\u00a7r\\n\\n\\u00a78\\u00a7oZhichao Zhang\\nShugong Xu\\nShunqing Zhang\\nTianhao Qiao\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2007.07241\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 12 Jul 2020 10:33:27 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oarXiv admin note: substantial text overlap with arXiv:1907.02230\\u00a7r"}']}
{title:'Wu et al. (§72020§r)', author: 'Xianchao Wu; Chengyuan Wang; Qinying Lei', display:{Lore:['[{"text": "arXiv:2007.07244", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.MM\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lTransformer-XL Based Music Generation with Multiple Sequences of Time-valued Notes\\u00a7r\\n\\n\\u00a78\\u00a7oXianchao Wu\\nChengyuan Wang\\nQinying Lei\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2007.07244\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 11 Jul 2020 20:16:24 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o9 pages, 7 figures\\u00a7r"}']}
{title:'Zehren et al. (§72020§r)', author: 'Mickaël Zehren; Marco Alunno; Paolo Bientinesi', display:{Lore:['[{"text": "arXiv:2007.08411", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAutomatic Detection of Cue Points for DJ Mixing\\u00a7r\\n\\n\\u00a78\\u00a7oMicka\\u00ebl Zehren\\nMarco Alunno\\nPaolo Bientinesi\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2007.08411\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 16 Jul 2020 15:45:25 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o7 pages, 4 figures, code available at https://github.com/MZehren/Automix, dataset available athttps://github.com/MZehren/M-DJCUE\\u00a7r"}']}
{title:'Castillo-Sanchez et al. (§72020§r)', author: 'Carlos Rodrigo Castillo-Sanchez; Leibny Paola Garcia-Perera; Anabel Martin-Gonzalez', display:{Lore:['[{"text": "arXiv:2007.10248", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDNN Speaker Tracking with Embeddings\\u00a7r\\n\\n\\u00a78\\u00a7oCarlos Rodrigo Castillo-Sanchez\\nLeibny Paola Garcia-Perera\\nAnabel Martin-Gonzalez\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2007.10248\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 13 Jul 2020 18:40:14 GMT)\\u00a7r"}']}
{title:'Han et al. (§72020§r)', author: 'Han Han; Vincent Lostanlen', display:{Lore:['[{"text": "arXiv:2007.10299", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lwav2shape: Hearing the Shape of a Drum Machine\\u00a7r\\n\\n\\u00a78\\u00a7oHan Han\\nVincent Lostanlen\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2007.10299\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 20 Jul 2020 17:35:24 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o11 pages, 7 figures. To appear in the Proceedings of Forum Acusticum, Lyon (France), December 2020\\u00a7r"}']}
{title:'Huang et al. (§72020§r)', author: 'Yuxin Huang; Liwei Lin; Shuo Ma; Xiangdong Wang; Hong Liu; Yueliang Qian; Min Liu; Kazushige Ouch', display:{Lore:['[{"text": "arXiv:2007.10638", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lGuided multi-branch learning systems for sound event detection with sound separation\\u00a7r\\n\\n\\u00a78\\u00a7oYuxin Huang\\nLiwei Lin\\nShuo Ma\\n+ 4 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2007.10638\\u00a7r\\n\\nVersion:\\u00a77v2 (Mon, 2 Nov 2020 02:56:27 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted by DCASE2020 Workshop\\u00a7r"}']}
{title:'Lostanlen et al. (§72020§r)', author: 'Vincent Lostanlen; Christian El-Hajj; Mathias Rossignol; Grégoire Lafay; Joakim Andén; Mathieu Lagrange', display:{Lore:['[{"text": "arXiv:2007.10926", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lTime-Frequency Scattering Accurately Models Auditory Similarities Between Instrumental Playing Techniques\\u00a7r\\n\\n\\u00a78\\u00a7oVincent Lostanlen\\nChristian El-Hajj\\nMathias Rossignol\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2007.10926\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 10 Nov 2020 17:36:37 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o32 pages, 5 figures. To appear in EURASIP Journal on Audio, Speech, and Music Processing (JASMP)\\u00a7r"}']}
{title:'Huh et al. (§72020§r)', author: 'Jaesung Huh; Hee Soo Heo; Jingu Kang; Shinji Watanabe; Joon Son Chung', display:{Lore:['[{"text": "arXiv:2007.12085", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAugmentation adversarial training for self-supervised speaker recognition\\u00a7r\\n\\n\\u00a78\\u00a7oJaesung Huh\\nHee Soo Heo\\nJingu Kang\\nShinji Watanabe\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2007.12085\\u00a7r\\n\\nVersion:\\u00a77v3 (Fri, 30 Oct 2020 16:12:17 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oWorkshop on Self-Supervised Learning for Speech and Audio Processing, NeurIPS\\u00a7r"}']}
{title:'Zhao et al. (§72020§r)', author: 'Jingqiao Zhao; Zhen-Hua Feng; Qiuqiang Kong; Xiaoning Song; Xiao-Jun Wu', display:{Lore:['[{"text": "arXiv:2007.12864", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDD-CNN: Depthwise Disout Convolutional Neural Network for Low-complexity Acoustic Scene Classification\\u00a7r\\n\\n\\u00a78\\u00a7oJingqiao Zhao\\nZhen-Hua Feng\\nQiuqiang Kong\\nXiaoning Song\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2007.12864\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 25 Jul 2020 06:02:20 GMT)\\u00a7r"}']}
{title:'Kim et al. (§72020§r)', author: 'Hyeongju Kim; Hyeonseung Lee; Woo Hyun Kang; Hyung Yong Kim; Nam Soo Kim', display:{Lore:['[{"text": "arXiv:2007.12903", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lRobust Front-End for Multi-Channel ASR using Flow-Based Density Estimation\\u00a7r\\n\\n\\u00a78\\u00a7oHyeongju Kim\\nHyeonseung Lee\\nWoo Hyun Kang\\nHyung Yong Kim\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2007.12903\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.24963/ijcai.2020/518\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nProceedings of the Twenty-Ninth International Joint Conference on\\n  Artificial Intelligence, {IJCAI} 2020\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 25 Jul 2020 10:35:54 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o7 pages, 3 figures\\u00a7r"}']}
{title:'Masuyama et al. (§72020§r)', author: 'Yoshiki Masuyama; Yoshiaki Bando; Kohei Yatabe; Yoko Sasaki; Masaki Onishi; Yasuhiro Oikawa', display:{Lore:['[{"text": "arXiv:2007.13976", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CV\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSelf-supervised Neural Audio-Visual Sound Source Localization via Probabilistic Spatial Modeling\\u00a7r\\n\\n\\u00a78\\u00a7oYoshiki Masuyama\\nYoshiaki Bando\\nKohei Yatabe\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2007.13976\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 28 Jul 2020 03:52:53 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted for publication in 2020 IEEE/RSJ InternationalConference on Intelligent Robots and Systems (IROS)\\u00a7r"}']}
{title:'Liao et al. (§72020§r)', author: 'Lele Liao; Zhaoyi Gu; Jing Lu', display:{Lore:['[{"text": "arXiv:2008.00143", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lEfficient Independent Vector Extraction of Dominant Target Speech\\u00a7r\\n\\n\\u00a78\\u00a7oLele Liao\\nZhaoyi Gu\\nJing Lu\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.00143\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 1 Aug 2020 01:23:36 GMT)\\u00a7r"}']}
{title:'Haunschmid et al. (§72020§r)', author: 'Verena Haunschmid; Ethan Manilow; Gerhard Widmer', display:{Lore:['[{"text": "arXiv:2008.00582", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.IR\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7laudioLIME: Listenable Explanations Using Source Separation\\u00a7r\\n\\n\\u00a78\\u00a7oVerena Haunschmid\\nEthan Manilow\\nGerhard Widmer\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.00582\\u00a7r\\n\\nVersion:\\u00a77v3 (Mon, 7 Sep 2020 08:55:19 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oIn The 13th International Workshop on Machine Learning and Music, ECML-PKDD 2020\\u00a7r"}']}
{title:'Wu et al. (§72020§r)', author: 'Shih-Lun Wu; Yi-Hsuan Yang', display:{Lore:['[{"text": "arXiv:2008.01307", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.AI\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lThe Jazz Transformer on the Front Line: Exploring the Shortcomings of AI-composed Music through Quantitative Measures\\u00a7r\\n\\n\\u00a78\\u00a7oShih-Lun Wu\\nYi-Hsuan Yang\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.01307\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 4 Aug 2020 03:32:59 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted to the 21st International Society for Music Information Retrieval Conference (ISMIR 2020)\\u00a7r"}']}
{title:'Caillon et al. (§72020§r)', author: 'Antoine Caillon; Adrien Bitton; Brice Gatinet; Philippe Esling', display:{Lore:['[{"text": "arXiv:2008.01370", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lTimbre latent space: exploration and creative aspects\\u00a7r\\n\\n\\u00a78\\u00a7oAntoine Caillon\\nAdrien Bitton\\nBrice Gatinet\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.01370\\u00a7r\\n\\nVersion:\\u00a77v2 (Mon, 17 Aug 2020 13:20:40 GMT)\\u00a7r"}']}
{title:'Chen et al. (§72020§r)', author: 'Yu-Hua Chen; Yu-Hsiang Huang; Wen-Yi Hsiao; Yi-Hsuan Yang', display:{Lore:['[{"text": "arXiv:2008.01431", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAutomatic Composition of Guitar Tabs by Transformers and Groove Modeling\\u00a7r\\n\\n\\u00a78\\u00a7oYu-Hua Chen\\nYu-Hsiang Huang\\nWen-Yi Hsiao\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.01431\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 4 Aug 2020 09:34:33 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted at Proc. Int. Society for Music Information Retrieval Conf. 2020\\u00a7r"}']}
{title:'Dong et al. (§72020§r)', author: 'Hao-Wen Dong; Ke Chen; Julian McAuley; Taylor Berg-Kirkpatrick', display:{Lore:['[{"text": "arXiv:2008.01951", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMusPy: A Toolkit for Symbolic Music Generation\\u00a7r\\n\\n\\u00a78\\u00a7oHao-Wen Dong\\nKe Chen\\nJulian McAuley\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.01951\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 5 Aug 2020 06:16:13 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted by International Society for Music Information Retrieval Conference (ISMIR), 2020\\u00a7r"}']}
{title:'Cancino-Chacón et al. (§72020§r)', author: 'Carlos Cancino-Chacón; Silvan Peter; Shreyan Chowdhury; Anna Aljanaki; Gerhard Widmer', display:{Lore:['[{"text": "arXiv:2008.02194", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.IR\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lOn the Characterization of Expressive Performance in Classical Music: First Results of the Con Espressione Game\\u00a7r\\n\\n\\u00a78\\u00a7oCarlos Cancino-Chac\\u00f3n\\nSilvan Peter\\nShreyan Chowdhury\\nAnna Aljanaki\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.02194\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 5 Aug 2020 15:40:57 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o8 pages, 2 figures, accepted for the 21st International Society for Music Information Retrieval Conference (ISMIR 2020)\\u00a7r"}']}
{title:'Tralie et al. (§72020§r)', author: 'Christopher Tralie; Elizabeth Dempsey', display:{Lore:['[{"text": "arXiv:2008.02734", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.IR\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.MM\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lExact, Parallelizable Dynamic Time Warping Alignment with Linear Memory\\u00a7r\\n\\n\\u00a78\\u00a7oChristopher Tralie\\nElizabeth Dempsey\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.02734\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 4 Aug 2020 15:00:33 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o12 Pages, 6 Figures, 1 Table, ISMIR 2020\\u00a7r"}']}
{title:'Wang et al. (§72020§r)', author: 'Yu Wang; Justin Salamon; Mark Cartwright; Nicholas J. Bryan; Juan Pablo Bello', display:{Lore:['[{"text": "arXiv:2008.02791", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lFew-Shot Drum Transcription in Polyphonic Music\\u00a7r\\n\\n\\u00a78\\u00a7oYu Wang\\nJustin Salamon\\nMark Cartwright\\nNicholas J. Bryan\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.02791\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 6 Aug 2020 17:58:14 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oISMIR 2020 camera-ready\\u00a7r"}']}
{title:'Xie et al. (§72020§r)', author: 'Yifan Xie; Rongfeng Li', display:{Lore:['[{"text": "arXiv:2008.03436", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSymbolic Music Playing Techniques Generation as a Tagging Problem\\u00a7r\\n\\n\\u00a78\\u00a7oYifan Xie\\nRongfeng Li\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.03436\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 13 Oct 2020 07:35:05 GMT)\\u00a7r"}']}
{title:'Akbar et al. (§72020§r)', author: 'Noman Akbar; Glenn Dickins; Mark R. P. Thomas; Prasanga Samarasinghe; Thushara Abhayapala', display:{Lore:['[{"text": "arXiv:2008.03513", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.IT\\u00a7r, \\u00a7eeess.AS\\u00a7r, \\u00a72math.IT\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Novel Method for Obtaining Diffuse Field Measurements for Microphone Calibration\\u00a7r\\n\\n\\u00a78\\u00a7oNoman Akbar\\nGlenn Dickins\\nMark R. P. Thomas\\nPrasanga Samarasinghe\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.03513\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/ICASSP40776.2020.9054728\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nIEEE International Conference on Acoustics, Speech and Signal\\n  Processing (ICASSP), 2020\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 8 Aug 2020 12:48:47 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted to appear in IEEE ICASSP 2020\\u00a7r"}']}
{title:'Lee et al. (§72020§r)', author: 'Jongpil Lee; Nicholas J. Bryan; Justin Salamon; Zeyu Jin; Juhan Nam', display:{Lore:['[{"text": "arXiv:2008.03729", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.IR\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMetric Learning vs Classification for Disentangled Music Representation Learning\\u00a7r\\n\\n\\u00a78\\u00a7oJongpil Lee\\nNicholas J. Bryan\\nJustin Salamon\\nZeyu Jin\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.03729\\u00a7r\\n\\nVersion:\\u00a77v2 (Wed, 12 Aug 2020 21:46:52 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted for publication at the 21st International Society for Music Information Retrieval Conference (ISMIR 2020)\\u00a7r"}']}
{title:'Comunità et al. (§72020§r)', author: 'Marco Comunità; Andrea Gerino; Veranika Lim; Lorenzo Picinali', display:{Lore:['[{"text": "arXiv:2008.04638", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.HC\\u00a7r, \\u00a7acs.MM\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lPlugSonic: a web- and mobile-based platform for binaural audio and sonic narratives\\u00a7r\\n\\n\\u00a78\\u00a7oMarco Comunit\\u00e0\\nAndrea Gerino\\nVeranika Lim\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.04638\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 11 Aug 2020 11:42:49 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o22 pages, 11 figures\\u00a7r"}']}
{title:'Paul et al. (§72020§r)', author: 'Dipjyoti Paul; Muhammed PV Shifas; Yannis Pantazis; Yannis Stylianou', display:{Lore:['[{"text": "arXiv:2008.05809", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lEnhancing Speech Intelligibility in Text-To-Speech Synthesis using Speaking Style Conversion\\u00a7r\\n\\n\\u00a78\\u00a7oDipjyoti Paul\\nMuhammed PV Shifas\\nYannis Pantazis\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.05809\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 13 Aug 2020 10:51:56 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted in INTERSPEECH 2020\\u00a7r"}']}
{title:'Ens et al. (§72020§r)', author: 'Jeff Ens; Philippe Pasquier', display:{Lore:['[{"text": "arXiv:2008.06048", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.MM\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMMM : Exploring Conditional Multi-Track Music Generation with the Transformer\\u00a7r\\n\\n\\u00a78\\u00a7oJeff Ens\\nPhilippe Pasquier\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.06048\\u00a7r\\n\\nVersion:\\u00a77v2 (Thu, 20 Aug 2020 19:13:39 GMT)\\u00a7r"}']}
{title:'Ferreira et al. (§72020§r)', author: 'Lucas N. Ferreira; Levi H. S. Lelis; Jim Whitehead', display:{Lore:['[{"text": "arXiv:2008.07009", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lComputer-Generated Music for Tabletop Role-Playing Games\\u00a7r\\n\\n\\u00a78\\u00a7oLucas N. Ferreira\\nLevi H. S. Lelis\\nJim Whitehead\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.07009\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 16 Aug 2020 21:53:49 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oTo be published in the 16th AAAI Conference ON Artificial Intelligence and Interactive Digital Entertainment\\u00a7r"}']}
{title:'Wang et al. (§72020§r)', author: 'Ziyu Wang; Dingsu Wang; Yixiao Zhang; Gus Xia', display:{Lore:['[{"text": "arXiv:2008.07122", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lLearning Interpretable Representation for Controllable Polyphonic Music Generation\\u00a7r\\n\\n\\u00a78\\u00a7oZiyu Wang\\nDingsu Wang\\nYixiao Zhang\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.07122\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nIn Proceedings of 21st International Conference on Music\\n  Information Retrieval (ISMIR), Montreal, Canada, 2020\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 17 Aug 2020 07:11:16 GMT)\\u00a7r"}']}
{title:'Wang et al. (§72020§r)', author: 'Ziyu Wang; Ke Chen; Junyan Jiang; Yiyi Zhang; Maoran Xu; Shuqi Dai; Xianbin Gu; Gus Xia', display:{Lore:['[{"text": "arXiv:2008.07142", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.IR\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lPOP909: A Pop-song Dataset for Music Arrangement Generation\\u00a7r\\n\\n\\u00a78\\u00a7oZiyu Wang\\nKe Chen\\nJunyan Jiang\\n+ 4 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.07142\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nIn Proceedings of 21st International Conference on Music\\n  Information Retrieval (ISMIR), Montreal, Canada (virtual conference), 2020\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 17 Aug 2020 08:08:14 GMT)\\u00a7r"}']}
{title:'Ren et al. (§72020§r)', author: 'Yi Ren; Jinzheng He; Xu Tan; Tao Qin; Zhou Zhao; Tie-Yan Liu', display:{Lore:['[{"text": "arXiv:2008.07703", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.IR\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lPopMAG: Pop Music Accompaniment Generation\\u00a7r\\n\\n\\u00a78\\u00a7oYi Ren\\nJinzheng He\\nXu Tan\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.07703\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 18 Aug 2020 02:28:36 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted by ACM-MM 2020\\u00a7r"}']}
{title:'Fernandes et al. (§72020§r)', author: 'Marcelo Schreiber Fernandes; Weverton Cordeiro; Mariana Recamonde-Mendoza', display:{Lore:['[{"text": "arXiv:2008.09024", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDetecting Aedes Aegypti Mosquitoes through Audio Classification with Convolutional Neural Networks\\u00a7r\\n\\n\\u00a78\\u00a7oMarcelo Schreiber Fernandes\\nWeverton Cordeiro\\nMariana Recamonde-Mendoza\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.09024\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1016/j.compbiomed.2020.104152\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 19 Aug 2020 00:26:21 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oPublished in Computers in Biology and Medicine\\u00a7r"}']}
{title:'Verma et al. (§72020§r)', author: 'Prateek Verma; Constantin Basica; Pamela Davis Kivelson', display:{Lore:['[{"text": "arXiv:2008.09960", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lTranslating Paintings Into Music Using Neural Networks\\u00a7r\\n\\n\\u00a78\\u00a7oPrateek Verma\\nConstantin Basica\\nPamela Davis Kivelson\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.09960\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 23 Aug 2020 05:08:39 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o8 pages, 3 figures\\u00a7r"}']}
{title:'Arnault et al. (§72020§r)', author: 'Augustin Arnault; Nicolas Riche', display:{Lore:['[{"text": "arXiv:2008.10413", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lCRNNs for Urban Sound Tagging with spatiotemporal context\\u00a7r\\n\\n\\u00a78\\u00a7oAugustin Arnault\\nNicolas Riche\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.10413\\u00a7r\\n\\nVersion:\\u00a77v2 (Wed, 30 Sep 2020 14:53:06 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o4 pages, 5 figures, DCASE2020 Challenge - DCASE\\u00a7r"}']}
{title:'Faber et al. (§72020§r)', author: 'Lukas Faber; Sandro Luck; Damian Pascual; Andreas Roth; Gino Brunner; Roger Wattenhofer', display:{Lore:['[{"text": "arXiv:2008.11159", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMedley2K: A Dataset of Medley Transitions\\u00a7r\\n\\n\\u00a78\\u00a7oLukas Faber\\nSandro Luck\\nDamian Pascual\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.11159\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 25 Aug 2020 16:46:56 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oMML 2020 - 13th Int. Workshop on Machine Learning and Music at ECML-PKDD 2020\\u00a7r"}']}
{title:'Liuni et al. (§72020§r)', author: 'Marco Liuni; Luc Ardaillon; Louise Bonal; Lou Seropian; Jean-Julien Aucouturier', display:{Lore:['[{"text": "arXiv:2008.11241", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7bq-bio.NC\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lANGUS: Real-time manipulation of vocal roughness for emotional speech transformations\\u00a7r\\n\\n\\u00a78\\u00a7oMarco Liuni\\nLuc Ardaillon\\nLouise Bonal\\nLou Seropian\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.11241\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 25 Aug 2020 19:06:03 GMT)\\u00a7r"}']}
{title:'Haunschmid et al. (§72020§r)', author: 'Verena Haunschmid; Ethan Manilow; Gerhard Widmer', display:{Lore:['[{"text": "arXiv:2009.02051", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.IR\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lTowards Musically Meaningful Explanations Using Source Separation\\u00a7r\\n\\n\\u00a78\\u00a7oVerena Haunschmid\\nEthan Manilow\\nGerhard Widmer\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2009.02051\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 4 Sep 2020 08:09:03 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o6+2 pages, 4 figures; Submitted to International Society for Music Information Retrieval Conference 2020\\u00a7r"}']}
{title:'Tarjano et al. (§72020§r)', author: 'Carlos Tarjano; Valdecy Pereira', display:{Lore:['[{"text": "arXiv:2009.02860", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r, \\u00a7eeess.SP\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDigital Envelope Estimation Via Geometric Properties of an Arbitrary Real Signal\\u00a7r\\n\\n\\u00a78\\u00a7oCarlos Tarjano\\nValdecy Pereira\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2009.02860\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1016/j.dsp.2021.103229\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nDigital Signal Processing, 2022\\u00a7r\\n\\nVersion:\\u00a77v2 (Sun, 6 Dec 2020 22:21:20 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oMore info here: https://envelope.netlify.app/\\u00a7r"}']}
{title:'Nahar et al. (§72020§r)', author: 'Fajilatun Nahar; Kat Agres; Balamurali BT; Dorien Herremans', display:{Lore:['[{"text": "arXiv:2009.04459", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA dataset and classification model for Malay, Hindi, Tamil and Chinese music\\u00a7r\\n\\n\\u00a78\\u00a7oFajilatun Nahar\\nKat Agres\\nBalamurali BT\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2009.04459\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 15 Sep 2020 05:29:59 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o4 pages\\u00a7r"}']}
{title:'Cartwright et al. (§72020§r)', author: 'Mark Cartwright; Jason Cramer; Ana Elisa Mendez Mendez; Yu Wang; Ho-Hsiang Wu; Vincent Lostanlen; Magdalena Fuentes; Graham Dove; Charlie Mydlarz; Justin Salamon; Oded Nov; Juan Pablo Bello', display:{Lore:['[{"text": "arXiv:2009.05188", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSONYC-UST-V2: An Urban Sound Tagging Dataset with Spatiotemporal Context\\u00a7r\\n\\n\\u00a78\\u00a7oMark Cartwright\\nJason Cramer\\nAna Elisa Mendez Mendez\\n+ 8 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2009.05188\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 11 Sep 2020 01:19:12 GMT)\\u00a7r"}']}
{title:'Prasad et al. (§72020§r)', author: 'RaviShankar Prasad; B. Yegnanarayana', display:{Lore:['[{"text": "arXiv:2009.06416", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA study of vowel nasalization using instantaneous spectra\\u00a7r\\n\\n\\u00a78\\u00a7oRaviShankar Prasad\\nB. Yegnanarayana\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2009.06416\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 14 Sep 2020 13:04:41 GMT)\\u00a7r"}']}
{title:'Bagad et al. (§72020§r)', author: 'Piyush Bagad; Aman Dalmia; Jigar Doshi; Arsha Nagrani; Parag Bhamare; Amrita Mahale; Saurabh Rane; Neeraj Agarwal; Rahul Panicker', display:{Lore:['[{"text": "arXiv:2009.08790", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lCough Against COVID: Evidence of COVID-19 Signature in Cough Sounds\\u00a7r\\n\\n\\u00a78\\u00a7oPiyush Bagad\\nAman Dalmia\\nJigar Doshi\\n+ 5 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2009.08790\\u00a7r\\n\\nVersion:\\u00a77v2 (Wed, 23 Sep 2020 06:31:00 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oUnder submission to AAAI 20\\u00a7r"}']}
{title:'Chattopadhyay et al. (§72020§r)', author: 'Soham Chattopadhyay; Arijit Dey; Hritam Basak', display:{Lore:['[{"text": "arXiv:2009.08909", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lOptimizing Speech Emotion Recognition using Manta-Ray Based Feature Selection\\u00a7r\\n\\n\\u00a78\\u00a7oSoham Chattopadhyay\\nArijit Dey\\nHritam Basak\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2009.08909\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 18 Sep 2020 16:09:34 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o10 pages, 8 figures\\u00a7r"}']}
{title:'Chen et al. (§72020§r)', author: 'Hang Chen; Jun Du; Yu Hu; Li-Rong Dai; Bao-Cai Yin; Chin-Hui Lee', display:{Lore:['[{"text": "arXiv:2009.09561", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lCorrelating Subword Articulation with Lip Shapes for Embedding Aware Audio-Visual Speech Enhancement\\u00a7r\\n\\n\\u00a78\\u00a7oHang Chen\\nJun Du\\nYu Hu\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2009.09561\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 21 Sep 2020 01:26:19 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o34 pages, 8 figures\\u00a7r"}']}
{title:'Orlandic et al. (§72020§r)', author: 'Lara Orlandic; Tomas Teijeiro; David Atienza', display:{Lore:['[{"text": "arXiv:2009.11644", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lThe COUGHVID crowdsourcing dataset: A corpus for the study of large-scale cough analysis algorithms\\u00a7r\\n\\n\\u00a78\\u00a7oLara Orlandic\\nTomas Teijeiro\\nDavid Atienza\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2009.11644\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1038/s41597-021-00937-4\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 24 Sep 2020 12:58:41 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o11 pages, 3 figures\\u00a7r"}']}
{title:'Vahidi et al. (§72020§r)', author: 'Cyrus Vahidi; George Fazekas; Charalampos Saitis; Alessandro Palladini', display:{Lore:['[{"text": "arXiv:2009.11706", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lTimbre Space Representation of a Subtractive Synthesizer\\u00a7r\\n\\n\\u00a78\\u00a7oCyrus Vahidi\\nGeorge Fazekas\\nCharalampos Saitis\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2009.11706\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 24 Sep 2020 14:04:51 GMT)\\u00a7r"}']}
{title:'Manilow et al. (§72020§r)', author: 'Ethan Manilow; Bryan Pardo', display:{Lore:['[{"text": "arXiv:2009.13729", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lBespoke Neural Networks for Score-Informed Source Separation\\u00a7r\\n\\n\\u00a78\\u00a7oEthan Manilow\\nBryan Pardo\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2009.13729\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 29 Sep 2020 02:09:23 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oISMIR 2020 - Late Breaking Demo\\u00a7r"}']}
{title:'Zhou et al. (§72020§r)', author: 'Xinquan Zhou; Yanhong Leng', display:{Lore:['[{"text": "arXiv:2009.13931", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.AI\\u00a7r, \\u00a7acs.MM\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lResidual acoustic echo suppression based on efficient multi-task convolutional neural network\\u00a7r\\n\\n\\u00a78\\u00a7oXinquan Zhou\\nYanhong Leng\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2009.13931\\u00a7r\\n\\nVersion:\\u00a77v2 (Fri, 6 Nov 2020 03:33:36 GMT)\\u00a7r"}']}
{title:'Thickstun et al. (§72020§r)', author: 'John Thickstun; Jennifer Brennan; Harsh Verma', display:{Lore:['[{"text": "arXiv:2009.14374", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lRethinking Evaluation Methodology for Audio-to-Score Alignment\\u00a7r\\n\\n\\u00a78\\u00a7oJohn Thickstun\\nJennifer Brennan\\nHarsh Verma\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2009.14374\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 30 Sep 2020 01:22:37 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o10 pages, 6 figures\\u00a7r"}']}
{title:'McLeod et al. (§72020§r)', author: 'Andrew McLeod; James Owers; Kazuyoshi Yoshii', display:{Lore:['[{"text": "arXiv:2010.00059", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lThe MIDI Degradation Toolkit: Symbolic Music Augmentation and Correction\\u00a7r\\n\\n\\u00a78\\u00a7oAndrew McLeod\\nJames Owers\\nKazuyoshi Yoshii\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.00059\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 30 Sep 2020 19:03:35 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAuthors 1 and 2 contributed equally to this work. Accepted by International Society for Music Information Retrieval Conference (ISMIR), 2020\\u00a7r"}']}
{title:'Kim et al. (§72020§r)', author: 'Sunghyeon Kim; Hyeyoon Lee; Sunjong Park; Jinho Lee; Keunwoo Choi', display:{Lore:['[{"text": "arXiv:2010.00823", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDeep Composer Classification Using Symbolic Representation\\u00a7r\\n\\n\\u00a78\\u00a7oSunghyeon Kim\\nHyeyoon Lee\\nSunjong Park\\nJinho Lee\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.00823\\u00a7r\\n\\nVersion:\\u00a77v2 (Mon, 26 Oct 2020 14:03:26 GMT)\\u00a7r"}']}
{title:'Goudeseune et al. (§72020§r)', author: 'Camille Goudeseune; Guy Garnett; Timothy Johnson', display:{Lore:['[{"text": "arXiv:2010.01572", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.HC\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lResonant Processing of Instrumental Sound Controlled by Spatial Position\\u00a7r\\n\\n\\u00a78\\u00a7oCamille Goudeseune\\nGuy Garnett\\nTimothy Johnson\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.01572\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.5281/zenodo.1176362\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 4 Oct 2020 12:56:41 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oProceedings of the International Conference on New Interfaces for Musical Expression, 2001\\u00a7r"}']}
{title:'Parikh et al. (§72020§r)', author: 'Dishant Parikh; Saurabh Sachdev', display:{Lore:['[{"text": "arXiv:2010.03136", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lImproving the efficiency of spectral features extraction by structuring the audio files\\u00a7r\\n\\n\\u00a78\\u00a7oDishant Parikh\\nSaurabh Sachdev\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.03136\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/HYDCON48903.2020.9242729\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 7 Oct 2020 03:35:39 GMT)\\u00a7r"}']}
{title:'Zhou et al. (§72020§r)', author: 'Yijun Zhou; Yuki Koyama; Masataka Goto; Takeo Igarashi', display:{Lore:['[{"text": "arXiv:2010.03190", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.HC\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lGenerative Melody Composition with Human-in-the-Loop Bayesian Optimization\\u00a7r\\n\\n\\u00a78\\u00a7oYijun Zhou\\nYuki Koyama\\nMasataka Goto\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.03190\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 7 Oct 2020 05:54:20 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o10 pages, 2 figures, Proceedings of the 2020 Joint Conference on AI Music Creativity (CSMC-MuMe 2020)\\u00a7r"}']}
{title:'Tripathi et al. (§72020§r)', author: 'Anshuman Tripathi; Jaeyoung Kim; Qian Zhang; Han Lu; Hasim Sak', display:{Lore:['[{"text": "arXiv:2010.03192", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lTransformer Transducer: One Model Unifying Streaming and Non-streaming Speech Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oAnshuman Tripathi\\nJaeyoung Kim\\nQian Zhang\\nHan Lu\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.03192\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 7 Oct 2020 05:58:28 GMT)\\u00a7r"}']}
{title:'Yesiler et al. (§72020§r)', author: 'Furkan Yesiler; Joan Serrà; Emilia Gómez', display:{Lore:['[{"text": "arXiv:2010.03284", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lLess is more: Faster and better music version identification with embedding distillation\\u00a7r\\n\\n\\u00a78\\u00a7oFurkan Yesiler\\nJoan Serr\\u00e0\\nEmilia G\\u00f3mez\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.03284\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 7 Oct 2020 09:02:12 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted to the 21st International Society for Music Information Retrieval Conference (ISMIR 2020)\\u00a7r"}']}
{title:'Woszczyk et al. (§72020§r)', author: 'Dominika Woszczyk; Stavros Petridis; David Millard', display:{Lore:['[{"text": "arXiv:2010.03623", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDomain Adversarial Neural Networks for Dysarthric Speech Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oDominika Woszczyk\\nStavros Petridis\\nDavid Millard\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.03623\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 7 Oct 2020 19:51:41 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, to be published in Interspeech 2020\\u00a7r"}']}
{title:'Ishizuka et al. (§72020§r)', author: 'Ryoto Ishizuka; Ryo Nishikimi; Eita Nakamura; Kazuyoshi Yoshii', display:{Lore:['[{"text": "arXiv:2010.03749", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lTatum-Level Drum Transcription Based on a Convolutional Recurrent Neural Network with Language Model-Based Regularized Training\\u00a7r\\n\\n\\u00a78\\u00a7oRyoto Ishizuka\\nRyo Nishikimi\\nEita Nakamura\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.03749\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 8 Oct 2020 03:47:25 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted to APSIPA 2020\\u00a7r"}']}
{title:'Erdem et al. (§72020§r)', author: 'Cagri Erdem; Katja Henriksen Schia; Alexander Refsum Jensenius', display:{Lore:['[{"text": "arXiv:2010.03779", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.HC\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lVrengt: A Shared Body-Machine Instrument for Music-Dance Performance\\u00a7r\\n\\n\\u00a78\\u00a7oCagri Erdem\\nKatja Henriksen Schia\\nAlexander Refsum Jensenius\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.03779\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.5281/zenodo.3672917\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nProceedings of the International Conference on New Interfaces for\\n  Musical Expression, 2019\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 8 Oct 2020 05:50:44 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oProceedings of the International Conference on New Interfaces for Musical Expression, 2019\\u00a7r"}']}
{title:'Gonzalez-Soler et al. (§72020§r)', author: 'Lazaro J. Gonzalez-Soler; Jose Patino; Marta Gomez-Barrero; Massimiliano Todisco; Christoph Busch; Nicholas Evans', display:{Lore:['[{"text": "arXiv:2010.04038", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CV\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lTexture-based Presentation Attack Detection for Automatic Speaker Verification\\u00a7r\\n\\n\\u00a78\\u00a7oLazaro J. Gonzalez-Soler\\nJose Patino\\nMarta Gomez-Barrero\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.04038\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 8 Oct 2020 15:03:29 GMT)\\u00a7r"}']}
{title:'Tobing et al. (§72020§r)', author: 'Patrick Lumban Tobing; Yi-Chiao Wu; Tomoki Toda', display:{Lore:['[{"text": "arXiv:2010.04429", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lBaseline System of Voice Conversion Challenge 2020 with Cyclic Variational Autoencoder and Parallel WaveGAN\\u00a7r\\n\\n\\u00a78\\u00a7oPatrick Lumban Tobing\\nYi-Chiao Wu\\nTomoki Toda\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.04429\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 9 Oct 2020 08:25:38 GMT)\\u00a7r"}']}
{title:'Guezenoc et al. (§72020§r)', author: 'Corentin Guezenoc; Renaud Seguier', display:{Lore:['[{"text": "arXiv:2010.04546", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDataset Augmentation and Dimensionality Reduction of Pinna-Related Transfer Functions\\u00a7r\\n\\n\\u00a78\\u00a7oCorentin Guezenoc\\nRenaud Seguier\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.04546\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.17743/aesconv.2020.978-1-942220-32-9\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 8 Oct 2020 07:50:15 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAudio Engineering Society Convention, May 2020, Vienna, Austria\\u00a7r"}']}
{title:'Tang et al. (§72020§r)', author: 'Zhenyu Tang; Hsien-Yu Meng; Dinesh Manocha', display:{Lore:['[{"text": "arXiv:2010.04865", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.GR\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lLearning Acoustic Scattering Fields for Dynamic Interactive Sound Propagation\\u00a7r\\n\\n\\u00a78\\u00a7oZhenyu Tang\\nHsien-Yu Meng\\nDinesh Manocha\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.04865\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/VR50410.2021.00111\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7n2021 IEEE Virtual Reality and 3D User Interfaces (VR) (pp.\\n  835-844)\\u00a7r\\n\\nVersion:\\u00a77v2 (Mon, 7 Dec 2020 20:44:44 GMT)\\u00a7r"}']}
{title:'Sun et al. (§72020§r)', author: 'Xingwei Sun; Ze-Feng Gao; Zhong-Yi Lu; Junfeng Li; Yonghong Yan', display:{Lore:['[{"text": "arXiv:2010.04950", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r, \\u00a75quant-ph\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Model Compression Method with Matrix Product Operators for Speech Enhancement\\u00a7r\\n\\n\\u00a78\\u00a7oXingwei Sun\\nZe-Feng Gao\\nZhong-Yi Lu\\nJunfeng Li\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.04950\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/TASLP.2020.3030495\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nIEEE Transactions on Audio, Speech and Language\\n  Processing.2020.3030495(2020)\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 10 Oct 2020 08:53:25 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o11 pages, 6 figures, 7 tables\\u00a7r"}']}
{title:'Huang et al. (§72020§r)', author: 'Cheng-Zhi Anna Huang; Hendrik Vincent Koops; Ed Newton-Rex; Monica Dinculescu; Carrie J. Cai', display:{Lore:['[{"text": "arXiv:2010.05388", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.HC\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAI Song Contest: Human-AI Co-Creation in Songwriting\\u00a7r\\n\\n\\u00a78\\u00a7oCheng-Zhi Anna Huang\\nHendrik Vincent Koops\\nEd Newton-Rex\\nMonica Dinculescu\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.05388\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nISMIR 2020\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 12 Oct 2020 01:27:41 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o6 pages + 3 pages of references\\u00a7r"}']}
{title:'Ohi et al. (§72020§r)', author: 'Abu Quwsar Ohi; M. F. Mridha; Md. Abdul Hamid; Muhammad Mostafa Monowar; Dongsu Lee; Jinsul Kim', display:{Lore:['[{"text": "arXiv:2010.05502", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.AI\\u00a7r, \\u00a7acs.LG\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Lightweight Speaker Recognition System Using Timbre Properties\\u00a7r\\n\\n\\u00a78\\u00a7oAbu Quwsar Ohi\\nM. F. Mridha\\nMd. Abdul Hamid\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.05502\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.9728/jcc.2020.06.2.1.139\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nThe Journal of Contents Computing 2, no. 1 (2020): 139-151\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 13 Oct 2020 05:58:43 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted in Journal of Contents Computing\\u00a7r"}']}
{title:'Kong et al. (§72020§r)', author: 'Jungil Kong; Jaehyeon Kim; Jaekyoung Bae', display:{Lore:['[{"text": "arXiv:2010.05646", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lHiFi-GAN: Generative Adversarial Networks for Efficient and High Fidelity Speech Synthesis\\u00a7r\\n\\n\\u00a78\\u00a7oJungil Kong\\nJaehyeon Kim\\nJaekyoung Bae\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.05646\\u00a7r\\n\\nVersion:\\u00a77v2 (Fri, 23 Oct 2020 09:12:04 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oNeurIPS 2020. Code available at https://github.com/jik876/hifi-gan\\u00a7r"}']}
{title:'Esmaeilpour et al. (§72020§r)', author: 'Mohammad Esmaeilpour; Raymel Alfonso Sallo; Olivier St-Georges; Patrick Cardinal; Alessandro Lameiras Koerich', display:{Lore:['[{"text": "arXiv:2010.05844", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lConditioning Trick for Training Stable GANs\\u00a7r\\n\\n\\u00a78\\u00a7oMohammad Esmaeilpour\\nRaymel Alfonso Sallo\\nOlivier St-Georges\\nPatrick Cardinal\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.05844\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 12 Oct 2020 16:50:22 GMT)\\u00a7r"}']}
{title:'Jenrungrot et al. (§72020§r)', author: 'Teerapat Jenrungrot; Vivek Jayaram; Steve Seitz; Ira Kemelmacher-Shlizerman', display:{Lore:['[{"text": "arXiv:2010.06007", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.AI\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lThe Cone of Silence: Speech Separation by Localization\\u00a7r\\n\\n\\u00a78\\u00a7oTeerapat Jenrungrot\\nVivek Jayaram\\nSteve Seitz\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.06007\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 12 Oct 2020 20:19:23 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o9 pages + references + supplementary. Oral presentation at NeurIPS 2020\\u00a7r"}']}
{title:'Kumar et al. (§72020§r)', author: 'Puneet Kumar; Sidharth Jain; Balasubramanian Raman; Partha Pratim Roy; Masakazu Iwamura', display:{Lore:['[{"text": "arXiv:2010.06200", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lEnd-to-end Triplet Loss based Emotion Embedding System for Speech Emotion Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oPuneet Kumar\\nSidharth Jain\\nBalasubramanian Raman\\nPartha Pratim Roy\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.06200\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 13 Oct 2020 06:56:41 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted in ICPR 2020\\u00a7r"}']}
{title:'Guo et al. (§72020§r)', author: 'Rui Guo; Ivor Simpson; Thor Magnusson; Chris Kiefer; Dorien Herremans', display:{Lore:['[{"text": "arXiv:2010.06230", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.SC\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA variational autoencoder for music generation controlled by tonal tension\\u00a7r\\n\\n\\u00a78\\u00a7oRui Guo\\nIvor Simpson\\nThor Magnusson\\nChris Kiefer\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.06230\\u00a7r\\n\\nVersion:\\u00a77v2 (Wed, 14 Oct 2020 08:24:25 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o2020 Joint Conference on AI Music Creativity\\u00a7r"}']}
{title:'Cook (§72020§r)', author: 'Perry R. Cook', display:{Lore:['[{"text": "arXiv:2010.06524", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.HC\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lPrinciples for Designing Computer Music Controllers\\u00a7r\\n\\n\\u00a78\\u00a7oPerry R. Cook\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.06524\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.5281/zenodo.1176358\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 6 Oct 2020 17:10:13 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oProceedings of the International Conference on New Interfaces for Musical Expression, 2001\\u00a7r"}']}
{title:'Dörr et al. (§72020§r)', author: 'Tom Dörr; Karla Markert; Nicolas M. Müller; Konstantin Böttinger', display:{Lore:['[{"text": "arXiv:2010.07190", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CR\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lTowards Resistant Audio Adversarial Examples\\u00a7r\\n\\n\\u00a78\\u00a7oTom D\\u00f6rr\\nKarla Markert\\nNicolas M. M\\u00fcller\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.07190\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1145/3385003.3410921\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nSPAI 20: Proceedings of the 1st ACM Workshop on Security and\\n  Privacy on Artificial IntelligenceOctober 2020 Pages 3-10\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 14 Oct 2020 16:04:02 GMT)\\u00a7r"}']}
{title:'Moulin-Frier et al. (§72020§r)', author: 'Clément Moulin-Frier; Jules Brochard; Freek Stulp; Pierre-Yves Oudeyer', display:{Lore:['[{"text": "arXiv:2010.07208", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r, \\u00a7bq-bio.NC\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lEmergent Jaw Predominance in Vocal Development through Stochastic Optimization\\u00a7r\\n\\n\\u00a78\\u00a7oCl\\u00e9ment Moulin-Frier\\nJules Brochard\\nFreek Stulp\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.07208\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/TCDS.2017.2704912\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nIEEE Transactions on Cognitive and Developmental Systems (Volume:\\n  12 , Issue: 3 , Sept. 2020)\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 8 Oct 2020 15:25:06 GMT)\\u00a7r"}']}
{title:'Dai et al. (§72020§r)', author: 'Shuqi Dai; Huan Zhang; Roger B. Dannenberg', display:{Lore:['[{"text": "arXiv:2010.07518", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAutomatic Analysis and Influence of Hierarchical Structure on Melody, Rhythm and Harmony in Popular Music\\u00a7r\\n\\n\\u00a78\\u00a7oShuqi Dai\\nHuan Zhang\\nRoger B. Dannenberg\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.07518\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 15 Oct 2020 04:52:02 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oIn Proceedings of the 2020 Joint Conference on AI Music Creativity (CSMC-MuMe 2020), Stockholm, Sweden, October 21-24, 2020\\u00a7r"}']}
{title:'Guo et al. (§72020§r)', author: 'Jinyue Guo; Aozhi Liu; Jing Xiao', display:{Lore:['[{"text": "arXiv:2010.07562", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.IR\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMelody Classification based on Performance Event Vector and BRNN\\u00a7r\\n\\n\\u00a78\\u00a7oJinyue Guo\\nAozhi Liu\\nJing Xiao\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.07562\\u00a7r\\n\\nVersion:\\u00a77v2 (Fri, 16 Oct 2020 03:50:27 GMT)\\u00a7r"}']}
{title:'Zhang (§72020§r)', author: 'Haitong Zhang', display:{Lore:['[{"text": "arXiv:2010.07630", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lThe NeteaseGames System for Voice Conversion Challenge 2020 with Vector-quantization Variational Autoencoder and WaveNet\\u00a7r\\n\\n\\u00a78\\u00a7oHaitong Zhang\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.07630\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 15 Oct 2020 09:53:56 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted to the ISCA Joint Workshop for the Blizzard Challenge and Voice Conversion Challenge 2020\\u00a7r"}']}
{title:'Xia et al. (§72020§r)', author: 'Yiting Xia; Yiwei Jiang; Tao Ye', display:{Lore:['[{"text": "arXiv:2010.07739", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.MM\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMusic Classification in MIDI Format based on LSTM Mdel\\u00a7r\\n\\n\\u00a78\\u00a7oYiting Xia\\nYiwei Jiang\\nTao Ye\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.07739\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 15 Oct 2020 13:30:40 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oin Chinese\\u00a7r"}']}
{title:'Chung et al. (§72020§r)', author: 'Hanwook Chung; Vikrant Singh Tomar; Benoit Champagne', display:{Lore:['[{"text": "arXiv:2010.07895", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDeep Convolutional Neural Network-based Inverse Filtering Approach for Speech De-reverberation\\u00a7r\\n\\n\\u00a78\\u00a7oHanwook Chung\\nVikrant Singh Tomar\\nBenoit Champagne\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.07895\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 15 Oct 2020 17:19:57 GMT)\\u00a7r"}']}
{title:'Liang et al. (§72020§r)', author: 'Hongru Liang; Wenqiang Lei; Paul Yaozhu Chan; Zhenglu Yang; Maosong Sun; Tat-Seng Chua', display:{Lore:['[{"text": "arXiv:2010.08091", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.MM\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lPiRhDy: Learning Pitch-, Rhythm-, and Dynamics-aware Embeddings for Symbolic Music\\u00a7r\\n\\n\\u00a78\\u00a7oHongru Liang\\nWenqiang Lei\\nPaul Yaozhu Chan\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.08091\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1145/3394171.3414032\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 16 Oct 2020 01:25:48 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oACM Multimedia 2020 \\u2013 best paper\\u00a7r"}']}
{title:'Li et al. (§72020§r)', author: 'You Li; Zhuowen Lin', display:{Lore:['[{"text": "arXiv:2010.08123", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.MM\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMelody Classifier with Stacked-LSTM\\u00a7r\\n\\n\\u00a78\\u00a7oYou Li\\nZhuowen Lin\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.08123\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 24 Nov 2020 20:37:52 GMT)\\u00a7r"}']}
{title:'Zhao et al. (§72020§r)', author: 'Shengkui Zhao; Trung Hieu Nguyen; Hao Wang; Bin Ma', display:{Lore:['[{"text": "arXiv:2010.08136", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lTowards Natural Bilingual and Code-Switched Speech Synthesis Based on Mix of Monolingual Recordings and Cross-Lingual Voice Conversion\\u00a7r\\n\\n\\u00a78\\u00a7oShengkui Zhao\\nTrung Hieu Nguyen\\nHao Wang\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.08136\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 16 Oct 2020 03:51:00 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 2 figures, INTERSPEECH 2020\\u00a7r"}']}
{title:'Greco et al. (§72020§r)', author: 'Danilo Greco; Jacopo Cavazza; Alessio Del Bue', display:{Lore:['[{"text": "arXiv:2010.08428", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAre Multiple Cross-Correlation Identities better than just Two? Improving the Estimate of Time Differences-of-Arrivals from Blind Audio Signals\\u00a7r\\n\\n\\u00a78\\u00a7oDanilo Greco\\nJacopo Cavazza\\nAlessio Del Bue\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.08428\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 16 Oct 2020 14:47:26 GMT)\\u00a7r"}']}
{title:'Keyes et al. (§72020§r)', author: 'Andrew Keyes; Nicky Bayat; Vahid Reza Khazaie; Yalda Mohsenzadeh', display:{Lore:['[{"text": "arXiv:2010.08534", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.AI\\u00a7r, \\u00a7acs.CV\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lLatent Vector Recovery of Audio GANs\\u00a7r\\n\\n\\u00a78\\u00a7oAndrew Keyes\\nNicky Bayat\\nVahid Reza Khazaie\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.08534\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 16 Oct 2020 17:45:35 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o7 pages, 5 figures\\u00a7r"}']}
{title:'Bader et al. (§72020§r)', author: 'Mohamed Bader; Ismail Shahin; Abdelfatah Hassan', display:{Lore:['[{"text": "arXiv:2010.08770", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lStudying the Similarity of COVID-19 Sounds based on Correlation Analysis of MFCC\\u00a7r\\n\\n\\u00a78\\u00a7oMohamed Bader\\nIsmail Shahin\\nAbdelfatah Hassan\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.08770\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 17 Oct 2020 11:38:05 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 4 figures, conference paper\\u00a7r"}']}
{title:'Tonami et al. (§72020§r)', author: 'Noriyuki Tonami; Keisuke Imoto; Ryosuke Yamanishi; Yoichi Yamashita', display:{Lore:['[{"text": "arXiv:2010.09213", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lJoint Analysis of Sound Events and Acoustic Scenes Using Multitask Learning\\u00a7r\\n\\n\\u00a78\\u00a7oNoriyuki Tonami\\nKeisuke Imoto\\nRyosuke Yamanishi\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.09213\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1587/transinf.2020EDP7036\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 16 Oct 2020 05:51:32 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted to IEICE Transactions on Information and Systems. arXiv admin note: text overlap with arXiv:1904.12146\\u00a7r"}']}
{title:'Herremans et al. (§72020§r)', author: 'Dorien Herremans; Tom Bergmans', display:{Lore:['[{"text": "arXiv:2010.09489", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.MM\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lHit Song Prediction Based on Early Adopter Data and Audio Features\\u00a7r\\n\\n\\u00a78\\u00a7oDorien Herremans\\nTom Bergmans\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.09489\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nThe 18th International Society for Music Information Retrieval\\n  Conference (ISMIR)2018 - LBD\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 16 Oct 2020 06:42:40 GMT)\\u00a7r"}']}
{title:'Al-Tahan et al. (§72020§r)', author: 'Haider Al-Tahan; Yalda Mohsenzadeh', display:{Lore:['[{"text": "arXiv:2010.09542", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lCLAR: Contrastive Learning of Auditory Representations\\u00a7r\\n\\n\\u00a78\\u00a7oHaider Al-Tahan\\nYalda Mohsenzadeh\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.09542\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 19 Oct 2020 14:15:31 GMT)\\u00a7r"}']}
{title:'Borsos et al. (§72020§r)', author: 'Zalán Borsos; Yunpeng Li; Beat Gfeller; Marco Tagliasacchi', display:{Lore:['[{"text": "arXiv:2010.09658", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMicAugment: One-shot Microphone Style Transfer\\u00a7r\\n\\n\\u00a78\\u00a7oZal\\u00e1n Borsos\\nYunpeng Li\\nBeat Gfeller\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.09658\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 19 Oct 2020 16:56:04 GMT)\\u00a7r"}']}
{title:'Grondin et al. (§72020§r)', author: 'François Grondin; Jean-Samuel Lauzon; Simon Michaud; Mirco Ravanelli; François Michaud', display:{Lore:['[{"text": "arXiv:2010.09930", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lBIRD: Big Impulse Response Dataset\\u00a7r\\n\\n\\u00a78\\u00a7oFran\\u00e7ois Grondin\\nJean-Samuel Lauzon\\nSimon Michaud\\nMirco Ravanelli\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.09930\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 19 Oct 2020 23:55:48 GMT)\\u00a7r"}']}
{title:'Cheuk et al. (§72020§r)', author: 'Kin Wai Cheuk; Yin-Jyun Luo; Emmanouil Benetos; Dorien Herremans', display:{Lore:['[{"text": "arXiv:2010.09969", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lThe Effect of Spectrogram Reconstruction on Automatic Music Transcription: An Alternative Approach to Improve Transcription Accuracy\\u00a7r\\n\\n\\u00a78\\u00a7oKin Wai Cheuk\\nYin-Jyun Luo\\nEmmanouil Benetos\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.09969\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 20 Oct 2020 02:37:39 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted in ICPR\\u00a7r"}']}
{title:'Shen et al. (§72020§r)', author: 'Shufan Shen; Ran Miao; Yi Wang; Zhihua Wei', display:{Lore:['[{"text": "arXiv:2010.10145", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lTongji University Undergraduate Team for the VoxCeleb Speaker Recognition Challenge2020\\u00a7r\\n\\n\\u00a78\\u00a7oShufan Shen\\nRan Miao\\nYi Wang\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.10145\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 20 Oct 2020 09:25:40 GMT)\\u00a7r"}']}
{title:'Wang et al. (§72020§r)', author: 'Peidong Wang; Zhuo Chen; DeLiang Wang; Jinyu Li; Yifan Gong', display:{Lore:['[{"text": "arXiv:2010.10556", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSpeaker Separation Using Speaker Inventories and Estimated Speech\\u00a7r\\n\\n\\u00a78\\u00a7oPeidong Wang\\nZhuo Chen\\nDeLiang Wang\\nJinyu Li\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.10556\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 20 Oct 2020 18:15:45 GMT)\\u00a7r"}']}
{title:'Shi et al. (§72020§r)', author: 'Yangyang Shi; Yongqiang Wang; Chunyang Wu; Ching-Feng Yeh; Julian Chan; Frank Zhang; Duc Le; Mike Seltzer', display:{Lore:['[{"text": "arXiv:2010.10759", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lEmformer: Efficient Memory Transformer Based Acoustic Model For Low Latency Streaming Speech Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oYangyang Shi\\nYongqiang Wang\\nChunyang Wu\\n+ 4 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.10759\\u00a7r\\n\\nVersion:\\u00a77v4 (Wed, 30 Dec 2020 07:07:35 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 2 figures, submitted to ICASSP 2021\\u00a7r"}']}
{title:'Saeed et al. (§72020§r)', author: 'Aaqib Saeed; David Grangier; Neil Zeghidour', display:{Lore:['[{"text": "arXiv:2010.10915", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lContrastive Learning of General-Purpose Audio Representations\\u00a7r\\n\\n\\u00a78\\u00a7oAaqib Saeed\\nDavid Grangier\\nNeil Zeghidour\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.10915\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 21 Oct 2020 11:56:22 GMT)\\u00a7r"}']}
{title:'Tran et al. (§72020§r)', author: 'An Tran; Konstantinos Drossos; Tuomas Virtanen', display:{Lore:['[{"text": "arXiv:2010.11098", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.MM\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lWaveTransformer: A Novel Architecture for Audio Captioning Based on Learning Temporal and Time-Frequency Information\\u00a7r\\n\\n\\u00a78\\u00a7oAn Tran\\nKonstantinos Drossos\\nTuomas Virtanen\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.11098\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 21 Oct 2020 16:02:25 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted for review at ICASSP2021\\u00a7r"}']}
{title:'Callens et al. (§72020§r)', author: 'Paul Callens; Milos Cernak', display:{Lore:['[{"text": "arXiv:2010.11167", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lJoint Blind Room Acoustic Characterization From Speech And Music Signals Using Convolutional Recurrent Neural Networks\\u00a7r\\n\\n\\u00a78\\u00a7oPaul Callens\\nMilos Cernak\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.11167\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 21 Oct 2020 17:41:21 GMT)\\u00a7r"}']}
{title:'Thao et al. (§72020§r)', author: 'Ha Thi Phuong Thao; Balamurali B. T.; Dorien Herremans; Gemma Roig', display:{Lore:['[{"text": "arXiv:2010.11188", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CV\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAttendAffectNet: Self-Attention based Networks for Predicting Affective Responses from Movies\\u00a7r\\n\\n\\u00a78\\u00a7oHa Thi Phuong Thao\\nBalamurali B. T.\\nDorien Herremans\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.11188\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nProceedings of the International Conference on Pattern Recognition\\n  (ICPR2020)\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 21 Oct 2020 05:13:24 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o8 pages, 6 figures\\u00a7r"}']}
{title:'Wilf et al. (§72020§r)', author: 'Alex Wilf; Emily Mower Provost', display:{Lore:['[{"text": "arXiv:2010.11226", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDynamic Layer Customization for Noise Robust Speech Emotion Recognition in Heterogeneous Condition Training\\u00a7r\\n\\n\\u00a78\\u00a7oAlex Wilf\\nEmily Mower Provost\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.11226\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 21 Oct 2020 18:07:32 GMT)\\u00a7r"}']}
{title:'Kumar et al. (§72020§r)', author: 'Rithesh Kumar; Kundan Kumar; Vicki Anand; Yoshua Bengio; Aaron Courville', display:{Lore:['[{"text": "arXiv:2010.11362", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.AI\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lNU-GAN: High resolution neural upsampling with GAN\\u00a7r\\n\\n\\u00a78\\u00a7oRithesh Kumar\\nKundan Kumar\\nVicki Anand\\nYoshua Bengio\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.11362\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 22 Oct 2020 01:00:23 GMT)\\u00a7r"}']}
{title:'Elias et al. (§72020§r)', author: 'Isaac Elias; Heiga Zen; Jonathan Shen; Yu Zhang; Ye Jia; Ron Weiss; Yonghui Wu', display:{Lore:['[{"text": "arXiv:2010.11439", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lParallel Tacotron: Non-Autoregressive and Controllable TTS\\u00a7r\\n\\n\\u00a78\\u00a7oIsaac Elias\\nHeiga Zen\\nJonathan Shen\\n+ 3 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.11439\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 22 Oct 2020 04:40:53 GMT)\\u00a7r"}']}
{title:'Korzeniowski et al. (§72020§r)', author: 'Filip Korzeniowski; Oriol Nieto; Matthew McCallum; Minz Won; Sergio Oramas; Erik Schmidt', display:{Lore:['[{"text": "arXiv:2010.11512", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.IR\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMood Classification Using Listening Data\\u00a7r\\n\\n\\u00a78\\u00a7oFilip Korzeniowski\\nOriol Nieto\\nMatthew McCallum\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.11512\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 22 Oct 2020 08:13:56 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAppears in Proc. of the International Society for Music Information Retrieval Conference 2020 (ISMIR 2020)\\u00a7r"}']}
{title:'Wang et al. (§72020§r)', author: 'Renyu Wang; Ruilin Tong; Yu Ting Yeung; Xiao Chen', display:{Lore:['[{"text": "arXiv:2010.11657", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lThe HUAWEI Speaker Diarisation System for the VoxCeleb Speaker Diarisation Challenge\\u00a7r\\n\\n\\u00a78\\u00a7oRenyu Wang\\nRuilin Tong\\nYu Ting Yeung\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.11657\\u00a7r\\n\\nVersion:\\u00a77v2 (Fri, 23 Oct 2020 07:45:47 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 2 figures, A report about our diarisation system for VoxCeleb Challenge, Interspeech conference workshop\\u00a7r"}']}
{title:'Kaneko et al. (§72020§r)', author: 'Takuhiro Kaneko; Hirokazu Kameoka; Kou Tanaka; Nobukatsu Hojo', display:{Lore:['[{"text": "arXiv:2010.11672", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lCycleGAN-VC3: Examining and Improving CycleGAN-VCs for Mel-spectrogram Conversion\\u00a7r\\n\\n\\u00a78\\u00a7oTakuhiro Kaneko\\nHirokazu Kameoka\\nKou Tanaka\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.11672\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 22 Oct 2020 13:08:44 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted to Interspeech 2020. Project page: http://www.kecl.ntt.co.jp/people/kaneko.takuhiro/projects/cyclegan-vc3/index.html\\u00a7r"}']}
{title:'Djukanović et al. (§72020§r)', author: 'Slobodan Djukanović; Jiři Matas; Tuomas Virtanen', display:{Lore:['[{"text": "arXiv:2010.11716", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lRobust Audio-Based Vehicle Counting in Low-to-Moderate Traffic Flow\\u00a7r\\n\\n\\u00a78\\u00a7oSlobodan Djukanovi\\u0107\\nJi\\u0159i Matas\\nTuomas Virtanen\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.11716\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 22 Oct 2020 13:42:26 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oThe paper has been accepted for the IV2020 conference\\u00a7r"}']}
{title:'Arnault et al. (§72020§r)', author: 'Augustin Arnault; Baptiste Hanssens; Nicolas Riche', display:{Lore:['[{"text": "arXiv:2010.11805", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lUrban Sound Classification : striving towards a fair comparison\\u00a7r\\n\\n\\u00a78\\u00a7oAugustin Arnault\\nBaptiste Hanssens\\nNicolas Riche\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.11805\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 22 Oct 2020 15:37:39 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o7 pages, 1 figure\\u00a7r"}']}
{title:'Hung et al. (§72020§r)', author: 'Yun-Ning Hung; Gordon Wichern; Jonathan Le Roux', display:{Lore:['[{"text": "arXiv:2010.11904", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lTranscription Is All You Need: Learning to Separate Musical Mixtures with Score as Supervision\\u00a7r\\n\\n\\u00a78\\u00a7oYun-Ning Hung\\nGordon Wichern\\nJonathan Le Roux\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.11904\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 22 Oct 2020 17:38:40 GMT)\\u00a7r"}']}
{title:'Xu et al. (§72020§r)', author: 'Ruilin Xu; Rundi Wu; Yuko Ishiwaka; Carl Vondrick; Changxi Zheng', display:{Lore:['[{"text": "arXiv:2010.12013", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lListening to Sounds of Silence for Speech Denoising\\u00a7r\\n\\n\\u00a78\\u00a7oRuilin Xu\\nRundi Wu\\nYuko Ishiwaka\\nCarl Vondrick\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.12013\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 22 Oct 2020 20:07:53 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o9 pages, 6 figures, accepted in NeurIPS 2020; Sound examples can be found at http://www.cs.columbia.edu/cg/listen_to_the_silence/\\u00a7r"}']}
{title:'Mao et al. (§72020§r)', author: 'Tingzhi Mao; Yerbolat Khassanov; Van Tung Pham; Haihua Xu; Hao Huang; Aishan Wumaier; Eng Siong Chng', display:{Lore:['[{"text": "arXiv:2010.12143", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lEnriching Under-Represented Named-Entities To Improve Speech Recognition Performance\\u00a7r\\n\\n\\u00a78\\u00a7oTingzhi Mao\\nYerbolat Khassanov\\nVan Tung Pham\\n+ 3 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.12143\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 23 Oct 2020 03:22:10 GMT)\\u00a7r"}']}
{title:'Chen et al. (§72020§r)', author: 'Sanyuan Chen; Yu Wu; Zhuo Chen; Takuya Yoshioka; Shujie Liu; Jinyu Li', display:{Lore:['[{"text": "arXiv:2010.12180", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDon\'t shoot butterfly with rifles: Multi-channel Continuous Speech Separation with Early Exit Transformer\\u00a7r\\n\\n\\u00a78\\u00a7oSanyuan Chen\\nYu Wu\\nZhuo Chen\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.12180\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 23 Oct 2020 06:21:11 GMT)\\u00a7r"}']}
{title:'Ren et al. (§72020§r)', author: 'Iris Ren; Anja Volk; Wouter Swierstra; Remco C. Veltkamp', display:{Lore:['[{"text": "arXiv:2010.12325", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.MM\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Computational Evaluation of Musical Pattern Discovery Algorithms\\u00a7r\\n\\n\\u00a78\\u00a7oIris Ren\\nAnja Volk\\nWouter Swierstra\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.12325\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 23 Oct 2020 12:07:21 GMT)\\u00a7r"}']}
{title:'Ghahabi et al. (§72020§r)', author: 'Omid Ghahabi; Volker Fischer', display:{Lore:['[{"text": "arXiv:2010.12497", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lEML System Description for VoxCeleb Speaker Diarization Challenge 2020\\u00a7r\\n\\n\\u00a78\\u00a7oOmid Ghahabi\\nVolker Fischer\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.12497\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 23 Oct 2020 16:01:28 GMT)\\u00a7r"}']}
{title:'Bugler et al. (§72020§r)', author: 'Andreas Bugler; Bryan Pardo; Prem Seetharaman', display:{Lore:['[{"text": "arXiv:2010.12650", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Study of Transfer Learning in Music Source Separation\\u00a7r\\n\\n\\u00a78\\u00a7oAndreas Bugler\\nBryan Pardo\\nPrem Seetharaman\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.12650\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 23 Oct 2020 20:29:47 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o4 pages + 1 reference page. 3 figures. Submitted to ICASSP\\u00a7r"}']}
{title:'Zhang et al. (§72020§r)', author: 'Zining Zhang; Bingsheng He; Zhenjie Zhang', display:{Lore:['[{"text": "arXiv:2010.12788", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lGAZEV: GAN-Based Zero-Shot Voice Conversion over Non-parallel Speech Corpus\\u00a7r\\n\\n\\u00a78\\u00a7oZining Zhang\\nBingsheng He\\nZhenjie Zhang\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.12788\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 24 Oct 2020 05:31:15 GMT)\\u00a7r"}']}
{title:'He et al. (§72020§r)', author: 'Shulin He; Hao Li; Xueliang Zhang', display:{Lore:['[{"text": "arXiv:2010.13053", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSpeakerfilter-Pro: an improved target speaker extractor combines the time domain and frequency domain\\u00a7r\\n\\n\\u00a78\\u00a7oShulin He\\nHao Li\\nXueliang Zhang\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.13053\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 25 Oct 2020 07:30:30 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oPreprint, submitted to ICASSP 2021\\u00a7r"}']}
{title:'Tzinis et al. (§72020§r)', author: 'Efthymios Tzinis; Dimitrios Bralios; Paris Smaragdis', display:{Lore:['[{"text": "arXiv:2010.13228", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lUnified Gradient Reweighting for Model Biasing with Applications to Source Separation\\u00a7r\\n\\n\\u00a78\\u00a7oEfthymios Tzinis\\nDimitrios Bralios\\nParis Smaragdis\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.13228\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/ICASSP39728.2021.9414071\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nICASSP 2021 - 2021 IEEE International Conference on Acoustics,\\n  Speech and Signal Processing (ICASSP)\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 25 Oct 2020 21:41:45 GMT)\\u00a7r"}']}
{title:'Yu et al. (§72020§r)', author: 'Zhesong Yu; Xingjian Du; Bilei Zhu; Zejun Ma', display:{Lore:['[{"text": "arXiv:2010.13540", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.MM\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lContrastive Unsupervised Learning for Audio Fingerprinting\\u00a7r\\n\\n\\u00a78\\u00a7oZhesong Yu\\nXingjian Du\\nBilei Zhu\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.13540\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 26 Oct 2020 12:49:39 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages\\u00a7r"}']}
{title:'Wolfe et al. (§72020§r)', author: 'Kristina Wolfe; Douglas Swanson; Rupert Till', display:{Lore:['[{"text": "arXiv:2010.13697", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r, \\u00a75physics.app-ph\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lThe Frequency Spectrum and Geometry of the Hal Saflieni Hypogeum Appear Tuned\\u00a7r\\n\\n\\u00a78\\u00a7oKristina Wolfe\\nDouglas Swanson\\nRupert Till\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.13697\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1016/j.jasrep.2020.102623\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nJournal of Archaeological Science: Reports 34 (2020)\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 26 Oct 2020 16:28:49 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o8 pages, 6 figures. Accepted to Journal of Archaeological Science: Reports (2020)\\u00a7r"}']}
{title:'Gao et al. (§72020§r)', author: 'Zhifu Gao; Shiliang Zhang; Ming Lei; Ian McLoughlin', display:{Lore:['[{"text": "arXiv:2010.14099", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lUniversal ASR: Unifying Streaming and Non-Streaming ASR Using a Single Encoder-Decoder Model\\u00a7r\\n\\n\\u00a78\\u00a7oZhifu Gao\\nShiliang Zhang\\nMing Lei\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.14099\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 27 Oct 2020 06:46:00 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 2 figures, submitted to ICASSP 2021\\u00a7r"}']}
{title:'Hou et al. (§72020§r)', author: 'Yuanbo Hou; Yi Deng; Bilei Zhu; Zejun Ma; Dick Botteldooren', display:{Lore:['[{"text": "arXiv:2010.14168", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.MM\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lRule-embedded network for audio-visual voice activity detection in live musical video streams\\u00a7r\\n\\n\\u00a78\\u00a7oYuanbo Hou\\nYi Deng\\nBilei Zhu\\nZejun Ma\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.14168\\u00a7r\\n\\nVersion:\\u00a77v2 (Sat, 31 Oct 2020 14:55:00 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to ICASSP 2021\\u00a7r"}']}
{title:'Favory et al. (§72020§r)', author: 'Xavier Favory; Konstantinos Drossos; Tuomas Virtanen; Xavier Serra', display:{Lore:['[{"text": "arXiv:2010.14171", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.IR\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lLearning Contextual Tag Embeddings for Cross-Modal Alignment of Audio and Tags\\u00a7r\\n\\n\\u00a78\\u00a7oXavier Favory\\nKonstantinos Drossos\\nTuomas Virtanen\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.14171\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 27 Oct 2020 10:13:17 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 1 figure\\u00a7r"}']}
{title:'Sun et al. (§72020§r)', author: 'Haoran Sun; Lantian Li; Yunqi Cai; Yang Zhang; Thomas Fang Zheng; Dong Wang', display:{Lore:['[{"text": "arXiv:2010.14242", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDeep generative factorization for speech signal\\u00a7r\\n\\n\\u00a78\\u00a7oHaoran Sun\\nLantian Li\\nYunqi Cai\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.14242\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 27 Oct 2020 12:27:58 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to ICASSP 2021\\u00a7r"}']}
{title:'Li et al. (§72020§r)', author: 'Lantian Li; Yang Zhang; Jiawen Kang; Thomas Fang Zheng; Dong Wang', display:{Lore:['[{"text": "arXiv:2010.14243", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSqueezing value of cross-domain labels: a decoupled scoring approach for speaker verification\\u00a7r\\n\\n\\u00a78\\u00a7oLantian Li\\nYang Zhang\\nJiawen Kang\\nThomas Fang Zheng\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.14243\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 27 Oct 2020 12:32:25 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to ICASSP 2021\\u00a7r"}']}
{title:'Yang et al. (§72020§r)', author: 'Li-Chia Yang; Alexander Lerch', display:{Lore:['[{"text": "arXiv:2010.14565", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.MM\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lRemixing Music with Visual Conditioning\\u00a7r\\n\\n\\u00a78\\u00a7oLi-Chia Yang\\nAlexander Lerch\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.14565\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7n2020 IEEE International Symposium on Multimedia\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 27 Oct 2020 19:12:08 GMT)\\u00a7r"}']}
{title:'Chen et al. (§72020§r)', author: 'Yihao Chen; Alexander Lerch', display:{Lore:['[{"text": "arXiv:2010.14709", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.IR\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.MM\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMelody-Conditioned Lyrics Generation with SeqGANs\\u00a7r\\n\\n\\u00a78\\u00a7oYihao Chen\\nAlexander Lerch\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.14709\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 28 Oct 2020 02:35:40 GMT)\\u00a7r"}']}
{title:'Zhang et al. (§72020§r)', author: 'Shuai Zhang; Jiangyan Yi; Zhengkun Tian; Ye Bai; Jianhua Tao; Zhengqi wen', display:{Lore:['[{"text": "arXiv:2010.14798", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDecoupling Pronunciation and Language for End-to-end Code-switching Automatic Speech Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oShuai Zhang\\nJiangyan Yi\\nZhengkun Tian\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.14798\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 28 Oct 2020 07:46:15 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 1 figures\\u00a7r"}']}
{title:'Li et al. (§72020§r)', author: 'Zhonghao Li; Benlai Tang; Xiang Yin; Yuan Wan; Ling Xu; Chen Shen; Zejun Ma', display:{Lore:['[{"text": "arXiv:2010.14804", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lPPG-based singing voice conversion with adversarial representation learning\\u00a7r\\n\\n\\u00a78\\u00a7oZhonghao Li\\nBenlai Tang\\nXiang Yin\\n+ 3 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.14804\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 28 Oct 2020 08:03:27 GMT)\\u00a7r"}']}
{title:'Kong et al. (§72020§r)', author: 'Qiuqiang Kong; Keunwoo Choi; Yuxuan Wang', display:{Lore:['[{"text": "arXiv:2010.14805", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CV\\u00a7r, \\u00a7acs.MM\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lLarge-Scale MIDI-based Composer Classification\\u00a7r\\n\\n\\u00a78\\u00a7oQiuqiang Kong\\nKeunwoo Choi\\nYuxuan Wang\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.14805\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 28 Oct 2020 08:07:55 GMT)\\u00a7r"}']}
{title:'Yao et al. (§72020§r)', author: 'Yiwu Yao; Yuchao Li; Chengyu Wang; Tianhang Yu; Houjiang Chen; Xiaotang Jiang; Jun Yang; Jun Huang; Wei Lin; Hui Shu; Chengfei Lv', display:{Lore:['[{"text": "arXiv:2010.14841", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lINT8 Winograd Acceleration for Conv1D Equipped ASR Models Deployed on Mobile Devices\\u00a7r\\n\\n\\u00a78\\u00a7oYiwu Yao\\nYuchao Li\\nChengyu Wang\\n+ 7 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.14841\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 28 Oct 2020 09:25:49 GMT)\\u00a7r"}']}
{title:'Gan et al. (§72020§r)', author: 'Wendong Gan; Haitao Chen; Yin Yan; Jianwei Li; Bolong Wen; Xueping Xu; Hai Li', display:{Lore:['[{"text": "arXiv:2010.15317", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lThe IQIYI System for Voice Conversion Challenge 2020\\u00a7r\\n\\n\\u00a78\\u00a7oWendong Gan\\nHaitao Chen\\nYin Yan\\n+ 3 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.15317\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 29 Oct 2020 02:18:16 GMT)\\u00a7r"}']}
{title:'Chen et al. (§72020§r)', author: 'Ke Chen; Beici Liang; Xiaoshuan Ma; Minwei Gu', display:{Lore:['[{"text": "arXiv:2010.15389", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lLearning Audio Embeddings with User Listening Data for Content-based Music Recommendation\\u00a7r\\n\\n\\u00a78\\u00a7oKe Chen\\nBeici Liang\\nXiaoshuan Ma\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.15389\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7n2021 IEEE International Conference on Acoustics, Speech and Signal\\n  Processing, ICASSP 2021\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 29 Oct 2020 06:59:21 GMT)\\u00a7r"}']}
{title:'Kolokolova et al. (§72020§r)', author: 'Antonina Kolokolova; Mitchell Billard; Robert Bishop; Moustafa Elsisy; Zachary Northcott; Laura Graves; Vineel Nagisetty; Heather Patey', display:{Lore:['[{"text": "arXiv:2010.15772", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lGANs     Reels: Creating Irish Music using a Generative Adversarial Network\\u00a7r\\n\\n\\u00a78\\u00a7oAntonina Kolokolova\\nMitchell Billard\\nRobert Bishop\\n+ 4 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.15772\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 29 Oct 2020 17:16:22 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o7 pages, (+ 2 pages of references)\\u00a7r"}']}
{title:'Kwon et al. (§72020§r)', author: 'Yoohwan Kwon; Hee-Soo Heo; Bong-Jin Lee; Joon Son Chung', display:{Lore:['[{"text": "arXiv:2010.15809", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lThe ins and outs of speaker recognition: lessons from VoxSRC 2020\\u00a7r\\n\\n\\u00a78\\u00a7oYoohwan Kwon\\nHee-Soo Heo\\nBong-Jin Lee\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.15809\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 29 Oct 2020 17:45:15 GMT)\\u00a7r"}']}
{title:'Memon (§72020§r)', author: 'Shahan Ali Memon', display:{Lore:['[{"text": "arXiv:2010.15869", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.MM\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAcoustic Correlates of the Voice Qualifiers: A Survey\\u00a7r\\n\\n\\u00a78\\u00a7oShahan Ali Memon\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.15869\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 29 Oct 2020 18:14:54 GMT)\\u00a7r"}']}
{title:'Taylor (§72020§r)', author: 'Jason Taylor', display:{Lore:['[{"text": "arXiv:2010.15989", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lLatent Space Oddity: Exploring Latent Spaces to Design Guitar Timbres\\u00a7r\\n\\n\\u00a78\\u00a7oJason Taylor\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.15989\\u00a7r\\n\\nVersion:\\u00a77v2 (Fri, 20 Nov 2020 00:11:27 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o3 pages, 1 figure. To appear in the 2020 NeurIps Workshop on Machine Learning for Creativity and Design\\u00a7r"}']}
{title:'Shi et al. (§72020§r)', author: 'Yanpei Shi; Mingjie Chen; Qiang Huang; Thomas Hain', display:{Lore:['[{"text": "arXiv:2010.16071", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lT-vectors: Weakly Supervised Speaker Identification Using Hierarchical Transformer Model\\u00a7r\\n\\n\\u00a78\\u00a7oYanpei Shi\\nMingjie Chen\\nQiang Huang\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.16071\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 29 Oct 2020 09:38:17 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to ICASSP2021. arXiv admin note: text overlapwith arXiv:2005.07817\\u00a7r"}']}
{title:'Cai et al. (§72020§r)', author: 'Yunqi Cai; Lantian Li; Dong Wang; Andrew Abel', display:{Lore:['[{"text": "arXiv:2010.16148", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDeep Speaker Vector Normalization with Maximum Gaussianality Training\\u00a7r\\n\\n\\u00a78\\u00a7oYunqi Cai\\nLantian Li\\nDong Wang\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.16148\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 30 Oct 2020 09:42:06 GMT)\\u00a7r"}']}
{title:'Muzammel et al. (§72020§r)', author: 'Muhammad Muzammel; Hanan Salam; Yann Hoffmann; Mohamed Chetouani; Alice Othmani', display:{Lore:['[{"text": "arXiv:2010.16201", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.HC\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAudVowelConsNet: A Phoneme-Level Based Deep CNN Architecture for Clinical Depression Diagnosis\\u00a7r\\n\\n\\u00a78\\u00a7oMuhammad Muzammel\\nHanan Salam\\nYann Hoffmann\\nMohamed Chetouani\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.16201\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1016/j.mlwa.2020.100005\\u00a7r\\n\\nVersion:\\u00a77v2 (Wed, 4 Nov 2020 11:59:01 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o12 pages, 8 figures\\u00a7r"}']}
{title:'Xiang (§72020§r)', author: 'Xu Xiang', display:{Lore:['[{"text": "arXiv:2011.00200", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lThe xx205 System for the VoxCeleb Speaker Recognition Challenge 2020\\u00a7r\\n\\n\\u00a78\\u00a7oXu Xiang\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.00200\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 31 Oct 2020 06:36:26 GMT)\\u00a7r"}']}
{title:'Huang et al. (§72020§r)', author: 'Yuxin Huang; Liwei Lin; Xiangdong Wang; Hong Liu; Yueliang Qian; Min Liu; Kazushige Ouchi', display:{Lore:['[{"text": "arXiv:2011.00695", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lLearning generic feature representation with synthetic data for weakly-supervised sound event detection by inter-frame distance loss\\u00a7r\\n\\n\\u00a78\\u00a7oYuxin Huang\\nLiwei Lin\\nXiangdong Wang\\n+ 3 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.00695\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 2 Nov 2020 03:05:33 GMT)\\u00a7r"}']}
{title:'Ranjan et al. (§72020§r)', author: 'Ashish Ranjan; Varun Nagesh Jolly Behera; Motahar Reza', display:{Lore:['[{"text": "arXiv:2011.00773", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.MM\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lUsing a Bi-directional LSTM Model with Attention Mechanism trained on MIDI Data for Generating Unique Music\\u00a7r\\n\\n\\u00a78\\u00a7oAshish Ranjan\\nVarun Nagesh Jolly Behera\\nMotahar Reza\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.00773\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 2 Nov 2020 06:43:28 GMT)\\u00a7r"}']}
{title:'Turpault et al. (§72020§r)', author: 'Nicolas Turpault; Romain Serizel; Scott Wisdom; Hakan Erdogan; John Hershey; Eduardo Fonseca; Prem Seetharaman; Justin Salamon', display:{Lore:['[{"text": "arXiv:2011.00801", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSound Event Detection and Separation: a Benchmark on Desed Synthetic Soundscapes\\u00a7r\\n\\n\\u00a78\\u00a7oNicolas Turpault\\nRomain Serizel\\nScott Wisdom\\n+ 4 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.00801\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 2 Nov 2020 08:05:01 GMT)\\u00a7r"}']}
{title:'Wisdom et al. (§72020§r)', author: 'Scott Wisdom; Hakan Erdogan; Daniel Ellis; Romain Serizel; Nicolas Turpault; Eduardo Fonseca; Justin Salamon; Prem Seetharaman; John Hershey', display:{Lore:['[{"text": "arXiv:2011.00803", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lWhat\'s All the FUSS About Free Universal Sound Separation Data?\\u00a7r\\n\\n\\u00a78\\u00a7oScott Wisdom\\nHakan Erdogan\\nDaniel Ellis\\n+ 5 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.00803\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 2 Nov 2020 08:09:34 GMT)\\u00a7r"}']}
{title:'Hu et al. (§72020§r)', author: 'Hu Hu; Chao-Han Huck Yang; Xianjun Xia; Xue Bai; Xin Tang; Yajian Wang; Shutong Niu; Li Chai; Juanjuan Li; Hongning Zhu; Feng Bao; Yuanjun Zhao; Sabato Marco Siniscalchi; Yannan Wang; Jun Du; Chin-Hui Lee', display:{Lore:['[{"text": "arXiv:2011.01447", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.AI\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.NE\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Two-Stage Approach to Device-Robust Acoustic Scene Classification\\u00a7r\\n\\n\\u00a78\\u00a7oHu Hu\\nChao-Han Huck Yang\\nXianjun Xia\\n+ 12 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.01447\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/ICASSP39728.2021.9414835\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nICASSP 2021-2021 IEEE International Conference on Acoustics,\\n  Speech and Signal Processing (ICASSP)\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 3 Nov 2020 03:27:18 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to ICASSP 2021. Code available: https://github.com/MihawkHu/DCASE2020_task1\\u00a7r"}']}
{title:'Chen (§72020§r)', author: 'Shen Chen', display:{Lore:['[{"text": "arXiv:2011.01518", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lShaneRun System Description to VoxCeleb Speaker Recognition Challenge 2020\\u00a7r\\n\\n\\u00a78\\u00a7oShen Chen\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.01518\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 3 Nov 2020 07:26:21 GMT)\\u00a7r"}']}
{title:'Li et al. (§72020§r)', author: 'Andong Li; Chengshi Zheng; Renhua Peng; Xiaodong Li', display:{Lore:['[{"text": "arXiv:2011.01561", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lTwo Heads Are Better Than One: A Two-Stage Approach for Monaural Noise Reduction in the Complex Domain\\u00a7r\\n\\n\\u00a78\\u00a7oAndong Li\\nChengshi Zheng\\nRenhua Peng\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.01561\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 3 Nov 2020 08:34:12 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to ICASSP 2021, 5 pages\\u00a7r"}']}
{title:'Pinto et al. (§72020§r)', author: 'A. Sá Pinto; I. Domingues; M. E. P. Davies', display:{Lore:['[{"text": "arXiv:2011.01637", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.IR\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lShift If You Can: Counting and Visualising Correction Operations for Beat Tracking Evaluation\\u00a7r\\n\\n\\u00a78\\u00a7oA. S\\u00e1 Pinto\\nI. Domingues\\nM. E. P. Davies\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.01637\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 3 Nov 2020 11:26:03 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oISMIR 2020 Late Breaking/Demo\\u00a7r"}']}
{title:'Shi et al. (§72020§r)', author: 'Ying Shi; Haolin Chen; Zhiyuan Tang; Lantian Li; Dong Wang; Jiqing Han', display:{Lore:['[{"text": "arXiv:2011.02110", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lCan We Trust Deep Speech Prior?\\u00a7r\\n\\n\\u00a78\\u00a7oYing Shi\\nHaolin Chen\\nZhiyuan Tang\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.02110\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 4 Nov 2020 03:35:21 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oTo be published in IEEE SLT 2021\\u00a7r"}']}
{title:'Fu et al. (§72020§r)', author: 'Yihui Fu; Jian Wu; Yanxin Hu; Mengtao Xing; Lei Xie', display:{Lore:['[{"text": "arXiv:2011.02131", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDESNet: A Multi-channel Network for Simultaneous Speech Dereverberation, Enhancement and Separation\\u00a7r\\n\\n\\u00a78\\u00a7oYihui Fu\\nJian Wu\\nYanxin Hu\\nMengtao Xing\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.02131\\u00a7r\\n\\nVersion:\\u00a77v3 (Sat, 14 Nov 2020 07:33:41 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted at IEEESLT 2021\\u00a7r"}']}
{title:'Fu et al. (§72020§r)', author: 'Yihui Fu; Zhuoyuan Yao; Weipeng He; Jian Wu; Xiong Wang; Zhanheng Yang; Shimin Zhang; Lei Xie; Dongyan Huang; Hui Bu; Petr Motlicek; Jean-Marc Odobez', display:{Lore:['[{"text": "arXiv:2011.02198", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lIEEE SLT 2021 Alpha-mini Speech Challenge: Open Datasets, Tracks, Rules and Baselines\\u00a7r\\n\\n\\u00a78\\u00a7oYihui Fu\\nZhuoyuan Yao\\nWeipeng He\\n+ 8 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.02198\\u00a7r\\n\\nVersion:\\u00a77v2 (Sat, 14 Nov 2020 08:03:50 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted at IEEESLT 2021\\u00a7r"}']}
{title:'Zhou et al. (§72020§r)', author: 'Kun Zhou; Berrak Sisman; Haizhou Li', display:{Lore:['[{"text": "arXiv:2011.02314", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lVAW-GAN for Disentanglement and Recomposition of Emotional Elements in Speech\\u00a7r\\n\\n\\u00a78\\u00a7oKun Zhou\\nBerrak Sisman\\nHaizhou Li\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.02314\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 3 Nov 2020 08:49:33 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted by IEEE SLT 2021. arXiv admin note: text overlapwith arXiv:2005.07025\\u00a7r"}']}
{title:'Chazan et al. (§72020§r)', author: 'Shlomo E. Chazan; Lior Wolf; Eliya Nachmani; Yossi Adi', display:{Lore:['[{"text": "arXiv:2011.02329", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSingle channel voice separation for unknown number of speakers under reverberant and noisy settings\\u00a7r\\n\\n\\u00a78\\u00a7oShlomo E. Chazan\\nLior Wolf\\nEliya Nachmani\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.02329\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 4 Nov 2020 14:59:14 GMT)\\u00a7r"}']}
{title:'Bonada et al. (§72020§r)', author: 'Jordi Bonada; Merlijn Blaauw', display:{Lore:['[{"text": "arXiv:2011.02809", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSemi-supervised Learning for Singing Synthesis Timbre\\u00a7r\\n\\n\\u00a78\\u00a7oJordi Bonada\\nMerlijn Blaauw\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.02809\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 5 Nov 2020 13:33:34 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 1 figure, submitted to ICASSP 2021\\u00a7r"}']}
{title:'Rocha et al. (§72020§r)', author: 'Bruno M. Rocha; Diogo Pessoa; Alda Marques; Paulo Carvalho; Rui Pedro Paiva', display:{Lore:['[{"text": "arXiv:2011.02874", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lInfluence of Event Duration on Automatic Wheeze Classification\\u00a7r\\n\\n\\u00a78\\u00a7oBruno M. Rocha\\nDiogo Pessoa\\nAlda Marques\\nPaulo Carvalho\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.02874\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 4 Nov 2020 11:03:25 GMT)\\u00a7r"}']}
{title:'Cheng et al. (§72020§r)', author: 'Yu-Sen Cheng; Chun-Liang Shih; Tien-Hong Lo; Wen-Ting Tseng; Berlin Chen', display:{Lore:['[{"text": "arXiv:2011.02882", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lQuery Expansion System for the VoxCeleb Speaker Recognition Challenge 2020\\u00a7r\\n\\n\\u00a78\\u00a7oYu-Sen Cheng\\nChun-Liang Shih\\nTien-Hong Lo\\nWen-Ting Tseng\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.02882\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 4 Nov 2020 05:24:18 GMT)\\u00a7r"}']}
{title:'Gray et al. (§72020§r)', author: 'Patrick Gray; Razvan Bunescu', display:{Lore:['[{"text": "arXiv:2011.03028", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.AI\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lFrom Note-Level to Chord-Level Neural Network Models for Voice Separation in Symbolic Music\\u00a7r\\n\\n\\u00a78\\u00a7oPatrick Gray\\nRazvan Bunescu\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.03028\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 5 Nov 2020 18:39:42 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oPaper submitted for publication in August 2018\\u00a7r"}']}
{title:'Hua et al. (§72020§r)', author: 'Guang Hua; Han Liao; Haijian Zhang; Dengpan Ye; Jiayi Ma', display:{Lore:['[{"text": "arXiv:2011.03414", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r, \\u00a7eeess.SP\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lRobust ENF Estimation Based on Harmonic Enhancement and Maximum Weight Clique\\u00a7r\\n\\n\\u00a78\\u00a7oGuang Hua\\nHan Liao\\nHaijian Zhang\\nDengpan Ye\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.03414\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/TIFS.2021.3099697\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nIEEE Transactions on Information Forensics and Security, 2021\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 6 Nov 2020 15:10:08 GMT)\\u00a7r"}']}
{title:'Gao et al. (§72020§r)', author: 'Yang Gao; Jiachen Lian; Bhiksha Raj; Rita Singh', display:{Lore:['[{"text": "arXiv:2011.03689", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDetection and Evaluation of human and machine generated speech in spoofing attacks on automatic speaker verification systems\\u00a7r\\n\\n\\u00a78\\u00a7oYang Gao\\nJiachen Lian\\nBhiksha Raj\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.03689\\u00a7r\\n\\nVersion:\\u00a77v2 (Wed, 25 Nov 2020 03:20:36 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o6 pages excluding references. Paper accepted by IEEE Spoken Language Technology (SLT) 2021\\u00a7r"}']}
{title:'Pandey et al. (§72020§r)', author: 'Ashutosh Pandey; Chunxi Liu; Yun Wang; Yatharth Saraf', display:{Lore:['[{"text": "arXiv:2011.03840", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDual Application of Speech Enhancement for Automatic Speech Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oAshutosh Pandey\\nChunxi Liu\\nYun Wang\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.03840\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 7 Nov 2020 19:56:55 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted for publication in SLT 2021\\u00a7r"}']}
{title:'Ai et al. (§72020§r)', author: 'Yang Ai; Haoyu Li; Xin Wang; Junichi Yamagishi; Zhenhua Ling', display:{Lore:['[{"text": "arXiv:2011.03955", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDenoising-and-Dereverberation Hierarchical Neural Vocoder for Robust Waveform Generation\\u00a7r\\n\\n\\u00a78\\u00a7oYang Ai\\nHaoyu Li\\nXin Wang\\nJunichi Yamagishi\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.03955\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 8 Nov 2020 11:09:00 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted by SLT 2021\\u00a7r"}']}
{title:'Oostermeijer et al. (§72020§r)', author: 'Koen Oostermeijer; Qing Wang; Jun Du', display:{Lore:['[{"text": "arXiv:2011.04092", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.NE\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lFrequency Gating: Improved Convolutional Neural Networks for Speech Enhancement in the Time-Frequency Domain\\u00a7r\\n\\n\\u00a78\\u00a7oKoen Oostermeijer\\nQing Wang\\nJun Du\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.04092\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 8 Nov 2020 22:04:00 GMT)\\u00a7r"}']}
{title:'Fan et al. (§72020§r)', author: 'Cunhang Fan; Jiangyan Yi; Jianhua Tao; Zhengkun Tian; Bin Liu; Zhengqi Wen', display:{Lore:['[{"text": "arXiv:2011.04249", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lGated Recurrent Fusion with Joint Training Framework for Robust End-to-End Speech Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oCunhang Fan\\nJiangyan Yi\\nJianhua Tao\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.04249\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 9 Nov 2020 08:52:05 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted by IEEE/ACM Transactionson Audio, Speech, and Language Processing\\u00a7r"}']}
{title:'Zezario et al. (§72020§r)', author: 'Ryandhimas E. Zezario; Szu-Wei Fu; Chiou-Shann Fuh; Yu Tsao; Hsin-Min Wang', display:{Lore:['[{"text": "arXiv:2011.04292", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSTOI-Net: A Deep Learning based Non-Intrusive Speech Intelligibility Assessment Model\\u00a7r\\n\\n\\u00a78\\u00a7oRyandhimas E. Zezario\\nSzu-Wei Fu\\nChiou-Shann Fuh\\nYu Tsao\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.04292\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 9 Nov 2020 09:57:10 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted in APSIPA 2020\\u00a7r"}']}
{title:'Ritwik et al. (§72020§r)', author: 'Kotra Venkata Sai Ritwik; Shareef Babu Kalluri; Deepu Vijayasenan', display:{Lore:['[{"text": "arXiv:2011.04299", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lCOVID-19 Patient Detection from Telephone Quality Speech Data\\u00a7r\\n\\n\\u00a78\\u00a7oKotra Venkata Sai Ritwik\\nShareef Babu Kalluri\\nDeepu Vijayasenan\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.04299\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 9 Nov 2020 10:16:08 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o6 pages, 7 figures\\u00a7r"}']}
{title:'Chen et al. (§72020§r)', author: 'Guoguo Chen; Xingyu Na; Yongqing Wang; Zhiyong Yan; Junbo Zhang; Sifan Ma; Yujun Wang', display:{Lore:['[{"text": "arXiv:2011.04547", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lData Augmentation For Children\'s Speech Recognition \\u2013 The \\"Ethiopian\\" System For The SLT 2021 Children Speech Recognition Challenge\\u00a7r\\n\\n\\u00a78\\u00a7oGuoguo Chen\\nXingyu Na\\nYongqing Wang\\n+ 3 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.04547\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 9 Nov 2020 16:44:47 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSystem description of the SLT 2021 Children Speech Recognition Challenge\\u00a7r"}']}
{title:'Ruiz-Marcos (§72020§r)', author: 'Germán Ruiz-Marcos', display:{Lore:['[{"text": "arXiv:2011.04568", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMusical analysis of Stravinski\'s \\"The Rite of Spring\\" based on computational methods\\u00a7r\\n\\n\\u00a78\\u00a7oGerm\\u00e1n Ruiz-Marcos\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.04568\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 9 Nov 2020 17:13:21 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAudio and Music Processing Lab, 2017\\u00a7r"}']}
{title:'Espinoza-Cuadros et al. (§72020§r)', author: 'Fernando M. Espinoza-Cuadros; Juan M. Perero-Codosero; Javier Antón-Martín; Luis A. Hernández-Gómez', display:{Lore:['[{"text": "arXiv:2011.04696", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSpeaker De-identification System using Autoencoders and Adversarial Training\\u00a7r\\n\\n\\u00a78\\u00a7oFernando M. Espinoza-Cuadros\\nJuan M. Perero-Codosero\\nJavier Ant\\u00f3n-Mart\\u00edn\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.04696\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 9 Nov 2020 19:22:05 GMT)\\u00a7r"}']}
{title:'Cooper et al. (§72020§r)', author: 'Erica Cooper; Xin Wang; Yi Zhao; Yusuke Yasuda; Junichi Yamagishi', display:{Lore:['[{"text": "arXiv:2011.04839", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lPretraining Strategies, Waveform Model Choice, and Acoustic Configurations for Multi-Speaker End-to-End Speech Synthesis\\u00a7r\\n\\n\\u00a78\\u00a7oErica Cooper\\nXin Wang\\nYi Zhao\\nYusuke Yasuda\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.04839\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 10 Nov 2020 00:19:04 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oTechnical report\\u00a7r"}']}
{title:'Xie et al. (§72020§r)', author: 'Yifan Xie; Rongfeng Li', display:{Lore:['[{"text": "arXiv:2011.04974", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDeconstruct and Reconstruct Dizi Music of the Northern School and the Southern School\\u00a7r\\n\\n\\u00a78\\u00a7oYifan Xie\\nRongfeng Li\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.04974\\u00a7r\\n\\nVersion:\\u00a77v2 (Wed, 2 Dec 2020 08:46:20 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oBest Student Paper in The 8th Conference on Sound and Music Technology (CSMT)\\u00a7r"}']}
{title:'Castro (§72020§r)', author: 'Pablo Samuel Castro', display:{Lore:['[{"text": "arXiv:2011.05158", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.AI\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lGANterpretations\\u00a7r\\n\\n\\u00a78\\u00a7oPablo Samuel Castro\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.05158\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 6 Nov 2020 19:08:40 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oIn 4th Workshop on Machine Learning for Creativityand Design at NeurIPS 2020, Vancouver, Canada\\u00a7r"}']}
{title:'Kye et al. (§72020§r)', author: 'Seong Min Kye; Joon Son Chung; Hoirin Kim', display:{Lore:['[{"text": "arXiv:2011.05189", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSupervised attention for speaker recognition\\u00a7r\\n\\n\\u00a78\\u00a7oSeong Min Kye\\nJoon Son Chung\\nHoirin Kim\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.05189\\u00a7r\\n\\nVersion:\\u00a77v2 (Thu, 3 Dec 2020 14:12:19 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSLT 2021\\u00a7r"}']}
{title:'Fan et al. (§72020§r)', author: 'Cunhang Fan; Bin Liu; Jianhua Tao; Jiangyan Yi; Zhengqi Wen; Leichao Song', display:{Lore:['[{"text": "arXiv:2011.05591", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDeep Time Delay Neural Network for Speech Enhancement with Full Data Learning\\u00a7r\\n\\n\\u00a78\\u00a7oCunhang Fan\\nBin Liu\\nJianhua Tao\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.05591\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 11 Nov 2020 06:32:37 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted by ISCSLP 2021\\u00a7r"}']}
{title:'Suresh et al. (§72020§r)', author: 'Prithvi Suresh; Abhijith Ragav', display:{Lore:['[{"text": "arXiv:2011.05594", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lWaDeNet: Wavelet Decomposition based CNN for Speech Processing\\u00a7r\\n\\n\\u00a78\\u00a7oPrithvi Suresh\\nAbhijith Ragav\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.05594\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 11 Nov 2020 06:43:03 GMT)\\u00a7r"}']}
{title:'Madhumani et al. (§72020§r)', author: 'Gurunath Reddy Madhumani; Yi Yu; Florian Harscoët; Simon Canales; Suhua Tang', display:{Lore:['[{"text": "arXiv:2011.06380", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAutomatic Neural Lyrics and Melody Composition\\u00a7r\\n\\n\\u00a78\\u00a7oGurunath Reddy Madhumani\\nYi Yu\\nFlorian Harsco\\u00ebt\\nSimon Canales\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.06380\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 12 Nov 2020 13:44:01 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o15 pages\\u00a7r"}']}
{title:'Yu et al. (§72020§r)', author: 'Fan Yu; Zhuoyuan Yao; Xiong Wang; Keyu An; Lei Xie; Zhijian Ou; Bo Liu; Xiulin Li; Guanqiong Miao', display:{Lore:['[{"text": "arXiv:2011.06724", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lThe SLT 2021 children speech recognition challenge: Open datasets, rules and baselines\\u00a7r\\n\\n\\u00a78\\u00a7oFan Yu\\nZhuoyuan Yao\\nXiong Wang\\n+ 5 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.06724\\u00a7r\\n\\nVersion:\\u00a77v2 (Mon, 16 Nov 2020 14:07:20 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o7 pages, 3 figures, 3 tables\\u00a7r"}']}
{title:'Ji et al. (§72020§r)', author: 'Shulei Ji; Jing Luo; Xinyu Yang', display:{Lore:['[{"text": "arXiv:2011.06801", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Comprehensive Survey on Deep Music Generation: Multi-level Representations, Algorithms, Evaluations, and Future Directions\\u00a7r\\n\\n\\u00a78\\u00a7oShulei Ji\\nJing Luo\\nXinyu Yang\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.06801\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 13 Nov 2020 08:01:20 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o96 pages,this is a draft\\u00a7r"}']}
{title:'Agrawal et al. (§72020§r)', author: 'Ruchit Agrawal; Simon Dixon', display:{Lore:['[{"text": "arXiv:2011.07546", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.IR\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lLearning Frame Similarity using Siamese networks for Audio-to-Score Alignment\\u00a7r\\n\\n\\u00a78\\u00a7oRuchit Agrawal\\nSimon Dixon\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.07546\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 15 Nov 2020 14:58:03 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted at EUSIPCO 2020\\u00a7r"}']}
{title:'Fonseca et al. (§72020§r)', author: "Eduardo Fonseca; Diego Ortego; Kevin McGuinness; Noel E. O'Connor; Xavier Serra", display:{Lore:['[{"text": "arXiv:2011.07616", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lUnsupervised Contrastive Learning of Sound Event Representations\\u00a7r\\n\\n\\u00a78\\u00a7oEduardo Fonseca\\nDiego Ortego\\nKevin McGuinness\\nNoel E. O\'Connor\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.07616\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 15 Nov 2020 19:50:14 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oA 4-page version is submitted to ICASSP 2021\\u00a7r"}']}
{title:'Xue et al. (§72020§r)', author: 'Heyang Xue; Shan Yang; Yi Lei; Lei Xie; Xiulin Li', display:{Lore:['[{"text": "arXiv:2011.08467", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lLearn2Sing: Target Speaker Singing Voice Synthesis by learning from a Singing Teacher\\u00a7r\\n\\n\\u00a78\\u00a7oHeyang Xue\\nShan Yang\\nYi Lei\\nLei Xie\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.08467\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 17 Nov 2020 06:35:39 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o8 pages, 3 figures\\u00a7r"}']}
{title:'Wang et al. (§72020§r)', author: 'Xiong Wang; Zhuoyuan Yao; Xian Shi; Lei Xie', display:{Lore:['[{"text": "arXiv:2011.08469", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lCascade RNN-Transducer: Syllable Based Streaming On-device Mandarin Speech Recognition with a Syllable-to-Character Converter\\u00a7r\\n\\n\\u00a78\\u00a7oXiong Wang\\nZhuoyuan Yao\\nXian Shi\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.08469\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 17 Nov 2020 06:42:47 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o7 pages, 3 figures, 5 tables\\u00a7r"}']}
{title:'Lei et al. (§72020§r)', author: 'Yi Lei; Shan Yang; Lei Xie', display:{Lore:['[{"text": "arXiv:2011.08477", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lFine-grained Emotion Strength Transfer, Control and Prediction for Emotional Speech Synthesis\\u00a7r\\n\\n\\u00a78\\u00a7oYi Lei\\nShan Yang\\nLei Xie\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.08477\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 17 Nov 2020 07:07:22 GMT)\\u00a7r"}']}
{title:'Du et al. (§72020§r)', author: 'Hongqiang Du; Xiaohai Tian; Lei Xie; Haizhou Li', display:{Lore:['[{"text": "arXiv:2011.08548", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lOptimizing voice conversion network with cycle consistency loss of speaker identity\\u00a7r\\n\\n\\u00a78\\u00a7oHongqiang Du\\nXiaohai Tian\\nLei Xie\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.08548\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 17 Nov 2020 10:27:39 GMT)\\u00a7r"}']}
{title:'Wang et al. (§72020§r)', author: 'Zhichao Wang; Wenshuo Ge; Xiong Wang; Shan Yang; Wendong Gan; Haitao Chen; Hai Li; Lei Xie; Xiulin Li', display:{Lore:['[{"text": "arXiv:2011.08609", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAccent and Speaker Disentanglement in Many-to-many Voice Conversion\\u00a7r\\n\\n\\u00a78\\u00a7oZhichao Wang\\nWenshuo Ge\\nXiong Wang\\n+ 5 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.08609\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 17 Nov 2020 13:07:51 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted to ISCSLP2021\\u00a7r"}']}
{title:'Wang et al. (§72020§r)', author: 'Qing Wang; Wei Rao; Pengcheng Guo; Lei Xie', display:{Lore:['[{"text": "arXiv:2011.08623", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAdversarial Training for Multi-domain Speaker Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oQing Wang\\nWei Rao\\nPengcheng Guo\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.08623\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 17 Nov 2020 13:25:29 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 2 figures\\u00a7r"}']}
{title:'Li et al. (§72020§r)', author: 'Tao Li; Shan Yang; Liumeng Xue; Lei Xie', display:{Lore:['[{"text": "arXiv:2011.08679", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lControllable Emotion Transfer For End-to-End Speech Synthesis\\u00a7r\\n\\n\\u00a78\\u00a7oTao Li\\nShan Yang\\nLiumeng Xue\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.08679\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 17 Nov 2020 14:54:46 GMT)\\u00a7r"}']}
{title:'Zhao et al. (§72020§r)', author: 'Yizhou Zhao; Liang Qiu; Wensi Ai; Feng Shi; Song-Chun Zhu', display:{Lore:['[{"text": "arXiv:2011.09078", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.MM\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lVertical-Horizontal Structured Attention for Generating Music with Chords\\u00a7r\\n\\n\\u00a78\\u00a7oYizhou Zhao\\nLiang Qiu\\nWensi Ai\\nFeng Shi\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.09078\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 18 Nov 2020 04:08:42 GMT)\\u00a7r"}']}
{title:'Kong et al. (§72020§r)', author: 'Yuxiang Kong; Jian Wu; Quandong Wang; Peng Gao; Weiji Zhuang; Yujun Wang; Lei Xie', display:{Lore:['[{"text": "arXiv:2011.09081", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMulti-Channel Automatic Speech Recognition Using Deep Complex Unet\\u00a7r\\n\\n\\u00a78\\u00a7oYuxiang Kong\\nJian Wu\\nQuandong Wang\\n+ 3 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.09081\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 18 Nov 2020 04:17:30 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o7 pages, 4 figures, IEEE SLT 2021 Technical Committee\\u00a7r"}']}
{title:'Jarvis-Holland et al. (§72020§r)', author: 'Quinn Jarvis-Holland; Crystal Cortez; Nathan; Gamill; Francisco Botello', display:{Lore:['[{"text": "arXiv:2011.09143", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.HC\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lExpanding Access to Music Technology \\u2013 Rapid Prototyping Accessible Instrument Solutions For Musicians With Intellectual Disabilities\\u00a7r\\n\\n\\u00a78\\u00a7oQuinn Jarvis-Holland\\nCrystal Cortez\\nNathan\\nGamill\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.09143\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 18 Nov 2020 07:48:12 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oProceedings of the International Conference on New Interfaces for Musical Expression, 2020\\u00a7r"}']}
{title:'Ren et al. (§72020§r)', author: 'Zhao Ren; Qiuqiang Kong; Jing Han; Mark D. Plumbley; Björn W. Schuller', display:{Lore:['[{"text": "arXiv:2011.09299", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lCAA-Net: Conditional Atrous CNNs with Attention for Explainable Device-robust Acoustic Scene Classification\\u00a7r\\n\\n\\u00a78\\u00a7oZhao Ren\\nQiuqiang Kong\\nJing Han\\nMark D. Plumbley\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.09299\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/TMM.2020.3037534\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 18 Nov 2020 14:12:44 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oIEEE Transactions on Multimedia\\u00a7r"}']}
{title:'Wei et al. (§72020§r)', author: 'Kun Wei; Pengcheng Guo; Hang Lv; Zhen Tu; Lei Xie', display:{Lore:['[{"text": "arXiv:2011.09301", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lContext-aware RNNLM Rescoring for Conversational Speech Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oKun Wei\\nPengcheng Guo\\nHang Lv\\nZhen Tu\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.09301\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 18 Nov 2020 14:18:59 GMT)\\u00a7r"}']}
{title:'Singkul et al. (§72020§r)', author: 'Sattaya Singkul; Thakorn Chatchaisathaporn; Boontawee Suntisrivaraporn; Kuntpong Woraratpanya', display:{Lore:['[{"text": "arXiv:2011.09767", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDeep Residual Local Feature Learning for Speech Emotion Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oSattaya Singkul\\nThakorn Chatchaisathaporn\\nBoontawee Suntisrivaraporn\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.09767\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1007/978-3-030-63830-6_21\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 19 Nov 2020 11:04:31 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o12 pages, 5 figures, submitted for review\\u00a7r"}']}
{title:'Qin et al. (§72020§r)', author: 'Xiaoyi Qin; Yaogen Yang; Lin Yang; Xuyang Wang; Junjie Wang; Ming Li', display:{Lore:['[{"text": "arXiv:2011.10710", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lExploring Voice Conversion based Data Augmentation in Text-Dependent Speaker Verification\\u00a7r\\n\\n\\u00a78\\u00a7oXiaoyi Qin\\nYaogen Yang\\nLin Yang\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.10710\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 21 Nov 2020 02:55:47 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to ICASSP2021\\u00a7r"}']}
{title:'Agrawal et al. (§72020§r)', author: 'Manish Agrawal; Abhilash Nandy', display:{Lore:['[{"text": "arXiv:2011.11970", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.IR\\u00a7r, \\u00a7acs.MM\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Novel Multimodal Music Genre Classifier using Hierarchical Attention and Convolutional Neural Network\\u00a7r\\n\\n\\u00a78\\u00a7oManish Agrawal\\nAbhilash Nandy\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.11970\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 24 Nov 2020 09:02:35 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o7 pages, 4 figures\\u00a7r"}']}
{title:'Zhu et al. (§72020§r)', author: 'Junzhe Zhu; Raymond Yeh; Mark Hasegawa-Johnson', display:{Lore:['[{"text": "arXiv:2011.12022", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMulti-Decoder DPRNN: High Accuracy Source Counting and Separation\\u00a7r\\n\\n\\u00a78\\u00a7oJunzhe Zhu\\nRaymond Yeh\\nMark Hasegawa-Johnson\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.12022\\u00a7r\\n\\nVersion:\\u00a77v2 (Mon, 30 Nov 2020 16:56:04 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oProject Page: https://junzhejosephzhu.github.io/Multi-Decoder-DPRNN/ Submitted toICASSP 2021\\u00a7r"}']}
{title:'Huzaifah et al. (§72020§r)', author: 'M. Huzaifah; L. Wyse', display:{Lore:['[{"text": "arXiv:2011.12596", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMTCRNN: A multi-scale RNN for directed audio texture synthesis\\u00a7r\\n\\n\\u00a78\\u00a7oM. Huzaifah\\nL. Wyse\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.12596\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 25 Nov 2020 09:13:53 GMT)\\u00a7r"}']}
{title:'Zhu et al. (§72020§r)', author: 'Xiaoyu Zhu; Hefeng Dong; Pierluigi Salvo Rossi; Martin Landrø', display:{Lore:['[{"text": "arXiv:2011.12754", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.SP\\u00a7r, \\u00a75physics.ao-ph\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lFeature Selection based on Principal Component Analysis for Underwater Source Localization by Deep Learning\\u00a7r\\n\\n\\u00a78\\u00a7oXiaoyu Zhu\\nHefeng Dong\\nPierluigi Salvo Rossi\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.12754\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 25 Nov 2020 14:17:06 GMT)\\u00a7r"}']}
{title:'Vial et al. (§72020§r)', author: 'Pierre-Hugo Vial; Paul Magron; Thomas Oberlin; Cédric Févotte', display:{Lore:['[{"text": "arXiv:2011.12818", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lPhase retrieval with Bregman divergences: Application to audio signal recovery\\u00a7r\\n\\n\\u00a78\\u00a7oPierre-Hugo Vial\\nPaul Magron\\nThomas Oberlin\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.12818\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 25 Nov 2020 15:21:39 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oin Proceedings of iTWIST\'20, Paper-ID: 16, Nantes, France, December, 2-4, 2020\\u00a7r"}']}
{title:'Wu et al. (§72020§r)', author: 'Bichen Wu; Qing He; Peizhao Zhang; Thilo Koehler; Kurt Keutzer; Peter Vajda', display:{Lore:['[{"text": "arXiv:2011.12985", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lFBWave: Efficient and Scalable Neural Vocoders for Streaming Text-To-Speech on the Edge\\u00a7r\\n\\n\\u00a78\\u00a7oBichen Wu\\nQing He\\nPeizhao Zhang\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.12985\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 25 Nov 2020 19:09:49 GMT)\\u00a7r"}']}
{title:'Tokui (§72020§r)', author: 'Nao Tokui', display:{Lore:['[{"text": "arXiv:2011.13062", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.AI\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lCan GAN originate new electronic dance music genres? \\u2013 Generating novel rhythm patterns using GAN with Genre Ambiguity Loss\\u00a7r\\n\\n\\u00a78\\u00a7oNao Tokui\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.13062\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 25 Nov 2020 23:22:12 GMT)\\u00a7r"}']}
{title:'Marinov (§72020§r)', author: 'Georgi Marinov', display:{Lore:['[{"text": "arXiv:2011.13122", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.AI\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lReal-time error correction and performance aid for MIDI instruments\\u00a7r\\n\\n\\u00a78\\u00a7oGeorgi Marinov\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.13122\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 26 Nov 2020 04:28:29 GMT)\\u00a7r"}']}
{title:'Wallace et al. (§72020§r)', author: 'Benedikte Wallace; Charles P. Martin; Jim Torresen; Kristian Nymoen', display:{Lore:['[{"text": "arXiv:2011.13453", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lTowards Movement Generation with Audio Features\\u00a7r\\n\\n\\u00a78\\u00a7oBenedikte Wallace\\nCharles P. Martin\\nJim Torresen\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.13453\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 26 Nov 2020 19:33:08 GMT)\\u00a7r"}']}
{title:'Zhang et al. (§72020§r)', author: 'Peng Zhang; Jiaming Xu; Jing shi; Yunzhe Hao; Bo Xu', display:{Lore:['[{"text": "arXiv:2011.14334", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CV\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAudio-visual Speech Separation with Adversarially Disentangled Visual Representation\\u00a7r\\n\\n\\u00a78\\u00a7oPeng Zhang\\nJiaming Xu\\nJing shi\\nYunzhe Hao\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.14334\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 29 Nov 2020 10:48:42 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 3 figures\\u00a7r"}']}
{title:'Hu et al. (§72020§r)', author: 'Gang Hu; Kejun Wang; Liangliang Liu', display:{Lore:['[{"text": "arXiv:2011.14336", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAn Features Extraction and Recognition Method for Underwater Acoustic Target Based on ATCNN\\u00a7r\\n\\n\\u00a78\\u00a7oGang Hu\\nKejun Wang\\nLiangliang Liu\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.14336\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 29 Nov 2020 11:11:38 GMT)\\u00a7r"}']}
{title:'Deshpande et al. (§72020§r)', author: 'Gauri Deshpande; Björn W. Schuller', display:{Lore:['[{"text": "arXiv:2011.14445", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAudio, Speech, Language,     Signal Processing for COVID-19: A Comprehensive Overview\\u00a7r\\n\\n\\u00a78\\u00a7oGauri Deshpande\\nBj\\u00f6rn W. Schuller\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.14445\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 29 Nov 2020 21:33:59 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oarXiv admin note: text overlapwith arXiv:2005.08579\\u00a7r"}']}
{title:'Kwon et al. (§72020§r)', author: 'Youngki Kwon; Hee Soo Heo; Jaesung Huh; Bong-Jin Lee; Joon Son Chung', display:{Lore:['[{"text": "arXiv:2011.14885", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lLook who\'s not talking\\u00a7r\\n\\n\\u00a78\\u00a7oYoungki Kwon\\nHee Soo Heo\\nJaesung Huh\\nBong-Jin Lee\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.14885\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 30 Nov 2020 15:25:21 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSLT 2021\\u00a7r"}']}
{title:'Martin et al. (§72020§r)', author: 'Charles Martin; Chi-Hsia Lai', display:{Lore:['[{"text": "arXiv:2012.00250", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.HC\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lStrike on Stage: a percussion and media performance\\u00a7r\\n\\n\\u00a78\\u00a7oCharles Martin\\nChi-Hsia Lai\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2012.00250\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.5281/zenodo.1178103\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nProceedings of the International Conference on New Interfaces for\\n  Musical Expression (2011) pp. 142-143\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 1 Dec 2020 04:10:24 GMT)\\u00a7r"}']}
{title:'Martin (§72020§r)', author: 'Charles Martin', display:{Lore:['[{"text": "arXiv:2012.00265", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.HC\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lPerforming with a Mobile Computer System for Vibraphone\\u00a7r\\n\\n\\u00a78\\u00a7oCharles Martin\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2012.00265\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.5281/zenodo.1178602\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nProceedings of the International Conference on New Interfaces for\\n  Musical Expression (2013), pp. 377-380\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 1 Dec 2020 04:57:25 GMT)\\u00a7r"}']}
{title:'Yang et al. (§72020§r)', author: 'Ziye Yang; Shanzheng Guan; Xiao-Lei Zhang', display:{Lore:['[{"text": "arXiv:2012.00403", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDeep Ad-hoc Beamforming Based on Speaker Extraction for Target-Dependent Speech Separation\\u00a7r\\n\\n\\u00a78\\u00a7oZiye Yang\\nShanzheng Guan\\nXiao-Lei Zhang\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2012.00403\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 1 Dec 2020 11:06:36 GMT)\\u00a7r"}']}
{title:'Garcia-Valencia et al. (§72020§r)', author: 'Sebastian Garcia-Valencia; Alejandro Betancourt; Juan G. Lalinde-Pulido', display:{Lore:['[{"text": "arXiv:2012.01231", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSequence Generation using Deep Recurrent Networks and Embeddings: A study case in music\\u00a7r\\n\\n\\u00a78\\u00a7oSebastian Garcia-Valencia\\nAlejandro Betancourt\\nJuan G. Lalinde-Pulido\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2012.01231\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 2 Dec 2020 14:19:19 GMT)\\u00a7r"}']}
{title:'Grezes et al. (§72020§r)', author: 'Felix Grezes; Zhaoheng Ni; Viet Anh Trinh; Michael Mandel', display:{Lore:['[{"text": "arXiv:2012.01576", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lEnhancement of Spatial Clustering-Based Time-Frequency Masks using LSTM Neural Networks\\u00a7r\\n\\n\\u00a78\\u00a7oFelix Grezes\\nZhaoheng Ni\\nViet Anh Trinh\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2012.01576\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 2 Dec 2020 22:29:29 GMT)\\u00a7r"}']}
{title:'Zeng et al. (§72020§r)', author: 'Zhen Zeng; Jianzong Wang; Ning Cheng; Jing Xiao', display:{Lore:['[{"text": "arXiv:2012.01684", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.AI\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMelGlow: Efficient Waveform Generative Network Based on Location-Variable Convolution\\u00a7r\\n\\n\\u00a78\\u00a7oZhen Zeng\\nJianzong Wang\\nNing Cheng\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2012.01684\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 3 Dec 2020 03:43:22 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7owill be presented in SLT 2021\\u00a7r"}']}
{title:'Guo et al. (§72020§r)', author: 'Haohan Guo; Heng Lu; Na Hu; Chunlei Zhang; Shan Yang; Lei Xie; Dan Su; Dong Yu', display:{Lore:['[{"text": "arXiv:2012.01837", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.AI\\u00a7r, \\u00a7acs.MM\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lPhonetic Posteriorgrams based Many-to-Many Singing Voice Conversion via Adversarial Training\\u00a7r\\n\\n\\u00a78\\u00a7oHaohan Guo\\nHeng Lu\\nNa Hu\\n+ 4 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2012.01837\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 3 Dec 2020 11:13:27 GMT)\\u00a7r"}']}
{title:'Ni et al. (§72020§r)', author: 'Zhaoheng Ni; Felix Grezes; Viet Anh Trinh; Michael I. Mandel', display:{Lore:['[{"text": "arXiv:2012.02191", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lImproved MVDR Beamforming Using LSTM Speech Models to Clean Spatial Clustering Masks\\u00a7r\\n\\n\\u00a78\\u00a7oZhaoheng Ni\\nFelix Grezes\\nViet Anh Trinh\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2012.02191\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 2 Dec 2020 22:35:00 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oarXiv admin note: substantial text overlap with arXiv:2012.01576\\u00a7r"}']}
{title:'Fushimi et al. (§72020§r)', author: 'Tatsuki Fushimi; Kenta Yamamoto; Yoichi Ochiai', display:{Lore:['[{"text": "arXiv:2012.02431", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r, \\u00a75physics.app-ph\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAcoustic Hologram Optimisation Using Automatic Differentiation\\u00a7r\\n\\n\\u00a78\\u00a7oTatsuki Fushimi\\nKenta Yamamoto\\nYoichi Ochiai\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2012.02431\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1038/s41598-021-91880-2\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 4 Dec 2020 06:52:22 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o25 pages, 5 figures, manuscript\\u00a7r"}']}
{title:'Abri et al. (§72020§r)', author: 'Faranak Abri; Luis Felipe Gutiérrez; Akbar Siami Namin; David R. W. Sears; Keith S. Jones', display:{Lore:['[{"text": "arXiv:2012.02643", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CV\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lPredicting Emotions Perceived from Sounds\\u00a7r\\n\\n\\u00a78\\u00a7oFaranak Abri\\nLuis Felipe Guti\\u00e9rrez\\nAkbar Siami Namin\\nDavid R. W. Sears\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2012.02643\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 4 Dec 2020 15:01:59 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o10 pages\\u00a7r"}']}
{title:'Comunità et al. (§72020§r)', author: 'Marco Comunità; Dan Stowell; Joshua D. Reiss', display:{Lore:['[{"text": "arXiv:2012.03216", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lGuitar Effects Recognition and Parameter Estimation with Convolutional Neural Networks\\u00a7r\\n\\n\\u00a78\\u00a7oMarco Comunit\\u00e0\\nDan Stowell\\nJoshua D. Reiss\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2012.03216\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.17743/jaes.2021.0019\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nJAES Volume 69 Issue 7/8 pp. 594-604; July 2021\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 6 Dec 2020 08:46:18 GMT)\\u00a7r"}']}
{title:'Mersy et al. (§72020§r)', author: 'Gabriel Mersy; Jin Hong Kuan', display:{Lore:['[{"text": "arXiv:2012.03359", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSource Separation and Depthwise Separable Convolutions for Computer Audition\\u00a7r\\n\\n\\u00a78\\u00a7oGabriel Mersy\\nJin Hong Kuan\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2012.03359\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 6 Dec 2020 19:30:26 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o2 pages, to appear in the AAAI-21 student abstract and poster program\\u00a7r"}']}
{title:'Grezes et al. (§72020§r)', author: 'Felix Grezes; Zhaoheng Ni; Viet Anh Trinh; Michael Mandel', display:{Lore:['[{"text": "arXiv:2012.03388", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lCombining Spatial Clustering with LSTM Speech Models for Multichannel Speech Enhancement\\u00a7r\\n\\n\\u00a78\\u00a7oFelix Grezes\\nZhaoheng Ni\\nViet Anh Trinh\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2012.03388\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 2 Dec 2020 22:37:50 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oarXiv admin note: text overlapwith arXiv:2012.01576, arXiv:2012.02191\\u00a7r"}']}
{title:'Su et al. (§72020§r)', author: 'Kun Su; Xiulong Liu; Eli Shlizerman', display:{Lore:['[{"text": "arXiv:2012.03478", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CV\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMulti-Instrumentalist Net: Unsupervised Generation of Music from Body Movements\\u00a7r\\n\\n\\u00a78\\u00a7oKun Su\\nXiulong Liu\\nEli Shlizerman\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2012.03478\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 7 Dec 2020 06:54:10 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oPleasesee associated video athttps://www.youtube.com/watch?v=yo5OZKBbBh4\\u00a7r"}']}
{title:'Li et al. (§72020§r)', author: 'Xiaofei Li; Laurent Girin; Fabien Badeig; Radu Horaud', display:{Lore:['[{"text": "arXiv:2012.03574", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.RO\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lReverberant Sound Localization with a Robot Head Based on Direct-Path Relative Transfer Function\\u00a7r\\n\\n\\u00a78\\u00a7oXiaofei Li\\nLaurent Girin\\nFabien Badeig\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2012.03574\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/IROS.2016.7759437\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 7 Dec 2020 10:29:40 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oIEEE/RSJ International Conference on Intelligent Robots and Systems,\\u00a7r"}']}
{title:'van der Merwe (§72020§r)', author: 'Ruan van der Merwe', display:{Lore:['[{"text": "arXiv:2012.03775", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CV\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lTriplet Entropy Loss: Improving The Generalisation of Short Speech Language Identification Systems\\u00a7r\\n\\n\\u00a78\\u00a7oRuan van der Merwe\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2012.03775\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 3 Dec 2020 08:20:03 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o22 pages, 26 figures, Codeavailable at https://github.com/ruanvdmerwe/triplet-entropy-loss\\u00a7r"}']}
{title:'Yuan et al. (§72020§r)', author: 'Ruibin Yuan; Ge Zhang; Anqiao Yang; Xinyue Zhang', display:{Lore:['[{"text": "arXiv:2012.03805", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.MM\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDiverse Melody Generation from Chinese Lyrics via Mutual Information Maximization\\u00a7r\\n\\n\\u00a78\\u00a7oRuibin Yuan\\nGe Zhang\\nAnqiao Yang\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2012.03805\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 7 Dec 2020 15:48:01 GMT)\\u00a7r"}']}
{title:'Goodman et al. (§72020§r)', author: 'Tom Goodman; Karoline van Gemst; Peter Tino', display:{Lore:['[{"text": "arXiv:2012.04517", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Geometric Framework for Pitch Estimation on Acoustic Musical Signals\\u00a7r\\n\\n\\u00a78\\u00a7oTom Goodman\\nKaroline van Gemst\\nPeter Tino\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2012.04517\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.13140/RG.2.2.22366.05444\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 8 Dec 2020 16:06:58 GMT)\\u00a7r"}']}
{title:'Turian et al. (§72020§r)', author: 'Joseph Turian; Max Henry', display:{Lore:['[{"text": "arXiv:2012.04572", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.AI\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lI\'m Sorry for Your Loss: Spectrally-Based Audio Distances Are Bad at Pitch\\u00a7r\\n\\n\\u00a78\\u00a7oJoseph Turian\\nMax Henry\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2012.04572\\u00a7r\\n\\nVersion:\\u00a77v2 (Wed, 9 Dec 2020 20:42:50 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oICBINB@NeurIPS 2020\\u00a7r"}']}
{title:'Qian et al. (§72020§r)', author: 'Kun Qian; Bjorn W. Schuller; Yoshiharu Yamamoto', display:{Lore:['[{"text": "arXiv:2012.04650", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lRecent Advances in Computer Audition for Diagnosing COVID-19: An Overview\\u00a7r\\n\\n\\u00a78\\u00a7oKun Qian\\nBjorn W. Schuller\\nYoshiharu Yamamoto\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2012.04650\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 8 Dec 2020 21:39:01 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o2 pages\\u00a7r"}']}
{title:'Sheng et al. (§72020§r)', author: 'Zhonghao Sheng; Kaitao Song; Xu Tan; Yi Ren; Wei Ye; Shikun Zhang; Tao Qin', display:{Lore:['[{"text": "arXiv:2012.05168", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSongMASS: Automatic Song Writing with Pre-training and Alignment Constraint\\u00a7r\\n\\n\\u00a78\\u00a7oZhonghao Sheng\\nKaitao Song\\nXu Tan\\n+ 3 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2012.05168\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 9 Dec 2020 16:56:59 GMT)\\u00a7r"}']}
{title:'Müller et al. (§72020§r)', author: 'Robert Müller; Steffen Illium; Fabian Ritz; Kyrill Schmid', display:{Lore:['[{"text": "arXiv:2012.06282", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAnalysis of Feature Representations for Anomalous Sound Detection\\u00a7r\\n\\n\\u00a78\\u00a7oRobert M\\u00fcller\\nSteffen Illium\\nFabian Ritz\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2012.06282\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.5220/0010226800970106\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 11 Dec 2020 12:31:50 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oICAART 2021, 10 pages, 7 figures, 2 tables\\u00a7r"}']}
{title:'Nagrani et al. (§72020§r)', author: 'Arsha Nagrani; Joon Son Chung; Jaesung Huh; Andrew Brown; Ernesto Coto; Weidi Xie; Mitchell McLaren; Douglas A Reynolds; Andrew Zisserman', display:{Lore:['[{"text": "arXiv:2012.06867", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lVoxSRC 2020: The Second VoxCeleb Speaker Recognition Challenge\\u00a7r\\n\\n\\u00a78\\u00a7oArsha Nagrani\\nJoon Son Chung\\nJaesung Huh\\n+ 5 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2012.06867\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 12 Dec 2020 17:20:57 GMT)\\u00a7r"}']}
{title:'Bartl-Pokorny et al. (§72020§r)', author: 'Katrin D. Bartl-Pokorny; Florian B. Pokorny; Anton Batliner; Shahin Amiriparian; Anastasia Semertzidou; Florian Eyben; Elena Kramer; Florian Schmidt; Rainer Schönweiler; Markus Wehler; Björn W. Schuller', display:{Lore:['[{"text": "arXiv:2012.09478", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lThe voice of COVID-19: Acoustic correlates of infection\\u00a7r\\n\\n\\u00a78\\u00a7oKatrin D. Bartl-Pokorny\\nFlorian B. Pokorny\\nAnton Batliner\\n+ 7 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2012.09478\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1121/10.0005194\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 17 Dec 2020 10:12:41 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o8 pages\\u00a7r"}']}
{title:'Sebastian et al. (§72020§r)', author: 'Arun Sebastian; Manu Francis; Arun Mathew', display:{Lore:['[{"text": "arXiv:2012.10663", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lNon-uniform FIR Digital Filter Bank for Hearing Aid Application Using Frequency Response Masking Technique: A Review\\u00a7r\\n\\n\\u00a78\\u00a7oArun Sebastian\\nManu Francis\\nArun Mathew\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2012.10663\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 19 Dec 2020 11:26:02 GMT)\\u00a7r"}']}
{title:'Ishida et al. (§72020§r)', author: 'Shoma Ishida; Satoshi Ono', display:{Lore:['[{"text": "arXiv:2012.11138", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAdjust-free adversarial example generation in speech recognition using evolutionary multi-objective optimization under black-box condition\\u00a7r\\n\\n\\u00a78\\u00a7oShoma Ishida\\nSatoshi Ono\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2012.11138\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1007/s10015-020-00671-x\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nArtif Life Robotics (2021)\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 22 Dec 2020 15:53:04 GMT)\\u00a7r"}']}
{title:'Elsetrønning et al. (§72020§r)', author: 'Andrine Elsetrønning; Adil Rasheed; Jon Bekker; Omer San', display:{Lore:['[{"text": "arXiv:2012.11759", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lOn the effectiveness of signal decomposition, feature extraction and selection on lung sound classification\\u00a7r\\n\\n\\u00a78\\u00a7oAndrine Elsetr\\u00f8nning\\nAdil Rasheed\\nJon Bekker\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2012.11759\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 22 Dec 2020 00:14:48 GMT)\\u00a7r"}']}
{title:'Pham et al. (§72020§r)', author: 'Lam Pham; Huy Phan; Ross King; Alfred Mertins; Ian McLoughlin', display:{Lore:['[{"text": "arXiv:2012.13699", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lInception-Based Network and Multi-Spectrogram Ensemble Applied For Predicting Respiratory Anomalies and Lung Diseases\\u00a7r\\n\\n\\u00a78\\u00a7oLam Pham\\nHuy Phan\\nRoss King\\nAlfred Mertins\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2012.13699\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 26 Dec 2020 08:25:02 GMT)\\u00a7r"}']}
{title:'Schuller et al. (§72020§r)', author: 'Björn W. Schuller; Harry Coppock; Alexander Gaskell', display:{Lore:['[{"text": "arXiv:2012.14553", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDetecting COVID-19 from Breathing and Coughing Sounds using Deep Neural Networks\\u00a7r\\n\\n\\u00a78\\u00a7oBj\\u00f6rn W. Schuller\\nHarry Coppock\\nAlexander Gaskell\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2012.14553\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 29 Dec 2020 01:14:17 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o6 pages\\u00a7r"}']}
{title:'Rida (§72020§r)', author: 'Imad Rida', display:{Lore:['[{"text": "arXiv:2012.14761", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lData-driven audio recognition: a supervised dictionary approach\\u00a7r\\n\\n\\u00a78\\u00a7oImad Rida\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2012.14761\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 29 Dec 2020 14:21:06 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oarXiv admin note: substantial text overlap with arXiv:1812.04748\\u00a7r"}']}
{title:'Gonzalez-Lopez et al. (§72020§r)', author: 'Jose A. Gonzalez-Lopez; Miriam Gonzalez-Atienza; Alejandro Gomez-Alanis; Jose L. Perez-Cordoba; Phil D. Green', display:{Lore:['[{"text": "arXiv:2012.15184", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMulti-view Temporal Alignment for Non-parallel Articulatory-to-Acoustic Speech Synthesis\\u00a7r\\n\\n\\u00a78\\u00a7oJose A. Gonzalez-Lopez\\nMiriam Gonzalez-Atienza\\nAlejandro Gomez-Alanis\\nJose L. Perez-Cordoba\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2012.15184\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 30 Dec 2020 15:09:02 GMT)\\u00a7r"}']}
{title:'Zhang et al. (§72020§r)', author: 'Yang Zhang; Liqun Deng; Yasheng Wang', display:{Lore:['[{"text": "arXiv:2012.15404", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lUnified Mandarin TTS Front-end Based on Distilled BERT Model\\u00a7r\\n\\n\\u00a78\\u00a7oYang Zhang\\nLiqun Deng\\nYasheng Wang\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2012.15404\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 31 Dec 2020 02:34:57 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages\\u00a7r"}']}
{title:'Rostami et al. (§72020§r)', author: 'Amir Mohammad Rostami; Ali Karimi; Mohammad Ali Akhaee', display:{Lore:['[{"text": "arXiv:2012.15695", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lEfficientNet-Absolute Zero for Continuous Speech Keyword Spotting\\u00a7r\\n\\n\\u00a78\\u00a7oAmir Mohammad Rostami\\nAli Karimi\\nMohammad Ali Akhaee\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2012.15695\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 31 Dec 2020 16:21:27 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o9 pages, 2 figures\\u00a7r"}']}
{title:'Zhen et al. (§72020§r)', author: 'Kai Zhen; Mi Suk Lee; Jongmo Sung; Seungkwon Beack; Minje Kim', display:{Lore:['[{"text": "arXiv:2101.00054", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7acs.SD\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lPsychoacoustic Calibration of Loss Functions for Efficient End-to-End Neural Audio Coding\\u00a7r\\n\\n\\u00a78\\u00a7oKai Zhen\\nMi Suk Lee\\nJongmo Sung\\nSeungkwon Beack\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2101.00054\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/LSP.2020.3039765\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nIEEE Signal Processing Letters, vol. 27, pp. 2159-2163, 2020\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 31 Dec 2020 19:46:46 GMT)\\u00a7r"}']}
