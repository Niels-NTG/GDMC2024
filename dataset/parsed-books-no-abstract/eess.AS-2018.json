{title:'Dieudonné et al. (§72018§r)', author: 'Benjamin Dieudonné; Tom Francart', display:{Lore:['[{"text": "arXiv:1710.01904", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lHead shadow enhancement with low-frequency beamforming improves sound localization and speech perception for simulated bimodal listeners\\u00a7r\\n\\n\\u00a78\\u00a7oBenjamin Dieudonn\\u00e9\\nTom Francart\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1710.01904\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1016/j.heares.2018.03.007\\u00a7r\\n\\nVersion:\\u00a77v2 (Wed, 14 Mar 2018 15:32:58 GMT)\\u00a7r"}']}
{title:'Rohdin et al. (§72018§r)', author: 'Johan Rohdin; Anna Silnova; Mireia Diez; Oldrich Plchot; Pavel Matejka; Lukas Burget', display:{Lore:['[{"text": "arXiv:1710.02369", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lEnd-to-end DNN Based Speaker Recognition Inspired by i-vector and PLDA\\u00a7r\\n\\n\\u00a78\\u00a7oJohan Rohdin\\nAnna Silnova\\nMireia Diez\\n+ 2 others\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1710.02369\\u00a7r\\n\\nVersion:\\u00a77v2 (Mon, 8 Jan 2018 13:17:38 GMT)\\u00a7r"}']}
{title:'Reddy et al. (§72018§r)', author: 'C Sandeep Reddy; Rajesh M Hegde', display:{Lore:['[{"text": "arXiv:1710.08633", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lOn the Conditioning of the Spherical Harmonic Matrix for Spatial Audio Applications\\u00a7r\\n\\n\\u00a78\\u00a7oC Sandeep Reddy\\nRajesh M Hegde\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1710.08633\\u00a7r\\n\\nVersion:\\u00a77v2 (Mon, 5 Mar 2018 20:47:31 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o12 pages; This paper is a preprint of a paper submitted to IET Signal Processing Journal. If accepted, the copy of record will be available at the IET Digital Library\\u00a7r"}']}
{title:'He et al. (§72018§r)', author: 'Di He; Boon Pang Lim; Xuesong Yang; Mark Hasegawa-Johnson; Deming Chen', display:{Lore:['[{"text": "arXiv:1710.09985", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAcoustic Landmarks Contain More Information About the Phone String than Other Frames for Automatic Speech Recognition with Deep Neural Network Acoustic Model\\u00a7r\\n\\n\\u00a78\\u00a7oDi He\\nBoon Pang Lim\\nXuesong Yang\\nMark Hasegawa-Johnson\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1710.09985\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1121/1.5039837\\u00a7r\\n\\nVersion:\\u00a77v2 (Wed, 21 Mar 2018 19:47:03 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oThe article has been submitted to Journal of the Acoustical Society of America\\u00a7r"}']}
{title:'Lin (§72018§r)', author: 'Shoufeng Lin', display:{Lore:['[{"text": "arXiv:1710.10432", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lJointly Tracking and Separating Speech Sources Using Multiple Features and the generalized labeled multi-Bernoulli Framework\\u00a7r\\n\\n\\u00a78\\u00a7oShoufeng Lin\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1710.10432\\u00a7r\\n\\nVersion:\\u00a77v2 (Mon, 16 Apr 2018 09:47:58 GMT)\\u00a7r"}']}
{title:'Chowdhury et al. (§72018§r)', author: 'F A Rezaur Rahman Chowdhury; Quan Wang; Ignacio Lopez Moreno; Li Wan', display:{Lore:['[{"text": "arXiv:1710.10470", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAttention-Based Models for Text-Dependent Speaker Verification\\u00a7r\\n\\n\\u00a78\\u00a7oF A Rezaur Rahman Chowdhury\\nQuan Wang\\nIgnacio Lopez Moreno\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1710.10470\\u00a7r\\n\\nVersion:\\u00a77v3 (Wed, 31 Jan 2018 20:58:17 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to ICASSP 2018\\u00a7r"}']}
{title:'Hua (§72018§r)', author: 'Kanru Hua', display:{Lore:['[{"text": "arXiv:1710.11317", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lNebula: F0 Estimation and Voicing Detection by Modeling the Statistical Properties of Feature Extractors\\u00a7r\\n\\n\\u00a78\\u00a7oKanru Hua\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1710.11317\\u00a7r\\n\\nVersion:\\u00a77v2 (Wed, 6 Jun 2018 11:55:58 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oTo be presented at Interspeech 2018\\u00a7r"}']}
{title:'Toshniwal et al. (§72018§r)', author: 'Shubham Toshniwal; Tara N. Sainath; Ron J. Weiss; Bo Li; Pedro Moreno; Eugene Weinstein; Kanishka Rao', display:{Lore:['[{"text": "arXiv:1711.01694", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.AI\\u00a7r, \\u00a7acs.CL\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMultilingual Speech Recognition With A Single End-To-End Model\\u00a7r\\n\\n\\u00a78\\u00a7oShubham Toshniwal\\nTara N. Sainath\\nRon J. Weiss\\n+ 3 others\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1711.01694\\u00a7r\\n\\nVersion:\\u00a77v2 (Thu, 15 Feb 2018 08:59:27 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted in ICASSP 2018\\u00a7r"}']}
{title:'C et al. (§72018§r)', author: 'Sandeep Reddy C; Rajesh M Hegde', display:{Lore:['[{"text": "arXiv:1711.01872", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMinimum-Phase HRTF Modeling of Pinna Spectral Notches using Group Delay Decomposition\\u00a7r\\n\\n\\u00a78\\u00a7oSandeep Reddy C\\nRajesh M Hegde\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1711.01872\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 3 Apr 2018 17:45:42 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o11 pages; This paper is a preprint of a paper submitted to IET Signal Processing Journal. If accepted, the copy of record will be available at the IET Digital Library\\u00a7r"}']}
{title:'Müller et al. (§72018§r)', author: 'Markus Müller; Sebastian Stüker; Alex Waibel', display:{Lore:['[{"text": "arXiv:1711.04569", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.AI\\u00a7r, \\u00a7acs.CL\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMultilingual Adaptation of RNN Based ASR Systems\\u00a7r\\n\\n\\u00a78\\u00a7oMarkus M\\u00fcller\\nSebastian St\\u00fcker\\nAlex Waibel\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1711.04569\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 27 Feb 2018 13:44:46 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 1 figure, to appear in 2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP 2018)\\u00a7r"}']}
{title:'Letcher et al. (§72018§r)', author: 'Alistair Letcher; Jelena Trišović; Collin Cademartori; Xi Chen; Jason Xu', display:{Lore:['[{"text": "arXiv:1711.05355", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAutomatic Conflict Detection in Police Body-Worn Audio\\u00a7r\\n\\n\\u00a78\\u00a7oAlistair Letcher\\nJelena Tri\\u0161ovi\\u0107\\nCollin Cademartori\\nXi Chen\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1711.05355\\u00a7r\\n\\nVersion:\\u00a77v2 (Wed, 14 Feb 2018 09:04:24 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 2 figures, 1 table\\u00a7r"}']}
{title:'Tong et al. (§72018§r)', author: 'Sibo Tong; Philip N. Garner; Hervé Bourlard', display:{Lore:['[{"text": "arXiv:1711.10025", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMultilingual Training and Cross-lingual Adaptation on CTC-based Acoustic Model\\u00a7r\\n\\n\\u00a78\\u00a7oSibo Tong\\nPhilip N. Garner\\nHerv\\u00e9 Bourlard\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1711.10025\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 23 Jan 2018 14:35:03 GMT)\\u00a7r"}']}
{title:'Silva et al. (§72018§r)', author: 'Nishal Silva; Chathuranga Weeraddana; Carlo Fischione', display:{Lore:['[{"text": "arXiv:1712.02567", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lOn Musical Onset Detection via the S-Transform\\u00a7r\\n\\n\\u00a78\\u00a7oNishal Silva\\nChathuranga Weeraddana\\nCarlo Fischione\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1712.02567\\u00a7r\\n\\nVersion:\\u00a77v2 (Wed, 28 Nov 2018 17:08:57 GMT)\\u00a7r"}']}
{title:'Stöter et al. (§72018§r)', author: 'Fabian-Robert Stöter; Soumitro Chakrabarty; Bernd Edler; Emanuël A. P. Habets', display:{Lore:['[{"text": "arXiv:1712.04555", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lClassification vs. Regression in Supervised Learning for Single Channel Speaker Count Estimation\\u00a7r\\n\\n\\u00a78\\u00a7oFabian-Robert St\\u00f6ter\\nSoumitro Chakrabarty\\nBernd Edler\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1712.04555\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/ICASSP.2018.8462159\\u00a7r\\n\\nVersion:\\u00a77v2 (Thu, 15 Feb 2018 18:41:09 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted in ICASSP 2018\\u00a7r"}']}
{title:'Mangalam et al. (§72018§r)', author: 'Karttikeya Mangalam; Tanaya Guha', display:{Lore:['[{"text": "arXiv:1712.04753", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.HC\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lLearning Spontaneity to Improve Emotion Recognition In Speech\\u00a7r\\n\\n\\u00a78\\u00a7oKarttikeya Mangalam\\nTanaya Guha\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1712.04753\\u00a7r\\n\\nVersion:\\u00a77v3 (Wed, 13 Jun 2018 18:58:29 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted at Interspeech 2018\\u00a7r"}']}
{title:'Meynard et al. (§72018§r)', author: 'Adrien Meynard; Bruno Torrésani', display:{Lore:['[{"text": "arXiv:1712.10252", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a72math.ST\\u00a7r, \\u00a7cstat.TH\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSpectral analysis for nonstationary audio\\u00a7r\\n\\n\\u00a78\\u00a7oAdrien Meynard\\nBruno Torr\\u00e9sani\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1712.10252\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/TASLP.2018.2862353\\u00a7r\\n\\nVersion:\\u00a77v3 (Thu, 23 Aug 2018 13:27:26 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oIEEE/ACM Transactions on Audio, Speech and Language Processing, Institute ofElectrical and Electronics Engineers, In press\\u00a7r"}']}
{title:'Badawy et al. (§72018§r)', author: 'Dalia El Badawy; Ivan Dokmanić', display:{Lore:['[{"text": "arXiv:1801.03740", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDirection of Arrival with One Microphone, a few LEGOs, and Non-Negative Matrix Factorization\\u00a7r\\n\\n\\u00a78\\u00a7oDalia El Badawy\\nIvan Dokmani\\u0107\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1801.03740\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/TASLP.2018.2867081\\u00a7r\\n\\nVersion:\\u00a77v3 (Tue, 28 Aug 2018 13:37:07 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oThis article has been accepted for publication in IEEE/ACM Transactions on Audio, Speech, and Language processing (TASLP)\\u00a7r"}']}
{title:'Chan et al. (§72018§r)', author: 'Tak-Shing T. Chan; Yi-Hsuan Yang', display:{Lore:['[{"text": "arXiv:1801.03815", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.IR\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7eeess.SP\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lInformed Group-Sparse Representation for Singing Voice Separation\\u00a7r\\n\\n\\u00a78\\u00a7oTak-Shing T. Chan\\nYi-Hsuan Yang\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1801.03815\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/LSP.2017.2647810\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nIEEE Signal Process. Lett., vol. 24, no. 2, pp. 156-160, Feb. 2017\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 9 Jan 2018 00:45:30 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 1 figure\\u00a7r"}']}
{title:'Rudresh et al. (§72018§r)', author: 'Sunil Rudresh; Aditya Vasisht; Karthika Vijayan; Chandra Sekhar Seelamantula', display:{Lore:['[{"text": "arXiv:1801.06492", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lEpoch-Synchronous Overlap-Add (ESOLA) for Time- and Pitch-Scale Modification of Speech Signals\\u00a7r\\n\\n\\u00a78\\u00a7oSunil Rudresh\\nAditya Vasisht\\nKarthika Vijayan\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1801.06492\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 19 Jan 2018 17:05:59 GMT)\\u00a7r"}']}
{title:'Escudero et al. (§72018§r)', author: 'Juan Pablo Escudero; Victor Poblete; José Novoa; Jorge Wuth; Josué Fredes; Rodrigo Mahu; Richard Stern; Néstor Becerra Yoma', display:{Lore:['[{"text": "arXiv:1801.09651", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lHighly-Reverberant Real Environment database: HRRE\\u00a7r\\n\\n\\u00a78\\u00a7oJuan Pablo Escudero\\nVictor Poblete\\nJos\\u00e9 Novoa\\n+ 4 others\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1801.09651\\u00a7r\\n\\nVersion:\\u00a77v2 (Fri, 23 Mar 2018 23:23:56 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7ofive pages\\u00a7r"}']}
{title:'Islam et al. (§72018§r)', author: 'Md Tauhidul Islam; Celia Shahnaz; Wei-Ping Zhu; M. Omair Ahmad', display:{Lore:['[{"text": "arXiv:1802.02665", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Divide and Conquer Strategy for Musical Noise-free Speech Enhancement in Adverse Environments\\u00a7r\\n\\n\\u00a78\\u00a7oMd Tauhidul Islam\\nCelia Shahnaz\\nWei-Ping Zhu\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1802.02665\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 7 Feb 2018 22:48:08 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o11 pages, 8 tables, 12 figures\\u00a7r"}']}
{title:'Islam et al. (§72018§r)', author: 'Md Tauhidul Islam; Celia Shahnaz; Wei-Ping Zhu; M. Omair Ahmad', display:{Lore:['[{"text": "arXiv:1802.03472", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lModeling of Teager Energy Operated Perceptual Wavelet Packet Coefficients with an Erlang-2 PDF for Real Time Enhancement of Noisy Speech\\u00a7r\\n\\n\\u00a78\\u00a7oMd Tauhidul Islam\\nCelia Shahnaz\\nWei-Ping Zhu\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1802.03472\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 9 Feb 2018 22:46:15 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oTo appear in Digital Signal Processing, 27 pages, 19 figures, 10 tables\\u00a7r"}']}
{title:'Ma et al. (§72018§r)', author: 'Wei Ma; Xun Liu', display:{Lore:['[{"text": "arXiv:1802.04479", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lPhased Microphone Array for Sound Source Localization with Deep Learning\\u00a7r\\n\\n\\u00a78\\u00a7oWei Ma\\nXun Liu\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1802.04479\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 13 Feb 2018 06:53:48 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o7 pages, 3 figures\\u00a7r"}']}
{title:'Islam et al. (§72018§r)', author: 'Md Tauhidul Islam; Celia Shahnaz; Wei-Ping Zhu; M. Omair Ahmad', display:{Lore:['[{"text": "arXiv:1802.05125", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lEnhancement of Noisy Speech with Low Speech Distortion Based on Probabilistic Geometric Spectral Subtraction\\u00a7r\\n\\n\\u00a78\\u00a7oMd Tauhidul Islam\\nCelia Shahnaz\\nWei-Ping Zhu\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1802.05125\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 13 Feb 2018 01:32:34 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oTo appear in Computer Speech and Language, 16 pages, 13 figures, 8 tables. arXiv admin note:text overlap with arXiv:1802.02665\\u00a7r"}']}
{title:'Drossos et al. (§72018§r)', author: 'Konstantinos Drossos; Stylianos Ioannis Mimilakis; Andreas Floros; Tuomas Virtanen; Gerald Schuller', display:{Lore:['[{"text": "arXiv:1802.05132", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lClose Miking Empirical Practice Verification: A Source Separation Approach\\u00a7r\\n\\n\\u00a78\\u00a7oKonstantinos Drossos\\nStylianos Ioannis Mimilakis\\nAndreas Floros\\nTuomas Virtanen\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1802.05132\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nIn Proceedings of the 142nd Audio Engineering Society Convention,\\n  Berlin, Germany, 2017\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 13 Feb 2018 09:42:46 GMT)\\u00a7r"}']}
{title:'Tukuljac et al. (§72018§r)', author: 'Helena Peić Tukuljac; Thach Pham Vu; Hervé Lissek; Pierre Vandergheynst', display:{Lore:['[{"text": "arXiv:1802.05879", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CV\\u00a7r, \\u00a7eeess.SP\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lJoint Estimation of Room Geometry and Modes with Compressed Sensing\\u00a7r\\n\\n\\u00a78\\u00a7oHelena Pei\\u0107 Tukuljac\\nThach Pham Vu\\nHerv\\u00e9 Lissek\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1802.05879\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 16 Feb 2018 09:41:56 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 4 figures\\u00a7r"}']}
{title:'Islam et al. (§72018§r)', author: 'Md Tauhidul Islam; Celia Shahnaz; Wei-Ping Zhu; M. Omair Ahmad', display:{Lore:['[{"text": "arXiv:1802.05962", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lEnhancement of Noisy Speech Exploiting an Exponential Model Based Threshold and a Custom Thresholding Function in Perceptual Wavelet Packet Domain\\u00a7r\\n\\n\\u00a78\\u00a7oMd Tauhidul Islam\\nCelia Shahnaz\\nWei-Ping Zhu\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1802.05962\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 15 Feb 2018 02:35:37 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to Circuits, Systems and Signal Processing, 17 pages, 20 figures, 8 tables. arXiv admin note:text overlap with arXiv:1802.03472\\u00a7r"}']}
{title:'Kim et al. (§72018§r)', author: 'Jong Wook Kim; Justin Salamon; Peter Li; Juan Pablo Bello', display:{Lore:['[{"text": "arXiv:1802.06182", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lCREPE: A Convolutional Representation for Pitch Estimation\\u00a7r\\n\\n\\u00a78\\u00a7oJong Wook Kim\\nJustin Salamon\\nPeter Li\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1802.06182\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 17 Feb 2018 03:50:11 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oICASSP 2018\\u00a7r"}']}
{title:'Xiang et al. (§72018§r)', author: 'Teng Xiang; Jing Lu; Kai Chen', display:{Lore:['[{"text": "arXiv:1802.08997", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lRLS-Based Adaptive Dereverberation Tracing Abrupt Position Change of Target Speaker\\u00a7r\\n\\n\\u00a78\\u00a7oTeng Xiang\\nJing Lu\\nKai Chen\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1802.08997\\u00a7r\\n\\nVersion:\\u00a77v3 (Thu, 23 Aug 2018 05:19:07 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted by 2018 IEEE Sensor Array and Multichannel Signal Processing Workshop (SAM)\\u00a7r"}']}
{title:'Wang et al. (§72018§r)', author: 'Zelin Wang; Jing Lu; Kai chen', display:{Lore:['[{"text": "arXiv:1802.09005", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lFrequency domain TRINICON-based blind source separation method with multi-source activity detection for sparsely mixed signals\\u00a7r\\n\\n\\u00a78\\u00a7oZelin Wang\\nJing Lu\\nKai chen\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1802.09005\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 25 Feb 2018 13:44:52 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oThis article has been submitted to 2018 IEEE Sensor Array and Multichannel Signal Processing Workshop (SAM)\\u00a7r"}']}
{title:'Laufer-Goldshtein et al. (§72018§r)', author: 'Bracha Laufer-Goldshtein; Ronen Talmon; Sharon Gannot', display:{Lore:['[{"text": "arXiv:1802.09221", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7eeess.SP\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lData-Driven Source Separation Based on Simplex Analysis\\u00a7r\\n\\n\\u00a78\\u00a7oBracha Laufer-Goldshtein\\nRonen Talmon\\nSharon Gannot\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1802.09221\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 26 Feb 2018 09:51:26 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7osubmitted to IEEETransactions on Signal Processing\\u00a7r"}']}
{title:'Huang et al. (§72018§r)', author: 'Yu-Siang Huang; Szu-Yu Chou; Yi-Hsuan Yang', display:{Lore:['[{"text": "arXiv:1802.10495", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.AI\\u00a7r, \\u00a7acs.MM\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lPop Music Highlighter: Marking the Emotion Keypoints\\u00a7r\\n\\n\\u00a78\\u00a7oYu-Siang Huang\\nSzu-Yu Chou\\nYi-Hsuan Yang\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1802.10495\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.5334/tismir.14\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 25 Sep 2018 18:34:47 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oTransactions of the ISMIR vol. 1, no. 1\\u00a7r"}']}
{title:'Islam et al. (§72018§r)', author: 'Md Tauhidul Islam; Asaduzzaman; Celia Shahnaz; Wei-Ping Zhu; M. Omair Ahmad', display:{Lore:['[{"text": "arXiv:1803.00396", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSpeech Enhancement in Adverse Environments Based on Non-stationary Noise-driven Spectral Subtraction and SNR-dependent Phase Compensation\\u00a7r\\n\\n\\u00a78\\u00a7oMd Tauhidul Islam\\nAsaduzzaman\\nCelia Shahnaz\\nWei-Ping Zhu\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1803.00396\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 19 Feb 2018 03:57:15 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o15 pages, 10 figures, 8 tables. arXiv admin note:substantial text overlap with arXiv:1802.02665; text overlap with arXiv:1802.05125\\u00a7r"}']}
{title:'Lorenzo-Trueba et al. (§72018§r)', author: 'Jaime Lorenzo-Trueba; Fuming Fang; Xin Wang; Isao Echizen; Junichi Yamagishi; Tomi Kinnunen', display:{Lore:['[{"text": "arXiv:1803.00860", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lCan we steal your vocal identity from the Internet?: Initial investigation of cloning Obama\'s voice using GAN, WaveNet and low-quality found data\\u00a7r\\n\\n\\u00a78\\u00a7oJaime Lorenzo-Trueba\\nFuming Fang\\nXin Wang\\n+ 2 others\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1803.00860\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 2 Mar 2018 14:21:16 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oconference manuscript submitted toSpeaker Odyssey 2018\\u00a7r"}']}
{title:'Li et al. (§72018§r)', author: 'Lantian Li; Dong Wang; Yixiang Chen; Ying Shi; Zhiyuan Tang; Thomas Fang Zheng', display:{Lore:['[{"text": "arXiv:1803.00886", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDeep factorization for speech signal\\u00a7r\\n\\n\\u00a78\\u00a7oLantian Li\\nDong Wang\\nYixiang Chen\\n+ 2 others\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1803.00886\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 27 Feb 2018 12:45:16 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted by ICASSP 2018. arXiv admin note: substantial text overlap with arXiv:1706.01777\\u00a7r"}']}
{title:'Tao et al. (§72018§r)', author: 'Fei Tao; Gang Liu; Qingen Zhao', display:{Lore:['[{"text": "arXiv:1803.01122", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAn Ensemble Framework of Voice-Based Emotion Recognition System for Films and TV Programs\\u00a7r\\n\\n\\u00a78\\u00a7oFei Tao\\nGang Liu\\nQingen Zhao\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1803.01122\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 3 Mar 2018 08:17:12 GMT)\\u00a7r"}']}
{title:'Islam et al. (§72018§r)', author: 'Md Tauhidul Islam; Celia Shahnaz', display:{Lore:['[{"text": "arXiv:1803.01841", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lEnhancement of Noisy Speech exploiting a Gaussian Modeling based Threshold and a PDF Dependent Thresholding Function\\u00a7r\\n\\n\\u00a78\\u00a7oMd Tauhidul Islam\\nCelia Shahnaz\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1803.01841\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 3 Mar 2018 05:55:59 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o22 pages, 18 figures, 8 tables; submitted to EURASIP Journal on Audio, Speech, and Music Processing. arXivadmin note: substantial text overlap with arXiv:1802.05962; text overlap with arXiv:1802.03472\\u00a7r"}']}
{title:'Yu et al. (§72018§r)', author: 'Changsong Yu; Karim Said Barsim; Qiuqiang Kong; Bin Yang', display:{Lore:['[{"text": "arXiv:1803.02353", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMulti-level Attention Model for Weakly Supervised Audio Classification\\u00a7r\\n\\n\\u00a78\\u00a7oChangsong Yu\\nKarim Said Barsim\\nQiuqiang Kong\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1803.02353\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 6 Mar 2018 15:59:21 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 3 figures, Submitted to Eusipco 2018\\u00a7r"}']}
{title:'Huang et al. (§72018§r)', author: 'Zhiying Huang; Heng Lu; Ming Lei; Zhijie Yan', display:{Lore:['[{"text": "arXiv:1803.02445", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lLinear networks based speaker adaptation for speech synthesis\\u00a7r\\n\\n\\u00a78\\u00a7oZhiying Huang\\nHeng Lu\\nMing Lei\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1803.02445\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 5 Mar 2018 05:35:34 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 6 figures, accepted by ICASSP 2018\\u00a7r"}']}
{title:'Islam et al. (§72018§r)', author: 'Md Tauhidul Islam; Udoy Saha; K. T. Shahid; Ahmed Bin Hussain; Celia Shahnaz', display:{Lore:['[{"text": "arXiv:1803.02870", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSpeech Enhancement Based on Non-stationary Noise-driven Geometric Spectral Subtraction and Phase Spectrum Compensation\\u00a7r\\n\\n\\u00a78\\u00a7oMd Tauhidul Islam\\nUdoy Saha\\nK. T. Shahid\\nAhmed Bin Hussain\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1803.02870\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 3 Mar 2018 05:57:11 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o13 pages, 10 figures, 8 tables. arXiv admin note:substantial text overlap with arXiv:1803.00396; text overlap with arXiv:1802.02665, arXiv:1802.05125, arXiv:1803.01841\\u00a7r"}']}
{title:'Hua (§72018§r)', author: 'Kanru Hua', display:{Lore:['[{"text": "arXiv:1803.04030", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lModeling Singing F0 With Neural Network Driven Transition-Sustain Models\\u00a7r\\n\\n\\u00a78\\u00a7oKanru Hua\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1803.04030\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 11 Mar 2018 19:55:02 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 5 figures\\u00a7r"}']}
{title:'Novoselov et al. (§72018§r)', author: 'Sergey Novoselov; Oleg Kudashev; Vadim Schemelinin; Ivan Kremnev; Galina Lavrentyeva', display:{Lore:['[{"text": "arXiv:1803.05307", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDeep CNN based feature extractor for text-prompted speaker recognition\\u00a7r\\n\\n\\u00a78\\u00a7oSergey Novoselov\\nOleg Kudashev\\nVadim Schemelinin\\nIvan Kremnev\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1803.05307\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 13 Mar 2018 10:59:24 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to ICASSP 2018\\u00a7r"}']}
{title:'Salehghaffari (§72018§r)', author: 'Hossein Salehghaffari', display:{Lore:['[{"text": "arXiv:1803.05427", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSpeaker Verification using Convolutional Neural Networks\\u00a7r\\n\\n\\u00a78\\u00a7oHossein Salehghaffari\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1803.05427\\u00a7r\\n\\nVersion:\\u00a77v2 (Fri, 10 Aug 2018 17:45:24 GMT)\\u00a7r"}']}
{title:'Kleijn (§72018§r)', author: 'W. Bastiaan Kleijn', display:{Lore:['[{"text": "arXiv:1803.06718", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDirectional emphasis in ambisonics\\u00a7r\\n\\n\\u00a78\\u00a7oW. Bastiaan Kleijn\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1803.06718\\u00a7r\\n\\nVersion:\\u00a77v2 (Thu, 24 May 2018 08:56:03 GMT)\\u00a7r"}']}
{title:'Novoa et al. (§72018§r)', author: 'José Novoa; Juan Pablo Escudero; Jorge Wuth; Victor Poblete; Simon King; Richard Stern; Néstor Becerra Yoma', display:{Lore:['[{"text": "arXiv:1803.09013", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lExploring the robustness of features and enhancement on speech recognition systems in highly-reverberant real environments\\u00a7r\\n\\n\\u00a78\\u00a7oJos\\u00e9 Novoa\\nJuan Pablo Escudero\\nJorge Wuth\\n+ 3 others\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1803.09013\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 23 Mar 2018 23:31:25 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages\\u00a7r"}']}
{title:'Escudero et al. (§72018§r)', author: 'Juan Pablo Escudero; José Novoa; Rodrigo Mahu; Jorge Wuth; Fernando Huenupán; Richard Stern; Néstor Becerra Yoma', display:{Lore:['[{"text": "arXiv:1803.09016", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAn improved DNN-based spectral feature mapping that removes noise and reverberation for robust automatic speech recognition\\u00a7r\\n\\n\\u00a78\\u00a7oJuan Pablo Escudero\\nJos\\u00e9 Novoa\\nRodrigo Mahu\\n+ 3 others\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1803.09016\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 3 Apr 2018 18:07:06 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages\\u00a7r"}']}
{title:'Nakashika et al. (§72018§r)', author: 'Toru Nakashika; Shinji Takaki; Junichi Yamagishi', display:{Lore:['[{"text": "arXiv:1803.09946", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lComplex-Valued Restricted Boltzmann Machine for Direct Speech Parameterization from Complex Spectra\\u00a7r\\n\\n\\u00a78\\u00a7oToru Nakashika\\nShinji Takaki\\nJunichi Yamagishi\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1803.09946\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 27 Mar 2018 08:07:20 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oUnder the IEEE T-ASLP Review\\u00a7r"}']}
{title:'Subramanian et al. (§72018§r)', author: 'Aswin Shanmugam Subramanian; Szu-Jui Chen; Shinji Watanabe', display:{Lore:['[{"text": "arXiv:1803.10013", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lStudent-Teacher Learning for BLSTM Mask-based Speech Enhancement\\u00a7r\\n\\n\\u00a78\\u00a7oAswin Shanmugam Subramanian\\nSzu-Jui Chen\\nShinji Watanabe\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1803.10013\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 27 Mar 2018 10:55:42 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted for Interspeech 2018\\u00a7r"}']}
{title:'Nahid et al. (§72018§r)', author: 'Md Mahadi Hasan Nahid; Md. Ashraful Islam; Bishwajit Purkaystha; Md Saiful Islam', display:{Lore:['[{"text": "arXiv:1803.10136", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.AI\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lComprehending Real Numbers: Development of Bengali Real Number Speech Corpus\\u00a7r\\n\\n\\u00a78\\u00a7oMd Mahadi Hasan Nahid\\nMd. Ashraful Islam\\nBishwajit Purkaystha\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1803.10136\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 27 Mar 2018 15:27:07 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o9 pages\\u00a7r"}']}
{title:'Ravanelli et al. (§72018§r)', author: 'Mirco Ravanelli; Philemon Brakel; Maurizio Omologo; Yoshua Bengio', display:{Lore:['[{"text": "arXiv:1803.10225", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.NE\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7eeess.SP\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lLight Gated Recurrent Units for Speech Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oMirco Ravanelli\\nPhilemon Brakel\\nMaurizio Omologo\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1803.10225\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/TETCI.2017.2762739\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nIEEE Transactions on Emerging Topics in Computational\\n  Intelligence, vol. 2, no. 2, pp. 92-102, April 2018\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 26 Mar 2018 17:48:18 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oCopyright 2018 IEEE\\u00a7r"}']}
{title:'Warnita et al. (§72018§r)', author: 'Tifani Warnita; Nakamasa Inoue; Koichi Shinoda', display:{Lore:['[{"text": "arXiv:1803.11344", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDetecting Alzheimer\'s Disease Using Gated Convolutional Neural Network from Audio Data\\u00a7r\\n\\n\\u00a78\\u00a7oTifani Warnita\\nNakamasa Inoue\\nKoichi Shinoda\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1803.11344\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 30 Mar 2018 05:33:05 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 3 figures, submitted to INTERSPEECH 2018\\u00a7r"}']}
{title:'Zhang et al. (§72018§r)', author: 'Jiacen Zhang; Nakamasa Inoue; Koichi Shinoda', display:{Lore:['[{"text": "arXiv:1804.00290", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lI-vector Transformation Using Conditional Generative Adversarial Networks for Short Utterance Speaker Verification\\u00a7r\\n\\n\\u00a78\\u00a7oJiacen Zhang\\nNakamasa Inoue\\nKoichi Shinoda\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1804.00290\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 1 Apr 2018 12:36:03 GMT)\\u00a7r"}']}
{title:'Cai et al. (§72018§r)', author: 'Weicheng Cai; Zexin Cai; Wenbo Liu; Xiaoqi Wang; Ming Li', display:{Lore:['[{"text": "arXiv:1804.00381", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lInsights into End-to-End Learning Scheme for Language Identification\\u00a7r\\n\\n\\u00a78\\u00a7oWeicheng Cai\\nZexin Cai\\nWenbo Liu\\nXiaoqi Wang\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1804.00381\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 2 Apr 2018 03:19:44 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oICASSP 2018 conference paper\\u00a7r"}']}
{title:'Cai et al. (§72018§r)', author: 'Weicheng Cai; Zexin Cai; Xiang Zhang; Xiaoqi Wang; Ming Li', display:{Lore:['[{"text": "arXiv:1804.00385", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Novel Learnable Dictionary Encoding Layer for End-to-End Language Identification\\u00a7r\\n\\n\\u00a78\\u00a7oWeicheng Cai\\nZexin Cai\\nXiang Zhang\\nXiaoqi Wang\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1804.00385\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 2 Apr 2018 03:31:01 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oICASSP 2018 conference paper\\u00a7r"}']}
{title:'Fang et al. (§72018§r)', author: 'Fuming Fang; Junichi Yamagishi; Isao Echizen; Jaime Lorenzo-Trueba', display:{Lore:['[{"text": "arXiv:1804.00425", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lHigh-quality nonparallel voice conversion based on cycle-consistent adversarial network\\u00a7r\\n\\n\\u00a78\\u00a7oFuming Fang\\nJunichi Yamagishi\\nIsao Echizen\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1804.00425\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 2 Apr 2018 07:58:23 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oaccepted at ICASSP 2018\\u00a7r"}']}
{title:'Juvela et al. (§72018§r)', author: 'Lauri Juvela; Bajibabu Bollepalli; Xin Wang; Hirokazu Kameoka; Manu Airaksinen; Junichi Yamagishi; Paavo Alku', display:{Lore:['[{"text": "arXiv:1804.00920", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSpeech waveform synthesis from MFCC sequences with generative adversarial networks\\u00a7r\\n\\n\\u00a78\\u00a7oLauri Juvela\\nBajibabu Bollepalli\\nXin Wang\\n+ 3 others\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1804.00920\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 3 Apr 2018 11:43:36 GMT)\\u00a7r"}']}
{title:'Wang et al. (§72018§r)', author: 'Xin Wang; Jaime Lorenzo-Trueba; Shinji Takaki; Lauri Juvela; Junichi Yamagishi', display:{Lore:['[{"text": "arXiv:1804.02549", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA comparison of recent waveform generation and acoustic modeling methods for neural-network-based speech synthesis\\u00a7r\\n\\n\\u00a78\\u00a7oXin Wang\\nJaime Lorenzo-Trueba\\nShinji Takaki\\nLauri Juvela\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1804.02549\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 7 Apr 2018 12:16:50 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oTo appear in ICASSP 2018\\u00a7r"}']}
{title:'Chou et al. (§72018§r)', author: 'Ju-chieh Chou; Cheng-chieh Yeh; Hung-yi Lee; Lin-shan Lee', display:{Lore:['[{"text": "arXiv:1804.02812", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMulti-target Voice Conversion without Parallel Data by Adversarially Learning Disentangled Audio Representations\\u00a7r\\n\\n\\u00a78\\u00a7oJu-chieh Chou\\nCheng-chieh Yeh\\nHung-yi Lee\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1804.02812\\u00a7r\\n\\nVersion:\\u00a77v2 (Sun, 24 Jun 2018 18:11:02 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted to Interspeech 2018\\u00a7r"}']}
{title:'Lorenzo-Trueba et al. (§72018§r)', author: 'Jaime Lorenzo-Trueba; Junichi Yamagishi; Tomoki Toda; Daisuke Saito; Fernando Villavicencio; Tomi Kinnunen; Zhenhua Ling', display:{Lore:['[{"text": "arXiv:1804.04262", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lThe Voice Conversion Challenge 2018: Promoting Development of Parallel and Nonparallel Methods\\u00a7r\\n\\n\\u00a78\\u00a7oJaime Lorenzo-Trueba\\nJunichi Yamagishi\\nTomoki Toda\\n+ 3 others\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1804.04262\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 12 Apr 2018 00:14:10 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted for Speaker Odyssey 2018\\u00a7r"}']}
{title:'Aralikatti et al. (§72018§r)', author: 'Rohith Aralikatti; Dilip Margam; Tanay Sharma; Thanda Abhinav; Shankar M Venkatesan', display:{Lore:['[{"text": "arXiv:1804.04353", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.AI\\u00a7r, \\u00a7eeess.SP\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lGlobal SNR Estimation of Speech Signals using Entropy and Uncertainty Estimates from Dropout Networks\\u00a7r\\n\\n\\u00a78\\u00a7oRohith Aralikatti\\nDilip Margam\\nTanay Sharma\\nThanda Abhinav\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1804.04353\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 12 Apr 2018 07:15:20 GMT)\\u00a7r"}']}
{title:'Sarma et al. (§72018§r)', author: 'Mousmita Sarma; Kandarpa Kumar Sarma; Nagendra Kumar Goel', display:{Lore:['[{"text": "arXiv:1804.05000", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lLanguage Recognition using Time Delay Deep Neural Network\\u00a7r\\n\\n\\u00a78\\u00a7oMousmita Sarma\\nKandarpa Kumar Sarma\\nNagendra Kumar Goel\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1804.05000\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 13 Apr 2018 15:43:59 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 1 figure, 1 table\\u00a7r"}']}
{title:'Cai et al. (§72018§r)', author: 'Weicheng Cai; Jinkun Chen; Ming Li', display:{Lore:['[{"text": "arXiv:1804.05160", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lExploring the Encoding Layer and Loss Function in End-to-End Speaker and Language Recognition System\\u00a7r\\n\\n\\u00a78\\u00a7oWeicheng Cai\\nJinkun Chen\\nMing Li\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1804.05160\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 14 Apr 2018 03:52:46 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted for Speaker Odyssey 2018\\u00a7r"}']}
{title:'Ravanelli et al. (§72018§r)', author: 'Mirco Ravanelli; Dmitriy Serdyuk; Yoshua Bengio', display:{Lore:['[{"text": "arXiv:1804.05374", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.AI\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.NE\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lTwin Regularization for online speech recognition\\u00a7r\\n\\n\\u00a78\\u00a7oMirco Ravanelli\\nDmitriy Serdyuk\\nYoshua Bengio\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1804.05374\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 12 Jun 2018 01:00:03 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted at INTESPEECH 2018\\u00a7r"}']}
{title:'Turan (§72018§r)', author: 'Mehmet Ali Tugtekin Turan', display:{Lore:['[{"text": "arXiv:1804.05937", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7eeess.SP\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lEnhancement of Throat Microphone Recordings Using Gaussian Mixture Model Probabilistic Estimator\\u00a7r\\n\\n\\u00a78\\u00a7oMehmet Ali Tugtekin Turan\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1804.05937\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 13 Apr 2018 13:05:01 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oM.Sc. Thesis\\u00a7r"}']}
{title:'Roy et al. (§72018§r)', author: 'Tanmoy Roy; Tshilidzi Marwala; Snehashish Chakraverty', display:{Lore:['[{"text": "arXiv:1804.06159", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lPrecise Detection of Speech Endpoints Dynamically: A Wavelet Convolution based approach\\u00a7r\\n\\n\\u00a78\\u00a7oTanmoy Roy\\nTshilidzi Marwala\\nSnehashish Chakraverty\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1804.06159\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1016/j.cnsns.2018.07.008\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 17 Apr 2018 10:53:30 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o25 Pages\\u00a7r"}']}
{title:'Stöter et al. (§72018§r)', author: 'Fabian-Robert Stöter; Antoine Liutkus; Nobutaka Ito', display:{Lore:['[{"text": "arXiv:1804.06267", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lThe 2018 Signal Separation Evaluation Campaign\\u00a7r\\n\\n\\u00a78\\u00a7oFabian-Robert St\\u00f6ter\\nAntoine Liutkus\\nNobutaka Ito\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1804.06267\\u00a7r\\n\\nVersion:\\u00a77v3 (Fri, 6 Jul 2018 08:30:29 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oTo appear in InternationalConference on Latent Variable Analysis and Signal Separation\\u00a7r"}']}
{title:'Abdelwahab et al. (§72018§r)', author: 'Mohammed Abdelwahab; Carlos Busso', display:{Lore:['[{"text": "arXiv:1804.07690", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDomain Adversarial for Acoustic Emotion Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oMohammed Abdelwahab\\nCarlos Busso\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1804.07690\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/TASLP.2018.2867099\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nIEEE/ACM Transactions on Audio, Speech, and Language Processing,\\n  vol. 26, no. 12, pp. 2423-2435, December 2018\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 20 Apr 2018 15:49:38 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7osubmitted to IEEEtransactions on signal processing\\u00a7r"}']}
{title:'Kinnunen et al. (§72018§r)', author: 'Tomi Kinnunen; Jaime Lorenzo-Trueba; Junichi Yamagishi; Tomoki Toda; Daisuke Saito; Fernando Villavicencio; Zhenhua Ling', display:{Lore:['[{"text": "arXiv:1804.08438", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Spoofing Benchmark for the 2018 Voice Conversion Challenge: Leveraging from Spoofing Countermeasures for Speech Artifact Assessment\\u00a7r\\n\\n\\u00a78\\u00a7oTomi Kinnunen\\nJaime Lorenzo-Trueba\\nJunichi Yamagishi\\n+ 3 others\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1804.08438\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 4 Sep 2018 17:14:57 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oCorrection (bug fix) of a published ODYSSEY 2018 publication with the same title and author list; more details in footnote in page 1\\u00a7r"}']}
{title:'Willi et al. (§72018§r)', author: 'Megan M. Willi; Stephanie A. Borrie; Tyson S. Barrett; Ming Tu; Visar Berisha', display:{Lore:['[{"text": "arXiv:1804.08663", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Discriminative Acoustic-Prosodic Approach for Measuring Local Entrainment\\u00a7r\\n\\n\\u00a78\\u00a7oMegan M. Willi\\nStephanie A. Borrie\\nTyson S. Barrett\\nMing Tu\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1804.08663\\u00a7r\\n\\nVersion:\\u00a77v2 (Thu, 12 Jul 2018 15:42:29 GMT)\\u00a7r"}']}
{title:'Nasir et al. (§72018§r)', author: 'Md Nasir; Brian Baucom; Shrikanth Narayanan; Panayiotis Georgiou', display:{Lore:['[{"text": "arXiv:1804.08782", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lTowards an Unsupervised Entrainment Distance in Conversational Speech using Deep Neural Networks\\u00a7r\\n\\n\\u00a78\\u00a7oMd Nasir\\nBrian Baucom\\nShrikanth Narayanan\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1804.08782\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.21437/Interspeech.2018-1395\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 23 Apr 2018 23:45:30 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7osubmitted to Interspeech 2018\\u00a7r"}']}
{title:'Yu et al. (§72018§r)', author: 'Dong Yu; Jinyu Li', display:{Lore:['[{"text": "arXiv:1804.09298", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lRecent Progresses in Deep Learning based Acoustic Models (Updated)\\u00a7r\\n\\n\\u00a78\\u00a7oDong Yu\\nJinyu Li\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1804.09298\\u00a7r\\n\\nVersion:\\u00a77v2 (Fri, 27 Apr 2018 01:13:39 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oThis is an updated version withlatest literature until ICASSP2018 of the paper: Dong Yu and Jinyu Li, \\"Recent Progresses in Deep Learning based Acoustic Models,\\" vol.4, no.3, IEEE/CAA Journal of Automatica Sinica, "}','{"text": "2017\\u00a7r"}']}
{title:'Juvela et al. (§72018§r)', author: 'Lauri Juvela; Vassilis Tsiaras; Bajibabu Bollepalli; Manu Airaksinen; Junichi Yamagishi; Paavo Alku', display:{Lore:['[{"text": "arXiv:1804.09593", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSpeaker-independent raw waveform model for glottal excitation\\u00a7r\\n\\n\\u00a78\\u00a7oLauri Juvela\\nVassilis Tsiaras\\nBajibabu Bollepalli\\n+ 2 others\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1804.09593\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 25 Apr 2018 14:29:08 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to Interspeech 2018\\u00a7r"}']}
{title:'Palaskar et al. (§72018§r)', author: 'Shruti Palaskar; Ramon Sanabria; Florian Metze', display:{Lore:['[{"text": "arXiv:1804.09713", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lEnd-to-End Multimodal Speech Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oShruti Palaskar\\nRamon Sanabria\\nFlorian Metze\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1804.09713\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 25 Apr 2018 22:54:06 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 5 figures, Accepted at IEEE International Conference on Acoustics, Speech and Signal Processing 2018(ICASSP 2018)\\u00a7r"}']}
{title:'Jiao et al. (§72018§r)', author: 'Yishan Jiao; Ming Tu; Visar Berisha; Julie Liss', display:{Lore:['[{"text": "arXiv:1804.10325", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSimulating dysarthric speech for training data augmentation in clinical speech applications\\u00a7r\\n\\n\\u00a78\\u00a7oYishan Jiao\\nMing Tu\\nVisar Berisha\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1804.10325\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 27 Apr 2018 02:20:24 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oWill appear in Proc. of ICASSP 2018\\u00a7r"}']}
{title:'Zhou et al. (§72018§r)', author: 'Shiyu Zhou; Linhao Dong; Shuang Xu; Bo Xu', display:{Lore:['[{"text": "arXiv:1804.10752", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSyllable-Based Sequence-to-Sequence Speech Recognition with the Transformer in Mandarin Chinese\\u00a7r\\n\\n\\u00a78\\u00a7oShiyu Zhou\\nLinhao Dong\\nShuang Xu\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1804.10752\\u00a7r\\n\\nVersion:\\u00a77v2 (Mon, 4 Jun 2018 07:46:02 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oaccepted by INTERSPEECH2018\\u00a7r"}']}
{title:'Parthasarathy et al. (§72018§r)', author: 'Srinivas Parthasarathy; Carlos Busso', display:{Lore:['[{"text": "arXiv:1804.10816", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lLadder Networks for Emotion Recognition: Using Unsupervised Auxiliary Tasks to Improve Predictions of Emotional Attributes\\u00a7r\\n\\n\\u00a78\\u00a7oSrinivas Parthasarathy\\nCarlos Busso\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1804.10816\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.21437/Interspeech.2018-1391\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nInterspeech 2018, Hyderabad, India, September 2018, pp. 3698-3702\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 28 Apr 2018 15:08:41 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to Interspeech 2018\\u00a7r"}']}
{title:'Wu et al. (§72018§r)', author: 'Yi-Chiao Wu; Kazuhiro Kobayashi; Tomoki Hayashi; Patrick Lumban Tobing; Tomoki Toda', display:{Lore:['[{"text": "arXiv:1804.11055", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lCollapsed speech segment detection and suppression for WaveNet vocoder\\u00a7r\\n\\n\\u00a78\\u00a7oYi-Chiao Wu\\nKazuhiro Kobayashi\\nTomoki Hayashi\\nPatrick Lumban Tobing\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1804.11055\\u00a7r\\n\\nVersion:\\u00a77v2 (Thu, 9 Aug 2018 16:06:26 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 6 figures. Proc. Interspeech, 2018\\u00a7r"}']}
{title:'Mobiny et al. (§72018§r)', author: 'Aryan Mobiny; Mohammad Najarian', display:{Lore:['[{"text": "arXiv:1805.00604", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lText-Independent Speaker Verification Using Long Short-Term Memory Networks\\u00a7r\\n\\n\\u00a78\\u00a7oAryan Mobiny\\nMohammad Najarian\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1805.00604\\u00a7r\\n\\nVersion:\\u00a77v3 (Fri, 7 Sep 2018 14:41:25 GMT)\\u00a7r"}']}
{title:'Vestman et al. (§72018§r)', author: 'Ville Vestman; Tomi Kinnunen', display:{Lore:['[{"text": "arXiv:1805.01156", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSupervector Compression Strategies to Speed up I-Vector System Development\\u00a7r\\n\\n\\u00a78\\u00a7oVille Vestman\\nTomi Kinnunen\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1805.01156\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 3 May 2018 08:12:39 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oTo appear in Speaker Odyssey 2018: The Speaker and Language Recognition Workshop\\u00a7r"}']}
{title:'Aubreville et al. (§72018§r)', author: 'Marc Aubreville; Kai Ehrensperger; Tobias Rosenkranz; Benjamin Graf; Henning Puder; Andreas Maier', display:{Lore:['[{"text": "arXiv:1805.01198", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDeep Denoising for Hearing Aid Applications\\u00a7r\\n\\n\\u00a78\\u00a7oMarc Aubreville\\nKai Ehrensperger\\nTobias Rosenkranz\\n+ 2 others\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1805.01198\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/IWAENC.2018.8521369\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7n2018 16th International Workshop on Acoustic Signal Enhancement\\n  (IWAENC), pp. 361-365\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 3 May 2018 10:04:39 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7osubmitted to IWAENC 2018\\u00a7r"}']}
{title:'Renkens et al. (§72018§r)', author: 'Vincent Renkens; Hugo Van hamme', display:{Lore:['[{"text": "arXiv:1805.02922", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lCapsule Networks for Low Resource Spoken Language Understanding\\u00a7r\\n\\n\\u00a78\\u00a7oVincent Renkens\\nHugo Van hamme\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1805.02922\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 8 May 2018 09:45:56 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to INTERSPEECH 2018\\u00a7r"}']}
{title:'Kato et al. (§72018§r)', author: 'Akihiro Kato; Tomi Kinnunen', display:{Lore:['[{"text": "arXiv:1805.02958", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Regression Model of Recurrent Deep Neural Networks for Noise Robust Estimation of the Fundamental Frequency Contour of Speech\\u00a7r\\n\\n\\u00a78\\u00a7oAkihiro Kato\\nTomi Kinnunen\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1805.02958\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 8 May 2018 11:54:06 GMT)\\u00a7r"}']}
{title:'Shivakumar et al. (§72018§r)', author: 'Prashanth Gurunath Shivakumar; Panayiotis Georgiou', display:{Lore:['[{"text": "arXiv:1805.03322", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lTransfer Learning from Adult to Children for Speech Recognition: Evaluation, Analysis and Recommendations\\u00a7r\\n\\n\\u00a78\\u00a7oPrashanth Gurunath Shivakumar\\nPanayiotis Georgiou\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1805.03322\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 8 May 2018 23:59:04 GMT)\\u00a7r"}']}
{title:'Zhou et al. (§72018§r)', author: 'Shiyu Zhou; Linhao Dong; Shuang Xu; Bo Xu', display:{Lore:['[{"text": "arXiv:1805.06239", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Comparison of Modeling Units in Sequence-to-Sequence Speech Recognition with the Transformer on Mandarin Chinese\\u00a7r\\n\\n\\u00a78\\u00a7oShiyu Zhou\\nLinhao Dong\\nShuang Xu\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1805.06239\\u00a7r\\n\\nVersion:\\u00a77v2 (Fri, 18 May 2018 12:46:54 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oarXiv admin note: substantial text overlap with arXiv:1804.10752\\u00a7r"}']}
{title:'Tripathi et al. (§72018§r)', author: 'Aditay Tripathi; Aanchan Mohan; Saket Anand; Maneesh Singh', display:{Lore:['[{"text": "arXiv:1805.08615", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAdversarial Learning of Raw Speech Features for Domain Invariant Speech Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oAditay Tripathi\\nAanchan Mohan\\nSaket Anand\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1805.08615\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 21 May 2018 11:13:27 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 1 figure, 2 tabels, ICASSP 2018\\u00a7r"}']}
{title:'Banerjee et al. (§72018§r)', author: 'Adrish Banerjee; Akash Dubey; Abhishek Menon; Shubham Nanda; Gora Chand Nandi', display:{Lore:['[{"text": "arXiv:1805.08865", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSpeaker Recognition using Deep Belief Networks\\u00a7r\\n\\n\\u00a78\\u00a7oAdrish Banerjee\\nAkash Dubey\\nAbhishek Menon\\nShubham Nanda\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1805.08865\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 9 May 2018 14:34:40 GMT)\\u00a7r"}']}
{title:'Chettri et al. (§72018§r)', author: 'Bhusan Chettri; Saumitra Mishra; Bob L. Sturm; Emmanouil Benetos', display:{Lore:['[{"text": "arXiv:1805.09164", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Study On Convolutional Neural Network Based End-To-End Replay Anti-Spoofing\\u00a7r\\n\\n\\u00a78\\u00a7oBhusan Chettri\\nSaumitra Mishra\\nBob L. Sturm\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1805.09164\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 22 May 2018 14:53:13 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o6 pages\\u00a7r"}']}
{title:'Tits et al. (§72018§r)', author: 'Noé Tits; Kevin El Haddad; Thierry Dutoit', display:{Lore:['[{"text": "arXiv:1805.09197", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.AI\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lASR-based Features for Emotion Recognition: A Transfer Learning Approach\\u00a7r\\n\\n\\u00a78\\u00a7oNo\\u00e9 Tits\\nKevin El Haddad\\nThierry Dutoit\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1805.09197\\u00a7r\\n\\nVersion:\\u00a77v3 (Fri, 1 Jun 2018 08:14:19 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted to be published in the First Workshop on Computational Modeling of Human Multimodal Language - ACL 2018\\u00a7r"}']}
{title:'Vougioukas et al. (§72018§r)', author: 'Konstantinos Vougioukas; Stavros Petridis; Maja Pantic', display:{Lore:['[{"text": "arXiv:1805.09313", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CV\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7eeess.IV\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lEnd-to-End Speech-Driven Facial Animation with Temporal GANs\\u00a7r\\n\\n\\u00a78\\u00a7oKonstantinos Vougioukas\\nStavros Petridis\\nMaja Pantic\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1805.09313\\u00a7r\\n\\nVersion:\\u00a77v4 (Thu, 19 Jul 2018 12:40:47 GMT)\\u00a7r"}']}
{title:'Mirabilii et al. (§72018§r)', author: 'Daniele Mirabilii; Emanuël A. P. Habets', display:{Lore:['[{"text": "arXiv:1805.09679", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSimulating Multi-channel Wind Noise Based on the Corcos Model\\u00a7r\\n\\n\\u00a78\\u00a7oDaniele Mirabilii\\nEmanu\\u00ebl A. P. Habets\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1805.09679\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/IWAENC.2018.8521302\\u00a7r\\n\\nVersion:\\u00a77v2 (Mon, 23 Jul 2018 17:12:42 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 2 figures, IWAENC 2018\\u00a7r"}']}
{title:'Gößling et al. (§72018§r)', author: 'N. Gößling; S. Doclo', display:{Lore:['[{"text": "arXiv:1805.10333", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lRelative Transfer Function Estimation Exploiting Spatially Separated Microphones in a Diffuse Noise Field\\u00a7r\\n\\n\\u00a78\\u00a7oN. G\\u00f6\\u00dfling\\nS. Doclo\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1805.10333\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/IWAENC.2018.8521295\\u00a7r\\n\\nVersion:\\u00a77v3 (Thu, 12 Jul 2018 11:21:33 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oTo appear in the Proc. of IWAENC2018\\u00a7r"}']}
{title:'Lotfian et al. (§72018§r)', author: 'Reza Lotfian; Carlos Busso', display:{Lore:['[{"text": "arXiv:1805.10339", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lCurriculum Learning for Speech Emotion Recognition from Crowdsourced Labels\\u00a7r\\n\\n\\u00a78\\u00a7oReza Lotfian\\nCarlos Busso\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1805.10339\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/TASLP.2019.2898816\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nIEEE/ACM Transactions on Audio, Speech, and Language Processing,\\n  2019\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 25 May 2018 19:27:59 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to IEEE/ACM Transactionson Audio, Speech, and Language Processing\\u00a7r"}']}
{title:'Ravanelli et al. (§72018§r)', author: 'Mirco Ravanelli; Maurizio Omologo', display:{Lore:['[{"text": "arXiv:1805.10498", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.NE\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAutomatic context window composition for distant speech recognition\\u00a7r\\n\\n\\u00a78\\u00a7oMirco Ravanelli\\nMaurizio Omologo\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1805.10498\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 26 May 2018 15:36:44 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oThis is a preprint version of the paper published on Speech Communication Journal, 2018. Please see https://www.sciencedirect.com/science/article/pii/S0167639318300128 for the published version of this article\\u00a7r"}']}
{title:'Park et al. (§72018§r)', author: 'Tae Jin Park; Panayiotis Georgiou', display:{Lore:['[{"text": "arXiv:1805.10731", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMultimodal Speaker Segmentation and Diarization using Lexical and Acoustic Cues via Sequence to Sequence Neural Networks\\u00a7r\\n\\n\\u00a78\\u00a7oTae Jin Park\\nPanayiotis Georgiou\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1805.10731\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 28 May 2018 01:58:55 GMT)\\u00a7r"}']}
{title:'Venkataramani et al. (§72018§r)', author: 'Shrikant Venkataramani; Ryley Higa; Paris Smaragdis', display:{Lore:['[{"text": "arXiv:1806.00511", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7eeess.SP\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lPerformance Based Cost Functions for End-to-End Speech Separation\\u00a7r\\n\\n\\u00a78\\u00a7oShrikant Venkataramani\\nRyley Higa\\nParis Smaragdis\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1806.00511\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 1 Jun 2018 19:04:48 GMT)\\u00a7r"}']}
{title:'M et al. (§72018§r)', author: 'Nazreen P M; A G Ramakrishnan', display:{Lore:['[{"text": "arXiv:1806.00516", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDNN Based Speech Enhancement for Unseen Noises Using Monte Carlo Dropout\\u00a7r\\n\\n\\u00a78\\u00a7oNazreen P M\\nA G Ramakrishnan\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1806.00516\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 1 Jun 2018 19:21:05 GMT)\\u00a7r"}']}
{title:'Cai et al. (§72018§r)', author: 'Weicheng Cai; Jinkun Chen; Ming Li', display:{Lore:['[{"text": "arXiv:1806.03209", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAnalysis of Length Normalization in End-to-End Speaker Verification System\\u00a7r\\n\\n\\u00a78\\u00a7oWeicheng Cai\\nJinkun Chen\\nMing Li\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1806.03209\\u00a7r\\n\\nVersion:\\u00a77v2 (Mon, 11 Jun 2018 04:06:16 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted for Interspeech 2018\\u00a7r"}']}
{title:'Li et al. (§72018§r)', author: 'Yutian Li; Feng Gao; Zhijian Ou; Jiasong Sun', display:{Lore:['[{"text": "arXiv:1806.03464", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAngular Softmax Loss for End-to-end Speaker Verification\\u00a7r\\n\\n\\u00a78\\u00a7oYutian Li\\nFeng Gao\\nZhijian Ou\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1806.03464\\u00a7r\\n\\nVersion:\\u00a77v2 (Wed, 12 Dec 2018 03:49:38 GMT)\\u00a7r"}']}
{title:'Kavalekalam et al. (§72018§r)', author: 'Mathew Shaji Kavalekalam; Jesper K. Nielsen; Jesper B. Boldt; Mads G. Christensen', display:{Lore:['[{"text": "arXiv:1806.04885", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lModel-based Speech Enhancement for Intelligibility Improvement in Binaural Hearing Aids\\u00a7r\\n\\n\\u00a78\\u00a7oMathew Shaji Kavalekalam\\nJesper K. Nielsen\\nJesper B. Boldt\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1806.04885\\u00a7r\\n\\nVersion:\\u00a77v2 (Mon, 1 Oct 2018 15:14:49 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oafter revision\\u00a7r"}']}
{title:'Zhou et al. (§72018§r)', author: 'Shiyu Zhou; Shuang Xu; Bo Xu', display:{Lore:['[{"text": "arXiv:1806.05059", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMultilingual End-to-End Speech Recognition with A Single Transformer on Low-Resource Languages\\u00a7r\\n\\n\\u00a78\\u00a7oShiyu Zhou\\nShuang Xu\\nBo Xu\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1806.05059\\u00a7r\\n\\nVersion:\\u00a77v2 (Thu, 14 Jun 2018 00:48:39 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oarXiv admin note: text overlapwith arXiv:1805.06239\\u00a7r"}']}
{title:'Casebeer et al. (§72018§r)', author: 'Jonah Casebeer; Brian Luc; Paris Smaragdis', display:{Lore:['[{"text": "arXiv:1806.05296", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMulti-View Networks for Denoising of Arbitrary Numbers of Channels\\u00a7r\\n\\n\\u00a78\\u00a7oJonah Casebeer\\nBrian Luc\\nParis Smaragdis\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1806.05296\\u00a7r\\n\\nVersion:\\u00a77v2 (Mon, 23 Jul 2018 11:45:37 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 6 figures, IWAENC 2018\\u00a7r"}']}
{title:'Gerazov et al. (§72018§r)', author: 'Branislav Gerazov; Gérard Bailly; Yi Xu', display:{Lore:['[{"text": "arXiv:1806.06779", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Weighted Superposition of Functional Contours Model for Modelling Contextual Prominence of Elementary Prosodic Contours\\u00a7r\\n\\n\\u00a78\\u00a7oBranislav Gerazov\\nG\\u00e9rard Bailly\\nYi Xu\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1806.06779\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.21437/Interspeech.2018\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nProceedings of Interspeech 2018\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 18 Jun 2018 15:41:41 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted for publication at INTERSPEECH 2018\\u00a7r"}']}
{title:'Gang et al. (§72018§r)', author: 'Arpita Gang; Pravesh Biyani; Akshay Soni', display:{Lore:['[{"text": "arXiv:1806.08086", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lTowards Automated Single Channel Source Separation using Neural Networks\\u00a7r\\n\\n\\u00a78\\u00a7oArpita Gang\\nPravesh Biyani\\nAkshay Soni\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1806.08086\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 21 Jun 2018 07:03:51 GMT)\\u00a7r"}']}
{title:'Gu et al. (§72018§r)', author: 'Yu Gu; Yongguo Kang', display:{Lore:['[{"text": "arXiv:1806.08619", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7eeess.SP\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMulti-task WaveNet: A Multi-task Generative Model for Statistical Parametric Speech Synthesis without Fundamental Frequency Conditions\\u00a7r\\n\\n\\u00a78\\u00a7oYu Gu\\nYongguo Kang\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1806.08619\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 22 Jun 2018 12:12:54 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted by Interspeech 2018\\u00a7r"}']}
{title:'Itturriet et al. (§72018§r)', author: 'Fábio P. Itturriet; Márcio H. Costa', display:{Lore:['[{"text": "arXiv:1806.09169", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lPerceptually Relevant Preservation of Interaural Time Differences in Binaural Hearing Aids\\u00a7r\\n\\n\\u00a78\\u00a7oF\\u00e1bio P. Itturriet\\nM\\u00e1rcio H. Costa\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1806.09169\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 24 Jun 2018 15:53:33 GMT)\\u00a7r"}']}
{title:'Li et al. (§72018§r)', author: 'Hao Li; Yongguo Kang; Zhenyu Wang', display:{Lore:['[{"text": "arXiv:1806.09276", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lEMPHASIS: An Emotional Phoneme-based Acoustic Model for Speech Synthesis System\\u00a7r\\n\\n\\u00a78\\u00a7oHao Li\\nYongguo Kang\\nZhenyu Wang\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1806.09276\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 26 Jun 2018 03:18:45 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted by Interspeech 2018\\u00a7r"}']}
{title:'Mogami et al. (§72018§r)', author: 'Shinichi Mogami; Hayato Sumino; Daichi Kitamura; Norihiro Takamune; Shinnosuke Takamichi; Hiroshi Saruwatari; Nobutaka Ono', display:{Lore:['[{"text": "arXiv:1806.10307", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lIndependent Deeply Learned Matrix Analysis for Multichannel Audio Source Separation\\u00a7r\\n\\n\\u00a78\\u00a7oShinichi Mogami\\nHayato Sumino\\nDaichi Kitamura\\n+ 3 others\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1806.10307\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 27 Jun 2018 05:52:40 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 4 figures, To appear in the Proceedings of the 26th European Signal Processing Conference (EUSIPCO 2018)\\u00a7r"}']}
{title:'Germain et al. (§72018§r)', author: 'Francois G. Germain; Qifeng Chen; Vladlen Koltun', display:{Lore:['[{"text": "arXiv:1806.10522", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSpeech Denoising with Deep Feature Losses\\u00a7r\\n\\n\\u00a78\\u00a7oFrancois G. Germain\\nQifeng Chen\\nVladlen Koltun\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1806.10522\\u00a7r\\n\\nVersion:\\u00a77v2 (Fri, 14 Sep 2018 18:46:12 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oCode can be found at https://github.com/francoisgermain/SpeechDenoisingWithDeepFeatureLosses . Sound examples canbe found at https://ccrma.stanford.edu/ francois/SpeechDenoisingWithDeepFeatureLosses/\\u00a7r"}']}
{title:'Kato et al. (§72018§r)', author: 'Akihiro Kato; Tomi Kinnunen', display:{Lore:['[{"text": "arXiv:1807.00752", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lWaveform to Single Sinusoid Regression to Estimate the F0 Contour from Noisy Speech Using Recurrent Deep Neural Networks\\u00a7r\\n\\n\\u00a78\\u00a7oAkihiro Kato\\nTomi Kinnunen\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1807.00752\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 2 Jul 2018 15:42:00 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted by peer reviewing for Interspeech 2018\\u00a7r"}']}
{title:'Tu et al. (§72018§r)', author: 'Ming Tu; Anna Grabek; Julie Liss; Visar Berisha', display:{Lore:['[{"text": "arXiv:1807.01738", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lInvestigating the role of L1 in automatic pronunciation evaluation of L2 speech\\u00a7r\\n\\n\\u00a78\\u00a7oMing Tu\\nAnna Grabek\\nJulie Liss\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1807.01738\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 4 Jul 2018 18:44:43 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oTo appear in Interspeech 2018\\u00a7r"}']}
{title:'Lugosch et al. (§72018§r)', author: 'Loren Lugosch; Vikrant Singh Tomar', display:{Lore:['[{"text": "arXiv:1807.02465", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lTone Recognition Using Lifters and CTC\\u00a7r\\n\\n\\u00a78\\u00a7oLoren Lugosch\\nVikrant Singh Tomar\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1807.02465\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 6 Jul 2018 16:05:00 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted to Interspeech 2018\\u00a7r"}']}
{title:'Záviška et al. (§72018§r)', author: 'Pavel Záviška; Pavel Rajmic; Zdeněk Průša; Vítězslav Veselý', display:{Lore:['[{"text": "arXiv:1807.03612", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7eeess.SP\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lRevisiting Synthesis Model of Sparse Audio Declipper\\u00a7r\\n\\n\\u00a78\\u00a7oPavel Z\\u00e1vi\\u0161ka\\nPavel Rajmic\\nZden\\u011bk Pr\\u016f\\u0161a\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1807.03612\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1007/978-3-319-93764-9_40\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nLVA ICA 2018. The 14th International Conference on Latent Variable\\n  Analysis and Signal Separation, Guildford, United Kingdom, July 2018\\u00a7r\\n\\nVersion:\\u00a77v2 (Wed, 11 Jul 2018 10:43:11 GMT)\\u00a7r"}']}
{title:'Gößling et al. (§72018§r)', author: 'N. Gößling; S. Doclo', display:{Lore:['[{"text": "arXiv:1807.04096", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lRTF-Based Binaural MVDR Beamformer Exploiting an External Microphone in a Diffuse Noise Field\\u00a7r\\n\\n\\u00a78\\u00a7oN. G\\u00f6\\u00dfling\\nS. Doclo\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1807.04096\\u00a7r\\n\\nVersion:\\u00a77v2 (Thu, 12 Jul 2018 11:23:18 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted at ITG Conference on Speech Communication 2018\\u00a7r"}']}
{title:'Myer et al. (§72018§r)', author: 'Samuel Myer; Vikrant Singh Tomar', display:{Lore:['[{"text": "arXiv:1807.04353", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lEfficient keyword spotting using time delay neural networks\\u00a7r\\n\\n\\u00a78\\u00a7oSamuel Myer\\nVikrant Singh Tomar\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1807.04353\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 28 Aug 2018 13:42:36 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oWill appear in Interspeech 2018\\u00a7r"}']}
{title:'Gößling et al. (§72018§r)', author: 'N. Gößling; D. Marquardt; I. Merks; T. Zhang; S. Doclo', display:{Lore:['[{"text": "arXiv:1807.04636", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lOptimal Binaural LCMV Beamforming in Complex Acoustic Scenarios: Theoretical and Practical Insights\\u00a7r\\n\\n\\u00a78\\u00a7oN. G\\u00f6\\u00dfling\\nD. Marquardt\\nI. Merks\\nT. Zhang\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1807.04636\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/IWAENC.2018.8521355\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 12 Jul 2018 14:29:51 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oTo appear in Proc. IWAENC 2018\\u00a7r"}']}
{title:'Xiao et al. (§72018§r)', author: 'Zhangyu Xiao; Zhijian Ou; Wei Chu; Hui Lin', display:{Lore:['[{"text": "arXiv:1807.04978", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lHybrid CTC-Attention based End-to-End Speech Recognition using Subword Units\\u00a7r\\n\\n\\u00a78\\u00a7oZhangyu Xiao\\nZhijian Ou\\nWei Chu\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1807.04978\\u00a7r\\n\\nVersion:\\u00a77v2 (Thu, 6 Sep 2018 02:21:41 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oaccepted by ISCSLP 2018\\u00a7r"}']}
{title:'Vanek et al. (§72018§r)', author: 'Jan Vanek; Josef Michalek; Jan Zelinka; Josef Psutka', display:{Lore:['[{"text": "arXiv:1807.06441", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Comparison of Adaptation Techniques and Recurrent Neural Network Architectures\\u00a7r\\n\\n\\u00a78\\u00a7oJan Vanek\\nJosef Michalek\\nJan Zelinka\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1807.06441\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 12 Jul 2018 09:40:21 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7osubmitted and accepted to SLSP 2018 conference. arXiv admin note: text overlapwith arXiv:1806.07186, arXiv:1806.07974\\u00a7r"}']}
{title:'Liang et al. (§72018§r)', author: 'Davis Liang; Zhiheng Huang; Zachary C. Lipton', display:{Lore:['[{"text": "arXiv:1807.06610", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lLearning Noise-Invariant Representations for Robust Speech Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oDavis Liang\\nZhiheng Huang\\nZachary C. Lipton\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1807.06610\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 17 Jul 2018 18:15:14 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oUnder Review at IEEE SLT 2018\\u00a7r"}']}
{title:'Shon et al. (§72018§r)', author: 'Suwon Shon; Najim Dehak; Douglas Reynolds; James Glass', display:{Lore:['[{"text": "arXiv:1807.06663", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMCE 2018: The 1st Multi-target Speaker Detection and Identification Challenge Evaluation (MCE) Plan, Dataset and Baseline System\\u00a7r\\n\\n\\u00a78\\u00a7oSuwon Shon\\nNajim Dehak\\nDouglas Reynolds\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1807.06663\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 17 Jul 2018 20:37:18 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oMCE 2018 Plan (http://mce.csail.mit.edu)\\u00a7r"}']}
{title:'Liu et al. (§72018§r)', author: 'Yaming Liu; Jian Tang; Yan Song; Lirong Dai', display:{Lore:['[{"text": "arXiv:1807.07436", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Capsule based Approach for Polyphonic Sound Event Detection\\u00a7r\\n\\n\\u00a78\\u00a7oYaming Liu\\nJian Tang\\nYan Song\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1807.07436\\u00a7r\\n\\nVersion:\\u00a77v2 (Mon, 23 Jul 2018 02:16:02 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o4 pages, 2 figures\\u00a7r"}']}
{title:'Hajibabaei et al. (§72018§r)', author: 'Mahdi Hajibabaei; Dengxin Dai', display:{Lore:['[{"text": "arXiv:1807.08312", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.AI\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lUnified Hypersphere Embedding for Speaker Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oMahdi Hajibabaei\\nDengxin Dai\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1807.08312\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 22 Jul 2018 16:26:31 GMT)\\u00a7r"}']}
{title:'Palaskar et al. (§72018§r)', author: 'Shruti Palaskar; Florian Metze', display:{Lore:['[{"text": "arXiv:1807.09597", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAcoustic-to-Word Recognition with Sequence-to-Sequence Models\\u00a7r\\n\\n\\u00a78\\u00a7oShruti Palaskar\\nFlorian Metze\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1807.09597\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 21 Aug 2018 11:28:14 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o9 pages, 3 figures, UnderReview at SLT 2018\\u00a7r"}']}
{title:'Mesaros et al. (§72018§r)', author: 'Annamaria Mesaros; Toni Heittola; Tuomas Virtanen', display:{Lore:['[{"text": "arXiv:1807.09840", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA multi-device dataset for urban acoustic scene classification\\u00a7r\\n\\n\\u00a78\\u00a7oAnnamaria Mesaros\\nToni Heittola\\nTuomas Virtanen\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1807.09840\\u00a7r\\n\\nVersion:\\u00a77v2 (Thu, 11 Oct 2018 12:42:28 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oaccepted to DCASE 2018 Workshop\\u00a7r"}']}
{title:'Toshniwal et al. (§72018§r)', author: 'Shubham Toshniwal; Anjuli Kannan; Chung-Cheng Chiu; Yonghui Wu; Tara N Sainath; Karen Livescu', display:{Lore:['[{"text": "arXiv:1807.10857", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.AI\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Comparison of Techniques for Language Model Integration in Encoder-Decoder Speech Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oShubham Toshniwal\\nAnjuli Kannan\\nChung-Cheng Chiu\\n+ 2 others\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1807.10857\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 6 Nov 2018 23:21:14 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted in SLT 2018\\u00a7r"}']}
{title:'Henter et al. (§72018§r)', author: 'Gustav Eje Henter; Simon King; Thomas Merritt; Gilles Degottex', display:{Lore:['[{"text": "arXiv:1807.10941", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAnalysing Shortcomings of Statistical Parametric Speech Synthesis\\u00a7r\\n\\n\\u00a78\\u00a7oGustav Eje Henter\\nSimon King\\nThomas Merritt\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1807.10941\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 28 Jul 2018 14:40:59 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o34 pages with 4 figures; draft book chapter\\u00a7r"}']}
{title:'Dekkers et al. (§72018§r)', author: 'Gert Dekkers; Lode Vuegen; Toon van Waterschoot; Bart Vanrumste; Peter Karsmakers', display:{Lore:['[{"text": "arXiv:1807.11246", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDCASE 2018 Challenge - Task 5: Monitoring of domestic activities based on multi-channel acoustics\\u00a7r\\n\\n\\u00a78\\u00a7oGert Dekkers\\nLode Vuegen\\nToon van Waterschoot\\nBart Vanrumste\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1807.11246\\u00a7r\\n\\nVersion:\\u00a77v2 (Wed, 1 Aug 2018 11:41:37 GMT)\\u00a7r"}']}
{title:'Denisov et al. (§72018§r)', author: 'Pavel Denisov; Ngoc Thang Vu; Marc Ferras Font', display:{Lore:['[{"text": "arXiv:1807.11284", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.AI\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lUnsupervised Domain Adaptation by Adversarial Learning for Robust Speech Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oPavel Denisov\\nNgoc Thang Vu\\nMarc Ferras Font\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1807.11284\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 30 Jul 2018 11:00:59 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 2 figures, the 13th ITG conference onSpeech Communication\\u00a7r"}']}
{title:'Henter et al. (§72018§r)', author: 'Gustav Eje Henter; Jaime Lorenzo-Trueba; Xin Wang; Junichi Yamagishi', display:{Lore:['[{"text": "arXiv:1807.11470", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDeep Encoder-Decoder Models for Unsupervised Learning of Controllable Speech Synthesis\\u00a7r\\n\\n\\u00a78\\u00a7oGustav Eje Henter\\nJaime Lorenzo-Trueba\\nXin Wang\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1807.11470\\u00a7r\\n\\nVersion:\\u00a77v3 (Sun, 9 Sep 2018 17:01:07 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o17 pages, 4 figures\\u00a7r"}']}
{title:'Luong et al. (§72018§r)', author: 'Hieu-Thi Luong; Junichi Yamagishi', display:{Lore:['[{"text": "arXiv:1807.11632", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lScaling and bias codes for modeling speaker-adaptive DNN-based speech synthesis systems\\u00a7r\\n\\n\\u00a78\\u00a7oHieu-Thi Luong\\nJunichi Yamagishi\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1807.11632\\u00a7r\\n\\nVersion:\\u00a77v2 (Mon, 1 Oct 2018 00:00:48 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted for 2018 IEEE Workshop on Spoken Language Technology (SLT), Athens, Greece\\u00a7r"}']}
{title:'Zhao et al. (§72018§r)', author: 'Yi Zhao; Shinji Takaki; Hieu-Thi Luong; Junichi Yamagishi; Daisuke Saito; Nobuaki Minematsu', display:{Lore:['[{"text": "arXiv:1807.11679", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lWasserstein GAN and Waveform Loss-based Acoustic Model Training for Multi-speaker Text-to-Speech Synthesis Systems Using a WaveNet Vocoder\\u00a7r\\n\\n\\u00a78\\u00a7oYi Zhao\\nShinji Takaki\\nHieu-Thi Luong\\n+ 2 others\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1807.11679\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 31 Jul 2018 06:38:54 GMT)\\u00a7r"}']}
{title:'Chakrabarty et al. (§72018§r)', author: 'Soumitro Chakrabarty; Emanuël A. P. Habets', display:{Lore:['[{"text": "arXiv:1807.11722", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMulti-Speaker DOA Estimation Using Deep Convolutional Networks Trained with Noise Signals\\u00a7r\\n\\n\\u00a78\\u00a7oSoumitro Chakrabarty\\nEmanu\\u00ebl A. P. Habets\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1807.11722\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/JSTSP.2019.2901664\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 31 Jul 2018 09:40:39 GMT)\\u00a7r"}']}
{title:'Fong et al. (§72018§r)', author: 'Judy Y. Fong; Michal Borsky; Inga R. Helgadóttir; Jon Gudnason', display:{Lore:['[{"text": "arXiv:1807.11893", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lManual Post-editing of Automatically Transcribed Speeches from the Icelandic Parliament - Althingi\\u00a7r\\n\\n\\u00a78\\u00a7oJudy Y. Fong\\nMichal Borsky\\nInga R. Helgad\\u00f3ttir\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1807.11893\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 31 Jul 2018 16:11:13 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7osubmitted to IEEESLT 2018, Athens\\u00a7r"}']}
{title:'Corey et al. (§72018§r)', author: 'Ryan M. Corey; Naoki Tsuda; Andrew C. Singer', display:{Lore:['[{"text": "arXiv:1808.00082", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDelay-Performance Tradeoffs in Causal Microphone Array Processing\\u00a7r\\n\\n\\u00a78\\u00a7oRyan M. Corey\\nNaoki Tsuda\\nAndrew C. Singer\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1808.00082\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/IWAENC.2018.8521263\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7n2018 16th International Workshop on Acoustic Signal Enhancement\\n  (IWAENC)\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 31 Jul 2018 22:04:22 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oTo appear at the International Workshopon Acoustic Signal Enhancement (IWAENC 2018)\\u00a7r"}']}
{title:'Corey et al. (§72018§r)', author: 'Ryan M. Corey; Andrew C. Singer', display:{Lore:['[{"text": "arXiv:1808.00096", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSpeech Separation Using Partially Asynchronous Microphone Arrays Without Resampling\\u00a7r\\n\\n\\u00a78\\u00a7oRyan M. Corey\\nAndrew C. Singer\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1808.00096\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/IWAENC.2018.8521260\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7n2018 16th International Workshop on Acoustic Signal Enhancement\\n  (IWAENC)\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 31 Jul 2018 22:34:52 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oTo appear at the International Workshopon Acoustic Signal Enhancement (IWAENC 2018)\\u00a7r"}']}
{title:'Luong et al. (§72018§r)', author: 'Hieu-Thi Luong; Xin Wang; Junichi Yamagishi; Nobuyuki Nishizawa', display:{Lore:['[{"text": "arXiv:1808.00665", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lInvestigating accuracy of pitch-accent annotations in neural network-based speech synthesis and denoising effects\\u00a7r\\n\\n\\u00a78\\u00a7oHieu-Thi Luong\\nXin Wang\\nJunichi Yamagishi\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1808.00665\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 2 Aug 2018 04:25:30 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted for Interspeech 2018\\u00a7r"}']}
{title:'Soleymani et al. (§72018§r)', author: 'Sobhan Soleymani; Ali Dabouei; Seyed Mehdi Iranmanesh; Hadi Kazemi; Jeremy Dawson; Nasser M. Nasrabadi', display:{Lore:['[{"text": "arXiv:1808.01026", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CV\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lProsodic-Enhanced Siamese Convolutional Neural Networks for Cross-Device Text-Independent Speaker Verification\\u00a7r\\n\\n\\u00a78\\u00a7oSobhan Soleymani\\nAli Dabouei\\nSeyed Mehdi Iranmanesh\\n+ 2 others\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1808.01026\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 31 Jul 2018 19:21:59 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted in 9th IEEE International Conference on Biometrics: Theory, Applications, and Systems (BTAS 2018)\\u00a7r"}']}
{title:'Song et al. (§72018§r)', author: 'Huan Song; Megan Willi; Jayaraman J. Thiagarajan; Visar Berisha; Andreas Spanias', display:{Lore:['[{"text": "arXiv:1808.01535", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lTriplet Network with Attention for Speaker Diarization\\u00a7r\\n\\n\\u00a78\\u00a7oHuan Song\\nMegan Willi\\nJayaraman J. Thiagarajan\\nVisar Berisha\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1808.01535\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 4 Aug 2018 21:10:03 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oInterspeech2018\\u00a7r"}']}
{title:'Gharib et al. (§72018§r)', author: 'Shayan Gharib; Honain Derrar; Daisuke Niizumi; Tuukka Senttula; Janne Tommola; Toni Heittola; Tuomas Virtanen; Heikki Huttunen', display:{Lore:['[{"text": "arXiv:1808.02357", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CV\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAcoustic Scene Classification: A Competition Review\\u00a7r\\n\\n\\u00a78\\u00a7oShayan Gharib\\nHonain Derrar\\nDaisuke Niizumi\\n+ 4 others\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1808.02357\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 2 Aug 2018 07:40:17 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oThis work has been accepted in IEEE International Workshopon Machine Learning for Signal Processing (MLSP 2018). Copyright may be transferred without notice, after which this version may no longer be accessible\\u00a7r"}']}
{title:'Pundak et al. (§72018§r)', author: 'Golan Pundak; Tara N. Sainath; Rohit Prabhavalkar; Anjuli Kannan; Ding Zhao', display:{Lore:['[{"text": "arXiv:1808.02480", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDeep context: end-to-end contextual speech recognition\\u00a7r\\n\\n\\u00a78\\u00a7oGolan Pundak\\nTara N. Sainath\\nRohit Prabhavalkar\\nAnjuli Kannan\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1808.02480\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 7 Aug 2018 21:23:21 GMT)\\u00a7r"}']}
{title:'Gharib et al. (§72018§r)', author: 'Shayan Gharib; Konstantinos Drossos; Emre Çakir; Dmitriy Serdyuk; Tuomas Virtanen', display:{Lore:['[{"text": "arXiv:1808.05777", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lUnsupervised adversarial domain adaptation for acoustic scene classification\\u00a7r\\n\\n\\u00a78\\u00a7oShayan Gharib\\nKonstantinos Drossos\\nEmre \\u00c7akir\\nDmitriy Serdyuk\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1808.05777\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 17 Aug 2018 07:25:31 GMT)\\u00a7r"}']}
{title:'Luong et al. (§72018§r)', author: 'Hieu-Thi Luong; Junichi Yamagishi', display:{Lore:['[{"text": "arXiv:1808.06288", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMultimodal speech synthesis architecture for unsupervised speaker adaptation\\u00a7r\\n\\n\\u00a78\\u00a7oHieu-Thi Luong\\nJunichi Yamagishi\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1808.06288\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 20 Aug 2018 02:36:19 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted for Interspeech 2018, India\\u00a7r"}']}
{title:'Hsu et al. (§72018§r)', author: 'Yi-Te Hsu; Yu-Chen Lin; Szu-Wei Fu; Yu Tsao; Tei-Wei Kuo', display:{Lore:['[{"text": "arXiv:1808.06474", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.AI\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7eeess.SP\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA study on speech enhancement using exponent-only floating point quantized neural network (EOFP-QNN)\\u00a7r\\n\\n\\u00a78\\u00a7oYi-Te Hsu\\nYu-Chen Lin\\nSzu-Wei Fu\\nYu Tsao\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1808.06474\\u00a7r\\n\\nVersion:\\u00a77v4 (Tue, 30 Oct 2018 23:49:21 GMT)\\u00a7r"}']}
{title:'Mogami et al. (§72018§r)', author: 'Shinichi Mogami; Norihiro Takamune; Daichi Kitamura; Hiroshi Saruwatari; Yu Takahashi; Kazunobu Kondo; Hiroaki Nakajima; Nobutaka Ono', display:{Lore:['[{"text": "arXiv:1808.08056", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lIndependent Low-Rank Matrix Analysis Based on Time-Variant Sub-Gaussian Source Model\\u00a7r\\n\\n\\u00a78\\u00a7oShinichi Mogami\\nNorihiro Takamune\\nDaichi Kitamura\\n+ 4 others\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1808.08056\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 24 Aug 2018 09:19:06 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o8 pages, 5 figures, To appear in the Proceedings of APSIPA ASC 2018\\u00a7r"}']}
{title:'de Andrade et al. (§72018§r)', author: 'Douglas Coimbra de Andrade; Sabato Leo; Martin Loesener Da Silva Viana; Christoph Bernkopf', display:{Lore:['[{"text": "arXiv:1808.08929", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA neural attention model for speech command recognition\\u00a7r\\n\\n\\u00a78\\u00a7oDouglas Coimbra de Andrade\\nSabato Leo\\nMartin Loesener Da Silva Viana\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1808.08929\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 27 Aug 2018 17:05:50 GMT)\\u00a7r"}']}
{title:'M. et al. (§72018§r)', author: 'Nazreen P. M.; A. G. Ramakrishnan', display:{Lore:['[{"text": "arXiv:1808.09432", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lUsing Monte Carlo dropout for non-stationary noise reduction from speech\\u00a7r\\n\\n\\u00a78\\u00a7oNazreen P. M.\\nA. G. Ramakrishnan\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1808.09432\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 28 Aug 2018 17:46:11 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oThis article draws from our previous work arXiv:1806.00516\\u00a7r"}']}
{title:'Huang et al. (§72018§r)', author: 'Wen-Chin Huang; Hsin-Te Hwang; Yu-Huai Peng; Yu Tsao; Hsin-Min Wang', display:{Lore:['[{"text": "arXiv:1808.09634", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lVoice Conversion Based on Cross-Domain Features Using Variational Auto Encoders\\u00a7r\\n\\n\\u00a78\\u00a7oWen-Chin Huang\\nHsin-Te Hwang\\nYu-Huai Peng\\nYu Tsao\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1808.09634\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/ISCSLP.2018.8706604\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 29 Aug 2018 04:32:42 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted to ISCSLP 2018\\u00a7r"}']}
{title:'Shim et al. (§72018§r)', author: 'Hye-Jin Shim; Jee-weon Jung; Hee-Soo Heo; Sunghyun Yoon; Ha-Jin Yu', display:{Lore:['[{"text": "arXiv:1808.09638", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7eeess.SP\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lReplay spoofing detection system for automatic speaker verification using multi-task learning of noise classes\\u00a7r\\n\\n\\u00a78\\u00a7oHye-Jin Shim\\nJee-weon Jung\\nHee-Soo Heo\\nSunghyun Yoon\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1808.09638\\u00a7r\\n\\nVersion:\\u00a77v4 (Thu, 25 Oct 2018 11:59:36 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, accepted by Technologies and Applications of Artificial Intelligence(TAAI)\\u00a7r"}']}
{title:'Li et al. (§72018§r)', author: 'Mohan Li; Min Liu; Masanori Hattori', display:{Lore:['[{"text": "arXiv:1808.10088", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lEnd-to-end Speech Recognition with Adaptive Computation Steps\\u00a7r\\n\\n\\u00a78\\u00a7oMohan Li\\nMin Liu\\nMasanori Hattori\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1808.10088\\u00a7r\\n\\nVersion:\\u00a77v2 (Wed, 26 Sep 2018 02:36:29 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 2 figures, submitted to ICASSP 2019\\u00a7r"}']}
{title:'Chen et al. (§72018§r)', author: 'Jinkun Chen; Weicheng Cai; Danwei Cai; Zexin Cai; Haibin Zhong; Ming Li', display:{Lore:['[{"text": "arXiv:1809.02906", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.AI\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7eeess.SP\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lEnd-to-end Language Identification using NetFV and NetVLAD\\u00a7r\\n\\n\\u00a78\\u00a7oJinkun Chen\\nWeicheng Cai\\nDanwei Cai\\n+ 2 others\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1809.02906\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 9 Sep 2018 01:07:11 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted for ISCSLP 2018\\u00a7r"}']}
{title:'Zhang et al. (§72018§r)', author: 'Hao Zhang; Stephen Zahorian; Xiao Chen; Peter Guzewich; Xiaoyu Liu', display:{Lore:['[{"text": "arXiv:1809.03868", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDual-label Deep LSTM Dereverberation For Speaker Verification\\u00a7r\\n\\n\\u00a78\\u00a7oHao Zhang\\nStephen Zahorian\\nXiao Chen\\nPeter Guzewich\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1809.03868\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 8 Sep 2018 04:55:24 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o4 pages, 3 figures, submitted to Interspeech 2018\\u00a7r"}']}
{title:'Vélez et al. (§72018§r)', author: 'Ivette Vélez; Caleb Rascon; Gibrán Fuentes-Pineda', display:{Lore:['[{"text": "arXiv:1809.04115", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lOne-Shot Speaker Identification for a Service Robot using a CNN-based Generic Verifier\\u00a7r\\n\\n\\u00a78\\u00a7oIvette V\\u00e9lez\\nCaleb Rascon\\nGibr\\u00e1n Fuentes-Pineda\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1809.04115\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 11 Sep 2018 19:16:07 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o8 pages, 9 figures, 2 tables. This paper is under review as a Submission for RA-L and ICRA for the IEEE Robotics and Automation Letters (RA-L). A video demonstration of the full system, as well as all relevant downloads"}','{"text": "(corpora, source code,models, etc.) can be found at: http://calebrascon.info/oneshotid/\\u00a7r"}']}
{title:'Shon et al. (§72018§r)', author: 'Suwon Shon; Hao Tang; James Glass', display:{Lore:['[{"text": "arXiv:1809.04437", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lFrame-level speaker embeddings for text-independent speaker recognition and analysis of end-to-end model\\u00a7r\\n\\n\\u00a78\\u00a7oSuwon Shon\\nHao Tang\\nJames Glass\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1809.04437\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 12 Sep 2018 13:48:44 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted at SLT 2018; Supplement materials: https://people.csail.mit.edu/swshon/supplement/slt18.html\\u00a7r"}']}
{title:'Shon et al. (§72018§r)', author: 'Suwon Shon; Wei-Ning Hsu; James Glass', display:{Lore:['[{"text": "arXiv:1809.04458", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lUnsupervised Representation Learning of Speech for Dialect Identification\\u00a7r\\n\\n\\u00a78\\u00a7oSuwon Shon\\nWei-Ning Hsu\\nJames Glass\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1809.04458\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 12 Sep 2018 13:57:06 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted at SLT 2018\\u00a7r"}']}
{title:'Xu et al. (§72018§r)', author: 'Longting Xu; Rohan Kumar Das; Emre Yılmaz; Jichen Yang; Haizhou Li', display:{Lore:['[{"text": "arXiv:1809.06798", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lGenerative x-vectors for text-independent speaker verification\\u00a7r\\n\\n\\u00a78\\u00a7oLongting Xu\\nRohan Kumar Das\\nEmre Y\\u0131lmaz\\nJichen Yang\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1809.06798\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 17 Sep 2018 06:04:54 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted for publication at SLT 2018\\u00a7r"}']}
{title:'Bear (§72018§r)', author: 'Helen L Bear', display:{Lore:['[{"text": "arXiv:1809.06800", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lVisual Speech Language Models\\u00a7r\\n\\n\\u00a78\\u00a7oHelen L Bear\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1809.06800\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.13140/RG.2.2.15396.94081\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 14 Sep 2018 11:07:32 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oExtended abstract based on Decoding Visemes: improving machine lipreading, Bear Harvey, ICASSP 2016\\u00a7r"}']}
{title:'Chiea et al. (§72018§r)', author: 'Rafael Attili Chiea; Márcio Holsbach Costa; Guillaume Barrault', display:{Lore:['[{"text": "arXiv:1809.07384", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7eeess.SP\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lNew insights on the optimality of parameterized wiener filters for speech enhancement applications\\u00a7r\\n\\n\\u00a78\\u00a7oRafael Attili Chiea\\nM\\u00e1rcio Holsbach Costa\\nGuillaume Barrault\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1809.07384\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 19 Sep 2018 19:33:51 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o26 pages\\u00a7r"}']}
{title:'Lin (§72018§r)', author: 'Shoufeng Lin', display:{Lore:['[{"text": "arXiv:1809.07549", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lEvaluating MCC-PHAT for the LOCATA Challenge - Task 1 and Task 3\\u00a7r\\n\\n\\u00a78\\u00a7oShoufeng Lin\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1809.07549\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 20 Sep 2018 09:52:36 GMT)\\u00a7r"}']}
{title:'Haghani et al. (§72018§r)', author: 'Parisa Haghani; Arun Narayanan; Michiel Bacchiani; Galen Chuang; Neeraj Gaur; Pedro Moreno; Rohit Prabhavalkar; Zhongdi Qu; Austin Waters', display:{Lore:['[{"text": "arXiv:1809.09190", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lFrom Audio to Semantics: Approaches to end-to-end spoken language understanding\\u00a7r\\n\\n\\u00a78\\u00a7oParisa Haghani\\nArun Narayanan\\nMichiel Bacchiani\\n+ 5 others\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1809.09190\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 24 Sep 2018 19:46:24 GMT)\\u00a7r"}']}
{title:'Zhang et al. (§72018§r)', author: 'Mingyang Zhang; Berrak Sisman; Sai Sirisha Rallabandi; Haizhou Li; Li Zhao', display:{Lore:['[{"text": "arXiv:1809.09841", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lError Reduction Network for DBLSTM-based Voice Conversion\\u00a7r\\n\\n\\u00a78\\u00a7oMingyang Zhang\\nBerrak Sisman\\nSai Sirisha Rallabandi\\nHaizhou Li\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1809.09841\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 26 Sep 2018 07:43:51 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted by APSIPA 2018\\u00a7r"}']}
{title:'Tanaka et al. (§72018§r)', author: 'Kou Tanaka; Takuhiro Kaneko; Nobukatsu Hojo; Hirokazu Kameoka', display:{Lore:['[{"text": "arXiv:1809.10288", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lWaveCycleGAN: Synthetic-to-natural speech waveform conversion using cycle-consistent adversarial networks\\u00a7r\\n\\n\\u00a78\\u00a7oKou Tanaka\\nTakuhiro Kaneko\\nNobukatsu Hojo\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1809.10288\\u00a7r\\n\\nVersion:\\u00a77v2 (Fri, 28 Sep 2018 18:25:11 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSLT2018\\u00a7r"}']}
{title:'Venkataramani et al. (§72018§r)', author: 'Shrikant Venkataramani; Paris Smaragdis', display:{Lore:['[{"text": "arXiv:1810.02568", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7eeess.SP\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lEnd-to-end Networks for Supervised Single-channel Speech Separation\\u00a7r\\n\\n\\u00a78\\u00a7oShrikant Venkataramani\\nParis Smaragdis\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1810.02568\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 5 Oct 2018 08:44:27 GMT)\\u00a7r"}']}
{title:'Yoshioka et al. (§72018§r)', author: 'Takuya Yoshioka; Hakan Erdogan; Zhuo Chen; Xiong Xiao; Fil Alleva', display:{Lore:['[{"text": "arXiv:1810.03655", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lRecognizing Overlapped Speech in Meetings: A Multichannel Separation Approach Using Neural Networks\\u00a7r\\n\\n\\u00a78\\u00a7oTakuya Yoshioka\\nHakan Erdogan\\nZhuo Chen\\nXiong Xiao\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1810.03655\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.21437/Interspeech.2018-2284\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nProc. Interspeech 2018, 3038-3042\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 8 Oct 2018 18:50:54 GMT)\\u00a7r"}']}
{title:'Zeinali et al. (§72018§r)', author: 'Hossein Zeinali; Lukas Burget; Jan Cernocky', display:{Lore:['[{"text": "arXiv:1810.04273", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lConvolutional Neural Networks and x-vector Embedding for DCASE2018 Acoustic Scene Classification Challenge\\u00a7r\\n\\n\\u00a78\\u00a7oHossein Zeinali\\nLukas Burget\\nJan Cernocky\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1810.04273\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nProceedings of the Detection and Classification of Acoustic Scenes\\n  and Events 2018 Workshop (DCASE2018)\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 1 Oct 2018 18:45:12 GMT)\\u00a7r"}']}
{title:'Alkishriwo (§72018§r)', author: 'Osama A. S. Alkishriwo', display:{Lore:['[{"text": "arXiv:1810.05260", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7eeess.SP\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Novel Chaotic Uniform Quantizer for Speech Coding\\u00a7r\\n\\n\\u00a78\\u00a7oOsama A. S. Alkishriwo\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1810.05260\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nFirst Conference for Engineering Sciences and Technology\\n  (CEST-2018)\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 11 Oct 2018 21:34:24 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o6 pages\\u00a7r"}']}
{title:'Koutrouvelis et al. (§72018§r)', author: 'Andreas I. Koutrouvelis; Richard C. Hendriks; Richard Heusdens; Jesper Jensen', display:{Lore:['[{"text": "arXiv:1810.05677", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lRobust Joint Estimation of Multi-Microphone Signal Model Parameters\\u00a7r\\n\\n\\u00a78\\u00a7oAndreas I. Koutrouvelis\\nRichard C. Hendriks\\nRichard Heusdens\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1810.05677\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 12 Oct 2018 18:55:55 GMT)\\u00a7r"}']}
{title:'Guo et al. (§72018§r)', author: 'Jinxi Guo; Ning Xu; Kailun Qian; Yang Shi; Kaiyuan Xu; Yingnian Wu; Abeer Alwan', display:{Lore:['[{"text": "arXiv:1810.07309", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDeep neural network based i-vector mapping for speaker verification using short utterances\\u00a7r\\n\\n\\u00a78\\u00a7oJinxi Guo\\nNing Xu\\nKailun Qian\\n+ 3 others\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1810.07309\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 16 Oct 2018 23:16:38 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to Speech Communication; under final review\\u00a7r"}']}
{title:'Di Gangi et al. (§72018§r)', author: 'Mattia Antonino Di Gangi; Roberto Dessì; Roldano Cattoni; Matteo Negri; Marco Turchi', display:{Lore:['[{"text": "arXiv:1810.07652", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lFine-tuning on Clean Data for End-to-End Speech Translation: FBK @ IWSLT 2018\\u00a7r\\n\\n\\u00a78\\u00a7oMattia Antonino Di Gangi\\nRoberto Dess\\u00ec\\nRoldano Cattoni\\nMatteo Negri\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1810.07652\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 16 Oct 2018 09:54:37 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o6 pages, 2 figures, system description at the 15th International Workshop on Spoken Language Translation (IWSLT) 2018\\u00a7r"}']}
{title:'Lin et al. (§72018§r)', author: 'Zhong Qiu Lin; Audrey G. Chung; Alexander Wong', display:{Lore:['[{"text": "arXiv:1810.08559", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.NE\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7eeess.SP\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lEdgeSpeechNets: Highly Efficient Deep Neural Networks for Speech Recognition on the Edge\\u00a7r\\n\\n\\u00a78\\u00a7oZhong Qiu Lin\\nAudrey G. Chung\\nAlexander Wong\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1810.08559\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 13 Nov 2018 19:25:08 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o4 pages\\u00a7r"}']}
{title:'Mirabilii et al. (§72018§r)', author: 'Daniele Mirabilii; Emanuël A. P. Habets', display:{Lore:['[{"text": "arXiv:1810.09708", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7eeess.SP\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lOn the difference-to-sum power ratio of speech and wind noise based on the Corcos model\\u00a7r\\n\\n\\u00a78\\u00a7oDaniele Mirabilii\\nEmanu\\u00ebl A. P. Habets\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1810.09708\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/ICSEE.2018.8645977\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 23 Oct 2018 07:57:33 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 3 figures, IEEE-ICSEE Eilat-Israel conference (special session)\\u00a7r"}']}
{title:'Kida et al. (§72018§r)', author: 'Yusuke Kida; Dung Tran; Motoi Omachi; Toru Taniguchi; Yuya Fujita', display:{Lore:['[{"text": "arXiv:1810.10727", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSpeaker Selective Beamformer with Keyword Mask Estimation\\u00a7r\\n\\n\\u00a78\\u00a7oYusuke Kida\\nDung Tran\\nMotoi Omachi\\nToru Taniguchi\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1810.10727\\u00a7r\\n\\nVersion:\\u00a77v2 (Wed, 7 Nov 2018 09:07:26 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted by SLT2018\\u00a7r"}']}
{title:'Xu et al. (§72018§r)', author: 'Ziyi Xu; Maximilian Strake; Tim Fingscheidt', display:{Lore:['[{"text": "arXiv:1810.11217", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lConcatenated Identical DNN (CI-DNN) to Reduce Noise-Type Dependence in DNN-Based Speech Enhancement\\u00a7r\\n\\n\\u00a78\\u00a7oZiyi Xu\\nMaximilian Strake\\nTim Fingscheidt\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1810.11217\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 26 Oct 2018 07:52:26 GMT)\\u00a7r"}']}
{title:'Takaki et al. (§72018§r)', author: 'Shinji Takaki; Toru Nakashika; Xin Wang; Junichi Yamagishi', display:{Lore:['[{"text": "arXiv:1810.11945", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSTFT spectral loss for training a neural speech waveform model\\u00a7r\\n\\n\\u00a78\\u00a7oShinji Takaki\\nToru Nakashika\\nXin Wang\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1810.11945\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 30 Oct 2018 05:35:57 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to the 2019 IEEE InternationalConference on Acoustics, Speech and Signal Processing (ICASSP)\\u00a7r"}']}
{title:'Zhou et al. (§72018§r)', author: 'Xinpei Zhou; Jiwei Li; Xi Zhou', display:{Lore:['[{"text": "arXiv:1810.12001", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lCascaded CNN-resBiLSTM-CTC: An End-to-End Acoustic Model For Speech Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oXinpei Zhou\\nJiwei Li\\nXi Zhou\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1810.12001\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 30 Oct 2018 11:13:35 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 1 figure, 4 tables. Submitted to 2019 ICASSP (International Conference on Acoustics, Speech, and Signal Processing)\\u00a7r"}']}
{title:'Alon et al. (§72018§r)', author: 'Uri Alon; Golan Pundak; Tara N. Sainath', display:{Lore:['[{"text": "arXiv:1810.12170", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lContextual Speech Recognition with Difficult Negative Training Examples\\u00a7r\\n\\n\\u00a78\\u00a7oUri Alon\\nGolan Pundak\\nTara N. Sainath\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1810.12170\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 29 Oct 2018 14:57:58 GMT)\\u00a7r"}']}
{title:'Juvela et al. (§72018§r)', author: 'Lauri Juvela; Bajibabu Bollepalli; Junichi Yamagishi; Paavo Alku', display:{Lore:['[{"text": "arXiv:1810.12598", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lWaveform generation for text-to-speech synthesis using pitch-synchronous multi-scale generative adversarial networks\\u00a7r\\n\\n\\u00a78\\u00a7oLauri Juvela\\nBajibabu Bollepalli\\nJunichi Yamagishi\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1810.12598\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 30 Oct 2018 09:23:56 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to ICASSP 2019\\u00a7r"}']}
{title:'Alvarado et al. (§72018§r)', author: 'Pablo A. Alvarado; Mauricio A. Álvarez; Dan Stowell', display:{Lore:['[{"text": "arXiv:1810.12679", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7eeess.SP\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSparse Gaussian Process Audio Source Separation Using Spectrum Priors in the Time-Domain\\u00a7r\\n\\n\\u00a78\\u00a7oPablo A. Alvarado\\nMauricio A. \\u00c1lvarez\\nDan Stowell\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1810.12679\\u00a7r\\n\\nVersion:\\u00a77v3 (Wed, 21 Nov 2018 12:18:46 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oPaper submitted to the 44th International Conference on Acoustics, Speech, and Signal Processing, ICASSP 2019. To be heldin Brighton, United Kingdom, between May 12 and May 17, 2019\\u00a7r"}']}
{title:'Fang et al. (§72018§r)', author: 'Fuming Fang; Xin Wang; Junichi Yamagishi; Isao Echizen', display:{Lore:['[{"text": "arXiv:1810.12730", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAudiovisual speaker conversion: jointly and simultaneously transforming facial expression and acoustic characteristics\\u00a7r\\n\\n\\u00a78\\u00a7oFuming Fang\\nXin Wang\\nJunichi Yamagishi\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1810.12730\\u00a7r\\n\\nVersion:\\u00a77v2 (Sat, 1 Dec 2018 15:36:52 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to ICASSP 2019\\u00a7r"}']}
{title:'Keren et al. (§72018§r)', author: 'Gil Keren; Jing Han; Björn Schuller', display:{Lore:['[{"text": "arXiv:1810.12757", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lScaling Speech Enhancement in Unseen Environments with Noise Embeddings\\u00a7r\\n\\n\\u00a78\\u00a7oGil Keren\\nJing Han\\nBj\\u00f6rn Schuller\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1810.12757\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nThe Fifth CHiME Challenge Workshop, 2018\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 26 Oct 2018 13:05:54 GMT)\\u00a7r"}']}
{title:'Ragni et al. (§72018§r)', author: 'Anton Ragni; Qiujia Li; Mark Gales; Yu Wang', display:{Lore:['[{"text": "arXiv:1810.13025", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lConfidence Estimation and Deletion Prediction Using Bidirectional Recurrent Neural Networks\\u00a7r\\n\\n\\u00a78\\u00a7oAnton Ragni\\nQiujia Li\\nMark Gales\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1810.13025\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 30 Oct 2018 22:39:54 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted as a conference paper at 2018 IEEE Workshop on Spoken Language Technology (SLT 2018)\\u00a7r"}']}
{title:'Lai et al. (§72018§r)', author: 'Cheng-I Lai; Alberto Abad; Korin Richmond; Junichi Yamagishi; Najim Dehak; Simon King', display:{Lore:['[{"text": "arXiv:1810.13048", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAttentive Filtering Networks for Audio Replay Attack Detection\\u00a7r\\n\\n\\u00a78\\u00a7oCheng-I Lai\\nAlberto Abad\\nKorin Richmond\\n+ 2 others\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1810.13048\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 31 Oct 2018 00:23:16 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to ICASSP 2019\\u00a7r"}']}
{title:'Chetupalli et al. (§72018§r)', author: 'Srikanth Raj Chetupalli; Anirban Bhowmick; Thippur V. Sreenivas', display:{Lore:['[{"text": "arXiv:1810.13109", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lLatent variable approach to diarization of audio recordings using ad-hoc randomly placed mobile devices\\u00a7r\\n\\n\\u00a78\\u00a7oSrikanth Raj Chetupalli\\nAnirban Bhowmick\\nThippur V. Sreenivas\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1810.13109\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 31 Oct 2018 05:16:25 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oPaper Submitted to the International Conference on Acoustics Speech and Signal Processing (ICASSP) 2019 to be held in Brighton, UK between May 12-17, 2019\\u00a7r"}']}
{title:'Novotny et al. (§72018§r)', author: 'Ondrej Novotny; Oldrich Plchot; Ondrej Glembek; Lukas Burget; Pavel Matejka', display:{Lore:['[{"text": "arXiv:1810.13183", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDiscriminatively Re-trained i-vector Extractor for Speaker Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oOndrej Novotny\\nOldrich Plchot\\nOndrej Glembek\\nLukas Burget\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1810.13183\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 31 Oct 2018 09:47:01 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 1 figure, submitted to ICASSP 2019\\u00a7r"}']}
{title:'Tang et al. (§72018§r)', author: 'Hao Tang; James Glass', display:{Lore:['[{"text": "arXiv:1810.13407", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lOn The Inductive Bias of Words in Acoustics-to-Word Models\\u00a7r\\n\\n\\u00a78\\u00a7oHao Tang\\nJames Glass\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1810.13407\\u00a7r\\n\\nVersion:\\u00a77v2 (Mon, 12 Nov 2018 20:51:27 GMT)\\u00a7r"}']}
{title:'Ramsay et al. (§72018§r)', author: 'David B. Ramsay; Kevin Kilgour; Dominik Roblek; Matthew Sharifi', display:{Lore:['[{"text": "arXiv:1811.00006", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lLow-Dimensional Bottleneck Features for On-Device Continuous Speech Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oDavid B. Ramsay\\nKevin Kilgour\\nDominik Roblek\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1811.00006\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 31 Oct 2018 14:20:24 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to ICASSP 2019\\u00a7r"}']}
{title:'Liu et al. (§72018§r)', author: 'Bin Liu; Shuai Nie; Yaping Zhang; Shan Liang; Wenju Liu', display:{Lore:['[{"text": "arXiv:1811.00883", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDeep Segment Attentive Embedding for Duration Robust Speaker Verification\\u00a7r\\n\\n\\u00a78\\u00a7oBin Liu\\nShuai Nie\\nYaping Zhang\\nShan Liang\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1811.00883\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 1 Nov 2018 01:21:41 GMT)\\u00a7r"}']}
{title:'Bhattacharjee et al. (§72018§r)', author: 'Mrinmoy Bhattacharjee; S. R. M. Prasanna; Prithwijit Guha', display:{Lore:['[{"text": "arXiv:1811.01222", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lTime-Frequency Audio Features for Speech-Music Classification\\u00a7r\\n\\n\\u00a78\\u00a7oMrinmoy Bhattacharjee\\nS. R. M. Prasanna\\nPrithwijit Guha\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1811.01222\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 3 Nov 2018 14:07:41 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o4 pages, 16 figures\\u00a7r"}']}
{title:'R et al. (§72018§r)', author: 'Pradeep R; Sreenivasa Rao K', display:{Lore:['[{"text": "arXiv:1811.01644", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lManner of Articulation Detection using Connectionist Temporal Classification to Improve Automatic Speech Recognition Performance\\u00a7r\\n\\n\\u00a78\\u00a7oPradeep R\\nSreenivasa Rao K\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1811.01644\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 5 Nov 2018 12:43:05 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 4 figures, ICASSP-2019\\u00a7r"}']}
{title:'Cho et al. (§72018§r)', author: 'Jaejin Cho; Shinji Watanabe; Takaaki Hori; Murali Karthick Baskar; Hirofumi Inaguma; Jesus Villalba; Najim Dehak', display:{Lore:['[{"text": "arXiv:1811.02162", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lLanguage model integration based on memory control for sequence to sequence speech recognition\\u00a7r\\n\\n\\u00a78\\u00a7oJaejin Cho\\nShinji Watanabe\\nTakaaki Hori\\n+ 3 others\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1811.02162\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 6 Nov 2018 04:56:44 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o4 pages, 1 figure, 5 tables, submitted to ICASSP 2019\\u00a7r"}']}
{title:'Rohdin et al. (§72018§r)', author: 'Johan Rohdin; Themos Stafylakis; Anna Silnova; Hossein Zeinali; Lukas Burget; Oldrich Plchot', display:{Lore:['[{"text": "arXiv:1811.02331", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSpeaker verification using end-to-end adversarial language adaptation\\u00a7r\\n\\n\\u00a78\\u00a7oJohan Rohdin\\nThemos Stafylakis\\nAnna Silnova\\n+ 2 others\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1811.02331\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 6 Nov 2018 12:56:01 GMT)\\u00a7r"}']}
{title:'Parcollet et al. (§72018§r)', author: 'Titouan Parcollet; Mohamed Morchid; Georges Linarès; Renato De Mori', display:{Lore:['[{"text": "arXiv:1811.02566", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7eeess.SP\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lBidirectional Quaternion Long-Short Term Memory Recurrent Neural Networks for Speech Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oTitouan Parcollet\\nMohamed Morchid\\nGeorges Linar\\u00e8s\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1811.02566\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 6 Nov 2018 21:17:34 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted at ICASSP 2019. arXiv admin note: text overlapwith arXiv:1806.04418\\u00a7r"}']}
{title:'Lim et al. (§72018§r)', author: 'Hyungjun Lim; Younggwan Kim; Youngmoon Jung; Myunghun Jung; Hoirin Kim', display:{Lore:['[{"text": "arXiv:1811.02736", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.AI\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7eeess.SP\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lLearning acoustic word embeddings with phonetically associated triplet network\\u00a7r\\n\\n\\u00a78\\u00a7oHyungjun Lim\\nYounggwan Kim\\nYoungmoon Jung\\nMyunghun Jung\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1811.02736\\u00a7r\\n\\nVersion:\\u00a77v3 (Wed, 28 Nov 2018 01:35:25 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 4 figures, submitted to ICASSP 2019\\u00a7r"}']}
{title:'Baskar et al. (§72018§r)', author: 'Murali Karthick Baskar; Lukáš Burget; Shinji Watanabe; Martin Karafiát; Takaaki Hori; Jan Honza Černocký', display:{Lore:['[{"text": "arXiv:1811.02770", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lPromising Accurate Prefix Boosting for sequence-to-sequence ASR\\u00a7r\\n\\n\\u00a78\\u00a7oMurali Karthick Baskar\\nLuk\\u00e1\\u0161 Burget\\nShinji Watanabe\\n+ 2 others\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1811.02770\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 7 Nov 2018 05:53:21 GMT)\\u00a7r"}']}
{title:'Novotny et al. (§72018§r)', author: 'Ondrej Novotny; Oldrich Plchot; Pavel Matejka; Ondrej Glembek', display:{Lore:['[{"text": "arXiv:1811.02938", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lOn the use of DNN Autoencoder for Robust Speaker Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oOndrej Novotny\\nOldrich Plchot\\nPavel Matejka\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1811.02938\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 7 Nov 2018 15:35:16 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 1 figure\\u00a7r"}']}
{title:'Klejsa et al. (§72018§r)', author: 'Janusz Klejsa; Per Hedelin; Cong Zhou; Roy Fejgin; Lars Villemoes', display:{Lore:['[{"text": "arXiv:1811.03021", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lHigh-quality speech coding with SampleRNN\\u00a7r\\n\\n\\u00a78\\u00a7oJanusz Klejsa\\nPer Hedelin\\nCong Zhou\\nRoy Fejgin\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1811.03021\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 7 Nov 2018 17:20:00 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to ICASSP 2019\\u00a7r"}']}
{title:'Bhattacharya et al. (§72018§r)', author: 'Gautam Bhattacharya; Jahangir Alam; Patrick Kenny', display:{Lore:['[{"text": "arXiv:1811.03055", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CV\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAdapting End-to-End Neural Speaker Verification to New Languages and Recording Conditions with Adversarial Training\\u00a7r\\n\\n\\u00a78\\u00a7oGautam Bhattacharya\\nJahangir Alam\\nPatrick Kenny\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1811.03055\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 7 Nov 2018 18:15:34 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to ICASSP 2019\\u00a7r"}']}
{title:'Bhattacharya et al. (§72018§r)', author: 'Gautam Bhattacharya; Joao Monteiro; Jahangir Alam; Patrick Kenny', display:{Lore:['[{"text": "arXiv:1811.03063", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CV\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lGenerative Adversarial Speaker Embedding Networks for Domain Robust End-to-End Speaker Verification\\u00a7r\\n\\n\\u00a78\\u00a7oGautam Bhattacharya\\nJoao Monteiro\\nJahangir Alam\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1811.03063\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 7 Nov 2018 18:23:01 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to ICASSP 2019\\u00a7r"}']}
{title:'Li et al. (§72018§r)', author: 'Lantian Li; Zhiyuan Tang; Ying Shi; Dong Wang', display:{Lore:['[{"text": "arXiv:1811.03255", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lPhonetic-attention scoring for deep speaker features in speaker verification\\u00a7r\\n\\n\\u00a78\\u00a7oLantian Li\\nZhiyuan Tang\\nYing Shi\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1811.03255\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 8 Nov 2018 03:54:55 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to ICASSP 2019\\u00a7r"}']}
{title:'Karafiát et al. (§72018§r)', author: 'Martin Karafiát; Murali Karthick Baskar; Shinji Watanabe; Takaaki Hori; Matthew Wiesner; Jan "Honza\'\' Černocký', display:{Lore:['[{"text": "arXiv:1811.03451", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAnalysis of Multilingual Sequence-to-Sequence speech recognition systems\\u00a7r\\n\\n\\u00a78\\u00a7oMartin Karafi\\u00e1t\\nMurali Karthick Baskar\\nShinji Watanabe\\n+ 2 others\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1811.03451\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 7 Nov 2018 09:59:24 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oarXiv admin note: text overlapwith arXiv:1810.03459\\u00a7r"}']}
{title:'Lee et al. (§72018§r)', author: 'Shih-kuang Lee; Syu-Siang Wang; Yu Tsao; Jeih-weih Hung', display:{Lore:['[{"text": "arXiv:1811.03486", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSpeech Enhancement Based on Reducing the Detail Portion of Speech Spectrograms in Modulation Domain via Discrete Wavelet Transform\\u00a7r\\n\\n\\u00a78\\u00a7oShih-kuang Lee\\nSyu-Siang Wang\\nYu Tsao\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1811.03486\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 8 Nov 2018 15:16:43 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o4 pages, 4 figures, to appear in ISCSLP 2018\\u00a7r"}']}
{title:'Kinnunen et al. (§72018§r)', author: 'Tomi Kinnunen; Rosa González Hautamäki; Ville Vestman; Md Sahidullah', display:{Lore:['[{"text": "arXiv:1811.03790", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lCan We Use Speaker Recognition Technology to Attack Itself? Enhancing Mimicry Attacks Using Automatic Target Speaker Selection\\u00a7r\\n\\n\\u00a78\\u00a7oTomi Kinnunen\\nRosa Gonz\\u00e1lez Hautam\\u00e4ki\\nVille Vestman\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1811.03790\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 9 Nov 2018 06:15:08 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o(A slightly shorter version) has been submitted to IEEE ICASSP 2019\\u00a7r"}']}
{title:'Kothinti et al. (§72018§r)', author: 'Sandeep Kothinti; Keisuke Imoto; Debmalya Chakrabarty; Gregory Sell; Shinji Watanabe; Mounya Elhilali', display:{Lore:['[{"text": "arXiv:1811.04048", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lJoint Acoustic and Class Inference for Weakly Supervised Sound Event Detection\\u00a7r\\n\\n\\u00a78\\u00a7oSandeep Kothinti\\nKeisuke Imoto\\nDebmalya Chakrabarty\\n+ 2 others\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1811.04048\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 9 Nov 2018 18:06:21 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to ICASSP 2019\\u00a7r"}']}
{title:'Tanaka et al. (§72018§r)', author: 'Kou Tanaka; Hirokazu Kameoka; Takuhiro Kaneko; Nobukatsu Hojo', display:{Lore:['[{"text": "arXiv:1811.04076", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAttS2S-VC: Sequence-to-Sequence Voice Conversion with Attention and Context Preservation Mechanisms\\u00a7r\\n\\n\\u00a78\\u00a7oKou Tanaka\\nHirokazu Kameoka\\nTakuhiro Kaneko\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1811.04076\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 9 Nov 2018 05:19:43 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to ICASSP2019\\u00a7r"}']}
{title:'Shen et al. (§72018§r)', author: 'Yih-Liang Shen; Chao-Yuan Huang; Syu-Siang Wang; Yu Tsao; Hsin-Min Wang; Tai-Shih Chi', display:{Lore:['[{"text": "arXiv:1811.04224", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lReinforcement Learning Based Speech Enhancement for Robust Speech Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oYih-Liang Shen\\nChao-Yuan Huang\\nSyu-Siang Wang\\n+ 2 others\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1811.04224\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 10 Nov 2018 09:38:36 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oConference paper with 4 pages, reinforcement learning, automatic speech recognition, speech enhancement, deep neural network, character error rate\\u00a7r"}']}
{title:'Bäckström (§72018§r)', author: 'Tom Bäckström', display:{Lore:['[{"text": "arXiv:1811.05720", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSpeech Coding, Speech Interfaces and IoT - Opportunities and Challenges\\u00a7r\\n\\n\\u00a78\\u00a7oTom B\\u00e4ckstr\\u00f6m\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1811.05720\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 14 Nov 2018 10:42:34 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oaccepted and presented at Asilomar Conference on Signals, Systems, and Computers 2018 (submitted version)\\u00a7r"}']}
{title:'Bhattacharya et al. (§72018§r)', author: 'Aniruddha Bhattacharya; K. V. Kadambari', display:{Lore:['[{"text": "arXiv:1811.05760", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.CV\\u00a7r, \\u00a7acs.MM\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Multimodal Approach towards Emotion Recognition of Music using Audio and Lyrical Content\\u00a7r\\n\\n\\u00a78\\u00a7oAniruddha Bhattacharya\\nK. V. Kadambari\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1811.05760\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 10 Oct 2018 20:51:03 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o6 pages\\u00a7r"}']}
{title:'Aussal et al. (§72018§r)', author: 'Matthieu Aussal; Robin Gueguen', display:{Lore:['[{"text": "arXiv:1811.05784", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CE\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lOpen-source platforms for fast room acoustic simulations in complex structures\\u00a7r\\n\\n\\u00a78\\u00a7oMatthieu Aussal\\nRobin Gueguen\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1811.05784\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 13 Nov 2018 14:41:25 GMT)\\u00a7r"}']}
{title:'Michelsanti et al. (§72018§r)', author: 'Daniel Michelsanti; Zheng-Hua Tan; Sigurdur Sigurdsson; Jesper Jensen', display:{Lore:['[{"text": "arXiv:1811.06234", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7eeess.IV\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lOn Training Targets and Objective Functions for Deep-Learning-Based Audio-Visual Speech Enhancement\\u00a7r\\n\\n\\u00a78\\u00a7oDaniel Michelsanti\\nZheng-Hua Tan\\nSigurdur Sigurdsson\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1811.06234\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/ICASSP.2019.8682790\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 15 Nov 2018 08:39:04 GMT)\\u00a7r"}']}
{title:'Michelsanti et al. (§72018§r)', author: 'Daniel Michelsanti; Zheng-Hua Tan; Sigurdur Sigurdsson; Jesper Jensen', display:{Lore:['[{"text": "arXiv:1811.06250", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7eeess.IV\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lEffects of Lombard Reflex on the Performance of Deep-Learning-Based Audio-Visual Speech Enhancement Systems\\u00a7r\\n\\n\\u00a78\\u00a7oDaniel Michelsanti\\nZheng-Hua Tan\\nSigurdur Sigurdsson\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1811.06250\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/ICASSP.2019.8682713\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 15 Nov 2018 09:29:14 GMT)\\u00a7r"}']}
{title:'Merritt et al. (§72018§r)', author: 'Thomas Merritt; Bartosz Putrycz; Adam Nadolski; Tianjun Ye; Daniel Korzekwa; Wiktor Dolecki; Thomas Drugman; Viacheslav Klimkov; Alexis Moinet; Andrew Breen; Rafal Kuklinski; Nikko Strom; Roberto Barra-Chicote', display:{Lore:['[{"text": "arXiv:1811.06296", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lComprehensive evaluation of statistical speech waveform synthesis\\u00a7r\\n\\n\\u00a78\\u00a7oThomas Merritt\\nBartosz Putrycz\\nAdam Nadolski\\n+ 9 others\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1811.06296\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 11 Dec 2018 15:13:51 GMT)\\u00a7r"}']}
{title:'Ananthabhotla et al. (§72018§r)', author: 'Ishwarya Ananthabhotla; Joseph A. Paradiso', display:{Lore:['[{"text": "arXiv:1811.06859", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.IR\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSoundSignaling: Realtime, Stylistic Modification of a Personal Music Corpus for Information Delivery\\u00a7r\\n\\n\\u00a78\\u00a7oIshwarya Ananthabhotla\\nJoseph A. Paradiso\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1811.06859\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 16 Nov 2018 15:32:28 GMT)\\u00a7r"}']}
{title:'Novotny et al. (§72018§r)', author: 'Ondrej Novotny; Oldrich Plchot; Ondrej Glembek; Jan "Honza" Cernocky; Lukas Burget', display:{Lore:['[{"text": "arXiv:1811.07629", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAnalysis of DNN Speech Signal Enhancement for Robust Speaker Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oOndrej Novotny\\nOldrich Plchot\\nOndrej Glembek\\nJan \\"Honza\\" Cernocky\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1811.07629\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 19 Nov 2018 11:41:23 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o16 pages, 7 figures, Submission to Computer Speech and Language, special issue on Speaker and language characterization and recognition\\u00a7r"}']}
{title:'Chakrabarty et al. (§72018§r)', author: 'Soumitro Chakrabarty; Emanuël A. P. Habets', display:{Lore:['[{"text": "arXiv:1811.08552", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMulti-scale aggregation of phase information for reducing computational cost of CNN based DOA estimation\\u00a7r\\n\\n\\u00a78\\u00a7oSoumitro Chakrabarty\\nEmanu\\u00ebl A. P. Habets\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1811.08552\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.23919/EUSIPCO.2019.8903176\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 20 Nov 2018 12:29:51 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oarXiv admin note: text overlapwith arXiv:1807.11722\\u00a7r"}']}
{title:'Noroozi et al. (§72018§r)', author: 'Fatemeh Noroozi; Marina Marjanovic; Angelina Njegus; Sergio Escalera; Gholamreza Anbarjafari', display:{Lore:['[{"text": "arXiv:1811.08935", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Study of Language and Classifier-independent Feature Analysis for Vocal Emotion Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oFatemeh Noroozi\\nMarina Marjanovic\\nAngelina Njegus\\nSergio Escalera\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1811.08935\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 14 Nov 2018 08:54:24 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o24 pages, 4 figure\\u00a7r"}']}
{title:'Li et al. (§72018§r)', author: 'Bo Li; Yu Zhang; Tara Sainath; Yonghui Wu; William Chan', display:{Lore:['[{"text": "arXiv:1811.09021", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lBytes are All You Need: End-to-End Multilingual Speech Recognition and Synthesis with Bytes\\u00a7r\\n\\n\\u00a78\\u00a7oBo Li\\nYu Zhang\\nTara Sainath\\nYonghui Wu\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1811.09021\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 22 Nov 2018 04:37:55 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7osubmitted to ICASSP 2019\\u00a7r"}']}
{title:'Parcollet et al. (§72018§r)', author: 'Titouan Parcollet; Mirco Ravanelli; Mohamed Morchid; Georges Linarès; Renato De Mori', display:{Lore:['[{"text": "arXiv:1811.09678", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSpeech recognition with quaternion neural networks\\u00a7r\\n\\n\\u00a78\\u00a7oTitouan Parcollet\\nMirco Ravanelli\\nMohamed Morchid\\nGeorges Linar\\u00e8s\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1811.09678\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 21 Nov 2018 10:27:02 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oNIPS 2018 (IRASL). arXiv admin note: text overlapwith arXiv:1806.04418\\u00a7r"}']}
{title:'Luz et al. (§72018§r)', author: 'Saturnino Luz; Sofia de la Fuente; Pierre Albert', display:{Lore:['[{"text": "arXiv:1811.09919", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Method for Analysis of Patient Speech in Dialogue for Dementia Detection\\u00a7r\\n\\n\\u00a78\\u00a7oSaturnino Luz\\nSofia de la Fuente\\nPierre Albert\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1811.09919\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 25 Nov 2018 01:30:16 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o8 pages, Resources and ProcessIng of linguistic, paralinguisticand extra-linguistic Data from people with various forms of cognitive impairment, LREC 2018\\u00a7r"}']}
{title:'Chai et al. (§72018§r)', author: 'Li Chai; Jun Du; Chin-Hui Lee', display:{Lore:['[{"text": "arXiv:1811.11517", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAcoustics-guided evaluation (AGE): a new measure for estimating performance of speech enhancement algorithms for robust ASR\\u00a7r\\n\\n\\u00a78\\u00a7oLi Chai\\nJun Du\\nChin-Hui Lee\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1811.11517\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 28 Nov 2018 12:13:23 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to ICASSP 2019\\u00a7r"}']}
{title:'Grondin et al. (§72018§r)', author: 'Francois Grondin; James Glass', display:{Lore:['[{"text": "arXiv:1811.11787", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7eeess.SP\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Study of the Complexity and Accuracy of Direction of Arrival Estimation Methods Based on GCC-PHAT for a Pair of Close Microphones\\u00a7r\\n\\n\\u00a78\\u00a7oFrancois Grondin\\nJames Glass\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1811.11787\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 28 Nov 2018 19:11:57 GMT)\\u00a7r"}']}
{title:'Grondin et al. (§72018§r)', author: 'Francois Grondin; Francois Michaud', display:{Lore:['[{"text": "arXiv:1812.00115", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lLightweight and Optimized Sound Source Localization and Tracking Methods for Open and Closed Microphone Array Configurations\\u00a7r\\n\\n\\u00a78\\u00a7oFrancois Grondin\\nFrancois Michaud\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1812.00115\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 1 Dec 2018 01:16:06 GMT)\\u00a7r"}']}
{title:'Chetupalli et al. (§72018§r)', author: 'Srikanth Raj Chetupalli; Thippur V. Sreenivas', display:{Lore:['[{"text": "arXiv:1812.01346", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lLSTM based AE-DNN constraint for better late reverb suppression in multi-channel LP formulation\\u00a7r\\n\\n\\u00a78\\u00a7oSrikanth Raj Chetupalli\\nThippur V. Sreenivas\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1812.01346\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 4 Dec 2018 11:37:25 GMT)\\u00a7r"}']}
{title:'Rida (§72018§r)', author: 'Imad Rida', display:{Lore:['[{"text": "arXiv:1812.01780", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7eeess.IV\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lFeature Extraction for Temporal Signal Recognition: An Overview\\u00a7r\\n\\n\\u00a78\\u00a7oImad Rida\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1812.01780\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 3 Dec 2018 21:26:57 GMT)\\u00a7r"}']}
{title:'Meghanani et al. (§72018§r)', author: 'Amit Meghanani; A G Ramakrishnan', display:{Lore:['[{"text": "arXiv:1812.02447", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lPitch-synchronous DCT features: A pilot study on speaker identification\\u00a7r\\n\\n\\u00a78\\u00a7oAmit Meghanani\\nA G Ramakrishnan\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1812.02447\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 6 Dec 2018 10:35:47 GMT)\\u00a7r"}']}
{title:'Klautau (§72018§r)', author: 'Aldebaro Klautau', display:{Lore:['[{"text": "arXiv:1812.02705", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7eeess.SP\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lFrequency Tracking: LMS and RLS Applied to Speech Formant Estimation (2000)\\u00a7r\\n\\n\\u00a78\\u00a7oAldebaro Klautau\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1812.02705\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 6 Dec 2018 18:39:45 GMT)\\u00a7r"}']}
{title:'Salin et al. (§72018§r)', author: 'Mikhail B. Salin; Dmitrii A. Kosteev', display:{Lore:['[{"text": "arXiv:1812.03826", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a75physics.app-ph\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lExamples of usage of nearfield acoustic holography methods for far field estimations: Part 1. CW signals\\u00a7r\\n\\n\\u00a78\\u00a7oMikhail B. Salin\\nDmitrii A. Kosteev\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1812.03826\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 27 Nov 2018 20:51:58 GMT)\\u00a7r"}']}
{title:'Chew et al. (§72018§r)', author: 'Jeremy Chew; Yingxiang Sun; Lahiru Jayasinghe; Chau Yuen', display:{Lore:['[{"text": "arXiv:1812.04618", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDCASE 2018 Challenge: Solution for Task 5\\u00a7r\\n\\n\\u00a78\\u00a7oJeremy Chew\\nYingxiang Sun\\nLahiru Jayasinghe\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1812.04618\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 11 Dec 2018 07:35:42 GMT)\\u00a7r"}']}
{title:'Dekkers et al. (§72018§r)', author: 'Gert Dekkers; Fernando Rosas; Steven Lauwereins; Sreeraj Rajendran; Sofie Pollin; Bart Vanrumste; Toon van Waterschoot; Marian Verhelst; Peter Karsmakers', display:{Lore:['[{"text": "arXiv:1812.06672", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA multi-layered energy consumption model for smart wireless acoustic sensor networks\\u00a7r\\n\\n\\u00a78\\u00a7oGert Dekkers\\nFernando Rosas\\nSteven Lauwereins\\n+ 5 others\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1812.06672\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 17 Dec 2018 09:59:24 GMT)\\u00a7r"}']}
{title:'Comminiello et al. (§72018§r)', author: 'Danilo Comminiello; Marco Lella; Simone Scardapane; Aurelio Uncini', display:{Lore:['[{"text": "arXiv:1812.06811", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lQuaternion Convolutional Neural Networks for Detection and Localization of 3D Sound Events\\u00a7r\\n\\n\\u00a78\\u00a7oDanilo Comminiello\\nMarco Lella\\nSimone Scardapane\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1812.06811\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/ICASSP.2019.8682711\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7n2019 IEEE International Conference on Acoustics, Speech and Signal\\n  Processing (ICASSP), 2019, pp. 8533-8537\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 17 Dec 2018 14:49:25 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to ICASSP 2019\\u00a7r"}']}
{title:'Pishgar et al. (§72018§r)', author: 'Maryam Pishgar; Fazle Karim; Somshubra Majumdar; Houshang Darabi', display:{Lore:['[{"text": "arXiv:1812.07729", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lPathological Voice Classification Using Mel-Cepstrum Vectors and Support Vector Machine\\u00a7r\\n\\n\\u00a78\\u00a7oMaryam Pishgar\\nFazle Karim\\nSomshubra Majumdar\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1812.07729\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 19 Dec 2018 02:00:24 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted at IEEEBigData 2018 Workshop - FEMH Voice Data Challenge\\u00a7r"}']}
{title:'Kim et al. (§72018§r)', author: 'Jang-Hyun Kim; Jaejun Yoo; Sanghyuk Chun; Adrian Kim; Jung-Woo Ha', display:{Lore:['[{"text": "arXiv:1812.08914", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMulti-Domain Processing via Hybrid Denoising Networks for Speech Enhancement\\u00a7r\\n\\n\\u00a78\\u00a7oJang-Hyun Kim\\nJaejun Yoo\\nSanghyuk Chun\\nAdrian Kim\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1812.08914\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 21 Dec 2018 02:12:22 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o7pages, 6 figures, 2 tables\\u00a7r"}']}
{title:'Yeh et al. (§72018§r)', author: 'Chih-Kuan Yeh; Jianshu Chen; Chengzhu Yu; Dong Yu', display:{Lore:['[{"text": "arXiv:1812.09323", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lUnsupervised Speech Recognition via Segmental Empirical Output Distribution Matching\\u00a7r\\n\\n\\u00a78\\u00a7oChih-Kuan Yeh\\nJianshu Chen\\nChengzhu Yu\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1812.09323\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 23 Dec 2018 01:58:39 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oPublished as a conference paper at ICLR 2019\\u00a7r"}']}
{title:'Choi et al. (§72018§r)', author: 'Yoona Choi; Bowon Lee', display:{Lore:['[{"text": "arXiv:1812.09798", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lPansori: ASR Corpus Generation from Open Online Video Contents\\u00a7r\\n\\n\\u00a78\\u00a7oYoona Choi\\nBowon Lee\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1812.09798\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nProceedings of IEEE Seoul Section Student Paper Contest 2018,\\n  Hongik University, pp. 117--121, Nov 2018\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 23 Dec 2018 23:57:07 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages with appendix\\u00a7r"}']}
{title:'Miguel et al. (§72018§r)', author: 'Antonio Miguel; Jorge Llombart; Alfonso Ortega; Eduardo Lleida', display:{Lore:['[{"text": "arXiv:1812.11946", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lTied Hidden Factors in Neural Networks for End-to-End Speaker Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oAntonio Miguel\\nJorge Llombart\\nAlfonso Ortega\\u00a7r\\n\\n\\u00a772018\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1812.11946\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.21437/Interspeech.2017-1314\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nProc. Interspeech 2017, 2819-2823\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 27 Dec 2018 17:07:12 GMT)\\u00a7r"}']}
