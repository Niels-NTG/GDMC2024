{title:'Wan et al. (§72020§r)', author: 'Li Wan; Quan Wang; Alan Papir; Ignacio Lopez Moreno', display:{Lore:['[{"text": "arXiv:1710.10467", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lGeneralized End-to-End Loss for Speaker Verification\\u00a7r\\n\\n\\u00a78\\u00a7oLi Wan\\nQuan Wang\\nAlan Papir\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1710.10467\\u00a7r\\n\\nVersion:\\u00a77v5 (Mon, 9 Nov 2020 17:02:39 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oPublished at ICASSP 2018\\u00a7r"}']}
{title:'Diaz-Guerra et al. (§72020§r)', author: 'David Diaz-Guerra; Antonio Miguel; Jose R. Beltran', display:{Lore:['[{"text": "arXiv:1810.11359", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lgpuRIR: A Python Library for Room Impulse Response Simulation with GPU Acceleration\\u00a7r\\n\\n\\u00a78\\u00a7oDavid Diaz-Guerra\\nAntonio Miguel\\nJose R. Beltran\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1810.11359\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1007/s11042-020-09905-3\\u00a7r\\n\\nVersion:\\u00a77v4 (Fri, 9 Oct 2020 07:51:26 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oThis is a pre-print of an article published in Multimedia Tools and Applications (2020)\\u00a7r"}']}
{title:'Záviška et al. (§72020§r)', author: 'Pavel Záviška; Pavel Rajmic; Ondřej Mokrý; Zdeněk Průša', display:{Lore:['[{"text": "arXiv:1810.12204", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Proper version of Synthesis-based Sparse Audio Declipper\\u00a7r\\n\\n\\u00a78\\u00a7oPavel Z\\u00e1vi\\u0161ka\\nPavel Rajmic\\nOnd\\u0159ej Mokr\\u00fd\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1810.12204\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/ICASSP.2019.8682348\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nICASSP 2019 - 2019 IEEE International Conference on Acoustics,\\n  Speech and Signal Processing (ICASSP), Brighton, United Kingdom, 2019, pp.\\n  591-595\\u00a7r\\n\\nVersion:\\u00a77v4 (Thu, 16 Jan 2020 11:40:16 GMT)\\u00a7r"}']}
{title:'Song et al. (§72020§r)', author: 'Eunwoo Song; Jin-Seob Kim; Kyungguen Byun; Hong-Goo Kang', display:{Lore:['[{"text": "arXiv:1811.03311", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSpeaker-adaptive neural vocoders for parametric speech synthesis systems\\u00a7r\\n\\n\\u00a78\\u00a7oEunwoo Song\\nJin-Seob Kim\\nKyungguen Byun\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1811.03311\\u00a7r\\n\\nVersion:\\u00a77v5 (Sat, 1 Aug 2020 05:24:15 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted to the IEEE Workshop of MMSP 2020\\u00a7r"}']}
{title:'Hermann et al. (§72020§r)', author: 'Enno Hermann; Herman Kamper; Sharon Goldwater', display:{Lore:['[{"text": "arXiv:1811.04791", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMultilingual and Unsupervised Subword Modeling for Zero-Resource Languages\\u00a7r\\n\\n\\u00a78\\u00a7oEnno Hermann\\nHerman Kamper\\nSharon Goldwater\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1811.04791\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1016/j.csl.2020.101098\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 7 Apr 2020 20:15:54 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o17 pages, 6 figures, 7 tables. Accepted for publication in Computer Speech and Language. arXiv admin note: text overlap with arXiv:1803.08863\\u00a7r"}']}
{title:'Hwang et al. (§72020§r)', author: 'Min-Jae Hwang; Frank Soong; Eunwoo Song; Xi Wang; Hyeonjoo Kang; Hong-Goo Kang', display:{Lore:['[{"text": "arXiv:1811.11913", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lLP-WaveNet: Linear Prediction-based WaveNet Speech Synthesis\\u00a7r\\n\\n\\u00a78\\u00a7oMin-Jae Hwang\\nFrank Soong\\nEunwoo Song\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1811.11913\\u00a7r\\n\\nVersion:\\u00a77v2 (Wed, 4 Mar 2020 09:24:33 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to EUSIPCO 2020\\u00a7r"}']}
{title:'Ma et al. (§72020§r)', author: 'Dabiao Ma; Zhiba Su; Wenxuan Wang; Yuhao Lu', display:{Lore:['[{"text": "arXiv:1812.05710", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lFPETS : Fully Parallel End-to-End Text-to-Speech System\\u00a7r\\n\\n\\u00a78\\u00a7oDabiao Ma\\nZhiba Su\\nWenxuan Wang\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1812.05710\\u00a7r\\n\\nVersion:\\u00a77v5 (Sun, 9 Feb 2020 18:19:09 GMT)\\u00a7r"}']}
{title:'Malekzadeh et al. (§72020§r)', author: 'Saber Malekzadeh; Mohammad Hossein Gholizadeh; Hossein Ghayoumi zadeh; Seyed Naser Razavi', display:{Lore:['[{"text": "arXiv:1812.08600", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lThe Recognition Of Persian Phonemes Using PPNet\\u00a7r\\n\\n\\u00a78\\u00a7oSaber Malekzadeh\\nMohammad Hossein Gholizadeh\\nHossein Ghayoumi zadeh\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1812.08600\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.13140/RG.2.2.34836.96647\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nhttp://www.journalonweb.com/jmss/2019\\u00a7r\\n\\nVersion:\\u00a77v2 (Sun, 22 Mar 2020 15:57:16 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted in \\"Journal of Medical Signals Sensors\\". arXivadmin note: substantial text overlap with arXiv:1812.06953\\u00a7r"}']}
{title:'Papayiannis et al. (§72020§r)', author: 'Constantinos Papayiannis; Christine Evers; Patrick A. Naylor', display:{Lore:['[{"text": "arXiv:1812.09324", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lEnd-to-End Classification of Reverberant Rooms using DNNs\\u00a7r\\n\\n\\u00a78\\u00a7oConstantinos Papayiannis\\nChristine Evers\\nPatrick A. Naylor\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1812.09324\\u00a7r\\n\\nVersion:\\u00a77v6 (Sun, 1 Nov 2020 22:04:47 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted for publication in IEEE/ACM Transactions on Audio, Speech, and Language Processing\\u00a7r"}']}
{title:'Papayiannis et al. (§72020§r)', author: 'Constantinos Papayiannis; Christine Evers; Patrick A. Naylor', display:{Lore:['[{"text": "arXiv:1901.03257", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lData Augmentation of Room Classifiers using Generative Adversarial Networks\\u00a7r\\n\\n\\u00a78\\u00a7oConstantinos Papayiannis\\nChristine Evers\\nPatrick A. Naylor\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1901.03257\\u00a7r\\n\\nVersion:\\u00a77v4 (Fri, 4 Dec 2020 14:28:30 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to IEEE/ACM Transactionson Audio, Speech, and Language Processing\\u00a7r"}']}
{title:'Liu et al. (§72020§r)', author: 'Xiaolei Liu; Xiaosong Zhang; Kun Wan; Qingxin Zhu; Yufei Ding', display:{Lore:['[{"text": "arXiv:1901.10300", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lWeighted-Sampling Audio Adversarial Example Attack\\u00a7r\\n\\n\\u00a78\\u00a7oXiaolei Liu\\nXiaosong Zhang\\nKun Wan\\nQingxin Zhu\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1901.10300\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1609/aaai.v34i04.5928\\u00a7r\\n\\nVersion:\\u00a77v4 (Sat, 22 Feb 2020 15:32:06 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7ohttps://aaai.org/Papers/AAAI/2020GB/AAAI-LiuXL.9260.pdf\\u00a7r"}']}
{title:'Bai et al. (§72020§r)', author: 'Zhongxin Bai; Xiao-Lei Zhang; Jingdong Chen', display:{Lore:['[{"text": "arXiv:1902.00889", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSpeaker Verification By Partial AUC Optimization With Mahalanobis Distance Metric Learning\\u00a7r\\n\\n\\u00a78\\u00a7oZhongxin Bai\\nXiao-Lei Zhang\\nJingdong Chen\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1902.00889\\u00a7r\\n\\nVersion:\\u00a77v4 (Tue, 21 Apr 2020 16:01:22 GMT)\\u00a7r"}']}
{title:'Kumar et al. (§72020§r)', author: 'Mari Ganesh Kumar; Suvidha Rupesh Kumar; Saranya M; B. Bharathi; Hema A. Murthy', display:{Lore:['[{"text": "arXiv:1904.07453", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CR\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSpoof detection using time-delay shallow neural network and feature switching\\u00a7r\\n\\n\\u00a78\\u00a7oMari Ganesh Kumar\\nSuvidha Rupesh Kumar\\nSaranya M\\nB. Bharathi\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1904.07453\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/ASRU46091.2019.9003824\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7n2019 IEEE Automatic Speech Recognition and Understanding Workshop\\n  (ASRU), 1011--1017\\u00a7r\\n\\nVersion:\\u00a77v2 (Thu, 23 Jan 2020 09:25:59 GMT)\\u00a7r"}']}
{title:'Alamdari et al. (§72020§r)', author: 'Nasim Alamdari; Arian Azarang; Nasser Kehtarnavaz', display:{Lore:['[{"text": "arXiv:1904.12069", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7eeess.SP\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lImproving Deep Speech Denoising by Noisy2Noisy Signal Mapping\\u00a7r\\n\\n\\u00a78\\u00a7oNasim Alamdari\\nArian Azarang\\nNasser Kehtarnavaz\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1904.12069\\u00a7r\\n\\nVersion:\\u00a77v2 (Fri, 21 Feb 2020 20:35:17 GMT)\\u00a7r"}']}
{title:'Jimenez-Fernandez et al. (§72020§r)', author: 'Angel Jimenez-Fernandez; Daniel Gutierrez-Galan; Antonio Rios-Navarro; Juan Pedro Dominguez-Morales; Gabriel Jimenez-Moreno', display:{Lore:['[{"text": "arXiv:1905.00390", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7eeess.SP\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lInterfacing PDM MEMS microphones with PFM spiking systems: Application for Neuromorphic Auditory Sensors\\u00a7r\\n\\n\\u00a78\\u00a7oAngel Jimenez-Fernandez\\nDaniel Gutierrez-Galan\\nAntonio Rios-Navarro\\nJuan Pedro Dominguez-Morales\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1905.00390\\u00a7r\\n\\nVersion:\\u00a77v2 (Mon, 16 Mar 2020 11:17:44 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oThis work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\\u00a7r"}']}
{title:'Záviška et al. (§72020§r)', author: 'Pavel Záviška; Pavel Rajmic; Jíří Schimmel', display:{Lore:['[{"text": "arXiv:1905.00628", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lPsychoacoustically Motivated Audio Declipping Based on Weighted l1 Minimization\\u00a7r\\n\\n\\u00a78\\u00a7oPavel Z\\u00e1vi\\u0161ka\\nPavel Rajmic\\nJ\\u00ed\\u0159\\u00ed Schimmel\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1905.00628\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/TSP.2019.8769109\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7n2019 42nd International Conference on Telecommunications and\\n  Signal Processing (TSP)\\u00a7r\\n\\nVersion:\\u00a77v2 (Wed, 1 Jul 2020 15:37:25 GMT)\\u00a7r"}']}
{title:'Gößling et al. (§72020§r)', author: 'Nico Gößling; Elior Hadad; Sharon Gannot; Simon Doclo', display:{Lore:['[{"text": "arXiv:1905.04050", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lBinaural LCMV Beamforming with Partial Noise Estimation\\u00a7r\\n\\n\\u00a78\\u00a7oNico G\\u00f6\\u00dfling\\nElior Hadad\\nSharon Gannot\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1905.04050\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/TASLP.2020.3034526\\u00a7r\\n\\nVersion:\\u00a77v2 (Thu, 21 May 2020 15:18:53 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7osubmitted to IEEE/ACM Transactionson Audio, Speech, and Language Processing\\u00a7r"}']}
{title:'Skoglund et al. (§72020§r)', author: 'Jan Skoglund; Jean-Marc Valin', display:{Lore:['[{"text": "arXiv:1905.04628", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lImproving Opus Low Bit Rate Quality with Neural Speech Synthesis\\u00a7r\\n\\n\\u00a78\\u00a7oJan Skoglund\\nJean-Marc Valin\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1905.04628\\u00a7r\\n\\nVersion:\\u00a77v3 (Mon, 10 Aug 2020 07:35:59 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oProc. Interspeech 2020, 5 pages\\u00a7r"}']}
{title:'Ren et al. (§72020§r)', author: 'Yi Ren; Xu Tan; Tao Qin; Sheng Zhao; Zhou Zhao; Tie-Yan Liu', display:{Lore:['[{"text": "arXiv:1905.06791", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAlmost Unsupervised Text to Speech and Automatic Speech Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oYi Ren\\nXu Tan\\nTao Qin\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1905.06791\\u00a7r\\n\\nVersion:\\u00a77v3 (Sun, 26 Jul 2020 09:31:42 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted by ICML2019\\u00a7r"}']}
{title:'Nicolson et al. (§72020§r)', author: 'Aaron Nicolson; Kuldip K. Paliwal', display:{Lore:['[{"text": "arXiv:1906.07319", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7eeess.SP\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDeep Xi as a Front-End for Robust Automatic Speech Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oAaron Nicolson\\nKuldip K. Paliwal\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1906.07319\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 28 Jan 2020 04:29:44 GMT)\\u00a7r"}']}
{title:'Han et al. (§72020§r)', author: 'Yan Han; Gautam Krishna; Co Tran; Mason Carnahan; Ahmed H Tewfik', display:{Lore:['[{"text": "arXiv:1906.08044", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7eeess.SP\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lRobust End-to-End Speaker Verification Using EEG\\u00a7r\\n\\n\\u00a78\\u00a7oYan Han\\nGautam Krishna\\nCo Tran\\nMason Carnahan\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1906.08044\\u00a7r\\n\\nVersion:\\u00a77v5 (Wed, 10 Jun 2020 00:42:49 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted for EUSIPCO 2020\\u00a7r"}']}
{title:'Krishna et al. (§72020§r)', author: 'Gautam Krishna; Co Tran; Yan Han; Mason Carnahan; Ahmed H Tewfik', display:{Lore:['[{"text": "arXiv:1906.08045", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7eeess.SP\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSpeech Recognition With No Speech Or With Noisy Speech Beyond English\\u00a7r\\n\\n\\u00a78\\u00a7oGautam Krishna\\nCo Tran\\nYan Han\\nMason Carnahan\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1906.08045\\u00a7r\\n\\nVersion:\\u00a77v5 (Thu, 27 Feb 2020 03:11:06 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oarXiv admin note: text overlapwith arXiv:1906.08871\\u00a7r"}']}
{title:'Krishna et al. (§72020§r)', author: 'Gautam Krishna; Co Tran; Mason Carnahan; Ahmed H Tewfik', display:{Lore:['[{"text": "arXiv:1906.08871", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAdvancing Speech Recognition With No Speech Or With Noisy Speech\\u00a7r\\n\\n\\u00a78\\u00a7oGautam Krishna\\nCo Tran\\nMason Carnahan\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1906.08871\\u00a7r\\n\\nVersion:\\u00a77v9 (Sun, 15 Mar 2020 02:51:46 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oExtended version of our accepted IEEE EUSIPCO 2019 paper with additional results for CTC model based recognition. arXiv adminnote: substantial text overlap with arXiv:1906.08045, arXiv:1906.08044\\u00a7r"}']}
{title:'Wu et al. (§72020§r)', author: 'Yi-Chiao Wu; Tomoki Hayashi; Patrick Lumban Tobing; Kazuhiro Kobayashi; Tomoki Toda', display:{Lore:['[{"text": "arXiv:1907.00797", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lQuasi-Periodic WaveNet Vocoder: A Pitch Dependent Dilated Convolution Model for Parametric Speech Generation\\u00a7r\\n\\n\\u00a78\\u00a7oYi-Chiao Wu\\nTomoki Hayashi\\nPatrick Lumban Tobing\\nKazuhiro Kobayashi\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1907.00797\\u00a7r\\n\\nVersion:\\u00a77v4 (Sun, 22 Mar 2020 05:20:18 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 4 figures, Proc. Interspeech, 2019\\u00a7r"}']}
{title:'Wu et al. (§72020§r)', author: 'Yi-Chiao Wu; Patrick Lumban Tobing; Tomoki Hayashi; Kazuhiro Kobayashi; Tomoki Toda', display:{Lore:['[{"text": "arXiv:1907.08940", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lStatistical Voice Conversion with Quasi-Periodic WaveNet Vocoder\\u00a7r\\n\\n\\u00a78\\u00a7oYi-Chiao Wu\\nPatrick Lumban Tobing\\nTomoki Hayashi\\nKazuhiro Kobayashi\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1907.08940\\u00a7r\\n\\nVersion:\\u00a77v2 (Sun, 22 Mar 2020 05:23:26 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o6pages, 7figures, Proc. SSW10, 2019\\u00a7r"}']}
{title:'Laufer et al. (§72020§r)', author: 'Yaron Laufer; Bracha Laufer-Goldshtein; Sharon Gannot', display:{Lore:['[{"text": "arXiv:1907.09250", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lML Estimation and CRBs for Reverberation, Speech and Noise PSDs in Rank-Deficient Noise-Field\\u00a7r\\n\\n\\u00a78\\u00a7oYaron Laufer\\nBracha Laufer-Goldshtein\\nSharon Gannot\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1907.09250\\u00a7r\\n\\nVersion:\\u00a77v2 (Mon, 27 Jan 2020 13:01:47 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted for publication in IEEE/ACM Transactions on Audio, Speech, and Language Processing\\u00a7r"}']}
{title:'De Sena et al. (§72020§r)', author: 'Enzo De Sena; Zoran Cvetkovic; Huseyin Hacihabiboglu; Marc Moonen; Toon van Waterschoot', display:{Lore:['[{"text": "arXiv:1907.11425", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lLocalization Uncertainty in Time-Amplitude Stereophonic Reproduction\\u00a7r\\n\\n\\u00a78\\u00a7oEnzo De Sena\\nZoran Cvetkovic\\nHuseyin Hacihabiboglu\\nMarc Moonen\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1907.11425\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/TASLP.2020.2975419\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nIEEE/ACM Trans. Audio, Speech and Language Process. vol 28, pp.\\n  1000 - 1015, Feb. 2020\\u00a7r\\n\\nVersion:\\u00a77v2 (Mon, 7 Sep 2020 00:30:51 GMT)\\u00a7r"}']}
{title:'Ding et al. (§72020§r)', author: 'Shaojin Ding; Quan Wang; Shuo-yiin Chang; Li Wan; Ignacio Lopez Moreno', display:{Lore:['[{"text": "arXiv:1908.04284", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lPersonal VAD: Speaker-Conditioned Voice Activity Detection\\u00a7r\\n\\n\\u00a78\\u00a7oShaojin Ding\\nQuan Wang\\nShuo-yiin Chang\\nLi Wan\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1908.04284\\u00a7r\\n\\nVersion:\\u00a77v4 (Wed, 8 Apr 2020 15:41:16 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSpeaker Odyssey 2020\\u00a7r"}']}
{title:'Krishna et al. (§72020§r)', author: 'Gautam Krishna; Yan Han; Co Tran; Mason Carnahan; Ahmed H Tewfik', display:{Lore:['[{"text": "arXiv:1908.05743", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lState-of-the-art Speech Recognition using EEG and Towards Decoding of Speech Spectrum From EEG\\u00a7r\\n\\n\\u00a78\\u00a7oGautam Krishna\\nYan Han\\nCo Tran\\nMason Carnahan\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1908.05743\\u00a7r\\n\\nVersion:\\u00a77v5 (Wed, 4 Mar 2020 22:43:33 GMT)\\u00a7r"}']}
{title:'Evers et al. (§72020§r)', author: 'Christine Evers; Heinrich Loellmann; Heinrich Mellmann; Alexander Schmidt; Hendrik Barfuss; Patrick Naylor; Walter Kellermann', display:{Lore:['[{"text": "arXiv:1909.01008", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7eeess.SP\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lThe LOCATA Challenge: Acoustic Source Localization and Tracking\\u00a7r\\n\\n\\u00a78\\u00a7oChristine Evers\\nHeinrich Loellmann\\nHeinrich Mellmann\\n+ 3 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1909.01008\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/TASLP.2020.2990485\\u00a7r\\n\\nVersion:\\u00a77v3 (Wed, 21 Oct 2020 08:18:41 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oPublished in IEEE/ACM Transactionson Audio, Speech, and Language Processing\\u00a7r"}']}
{title:'Li et al. (§72020§r)', author: 'Tingle Li; Jiawei Chen; Haowen Hou; Ming Li', display:{Lore:['[{"text": "arXiv:1909.05746", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.IR\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSams-Net: A Sliced Attention-based Neural Network for Music Source Separation\\u00a7r\\n\\n\\u00a78\\u00a7oTingle Li\\nJiawei Chen\\nHaowen Hou\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1909.05746\\u00a7r\\n\\nVersion:\\u00a77v4 (Tue, 19 May 2020 03:37:22 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to Interspeech 2020\\u00a7r"}']}
{title:'Liu et al. (§72020§r)', author: 'Chunxi Liu; Qiaochu Zhang; Xiaohui Zhang; Kritika Singh; Yatharth Saraf; Geoffrey Zweig', display:{Lore:['[{"text": "arXiv:1909.06522", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMultilingual Graphemic Hybrid ASR with Massive Data Augmentation\\u00a7r\\n\\n\\u00a78\\u00a7oChunxi Liu\\nQiaochu Zhang\\nXiaohui Zhang\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1909.06522\\u00a7r\\n\\nVersion:\\u00a77v3 (Wed, 8 Apr 2020 22:09:51 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted for publication at the 1st Joint Workshop of SLTU (Spoken Language Technologies for Under-resourced languages) and CCURL (Collaboration and Computing for Under-Resourced Languages) (SLTU-CCURL 2020)\\u00a7r"}']}
{title:'Lee et al. (§72020§r)', author: 'Keonnyeong Lee; In-Chul Yoo; Dongsuk Yook', display:{Lore:['[{"text": "arXiv:1909.06805", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMany-to-Many Voice Conversion using Cycle-Consistent Variational Autoencoder with Multiple Decoders\\u00a7r\\n\\n\\u00a78\\u00a7oKeonnyeong Lee\\nIn-Chul Yoo\\nDongsuk Yook\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1909.06805\\u00a7r\\n\\nVersion:\\u00a77v4 (Sun, 2 Feb 2020 05:24:56 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o6 pages\\u00a7r"}']}
{title:'Tan et al. (§72020§r)', author: 'Ke Tan; Yong Xu; Shi-Xiong Zhang; Meng Yu; Dong Yu', display:{Lore:['[{"text": "arXiv:1909.07352", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7eeess.SP\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAudio-Visual Speech Separation and Dereverberation with a Two-Stage Multimodal Network\\u00a7r\\n\\n\\u00a78\\u00a7oKe Tan\\nYong Xu\\nShi-Xiong Zhang\\nMeng Yu\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1909.07352\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/JSTSP.2020.2987209\\u00a7r\\n\\nVersion:\\u00a77v4 (Fri, 10 Apr 2020 14:20:37 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o13 pages, accepted by IEEE JSTSP Special Issue on Deep Learningfor Multi-modal Intelligence across Speech, Language, Vision, and Heterogeneous Signals\\u00a7r"}']}
{title:'Krishna et al. (§72020§r)', author: 'Gautam Krishna; Co Tran; Yan Han; Mason Carnahan; Ahmed H Tewfik', display:{Lore:['[{"text": "arXiv:1909.09132", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSpoken Speech Enhancement using EEG\\u00a7r\\n\\n\\u00a78\\u00a7oGautam Krishna\\nCo Tran\\nYan Han\\nMason Carnahan\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1909.09132\\u00a7r\\n\\nVersion:\\u00a77v8 (Sun, 19 Apr 2020 21:12:56 GMT)\\u00a7r"}']}
{title:'Shi et al. (§72020§r)', author: 'Yanpei Shi; Qiang Huang; Thomas Hain', display:{Lore:['[{"text": "arXiv:1909.11200", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.AI\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lImproving Noise Robustness In Speaker Identification Using A Two-Stage Attention Model\\u00a7r\\n\\n\\u00a78\\u00a7oYanpei Shi\\nQiang Huang\\nThomas Hain\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1909.11200\\u00a7r\\n\\nVersion:\\u00a77v2 (Fri, 15 May 2020 22:53:15 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to Interspeech2020\\u00a7r"}']}
{title:'Luo et al. (§72020§r)', author: 'Yi Luo; Zhuo Chen; Takuya Yoshioka', display:{Lore:['[{"text": "arXiv:1910.06379", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDual-path RNN: efficient long sequence modeling for time-domain single-channel speech separation\\u00a7r\\n\\n\\u00a78\\u00a7oYi Luo\\nZhuo Chen\\nTakuya Yoshioka\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1910.06379\\u00a7r\\n\\nVersion:\\u00a77v2 (Fri, 27 Mar 2020 10:15:38 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oICASSP 2020\\u00a7r"}']}
{title:'Kim et al. (§72020§r)', author: 'Jaeyoung Kim; Mostafa El-Khamy; Jungwon Lee', display:{Lore:['[{"text": "arXiv:1910.06762", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lT-GSA: Transformer with Gaussian-weighted self-attention for speech enhancement\\u00a7r\\n\\n\\u00a78\\u00a7oJaeyoung Kim\\nMostafa El-Khamy\\nJungwon Lee\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1910.06762\\u00a7r\\n\\nVersion:\\u00a77v3 (Tue, 11 Feb 2020 06:54:29 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, Submitted to ICASSP 2020\\u00a7r"}']}
{title:'Bilen et al. (§72020§r)', author: 'Cagdas Bilen; Giacomo Ferroni; Francesco Tuveri; Juan Azcarreta; Sacha Krstulovic', display:{Lore:['[{"text": "arXiv:1910.08440", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Framework for the Robust Evaluation of Sound Event Detection\\u00a7r\\n\\n\\u00a78\\u00a7oCagdas Bilen\\nGiacomo Ferroni\\nFrancesco Tuveri\\nJuan Azcarreta\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1910.08440\\u00a7r\\n\\nVersion:\\u00a77v2 (Fri, 14 Feb 2020 13:20:23 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted to ICASSP 2020\\u00a7r"}']}
{title:'Cobos et al. (§72020§r)', author: 'Maximo Cobos; Fabio Antonacci; Luca Comanducci; Augusto Sarti', display:{Lore:['[{"text": "arXiv:1910.08838", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lFrequency-Sliding Generalized Cross-Correlation: A Sub-band Time Delay Estimation Approach\\u00a7r\\n\\n\\u00a78\\u00a7oMaximo Cobos\\nFabio Antonacci\\nLuca Comanducci\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1910.08838\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 24 Mar 2020 16:04:15 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oArticleaccepted in IEEE/ACM Transactions on Audio, Speech, and Language Processing\\u00a7r"}']}
{title:'Wang et al. (§72020§r)', author: 'Jianyou Wang; Michael Xue; Ryan Culhane; Enmao Diao; Jie Ding; Vahid Tarokh', display:{Lore:['[{"text": "arXiv:1910.08874", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSpeech Emotion Recognition with Dual-Sequence LSTM Architecture\\u00a7r\\n\\n\\u00a78\\u00a7oJianyou Wang\\nMichael Xue\\nRyan Culhane\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1910.08874\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/ICASSP40776.2020.9054629\\u00a7r\\n\\nVersion:\\u00a77v4 (Thu, 13 Feb 2020 03:02:31 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted by ICASSP 2020\\u00a7r"}']}
{title:'Zhang et al. (§72020§r)', author: 'Mengfan Zhang; Zhongshu Ge; Tiejun Liu; Xihong Wu; Tianshu Qu', display:{Lore:['[{"text": "arXiv:1910.09484", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7eeess.SP\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lModeling of Individual HRTFs based on Spatial Principal Component Analysis\\u00a7r\\n\\n\\u00a78\\u00a7oMengfan Zhang\\nZhongshu Ge\\nTiejun Liu\\nXihong Wu\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1910.09484\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/TASLP.2020.2967539\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nIEEE/ACM Transactions on Audio, Speech and Language Processing,\\n  Vol. 28, No. 1, December 2020\\u00a7r\\n\\nVersion:\\u00a77v6 (Thu, 6 Feb 2020 02:06:27 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o12 pages with 18 figures. This paper was published in IEEE/ACM Transactions on Audio, Speech and Language Processing. Copyright 2020 IEEE. Personal use of this material is permitted. Permission from IEEE must be "}','{"text": "obtained for all other uses, in any current or future media\\u00a7r"}']}
{title:'Li et al. (§72020§r)', author: 'Qiujia Li; Florian L. Kreyssig; Chao Zhang; Philip C. Woodland', display:{Lore:['[{"text": "arXiv:1910.09703", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.CV\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDiscriminative Neural Clustering for Speaker Diarisation\\u00a7r\\n\\n\\u00a78\\u00a7oQiujia Li\\nFlorian L. Kreyssig\\nChao Zhang\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1910.09703\\u00a7r\\n\\nVersion:\\u00a77v2 (Mon, 23 Nov 2020 15:32:03 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted as a conference paper at the 8th IEEE Spoken Language Technology Workshop (SLT 2021)\\u00a7r"}']}
{title:'Martinelli et al. (§72020§r)', author: 'Flavio Martinelli; Giorgia Dellaferrera; Pablo Mainar; Milos Cernak', display:{Lore:['[{"text": "arXiv:1910.09993", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.NE\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSpiking neural networks trained with backpropagation for low power neuromorphic implementation of voice activity detection\\u00a7r\\n\\n\\u00a78\\u00a7oFlavio Martinelli\\nGiorgia Dellaferrera\\nPablo Mainar\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1910.09993\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/ICASSP40776.2020.9053412\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nICASSP 2020 - 2020 IEEE International Conference on Acoustics,\\n  Speech and Signal Processing (ICASSP), Barcelona, Spain, 2020, pp. 8544-8548\\u00a7r\\n\\nVersion:\\u00a77v2 (Thu, 30 Apr 2020 16:46:12 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 2 figures, 2 tables\\u00a7r"}']}
{title:'Ramírez et al. (§72020§r)', author: 'Marco A. Martínez Ramírez; Emmanouil Benetos; Joshua D. Reiss', display:{Lore:['[{"text": "arXiv:1910.10105", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7eeess.SP\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lModeling plate and spring reverberation using a DSP-informed deep neural network\\u00a7r\\n\\n\\u00a78\\u00a7oMarco A. Mart\\u00ednez Ram\\u00edrez\\nEmmanouil Benetos\\nJoshua D. Reiss\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1910.10105\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/ICASSP40776.2020.9053093\\u00a7r\\n\\nVersion:\\u00a77v2 (Fri, 17 Apr 2020 13:12:46 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oPresented at theIEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP), Barcelona, Spain, May 2020. Sourcecode, dataset, audio examples and more detailed diagrams: https://mchijmma.github.io/"}','{"text": "modeling-plate-spring-reverb/\\u00a7r"}']}
{title:'Ardaillon et al. (§72020§r)', author: 'Luc Ardaillon; Axel Roebel', display:{Lore:['[{"text": "arXiv:1910.10235", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lGCI detection from raw speech using a fully-convolutional network\\u00a7r\\n\\n\\u00a78\\u00a7oLuc Ardaillon\\nAxel Roebel\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1910.10235\\u00a7r\\n\\nVersion:\\u00a77v2 (Thu, 20 Feb 2020 17:15:51 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oMinor corrections after reviews of ICASSP 2020(accepted paper). (Corrected typos, added funding aknowledgments, added some references, cleaned bibliography, added a few details)\\u00a7r"}']}
{title:'Palogiannidi et al. (§72020§r)', author: 'Elisavet Palogiannidi; Ioannis Gkinis; George Mastrapas; Petr Mizera; Themos Stafylakis', display:{Lore:['[{"text": "arXiv:1910.10599", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lEnd-to-end architectures for ASR-free spoken language understanding\\u00a7r\\n\\n\\u00a78\\u00a7oElisavet Palogiannidi\\nIoannis Gkinis\\nGeorge Mastrapas\\nPetr Mizera\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1910.10599\\u00a7r\\n\\nVersion:\\u00a77v3 (Fri, 1 May 2020 07:31:53 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted at ICASSP-2020\\u00a7r"}']}
{title:'Lavechin et al. (§72020§r)', author: 'Marvin Lavechin; Marie-Philippe Gill; Ruben Bousbib; Hervé Bredin; Leibny Paola Garcia-Perera', display:{Lore:['[{"text": "arXiv:1910.10655", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lEnd-to-end Domain-Adversarial Voice Activity Detection\\u00a7r\\n\\n\\u00a78\\u00a7oMarvin Lavechin\\nMarie-Philippe Gill\\nRuben Bousbib\\nHerv\\u00e9 Bredin\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1910.10655\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 26 May 2020 12:11:56 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7osubmitted to Interspeech 2020\\u00a7r"}']}
{title:'Cooper et al. (§72020§r)', author: 'Erica Cooper; Cheng-I Lai; Yusuke Yasuda; Fuming Fang; Xin Wang; Nanxin Chen; Junichi Yamagishi', display:{Lore:['[{"text": "arXiv:1910.10838", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lZero-Shot Multi-Speaker Text-To-Speech with State-of-the-art Neural Speaker Embeddings\\u00a7r\\n\\n\\u00a78\\u00a7oErica Cooper\\nCheng-I Lai\\nYusuke Yasuda\\n+ 3 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1910.10838\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 4 Feb 2020 08:00:59 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted to ICASSP 2020\\u00a7r"}']}
{title:'Yamamoto et al. (§72020§r)', author: 'Ryuichi Yamamoto; Eunwoo Song; Jae-Min Kim', display:{Lore:['[{"text": "arXiv:1910.11480", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7eeess.SP\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lParallel WaveGAN: A fast waveform generation model based on generative adversarial networks with multi-resolution spectrogram\\u00a7r\\n\\n\\u00a78\\u00a7oRyuichi Yamamoto\\nEunwoo Song\\nJae-Min Kim\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1910.11480\\u00a7r\\n\\nVersion:\\u00a77v2 (Thu, 6 Feb 2020 09:34:21 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted to the conference of ICASSP 2020\\u00a7r"}']}
{title:'Zhang et al. (§72020§r)', author: 'Jingchi Zhang; Jonathan Huang; Michael Deisher; Hai Li; Yiran Chen', display:{Lore:['[{"text": "arXiv:1910.11488", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lStructural sparsification for Far-field Speaker Recognition with GNA\\u00a7r\\n\\n\\u00a78\\u00a7oJingchi Zhang\\nJonathan Huang\\nMichael Deisher\\nHai Li\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1910.11488\\u00a7r\\n\\nVersion:\\u00a77v2 (Fri, 14 Feb 2020 19:59:40 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7osubmitted to icassp2020\\u00a7r"}']}
{title:'Ditter et al. (§72020§r)', author: 'David Ditter; Timo Gerkmann', display:{Lore:['[{"text": "arXiv:1910.11615", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Multi-Phase Gammatone Filterbank for Speech Separation via TasNet\\u00a7r\\n\\n\\u00a78\\u00a7oDavid Ditter\\nTimo Gerkmann\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1910.11615\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/ICASSP40776.2020.9053602\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 10 Mar 2020 13:33:17 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted at ICASSP 2020\\u00a7r"}']}
{title:'Gfeller et al. (§72020§r)', author: 'Beat Gfeller; Christian Frank; Dominik Roblek; Matt Sharifi; Marco Tagliasacchi; Mihajlo Velimirović', display:{Lore:['[{"text": "arXiv:1910.11664", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSPICE: Self-supervised Pitch Estimation\\u00a7r\\n\\n\\u00a78\\u00a7oBeat Gfeller\\nChristian Frank\\nDominik Roblek\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1910.11664\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/TASLP.2020.2982285\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nin IEEE/ACM Transactions on Audio, Speech, and Language\\n  Processing, vol. 28, pp. 1118-1128, 2020\\u00a7r\\n\\nVersion:\\u00a77v2 (Fri, 4 Sep 2020 10:40:39 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted to IEEETransactions on Audio, Speech and Language Processing\\u00a7r"}']}
{title:'Nakamura et al. (§72020§r)', author: 'Kazuhiro Nakamura; Shinji Takaki; Kei Hashimoto; Keiichiro Oura; Yoshihiko Nankaku; Keiichi Tokuda', display:{Lore:['[{"text": "arXiv:1910.11690", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lFast and High-Quality Singing Voice Synthesis System based on Convolutional Neural Networks\\u00a7r\\n\\n\\u00a78\\u00a7oKazuhiro Nakamura\\nShinji Takaki\\nKei Hashimoto\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1910.11690\\u00a7r\\n\\nVersion:\\u00a77v2 (Wed, 22 Apr 2020 00:30:04 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted to ICASSP 2020. Singing voice samples (Japanese, English, Chinese): https://www.techno-speech.com/news-20181214a-en. arXiv admin note: substantial text overlap with arXiv:1904.06868\\u00a7r"}']}
{title:'Kataria et al. (§72020§r)', author: 'Saurabh Kataria; Phani Sankar Nidadavolu; Jesús Villalba; Nanxin Chen; Paola García; Najim Dehak', display:{Lore:['[{"text": "arXiv:1910.11905", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lFeature Enhancement with Deep Feature Losses for Speaker Verification\\u00a7r\\n\\n\\u00a78\\u00a7oSaurabh Kataria\\nPhani Sankar Nidadavolu\\nJes\\u00fas Villalba\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1910.11905\\u00a7r\\n\\nVersion:\\u00a77v2 (Fri, 14 Feb 2020 19:26:38 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, accepted in ICASSP 2020\\u00a7r"}']}
{title:'Nidadavolu et al. (§72020§r)', author: 'Phani Sankar Nidadavolu; Saurabh Kataria; Jesús Villalba; Paola García-Perera; Najim Dehak', display:{Lore:['[{"text": "arXiv:1910.11915", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lUnsupervised Feature Enhancement for speaker verification\\u00a7r\\n\\n\\u00a78\\u00a7oPhani Sankar Nidadavolu\\nSaurabh Kataria\\nJes\\u00fas Villalba\\nPaola Garc\\u00eda-Perera\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1910.11915\\u00a7r\\n\\nVersion:\\u00a77v2 (Fri, 14 Feb 2020 22:24:49 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages; accepted in ICASSP 2020\\u00a7r"}']}
{title:'Kastanos et al. (§72020§r)', author: 'Alexandros Kastanos; Anton Ragni; Mark Gales', display:{Lore:['[{"text": "arXiv:1910.11933", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lConfidence Estimation for Black Box Automatic Speech Recognition Systems Using Lattice Recurrent Neural Networks\\u00a7r\\n\\n\\u00a78\\u00a7oAlexandros Kastanos\\nAnton Ragni\\nMark Gales\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1910.11933\\u00a7r\\n\\nVersion:\\u00a77v2 (Sun, 15 Mar 2020 15:15:39 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 8 figures, ICASSP submission\\u00a7r"}']}
{title:'Nicolson et al. (§72020§r)', author: 'Aaron Nicolson; Kuldip K. Paliwal', display:{Lore:['[{"text": "arXiv:1910.11969", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSum-Product Networks for Robust Automatic Speaker Identification\\u00a7r\\n\\n\\u00a78\\u00a7oAaron Nicolson\\nKuldip K. Paliwal\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1910.11969\\u00a7r\\n\\nVersion:\\u00a77v3 (Thu, 13 Aug 2020 09:47:16 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oProc. Interspeech 2020\\u00a7r"}']}
{title:'Chung et al. (§72020§r)', author: 'Yu-An Chung; James Glass', display:{Lore:['[{"text": "arXiv:1910.12607", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lGenerative Pre-Training for Speech with Autoregressive Predictive Coding\\u00a7r\\n\\n\\u00a78\\u00a7oYu-An Chung\\nJames Glass\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1910.12607\\u00a7r\\n\\nVersion:\\u00a77v2 (Sun, 26 Jan 2020 09:36:23 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted to ICASSP 2020. Code and pre-trained models areavailable at https://github.com/iamyuanchung/Autoregressive-Predictive-Coding\\u00a7r"}']}
{title:'Le et al. (§72020§r)', author: 'Duc Le; Thilo Koehler; Christian Fuegen; Michael L. Seltzer', display:{Lore:['[{"text": "arXiv:1910.12612", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lG2G: TTS-Driven Pronunciation Learning for Graphemic Hybrid ASR\\u00a7r\\n\\n\\u00a78\\u00a7oDuc Le\\nThilo Koehler\\nChristian Fuegen\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1910.12612\\u00a7r\\n\\nVersion:\\u00a77v2 (Thu, 13 Feb 2020 21:24:48 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oTo appear at ICASSP 2020\\u00a7r"}']}
{title:'Ferro et al. (§72020§r)', author: 'Rafael Ferro; Nicolas Obin; Axel Roebel', display:{Lore:['[{"text": "arXiv:1910.12614", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lCycleGAN Voice Conversion of Spectral Envelopes using Adversarial Weights\\u00a7r\\n\\n\\u00a78\\u00a7oRafael Ferro\\nNicolas Obin\\nAxel Roebel\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1910.12614\\u00a7r\\n\\nVersion:\\u00a77v2 (Sat, 11 Jul 2020 14:43:03 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 1 figure\\u00a7r"}']}
{title:'Abdulatif et al. (§72020§r)', author: 'Sherif Abdulatif; Karim Armanious; Karim Guirguis; Jayasankar T. Sajeev; Bin Yang', display:{Lore:['[{"text": "arXiv:1910.12620", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.NE\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAeGAN: Time-Frequency Speech Denoising via Generative Adversarial Networks\\u00a7r\\n\\n\\u00a78\\u00a7oSherif Abdulatif\\nKarim Armanious\\nKarim Guirguis\\nJayasankar T. Sajeev\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1910.12620\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.23919/Eusipco47968.2020.9287606\\u00a7r\\n\\nVersion:\\u00a77v3 (Sat, 6 Jun 2020 00:10:35 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 4 figures and 2 Tables. Accepted in EUSIPCO 2020\\u00a7r"}']}
{title:'Manilow et al. (§72020§r)', author: 'Ethan Manilow; Prem Seetharaman; Bryan Pardo', display:{Lore:['[{"text": "arXiv:1910.12621", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSimultaneous Separation and Transcription of Mixtures with Multiple Polyphonic and Percussive Instruments\\u00a7r\\n\\n\\u00a78\\u00a7oEthan Manilow\\nPrem Seetharaman\\nBryan Pardo\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1910.12621\\u00a7r\\n\\nVersion:\\u00a77v2 (Wed, 12 Feb 2020 22:14:54 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted to ICASSP 2020\\u00a7r"}']}
{title:'Liu et al. (§72020§r)', author: 'Alisa Liu; Prem Seetharaman; Bryan Pardo', display:{Lore:['[{"text": "arXiv:1910.12626", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lModel selection for deep audio source separation via clustering analysis\\u00a7r\\n\\n\\u00a78\\u00a7oAlisa Liu\\nPrem Seetharaman\\nBryan Pardo\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1910.12626\\u00a7r\\n\\nVersion:\\u00a77v2 (Sun, 26 Jul 2020 19:28:28 GMT)\\u00a7r"}']}
{title:'Liu et al. (§72020§r)', author: 'Andy T. Liu; Shu-wen Yang; Po-Han Chi; Po-chun Hsu; Hung-yi Lee', display:{Lore:['[{"text": "arXiv:1910.12638", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMockingjay: Unsupervised Speech Representation Learning with Deep Bidirectional Transformer Encoders\\u00a7r\\n\\n\\u00a78\\u00a7oAndy T. Liu\\nShu-wen Yang\\nPo-Han Chi\\nPo-chun Hsu\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1910.12638\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/ICASSP40776.2020.9054458\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nICASSP 2020 - 2020 IEEE International Conference on Acoustics,\\n  Speech and Signal Processing (ICASSP)\\u00a7r\\n\\nVersion:\\u00a77v2 (Sun, 2 Feb 2020 15:08:39 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted by ICASSP 2020, Lecture Session\\u00a7r"}']}
{title:'Lam et al. (§72020§r)', author: 'Max W. Y. Lam; Jun Wang; Dan Su; Dong Yu', display:{Lore:['[{"text": "arXiv:1910.13253", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMixup-breakdown: a consistency training method for improving generalization of speech separation models\\u00a7r\\n\\n\\u00a78\\u00a7oMax W. Y. Lam\\nJun Wang\\nDan Su\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1910.13253\\u00a7r\\n\\nVersion:\\u00a77v3 (Tue, 3 Mar 2020 10:00:06 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted in a Lesson session in ICASSP2020\\u00a7r"}']}
{title:'Nguyen et al. (§72020§r)', author: 'Thai-Son Nguyen; Sebastian Stueker; Jan Niehues; Alex Waibel', display:{Lore:['[{"text": "arXiv:1910.13296", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CV\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lImproving sequence-to-sequence speech recognition training with on-the-fly data augmentation\\u00a7r\\n\\n\\u00a78\\u00a7oThai-Son Nguyen\\nSebastian Stueker\\nJan Niehues\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1910.13296\\u00a7r\\n\\nVersion:\\u00a77v2 (Mon, 3 Feb 2020 08:12:31 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oTo appear in ICASSP 2020\\u00a7r"}']}
{title:'Shimada et al. (§72020§r)', author: 'Kazuki Shimada; Yuichiro Koyama; Akira Inoue', display:{Lore:['[{"text": "arXiv:1910.13724", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMetric Learning with Background Noise Class for Few-shot Detection of Rare Sound Events\\u00a7r\\n\\n\\u00a78\\u00a7oKazuki Shimada\\nYuichiro Koyama\\nAkira Inoue\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1910.13724\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 18 Feb 2020 11:24:49 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 5 figures, accepted for publication in IEEE ICASSP 2020\\u00a7r"}']}
{title:'Li et al. (§72020§r)', author: 'Hang Li; Yu Kang; Wenbiao Ding; Song Yang; Songfan Yang; Gale Yan Huang; Zitao Liu', display:{Lore:['[{"text": "arXiv:1910.13799", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMultimodal Learning For Classroom Activity Detection\\u00a7r\\n\\n\\u00a78\\u00a7oHang Li\\nYu Kang\\nWenbiao Ding\\n+ 3 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1910.13799\\u00a7r\\n\\nVersion:\\u00a77v3 (Mon, 10 Feb 2020 23:12:27 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oThe 45th International Conference on Acoustics, Speech, and Signal Processing (ICASSP 2020)\\u00a7r"}']}
{title:'Luo et al. (§72020§r)', author: 'Yi Luo; Zhuo Chen; Nima Mesgarani; Takuya Yoshioka', display:{Lore:['[{"text": "arXiv:1910.14104", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lEnd-to-end Microphone Permutation and Number Invariant Multi-channel Speech Separation\\u00a7r\\n\\n\\u00a78\\u00a7oYi Luo\\nZhuo Chen\\nNima Mesgarani\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1910.14104\\u00a7r\\n\\nVersion:\\u00a77v3 (Fri, 27 Mar 2020 10:12:19 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oICASSP 2020\\u00a7r"}']}
{title:'Singh et al. (§72020§r)', author: 'Abhayjeet Singh; Aravind Illa; Prasanta Kumar Ghosh', display:{Lore:['[{"text": "arXiv:1910.14375", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA comparative study of estimating articulatory movements from phoneme sequences and acoustic features\\u00a7r\\n\\n\\u00a78\\u00a7oAbhayjeet Singh\\nAravind Illa\\nPrasanta Kumar Ghosh\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1910.14375\\u00a7r\\n\\nVersion:\\u00a77v2 (Wed, 19 Feb 2020 13:26:08 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 5 figures, accepted in ICASSP 2020\\u00a7r"}']}
{title:'Kato et al. (§72020§r)', author: 'Shuhei Kato; Yusuke Yasuda; Xin Wang; Erica Cooper; Shinji Takaki; Junichi Yamagishi', display:{Lore:['[{"text": "arXiv:1911.00137", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lModeling of Rakugo Speech and Its Limitations: Toward Speech Synthesis That Entertains Audiences\\u00a7r\\n\\n\\u00a78\\u00a7oShuhei Kato\\nYusuke Yasuda\\nXin Wang\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1911.00137\\u00a7r\\n\\nVersion:\\u00a77v3 (Mon, 1 Jun 2020 08:06:05 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oResubmitted to IEEE Access\\u00a7r"}']}
{title:'Gamper et al. (§72020§r)', author: 'Hannes Gamper; Dimitra Emmanouilidou; Sebastian Braun; Ivan J. Tashev', display:{Lore:['[{"text": "arXiv:1911.00566", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lPredicting word error rate for reverberant speech\\u00a7r\\n\\n\\u00a78\\u00a7oHannes Gamper\\nDimitra Emmanouilidou\\nSebastian Braun\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1911.00566\\u00a7r\\n\\nVersion:\\u00a77v2 (Fri, 14 Feb 2020 08:08:25 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oPresented at IEEE 45th InternationalConference on Acoustics, Speech, and Signal Processing (ICASSP 2020)\\u00a7r"}']}
{title:'Wang et al. (§72020§r)', author: 'Xin Wang; Junichi Yamagishi; Massimiliano Todisco; Hector Delgado; Andreas Nautsch; Nicholas Evans; Md Sahidullah; Ville Vestman; Tomi Kinnunen; Kong Aik Lee; Lauri Juvela; Paavo Alku; Yu-Huai Peng; Hsin-Te Hwang; Yu Tsao; Hsin-Min Wang; Sebastien Le Maguer; Markus Becker; Fergus Henderson; Rob Clark; Yu Zhang; Quan Wang; Ye Jia; Kai Onuma; Koji Mushika; Takashi Kaneda; Yuan Jiang; Li-Juan Liu; Yi-Chiao Wu; Wen-Chin Huang; Tomoki Toda; Kou Tanaka; Hirokazu Kameoka; Ingmar Steiner; Driss Matrouf; Jean-Francois Bonastre; Avashna Govender; Srikanth Ronanki; Jing-Xuan Zhang; Zhen-Hua Ling', display:{Lore:['[{"text": "arXiv:1911.01601", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CR\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7eeess.SP\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lASVspoof 2019: A large-scale public database of synthesized, converted and replayed speech\\u00a7r\\n\\n\\u00a78\\u00a7oXin Wang\\nJunichi Yamagishi\\nMassimiliano Todisco\\n+ 36 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1911.01601\\u00a7r\\n\\nVersion:\\u00a77v4 (Tue, 14 Jul 2020 09:01:31 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted, Computer Speech and Language. This manuscript version is made available under the CC-BY-NC-ND 4.0. For the published version on Elsevier website, please visit https://doi.org/10.1016/j.csl.2020.101114\\u00a7r"}']}
{title:'Fan et al. (§72020§r)', author: 'Ziqi Fan; Vibhav Vineet; Hannes Gamper; Nikunj Raghuvanshi', display:{Lore:['[{"text": "arXiv:1911.01802", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7eeess.IV\\u00a7r, \\u00a7eeess.SP\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lFast acoustic scattering using convolutional neural networks\\u00a7r\\n\\n\\u00a78\\u00a7oZiqi Fan\\nVibhav Vineet\\nHannes Gamper\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1911.01802\\u00a7r\\n\\nVersion:\\u00a77v3 (Sat, 15 Feb 2020 20:04:43 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted by ICASSP 2020\\u00a7r"}']}
{title:'Chen et al. (§72020§r)', author: 'Guangke Chen; Sen Chen; Lingling Fan; Xiaoning Du; Zhe Zhao; Fu Song; Yang Liu', display:{Lore:['[{"text": "arXiv:1911.01840", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CR\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.MM\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lWho is Real Bob? Adversarial Attacks on Speaker Recognition Systems\\u00a7r\\n\\n\\u00a78\\u00a7oGuangke Chen\\nSen Chen\\nLingling Fan\\n+ 3 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1911.01840\\u00a7r\\n\\nVersion:\\u00a77v2 (Fri, 24 Apr 2020 02:10:01 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oIEEE Symposium on Security and Privacy 2021\\u00a7r"}']}
{title:'Mittermaier et al. (§72020§r)', author: 'Simon Mittermaier; Ludwig Kürzinger; Bernd Waschneck; Gerhard Rigoll', display:{Lore:['[{"text": "arXiv:1911.02086", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSmall-Footprint Keyword Spotting on Raw Audio Data with Sinc-Convolutions\\u00a7r\\n\\n\\u00a78\\u00a7oSimon Mittermaier\\nLudwig K\\u00fcrzinger\\nBernd Waschneck\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1911.02086\\u00a7r\\n\\nVersion:\\u00a77v2 (Sun, 3 May 2020 12:07:28 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted at ICASSP 2020\\u00a7r"}']}
{title:'He et al. (§72020§r)', author: 'Weipeng He; Lu Lu; Biqiao Zhang; Jay Mahadeokar; Kaustubh Kalgaonkar; Christian Fuegen', display:{Lore:['[{"text": "arXiv:1911.02115", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSpatial Attention for Far-field Speech Recognition with Deep Beamforming Neural Networks\\u00a7r\\n\\n\\u00a78\\u00a7oWeipeng He\\nLu Lu\\nBiqiao Zhang\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1911.02115\\u00a7r\\n\\nVersion:\\u00a77v2 (Mon, 9 Mar 2020 10:39:05 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oTo be presented at ICASSP 2020\\u00a7r"}']}
{title:'Ni et al. (§72020§r)', author: 'Zhaoheng Ni; Michael I Mandel', display:{Lore:['[{"text": "arXiv:1911.02746", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMask-dependent Phase Estimation for Monaural Speaker Separation\\u00a7r\\n\\n\\u00a78\\u00a7oZhaoheng Ni\\nMichael I Mandel\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1911.02746\\u00a7r\\n\\nVersion:\\u00a77v2 (Wed, 15 Apr 2020 06:48:41 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted by ICASSP 2020\\u00a7r"}']}
{title:'Li et al. (§72020§r)', author: 'Xu Li; Jinghua Zhong; Xixin Wu; Jianwei Yu; Xunying Liu; Helen Meng', display:{Lore:['[{"text": "arXiv:1911.03078", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.CR\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.SP\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAdversarial Attacks on GMM i-vector based Speaker Verification Systems\\u00a7r\\n\\n\\u00a78\\u00a7oXu Li\\nJinghua Zhong\\nXixin Wu\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1911.03078\\u00a7r\\n\\nVersion:\\u00a77v2 (Wed, 12 Feb 2020 13:54:35 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted by ICASSP 2020\\u00a7r"}']}
{title:'Fathullah et al. (§72020§r)', author: 'Yassir Fathullah; Chao Zhang; Philip C. Woodland', display:{Lore:['[{"text": "arXiv:1911.03970", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lImproved Large-margin Softmax Loss for Speaker Diarisation\\u00a7r\\n\\n\\u00a78\\u00a7oYassir Fathullah\\nChao Zhang\\nPhilip C. Woodland\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1911.03970\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/ICASSP40776.2020.9053373\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nICASSP 2020, Barcelona, Spain, 2020, pp. 7104-7108\\u00a7r\\n\\nVersion:\\u00a77v3 (Mon, 6 Jul 2020 09:32:49 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oICASSP 2020\\u00a7r"}']}
{title:'Chen et al. (§72020§r)', author: 'Nanxin Chen; Shinji Watanabe; Jesús Villalba; Najim Dehak', display:{Lore:['[{"text": "arXiv:1911.04908", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lListen and Fill in the Missing Letters: Non-Autoregressive Transformer for Speech Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oNanxin Chen\\nShinji Watanabe\\nJes\\u00fas Villalba\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1911.04908\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/LSP.2020.3044547\\u00a7r\\n\\nVersion:\\u00a77v2 (Mon, 6 Apr 2020 14:45:19 GMT)\\u00a7r"}']}
{title:'Purushothaman et al. (§72020§r)', author: 'Anurenjan Purushothaman; Anirudh Sreeram; Sriram Ganapathy', display:{Lore:['[{"text": "arXiv:1911.05504", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7l3-D Feature and Acoustic Modeling for Far-Field Speech Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oAnurenjan Purushothaman\\nAnirudh Sreeram\\nSriram Ganapathy\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1911.05504\\u00a7r\\n\\nVersion:\\u00a77v2 (Mon, 27 Jan 2020 04:31:26 GMT)\\u00a7r"}']}
{title:'Dhamyal et al. (§72020§r)', author: 'Hira Dhamyal; Shahan Ali Memon; Bhiksha Raj; Rita Singh', display:{Lore:['[{"text": "arXiv:1911.05733", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lThe phonetic bases of vocal expressed emotion: natural versus acted\\u00a7r\\n\\n\\u00a78\\u00a7oHira Dhamyal\\nShahan Ali Memon\\nBhiksha Raj\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1911.05733\\u00a7r\\n\\nVersion:\\u00a77v3 (Sat, 25 Jul 2020 02:49:50 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 6 figures\\u00a7r"}']}
{title:'Flemotomos et al. (§72020§r)', author: 'Nikolaos Flemotomos; Panayiotis Georgiou; Shrikanth Narayanan', display:{Lore:['[{"text": "arXiv:1911.07994", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lLinguistically Aided Speaker Diarization Using Speaker Role Information\\u00a7r\\n\\n\\u00a78\\u00a7oNikolaos Flemotomos\\nPanayiotis Georgiou\\nShrikanth Narayanan\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1911.07994\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.21437/Odyssey.2020-17\\u00a7r\\n\\nVersion:\\u00a77v2 (Wed, 5 Feb 2020 23:55:58 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7ofrom v1: restructured Introduction and Background, added experimental results with ASR text and language-only baseline\\u00a7r"}']}
{title:'Wang et al. (§72020§r)', author: 'Syu-Siang Wang; Yu-You Liang; Jeih-weih Hung; Yu Tsao; Hsin-Min Wang; Shih-Hau Fang', display:{Lore:['[{"text": "arXiv:1911.08153", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDistributed Microphone Speech Enhancement based on Deep Learning\\u00a7r\\n\\n\\u00a78\\u00a7oSyu-Siang Wang\\nYu-You Liang\\nJeih-weih Hung\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1911.08153\\u00a7r\\n\\nVersion:\\u00a77v3 (Sun, 24 May 2020 10:07:23 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7odeep neural network, multi-channel speech enhancement, distributed microphone architecture, diffuse noise environment\\u00a7r"}']}
{title:'Yu et al. (§72020§r)', author: 'Cheng Yu; Kuo-Hsuan Hung; Syu-Siang Wang; Szu-Wei Fu; Yu Tsao; Jeih-weih Hung', display:{Lore:['[{"text": "arXiv:1911.09847", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7eeess.SP\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lTime-Domain Multi-modal Bone/air Conducted Speech Enhancement\\u00a7r\\n\\n\\u00a78\\u00a7oCheng Yu\\nKuo-Hsuan Hung\\nSyu-Siang Wang\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1911.09847\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/LSP.2020.3000968\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nIEEE Signal Processing Letters, vol. 27, pp. 1035-1039, 2020\\u00a7r\\n\\nVersion:\\u00a77v3 (Thu, 18 Jun 2020 00:34:48 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7omulti-modal, bone/air-conducted signals, speech enhancement, fully convolutional network\\u00a7r"}']}
{title:'Lee et al. (§72020§r)', author: 'Taewoong Lee; Jesper Kjær Nielsen; Mads Græsbøll Christensen', display:{Lore:['[{"text": "arXiv:1911.10016", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSignal-Adaptive and Perceptually Optimized Sound Zones with Variable Span Trade-Off Filters\\u00a7r\\n\\n\\u00a78\\u00a7oTaewoong Lee\\nJesper Kj\\u00e6r Nielsen\\nMads Gr\\u00e6sb\\u00f8ll Christensen\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1911.10016\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/TASLP.2020.3013397\\u00a7r\\n\\nVersion:\\u00a77v3 (Tue, 4 Aug 2020 11:02:25 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted for publication in IEEE/ACM TRANSACTIONS ON AUDIO, SPEECH, AND LANGUAGE PROCESSING\\u00a7r"}']}
{title:'Takeuchi et al. (§72020§r)', author: 'Daiki Takeuchi; Kohei Yatabe; Yuma Koizumi; Yasuhiro Oikawa; Noboru Harada', display:{Lore:['[{"text": "arXiv:1911.10764", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lInvertible DNN-based nonlinear time-frequency transform for speech enhancement\\u00a7r\\n\\n\\u00a78\\u00a7oDaiki Takeuchi\\nKohei Yatabe\\nYuma Koizumi\\nYasuhiro Oikawa\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1911.10764\\u00a7r\\n\\nVersion:\\u00a77v2 (Fri, 14 Feb 2020 02:00:17 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oTo appear in Proc. IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP 2020)\\u00a7r"}']}
{title:'Li et al. (§72020§r)', author: 'Yanxiong Li; Mingle Liu; Konstantinos Drossos; Tuomas Virtanen', display:{Lore:['[{"text": "arXiv:1911.10888", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSound event detection via dilated convolutional recurrent neural networks\\u00a7r\\n\\n\\u00a78\\u00a7oYanxiong Li\\nMingle Liu\\nKonstantinos Drossos\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1911.10888\\u00a7r\\n\\nVersion:\\u00a77v4 (Mon, 20 Jul 2020 13:48:20 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 3 tables and 3 figures\\u00a7r"}']}
{title:'Saxon et al. (§72020§r)', author: 'Michael Saxon; Ayush Tripathi; Yishan Jiao; Julie Liss; Visar Berisha', display:{Lore:['[{"text": "arXiv:1911.11360", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7eeess.SP\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lRobust Estimation of Hypernasality in Dysarthria with Acoustic Model Likelihood Features\\u00a7r\\n\\n\\u00a78\\u00a7oMichael Saxon\\nAyush Tripathi\\nYishan Jiao\\nJulie Liss\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1911.11360\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/TASLP.2020.3015035\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nIEEE/ACM Trans. on Audio, Speech, and Language Proc. 28 (2020)\\n  2511-2522\\u00a7r\\n\\nVersion:\\u00a77v4 (Thu, 6 Aug 2020 03:38:35 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o12 pages, 9 figures, 2 tables\\u00a7r"}']}
{title:'Ramires et al. (§72020§r)', author: 'António Ramires; Pritish Chandna; Xavier Favory; Emilia Gómez; Xavier Serra', display:{Lore:['[{"text": "arXiv:1911.11853", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lNeural Percussive Synthesis Parameterised by High-Level Timbral Features\\u00a7r\\n\\n\\u00a78\\u00a7oAnt\\u00f3nio Ramires\\nPritish Chandna\\nXavier Favory\\nEmilia G\\u00f3mez\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1911.11853\\u00a7r\\n\\nVersion:\\u00a77v2 (Fri, 3 Apr 2020 10:34:14 GMT)\\u00a7r"}']}
{title:'Ling et al. (§72020§r)', author: 'Shaoshi Ling; Yuzong Liu; Julian Salazar; Katrin Kirchhoff', display:{Lore:['[{"text": "arXiv:1912.01679", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDeep Contextualized Acoustic Representations For Semi-Supervised Speech Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oShaoshi Ling\\nYuzong Liu\\nJulian Salazar\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1912.01679\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/ICASSP40776.2020.9053176\\u00a7r\\n\\nVersion:\\u00a77v2 (Thu, 9 Apr 2020 17:55:35 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted to ICASSP 2020 (oral)\\u00a7r"}']}
{title:'Choi et al. (§72020§r)', author: 'Woosung Choi; Minseok Kim; Jaehwa Chung; Daewon Lee; Soonyoung Jung', display:{Lore:['[{"text": "arXiv:1912.02591", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.MM\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lInvestigating U-Nets with various Intermediate Blocks for Spectrogram-based Singing Voice Separation\\u00a7r\\n\\n\\u00a78\\u00a7oWoosung Choi\\nMinseok Kim\\nJaehwa Chung\\nDaewon Lee\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1912.02591\\u00a7r\\n\\nVersion:\\u00a77v3 (Thu, 8 Oct 2020 16:39:49 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o8 pages 4 tables 6 figures, accepted to ISMIR 2020\\u00a7r"}']}
{title:'Racharla et al. (§72020§r)', author: 'Karthikeya Racharla; Vineet Kumar; Chaudhari Bhushan Jayant; Ankit Khairkar; Paturu Harish', display:{Lore:['[{"text": "arXiv:1912.02606", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lPredominant Musical Instrument Classification based on Spectral Features\\u00a7r\\n\\n\\u00a78\\u00a7oKarthikeya Racharla\\nVineet Kumar\\nChaudhari Bhushan Jayant\\nAnkit Khairkar\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1912.02606\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/SPIN48934.2020.9071125\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 21 Apr 2020 18:53:52 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAppeared in Proceedings of SPIN 2020\\u00a7r"}']}
{title:'Tai et al. (§72020§r)', author: 'Jianwei Tai; Xiaoqi Jia; Qingjia Huang; Weijuan Zhang; Haichao Du; Shengzhi Zhang', display:{Lore:['[{"text": "arXiv:1912.02608", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSEEF-ALDR: A Speaker Embedding Enhancement Framework via Adversarial Learning based Disentangled Representation\\u00a7r\\n\\n\\u00a78\\u00a7oJianwei Tai\\nXiaoqi Jia\\nQingjia Huang\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1912.02608\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1145/3427228.3427274\\u00a7r\\n\\nVersion:\\u00a77v4 (Sun, 25 Oct 2020 04:19:40 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o12 pages, 4 figures, Accepted by ACSAC 2020\\u00a7r"}']}
{title:'Luo et al. (§72020§r)', author: 'Yin-Jyun Luo; Chin-Chen Hsu; Kat Agres; Dorien Herremans', display:{Lore:['[{"text": "arXiv:1912.02613", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSinging Voice Conversion with Disentangled Representations of Singer and Vocal Technique Using Variational Autoencoders\\u00a7r\\n\\n\\u00a78\\u00a7oYin-Jyun Luo\\nChin-Chen Hsu\\nKat Agres\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1912.02613\\u00a7r\\n\\nVersion:\\u00a77v3 (Tue, 25 Feb 2020 03:33:46 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted to ICASSP 2020\\u00a7r"}']}
{title:'Tian et al. (§72020§r)', author: 'Zhengkun Tian; Jiangyan Yi; Ye Bai; Jianhua Tao; Shuai Zhang; Zhengqi Wen', display:{Lore:['[{"text": "arXiv:1912.02958", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSynchronous Transformers for End-to-End Speech Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oZhengkun Tian\\nJiangyan Yi\\nYe Bai\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1912.02958\\u00a7r\\n\\nVersion:\\u00a77v2 (Mon, 24 Feb 2020 03:49:45 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted by ICASSP 2020\\u00a7r"}']}
{title:'Gandhe et al. (§72020§r)', author: 'Ankur Gandhe; Ariya Rastrow', display:{Lore:['[{"text": "arXiv:1912.03363", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAudio-attention discriminative language model for ASR rescoring\\u00a7r\\n\\n\\u00a78\\u00a7oAnkur Gandhe\\nAriya Rastrow\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1912.03363\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 18 Feb 2020 18:03:03 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o4 pages, 1 figure, Accepted at ICASSP 2020\\u00a7r"}']}
{title:'Agarwal et al. (§72020§r)', author: 'Dolly Agarwal; Jayant Gupchup; Nishant Baghel', display:{Lore:['[{"text": "arXiv:1912.04381", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CY\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Dataset for measuring reading levels in India at scale\\u00a7r\\n\\n\\u00a78\\u00a7oDolly Agarwal\\nJayant Gupchup\\nNishant Baghel\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1912.04381\\u00a7r\\n\\nVersion:\\u00a77v2 (Thu, 13 Feb 2020 07:57:21 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 3 figures, 3 Tables, Paper acceptedto ICASSP 2020\\u00a7r"}']}
{title:'Angelini et al. (§72020§r)', author: 'Orazio Angelini; Alexis Moinet; Kayoko Yanagisawa; Thomas Drugman', display:{Lore:['[{"text": "arXiv:1912.05881", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSinging Synthesis: with a little help from my attention\\u00a7r\\n\\n\\u00a78\\u00a7oOrazio Angelini\\nAlexis Moinet\\nKayoko Yanagisawa\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1912.05881\\u00a7r\\n\\nVersion:\\u00a77v2 (Wed, 6 May 2020 12:12:45 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to Interspeech 2020\\u00a7r"}']}
{title:'von Neumann et al. (§72020§r)', author: 'Thilo von Neumann; Keisuke Kinoshita; Lukas Drude; Christoph Boeddeker; Marc Delcroix; Tomohiro Nakatani; Reinhold Haeb-Umbach', display:{Lore:['[{"text": "arXiv:1912.08462", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lEnd-to-end training of time domain audio separation and recognition\\u00a7r\\n\\n\\u00a78\\u00a7oThilo von Neumann\\nKeisuke Kinoshita\\nLukas Drude\\n+ 3 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1912.08462\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/ICASSP40776.2020.9053461\\u00a7r\\n\\nVersion:\\u00a77v3 (Mon, 13 Apr 2020 11:39:14 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 1 figure, to appear in ICASSP 2020\\u00a7r"}']}
{title:'Fujita et al. (§72020§r)', author: 'Yuya Fujita; Aswin Shanmugam Subramanian; Motoi Omachi; Shinji Watanabe', display:{Lore:['[{"text": "arXiv:1912.11793", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAttention-based ASR with Lightweight and Dynamic Convolutions\\u00a7r\\n\\n\\u00a78\\u00a7oYuya Fujita\\nAswin Shanmugam Subramanian\\nMotoi Omachi\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1912.11793\\u00a7r\\n\\nVersion:\\u00a77v2 (Thu, 20 Feb 2020 01:59:01 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oICASSP 2020\\u00a7r"}']}
{title:'Zhang et al. (§72020§r)', author: 'Qiquan Zhang; Aaron Nicolson; Mingjiang Wang; Kuldip K. Paliwal; Chenxu Wang', display:{Lore:['[{"text": "arXiv:1912.12023", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7eeess.SP\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMonaural Speech Enhancement Using a Multi-Branch Temporal Convolutional Network\\u00a7r\\n\\n\\u00a78\\u00a7oQiquan Zhang\\nAaron Nicolson\\nMingjiang Wang\\nKuldip K. Paliwal\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n1912.12023\\u00a7r\\n\\nVersion:\\u00a77v5 (Sun, 17 May 2020 08:01:17 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oThere are some inappropriatedecriptions. These descriptions exist on many pages\\u00a7r"}']}
{title:'Ding et al. (§72020§r)', author: 'Fenglin Ding; Wu Guo; Lirong Dai; Jun Du', display:{Lore:['[{"text": "arXiv:2001.00129", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAttentive batch normalization for lstm-based acoustic modeling of speech recognition\\u00a7r\\n\\n\\u00a78\\u00a7oFenglin Ding\\nWu Guo\\nLirong Dai\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2001.00129\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 1 Jan 2020 02:39:42 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages,1 figure, submitted to ICASSP 2020\\u00a7r"}']}
{title:'Krishna et al. (§72020§r)', author: 'Gautam Krishna; Co Tran; Mason Carnahan; Ahmed H Tewfik', display:{Lore:['[{"text": "arXiv:2001.00501", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lEEG based Continuous Speech Recognition using Transformers\\u00a7r\\n\\n\\u00a78\\u00a7oGautam Krishna\\nCo Tran\\nMason Carnahan\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2001.00501\\u00a7r\\n\\nVersion:\\u00a77v3 (Tue, 5 May 2020 05:50:08 GMT)\\u00a7r"}']}
{title:'Kim et al. (§72020§r)', author: 'Kwangyoun Kim; Kyungmin Lee; Dhananjaya Gowda; Junmo Park; Sungsoo Kim; Sichen Jin; Young-Yoon Lee; Jinsu Yeo; Daehyun Kim; Seokyeong Jung; Jungin Lee; Myoungji Han; Chanwoo Kim', display:{Lore:['[{"text": "arXiv:2001.00577", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAttention based on-device streaming speech recognition with large speech corpus\\u00a7r\\n\\n\\u00a78\\u00a7oKwangyoun Kim\\nKyungmin Lee\\nDhananjaya Gowda\\n+ 9 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2001.00577\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 2 Jan 2020 04:24:44 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted and presented at the ASRU 2019 conference\\u00a7r"}']}
{title:'Li et al. (§72020§r)', author: 'Liu Li; Feng Gang', display:{Lore:['[{"text": "arXiv:2001.00731", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Pilot Study on Mandarin Chinese Cued Speech\\u00a7r\\n\\n\\u00a78\\u00a7oLiu Li\\nFeng Gang\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2001.00731\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 3 Jan 2020 05:39:16 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted by Journal of American Annals of the Deaf\\u00a7r"}']}
{title:'Liu et al. (§72020§r)', author: 'Li Liu; Gang Feng; Denis Beautemps; Xiao-Ping Zhang', display:{Lore:['[{"text": "arXiv:2001.00854", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lRe-synchronization using the Hand Preceding Model for Multi-modal Fusion in Automatic Continuous Cued Speech Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oLi Liu\\nGang Feng\\nDenis Beautemps\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2001.00854\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nIEEE TMM-2020\\u00a7r\\n\\nVersion:\\u00a77v2 (Sun, 23 Feb 2020 02:47:33 GMT)\\u00a7r"}']}
{title:'Yu et al. (§72020§r)', author: 'Cheng Yu; Ryandhimas E. Zezario; Syu-Siang Wang; Jonathan Sherman; Yi-Yen Hsieh; Xugang Lu; Hsin-Min Wang; Yu Tsao', display:{Lore:['[{"text": "arXiv:2001.01538", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSpeech Enhancement based on Denoising Autoencoder with Multi-branched Encoders\\u00a7r\\n\\n\\u00a78\\u00a7oCheng Yu\\nRyandhimas E. Zezario\\nSyu-Siang Wang\\n+ 4 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2001.01538\\u00a7r\\n\\nVersion:\\u00a77v3 (Fri, 25 Dec 2020 01:58:53 GMT)\\u00a7r"}']}
{title:'Yu et al. (§72020§r)', author: 'Jianwei Yu; Shi-Xiong Zhang; Jian Wu; Shahram Ghorbani; Bo Wu; Shiyin Kang; Shansong Liu; Xunying Liu; Helen Meng; Dong Yu', display:{Lore:['[{"text": "arXiv:2001.01656", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAudio-visual Recognition of Overlapped speech for the LRS2 dataset\\u00a7r\\n\\n\\u00a78\\u00a7oJianwei Yu\\nShi-Xiong Zhang\\nJian Wu\\n+ 6 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2001.01656\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 6 Jan 2020 16:43:05 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 5 figures, submitted to icassp2019\\u00a7r"}']}
{title:'Meng et al. (§72020§r)', author: 'Zhong Meng; Yashesh Gaur; Jinyu Li; Yifan Gong', display:{Lore:['[{"text": "arXiv:2001.01795", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.NE\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lCharacter-Aware Attention-Based End-to-End Speech Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oZhong Meng\\nYashesh Gaur\\nJinyu Li\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2001.01795\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7n2019 IEEE Automatic Speech Recognition and Understanding Workshop\\n  (ASRU), Sentosa, Singapore\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 6 Jan 2020 22:19:17 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o7 pages, 3 figures, ASRU 2019\\u00a7r"}']}
{title:'Meng et al. (§72020§r)', author: 'Zhong Meng; Jinyu Li; Yashesh Gaur; Yifan Gong', display:{Lore:['[{"text": "arXiv:2001.01798", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.NE\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDomain Adaptation via Teacher-Student Learning for End-to-End Speech Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oZhong Meng\\nJinyu Li\\nYashesh Gaur\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2001.01798\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7n2019 IEEE Automatic Speech Recognition and Understanding Workshop\\n  (ASRU), Sentosa, Singapore\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 6 Jan 2020 22:30:33 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o8 pages, 2 figures, ASRU 2019\\u00a7r"}']}
{title:'Mokrý et al. (§72020§r)', author: 'Ondřej Mokrý; Pavel Rajmic', display:{Lore:['[{"text": "arXiv:2001.02480", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAudio Inpainting: Revisited and Reweighted\\u00a7r\\n\\n\\u00a78\\u00a7oOnd\\u0159ej Mokr\\u00fd\\nPavel Rajmic\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2001.02480\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/TASLP.2020.3030486\\u00a7r\\n\\nVersion:\\u00a77v3 (Fri, 21 Aug 2020 13:45:45 GMT)\\u00a7r"}']}
{title:'Yang et al. (§72020§r)', author: 'Seung Hee Yang; Minhwa Chung', display:{Lore:['[{"text": "arXiv:2001.04260", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lImproving Dysarthric Speech Intelligibility Using Cycle-consistent Adversarial Training\\u00a7r\\n\\n\\u00a78\\u00a7oSeung Hee Yang\\nMinhwa Chung\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2001.04260\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 10 Jan 2020 01:40:27 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oTo be Published on the 24th February in BIOSIGNALS 2020. arXiv admin note: text overlapwith arXiv:1904.09407\\u00a7r"}']}
{title:'Shukla et al. (§72020§r)', author: 'Abhinav Shukla; Konstantinos Vougioukas; Pingchuan Ma; Stavros Petridis; Maja Pantic', display:{Lore:['[{"text": "arXiv:2001.04316", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CV\\u00a7r, \\u00a7acs.MM\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lVisually Guided Self Supervised Learning of Speech Representations\\u00a7r\\n\\n\\u00a78\\u00a7oAbhinav Shukla\\nKonstantinos Vougioukas\\nPingchuan Ma\\nStavros Petridis\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2001.04316\\u00a7r\\n\\nVersion:\\u00a77v2 (Thu, 20 Feb 2020 12:51:50 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted at ICASSP 2020 v2: Updated to the ICASSP 2020 camera ready version\\u00a7r"}']}
{title:'Manocha et al. (§72020§r)', author: 'Pranay Manocha; Adam Finkelstein; Richard Zhang; Nicholas J. Bryan; Gautham J. Mysore; Zeyu Jin', display:{Lore:['[{"text": "arXiv:2001.04460", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Differentiable Perceptual Audio Metric Learned from Just Noticeable Differences\\u00a7r\\n\\n\\u00a78\\u00a7oPranay Manocha\\nAdam Finkelstein\\nRichard Zhang\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2001.04460\\u00a7r\\n\\nVersion:\\u00a77v2 (Mon, 18 May 2020 16:29:21 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oDataset, code and sound examples can be found at https://pixl.cs.princeton.edu/pubs/Manocha_2020_ADP/\\u00a7r"}']}
{title:'Gu et al. (§72020§r)', author: 'Bin Gu; Wu Guo', display:{Lore:['[{"text": "arXiv:2001.04584", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7eeess.SP\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAn Improved Deep Neural Network for Modeling Speaker Characteristics at Different Temporal Scales\\u00a7r\\n\\n\\u00a78\\u00a7oBin Gu\\nWu Guo\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2001.04584\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 14 Jan 2020 02:02:47 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages,2 figures\\u00a7r"}']}
{title:'Gu et al. (§72020§r)', author: 'Bin Gu; Wu Guo', display:{Lore:['[{"text": "arXiv:2001.04585", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7eeess.SP\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lGaussian speaker embedding learning for text-independent speaker verification\\u00a7r\\n\\n\\u00a78\\u00a7oBin Gu\\nWu Guo\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2001.04585\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 14 Jan 2020 02:03:01 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 3 figures\\u00a7r"}']}
{title:'Jankowski et al. (§72020§r)', author: 'Charles Jankowski; Vishwas Mruthyunjaya; Ruixi Lin', display:{Lore:['[{"text": "arXiv:2001.04619", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lImproved Robust ASR for Social Robots in Public Spaces\\u00a7r\\n\\n\\u00a78\\u00a7oCharles Jankowski\\nVishwas Mruthyunjaya\\nRuixi Lin\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2001.04619\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 14 Jan 2020 04:21:18 GMT)\\u00a7r"}']}
{title:'Khandelwal et al. (§72020§r)', author: 'Anant Khandelwal; E. B. Goud; Y. Chand; L. Kumar; S. Prasad; N. Agarwala; R. Singh', display:{Lore:['[{"text": "arXiv:2001.04940", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lTwo Channel Audio Zooming System For Smartphone\\u00a7r\\n\\n\\u00a78\\u00a7oAnant Khandelwal\\nE. B. Goud\\nY. Chand\\n+ 3 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2001.04940\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 13 Jan 2020 18:06:47 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oPre-print for WASPAA\\u00a7r"}']}
{title:'Flemotomos et al. (§72020§r)', author: 'Nikolaos Flemotomos; Dimitrios Dimitriadis', display:{Lore:['[{"text": "arXiv:2001.05118", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Memory Augmented Architecture for Continuous Speaker Identification in Meetings\\u00a7r\\n\\n\\u00a78\\u00a7oNikolaos Flemotomos\\nDimitrios Dimitriadis\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2001.05118\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/ICASSP40776.2020.9053152\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 15 Jan 2020 03:32:18 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to ICASSP 2020\\u00a7r"}']}
{title:'Ramoji et al. (§72020§r)', author: 'Shreyas Ramoji; V Prashant Krishnan; Prachi Singh; Sriram Ganapathy', display:{Lore:['[{"text": "arXiv:2001.07034", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7eeess.SP\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lPairwise Discriminative Neural PLDA for Speaker Verification\\u00a7r\\n\\n\\u00a78\\u00a7oShreyas Ramoji\\nV Prashant Krishnan\\nPrachi Singh\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2001.07034\\u00a7r\\n\\nVersion:\\u00a77v2 (Fri, 7 Feb 2020 09:32:10 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oThis paper was submitted to IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP) 2020. Link to GitHub Repository: https://github.com/iiscleap/NeuralPlda\\u00a7r"}']}
{title:'Agrawal et al. (§72020§r)', author: 'Purvi Agrawal; Sriram Ganapathy', display:{Lore:['[{"text": "arXiv:2001.07067", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lInterpretable Filter Learning Using Soft Self-attention For Raw Waveform Speech Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oPurvi Agrawal\\nSriram Ganapathy\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2001.07067\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 20 Jan 2020 11:39:44 GMT)\\u00a7r"}']}
{title:'Tüske et al. (§72020§r)', author: 'Zoltán Tüske; George Saon; Kartik Audhkhasi; Brian Kingsbury', display:{Lore:['[{"text": "arXiv:2001.07263", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSingle headed attention based sequence-to-sequence model for state-of-the-art results on Switchboard\\u00a7r\\n\\n\\u00a78\\u00a7oZolt\\u00e1n T\\u00fcske\\nGeorge Saon\\nKartik Audhkhasi\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2001.07263\\u00a7r\\n\\nVersion:\\u00a77v3 (Tue, 20 Oct 2020 03:33:19 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 2 figures\\u00a7r"}']}
{title:'Huang et al. (§72020§r)', author: 'Wen-Chin Huang; Hao Luo; Hsin-Te Hwang; Chen-Chou Lo; Yu-Huai Peng; Yu Tsao; Hsin-Min Wang', display:{Lore:['[{"text": "arXiv:2001.07849", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lUnsupervised Representation Disentanglement using Cross Domain Features and Adversarial Learning in Variational Autoencoder based Voice Conversion\\u00a7r\\n\\n\\u00a78\\u00a7oWen-Chin Huang\\nHao Luo\\nHsin-Te Hwang\\n+ 3 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2001.07849\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/TETCI.2020.2977678\\u00a7r\\n\\nVersion:\\u00a77v3 (Fri, 7 Feb 2020 10:16:28 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted to IEEETransactions on Emerging Topics in Computational Intelligence\\u00a7r"}']}
{title:'Miao et al. (§72020§r)', author: 'Haoran Miao; Gaofeng Cheng; Changfeng Gao; Pengyuan Zhang; Yonghong Yan', display:{Lore:['[{"text": "arXiv:2001.08290", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.NE\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lTransformer-based Online CTC/attention End-to-End Speech Recognition Architecture\\u00a7r\\n\\n\\u00a78\\u00a7oHaoran Miao\\nGaofeng Cheng\\nChangfeng Gao\\nPengyuan Zhang\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2001.08290\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 11 Feb 2020 08:05:47 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted by ICASSP 2020\\u00a7r"}']}
{title:'Delcroix et al. (§72020§r)', author: 'Marc Delcroix; Tsubasa Ochiai; Katerina Zmolikova; Keisuke Kinoshita; Naohiro Tawara; Tomohiro Nakatani; Shoko Araki', display:{Lore:['[{"text": "arXiv:2001.08378", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lImproving speaker discrimination of target speech extraction with time-domain SpeakerBeam\\u00a7r\\n\\n\\u00a78\\u00a7oMarc Delcroix\\nTsubasa Ochiai\\nKaterina Zmolikova\\n+ 3 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2001.08378\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 23 Jan 2020 05:36:06 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 3 figures. Submitted to ICASSP 2020\\u00a7r"}']}
{title:'Gooneratne et al. (§72020§r)', author: 'Mary Gooneratne; Khe Chai Sim; Petr Zadrazil; Andreas Kabel; Françoise Beaufays; Giovanni Motta', display:{Lore:['[{"text": "arXiv:2001.08885", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lLow-rank Gradient Approximation For Memory-Efficient On-device Training of Deep Neural Network\\u00a7r\\n\\n\\u00a78\\u00a7oMary Gooneratne\\nKhe Chai Sim\\nPetr Zadrazil\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2001.08885\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 24 Jan 2020 05:12:18 GMT)\\u00a7r"}']}
{title:'Kirsebom et al. (§72020§r)', author: 'Oliver S. Kirsebom; Fabio Frazao; Yvan Simard; Nathalie Roy; Stan Matwin; Samuel Giard', display:{Lore:['[{"text": "arXiv:2001.09127", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lPerformance of a Deep Neural Network at Detecting North Atlantic Right Whale Upcalls\\u00a7r\\n\\n\\u00a78\\u00a7oOliver S. Kirsebom\\nFabio Frazao\\nYvan Simard\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2001.09127\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1121/10.0001132\\u00a7r\\n\\nVersion:\\u00a77v2 (Sat, 29 Feb 2020 20:39:30 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o11 pages, 9 figures, 2 tables, submitted to JASA on Dec 22, 2019, as part of a special issue on The Effects ofNoise on Aquatic Life; resubmitted on Feb 29, 2020, upon minor revisions and improved SNR estimates\\u00a7r"}']}
{title:'Chen et al. (§72020§r)', author: 'Yang Chen; Weiran Wang; Chao Wang', display:{Lore:['[{"text": "arXiv:2001.09128", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSemi-supervised ASR by End-to-end Self-training\\u00a7r\\n\\n\\u00a78\\u00a7oYang Chen\\nWeiran Wang\\nChao Wang\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2001.09128\\u00a7r\\n\\nVersion:\\u00a77v2 (Thu, 30 Jul 2020 14:48:51 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted by Interspeech 2020\\u00a7r"}']}
{title:'Chen et al. (§72020§r)', author: 'Yang Chen; Weiran Wang; I-Fan Chen; Chao Wang', display:{Lore:['[{"text": "arXiv:2001.09221", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lData Techniques For Online End-to-end Speech Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oYang Chen\\nWeiran Wang\\nI-Fan Chen\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2001.09221\\u00a7r\\n\\nVersion:\\u00a77v2 (Sun, 26 Jul 2020 22:58:12 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 1 figure\\u00a7r"}']}
{title:'Ravanelli et al. (§72020§r)', author: 'Mirco Ravanelli; Jianyuan Zhong; Santiago Pascual; Pawel Swietojanski; Joao Monteiro; Jan Trmal; Yoshua Bengio', display:{Lore:['[{"text": "arXiv:2001.09239", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMulti-task self-supervised learning for Robust Speech Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oMirco Ravanelli\\nJianyuan Zhong\\nSantiago Pascual\\n+ 3 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2001.09239\\u00a7r\\n\\nVersion:\\u00a77v2 (Fri, 17 Apr 2020 19:40:35 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oIn Proc. of ICASSP 2020\\u00a7r"}']}
{title:'Sigtia et al. (§72020§r)', author: 'Siddharth Sigtia; Pascal Clark; Rob Haynes; Hywel Richards; John Bridle', display:{Lore:['[{"text": "arXiv:2001.09519", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMulti-task Learning for Voice Trigger Detection\\u00a7r\\n\\n\\u00a78\\u00a7oSiddharth Sigtia\\nPascal Clark\\nRob Haynes\\nHywel Richards\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2001.09519\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/ICASSP40776.2020.9053577\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nIEEE International Conference on Acoustics, Speech and Signal\\n  Processing (ICASSP), Barcelona, Spain, 2020, pp. 7449-7453\\u00a7r\\n\\nVersion:\\u00a77v2 (Mon, 20 Apr 2020 09:05:35 GMT)\\u00a7r"}']}
{title:'Shankar et al. (§72020§r)', author: 'Nikhil Shankar; Gautam S Bhat; Chandan K A Reddy; Issa Panahi', display:{Lore:['[{"text": "arXiv:2001.09571", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lNoise dependent Super Gaussian-Coherence based dual microphone Speech Enhancement for hearing aid application using smartphone\\u00a7r\\n\\n\\u00a78\\u00a7oNikhil Shankar\\nGautam S Bhat\\nChandan K A Reddy\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2001.09571\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 27 Jan 2020 03:13:21 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o4 pages, 3 figures\\u00a7r"}']}
{title:'Biswas et al. (§72020§r)', author: 'Arijit Biswas; Dai Jia', display:{Lore:['[{"text": "arXiv:2001.09653", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7eeess.SP\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAudio Codec Enhancement with Generative Adversarial Networks\\u00a7r\\n\\n\\u00a78\\u00a7oArijit Biswas\\nDai Jia\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2001.09653\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 27 Jan 2020 09:50:36 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted to 45thIEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), Barcelona, Spain, 04-08 May 2020\\u00a7r"}']}
{title:'Kim et al. (§72020§r)', author: 'Juntae Kim; Jaesung Bae', display:{Lore:['[{"text": "arXiv:2001.09772", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lPhase-Aware Speech Enhancement with a Recurrent Two Stage Net work\\u00a7r\\n\\n\\u00a78\\u00a7oJuntae Kim\\nJaesung Bae\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2001.09772\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 27 Jan 2020 13:46:32 GMT)\\u00a7r"}']}
{title:'Fejgin et al. (§72020§r)', author: 'Roy Fejgin; Janusz Klejsa; Lars Villemoes; Cong Zhou', display:{Lore:['[{"text": "arXiv:2001.09847", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSource coding of audio signals with a generative model\\u00a7r\\n\\n\\u00a78\\u00a7oRoy Fejgin\\nJanusz Klejsa\\nLars Villemoes\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2001.09847\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 27 Jan 2020 15:09:58 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oPre-review version, accepted to ICASSP 2020\\u00a7r"}']}
{title:'Yousefi et al. (§72020§r)', author: 'Midia Yousefi; John H. L. Hansen', display:{Lore:['[{"text": "arXiv:2001.09937", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7eeess.SP\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lFrame-based overlapping speech detection using Convolutional Neural Networks\\u00a7r\\n\\n\\u00a78\\u00a7oMidia Yousefi\\nJohn H. L. Hansen\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2001.09937\\u00a7r\\n\\nVersion:\\u00a77v2 (Thu, 13 Feb 2020 04:08:24 GMT)\\u00a7r"}']}
{title:'P et al. (§72020§r)', author: 'Bharath K P; Sylash K; Pravina K; Rajesh Kumar M', display:{Lore:['[{"text": "arXiv:2001.10094", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lOMAP-L138 LCDK Development Kit\\u00a7r\\n\\n\\u00a78\\u00a7oBharath K P\\nSylash K\\nPravina K\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2001.10094\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 13 Jan 2020 13:09:48 GMT)\\u00a7r"}']}
{title:'Schröter et al. (§72020§r)', author: 'Hendrik Schröter; Tobias Rosenkranz; Alberto N. Escalante B.; Marc Aubreville; Andreas Maier', display:{Lore:['[{"text": "arXiv:2001.10218", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lCLCNet: Deep learning-based Noise Reduction for Hearing Aids using Complex Linear Coding\\u00a7r\\n\\n\\u00a78\\u00a7oHendrik Schr\\u00f6ter\\nTobias Rosenkranz\\nAlberto N. Escalante B.\\nMarc Aubreville\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2001.10218\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 28 Jan 2020 09:08:35 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 Pages, ICASSP 2020\\u00a7r"}']}
{title:'Qi et al. (§72020§r)', author: 'Jun Qi; Chao-Han Huck Yang; Javier Tejedor', display:{Lore:['[{"text": "arXiv:2001.10529", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.NE\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSubmodular Rank Aggregation on Score-based Permutations for Distributed Automatic Speech Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oJun Qi\\nChao-Han Huck Yang\\nJavier Tejedor\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2001.10529\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/ICASSP40776.2020.9054219\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7n2020 IEEE International Conference on Acoustics, Speech and Signal\\n  Processing (ICASSP)\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 27 Jan 2020 19:46:41 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted to ICASSP 2020. Please download the pdf to view Figure 1. arXiv admin note: substantial text overlap with arXiv:1707.01166\\u00a7r"}']}
{title:'Xia et al. (§72020§r)', author: 'Yangyang Xia; Sebastian Braun; Chandan K. A. Reddy; Harishchandra Dubey; Ross Cutler; Ivan Tashev', display:{Lore:['[{"text": "arXiv:2001.10601", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lWeighted Speech Distortion Losses for Neural-network-based Real-time Speech Enhancement\\u00a7r\\n\\n\\u00a78\\u00a7oYangyang Xia\\nSebastian Braun\\nChandan K. A. Reddy\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2001.10601\\u00a7r\\n\\nVersion:\\u00a77v2 (Wed, 12 Feb 2020 22:10:56 GMT)\\u00a7r"}']}
{title:'Wang et al. (§72020§r)', author: 'Weiran Wang; Qingming Tang; Karen Livescu', display:{Lore:['[{"text": "arXiv:2001.10603", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lUnsupervised Pre-training of Bidirectional Speech Encoders via Masked Reconstruction\\u00a7r\\n\\n\\u00a78\\u00a7oWeiran Wang\\nQingming Tang\\nKaren Livescu\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2001.10603\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 5 May 2020 21:27:13 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oFinal version for ICASSP 2020\\u00a7r"}']}
{title:'Yang et al. (§72020§r)', author: 'Jun Yang; Joshua Bingham', display:{Lore:['[{"text": "arXiv:2001.10718", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7eeess.SP\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lEnvironment-aware Reconfigurable Noise Suppression\\u00a7r\\n\\n\\u00a78\\u00a7oJun Yang\\nJoshua Bingham\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2001.10718\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nICASSP 2020, May 4-8, 2020, Barcelona, Spain\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 29 Jan 2020 08:22:51 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, ICASSP 2020 publication\\u00a7r"}']}
{title:'Sigtia et al. (§72020§r)', author: 'Siddharth Sigtia; Erik Marchi; Sachin Kajarekar; Devang Naik; John Bridle', display:{Lore:['[{"text": "arXiv:2001.10816", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMulti-task Learning for Speaker Verification and Voice Trigger Detection\\u00a7r\\n\\n\\u00a78\\u00a7oSiddharth Sigtia\\nErik Marchi\\nSachin Kajarekar\\nDevang Naik\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2001.10816\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/ICASSP40776.2020.9054760\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nInternational Conference on Acoustics, Speech and Signal\\n  Processing (ICASSP), Spain, 2020, pp. 6844-6848\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 26 Jan 2020 21:19:27 GMT)\\u00a7r"}']}
{title:'Seo et al. (§72020§r)', author: 'Soonshin Seo; Ji-Hwan Kim', display:{Lore:['[{"text": "arXiv:2001.10817", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMCSAE: Masked Cross Self-Attentive Encoding for Speaker Embedding\\u00a7r\\n\\n\\u00a78\\u00a7oSoonshin Seo\\nJi-Hwan Kim\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2001.10817\\u00a7r\\n\\nVersion:\\u00a77v4 (Tue, 28 Jul 2020 07:19:37 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 3 figures, 4 tables\\u00a7r"}']}
{title:'Dighe et al. (§72020§r)', author: 'Pranay Dighe; Saurabh Adya; Nuoyu Li; Srikanth Vishnubhotla; Devang Naik; Adithya Sagar; Ying Ma; Stephen Pulman; Jason Williams', display:{Lore:['[{"text": "arXiv:2001.10822", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lLattice-based Improvements for Voice Triggering Using Graph Neural Networks\\u00a7r\\n\\n\\u00a78\\u00a7oPranay Dighe\\nSaurabh Adya\\nNuoyu Li\\n+ 5 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2001.10822\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 25 Jan 2020 01:34:15 GMT)\\u00a7r"}']}
{title:'Aralikatti et al. (§72020§r)', author: 'Rohith Aralikatti; Sharad Roy; Abhinav Thanda; Dilip Kumar Margam; Pujitha Appan Kandala; Tanay Sharma; Shankar M Venkatesan', display:{Lore:['[{"text": "arXiv:2001.10832", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.MM\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7eeess.IV\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAudio-Visual Decision Fusion for WFST-based and seq2seq Models\\u00a7r\\n\\n\\u00a78\\u00a7oRohith Aralikatti\\nSharad Roy\\nAbhinav Thanda\\n+ 3 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2001.10832\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 29 Jan 2020 13:45:08 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted for review to ICASSP 2020 on October 21st, 2019\\u00a7r"}']}
{title:'Cerutti et al. (§72020§r)', author: 'Gianmarco Cerutti; Rahul Prasad; Alessio Brutti; Elisabetta Farella', display:{Lore:['[{"text": "arXiv:2001.10876", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lCompact recurrent neural networks for acoustic event detection on low-energy low-complexity platforms\\u00a7r\\n\\n\\u00a78\\u00a7oGianmarco Cerutti\\nRahul Prasad\\nAlessio Brutti\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2001.10876\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/JSTSP.2020.2969775\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 29 Jan 2020 14:56:52 GMT)\\u00a7r"}']}
{title:'Titus et al. (§72020§r)', author: 'Andrew Titus; Jan Silovsky; Nanxin Chen; Roger Hsiao; Mary Young; Arnab Ghoshal', display:{Lore:['[{"text": "arXiv:2001.11019", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lImproving Language Identification for Multilingual Speakers\\u00a7r\\n\\n\\u00a78\\u00a7oAndrew Titus\\nJan Silovsky\\nNanxin Chen\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2001.11019\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 29 Jan 2020 18:58:11 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 2 figures. Submitted to ICASSP 2020\\u00a7r"}']}
{title:'Colonel et al. (§72020§r)', author: 'Joseph T Colonel; Sam Keene', display:{Lore:['[{"text": "arXiv:2001.11296", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.NE\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lConditioning Autoencoder Latent Spaces for Real-Time Timbre Interpolation and Synthesis\\u00a7r\\n\\n\\u00a78\\u00a7oJoseph T Colonel\\nSam Keene\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2001.11296\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 30 Jan 2020 13:06:26 GMT)\\u00a7r"}']}
{title:'Karafiát et al. (§72020§r)', author: 'Martin Karafiát; Murali Karthick Baskar; Igor Szöke; Hari Krishna Vydana; Karel Veselý; Jan "Honza\'\' Černocký', display:{Lore:['[{"text": "arXiv:2001.11360", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lBUT Opensat 2019 Speech Recognition System\\u00a7r\\n\\n\\u00a78\\u00a7oMartin Karafi\\u00e1t\\nMurali Karthick Baskar\\nIgor Sz\\u00f6ke\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2001.11360\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 30 Jan 2020 14:35:34 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oREJECTED in ICASSP 2020\\u00a7r"}']}
{title:'Hwang et al. (§72020§r)', author: 'Min-Jae Hwang; Eunwoo Song; Ryuichi Yamamoto; Frank Soong; Hong-Goo Kang', display:{Lore:['[{"text": "arXiv:2001.11686", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lImproving LPCNet-based Text-to-Speech with Linear Prediction-structured Mixture Density Network\\u00a7r\\n\\n\\u00a78\\u00a7oMin-Jae Hwang\\nEunwoo Song\\nRyuichi Yamamoto\\nFrank Soong\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2001.11686\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nIEEE ICASSP 2020\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 31 Jan 2020 07:43:01 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted to ICASSP 2020\\u00a7r"}']}
{title:'Jung et al. (§72020§r)', author: 'Jee-weon Jung; Hye-jin Shim; Hee-Soo Heo; Ha-Jin Yu', display:{Lore:['[{"text": "arXiv:2001.11688", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA study on the role of subsidiary information in replay attack spoofing detection\\u00a7r\\n\\n\\u00a78\\u00a7oJee-weon Jung\\nHye-jin Shim\\nHee-Soo Heo\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2001.11688\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 31 Jan 2020 07:45:03 GMT)\\u00a7r"}']}
{title:'Imoto (§72020§r)', author: 'Keisuke Imoto', display:{Lore:['[{"text": "arXiv:2001.11894", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lGraph Cepstrum: Spatial Feature Extracted from Partially Connected Microphones\\u00a7r\\n\\n\\u00a78\\u00a7oKeisuke Imoto\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2001.11894\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1587/transinf.2019EDP7162\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 30 Jan 2020 17:45:13 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted to IEICE Transactions on Information and Systems. arXiv admin note: substantial text overlap with arXiv:1805.11782\\u00a7r"}']}
{title:'Kataria et al. (§72020§r)', author: 'Saurabh Kataria; Phani Sankar Nidadavolu; Jesús Villalba; Najim Dehak', display:{Lore:['[{"text": "arXiv:2002.00139", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAnalysis of Deep Feature Loss based Enhancement for Speaker Verification\\u00a7r\\n\\n\\u00a78\\u00a7oSaurabh Kataria\\nPhani Sankar Nidadavolu\\nJes\\u00fas Villalba\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2002.00139\\u00a7r\\n\\nVersion:\\u00a77v2 (Mon, 27 Apr 2020 20:46:27 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o8 pages; accepted in Odyssey2020 workshop\\u00a7r"}']}
{title:'Zhou et al. (§72020§r)', author: 'Kun Zhou; Berrak Sisman; Haizhou Li', display:{Lore:['[{"text": "arXiv:2002.00198", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lTransforming Spectrum and Prosody for Emotional Voice Conversion with Non-Parallel Training Data\\u00a7r\\n\\n\\u00a78\\u00a7oKun Zhou\\nBerrak Sisman\\nHaizhou Li\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2002.00198\\u00a7r\\n\\nVersion:\\u00a77v5 (Sat, 24 Oct 2020 06:37:42 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oaccepted by Speaker Odyssey 2020 in Tokyo, Japan\\u00a7r"}']}
{title:'Liu et al. (§72020§r)', author: 'Rui Liu; Berrak Sisman; Feilong Bao; Guanglai Gao; Haizhou Li', display:{Lore:['[{"text": "arXiv:2002.00417", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lWaveTTS: Tacotron-based TTS with Joint Time-Frequency Domain Loss\\u00a7r\\n\\n\\u00a78\\u00a7oRui Liu\\nBerrak Sisman\\nFeilong Bao\\nGuanglai Gao\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2002.00417\\u00a7r\\n\\nVersion:\\u00a77v3 (Tue, 7 Apr 2020 01:24:14 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oTo appear at Odyssey 2020, Tokyo, Japan\\u00a7r"}']}
{title:'Qi et al. (§72020§r)', author: 'Jun Qi; Hu Hu; Yannan Wang; Chao-Han Huck Yang; Sabato Marco Siniscalchi; Chin-Hui Lee', display:{Lore:['[{"text": "arXiv:2002.00544", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.NE\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lTensor-to-Vector Regression for Multi-channel Speech Enhancement based on Tensor-Train Network\\u00a7r\\n\\n\\u00a78\\u00a7oJun Qi\\nHu Hu\\nYannan Wang\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2002.00544\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nIEEE ICASSP 2020\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 3 Feb 2020 02:58:00 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted to ICASSP 2020. Update reproducible code\\u00a7r"}']}
{title:'Yoshimura et al. (§72020§r)', author: 'Takenori Yoshimura; Tomoki Hayashi; Kazuya Takeda; Shinji Watanabe', display:{Lore:['[{"text": "arXiv:2002.00551", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lEnd-to-End Automatic Speech Recognition Integrated With CTC-Based Voice Activity Detection\\u00a7r\\n\\n\\u00a78\\u00a7oTakenori Yoshimura\\nTomoki Hayashi\\nKazuya Takeda\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2002.00551\\u00a7r\\n\\nVersion:\\u00a77v2 (Fri, 14 Feb 2020 06:15:58 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to ICASSP 2020\\u00a7r"}']}
{title:'Comanducci et al. (§72020§r)', author: 'Luca Comanducci; Maximo Cobos; Fabio Antonacci; Augusto Sarti', display:{Lore:['[{"text": "arXiv:2002.00641", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lTime Difference of Arrival Estimation from Frequency-Sliding Generalized Cross-Correlations Using Convolutional Neural Networks\\u00a7r\\n\\n\\u00a78\\u00a7oLuca Comanducci\\nMaximo Cobos\\nFabio Antonacci\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2002.00641\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 3 Feb 2020 10:42:49 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oPaper accepted for presentation in ICASSP 2020\\u00a7r"}']}
{title:'Cai et al. (§72020§r)', author: 'Danwei Cai; Weicheng Cai; Ming Li', display:{Lore:['[{"text": "arXiv:2002.00924", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lWithin-sample variability-invariant loss for robust speaker recognition under noisy environments\\u00a7r\\n\\n\\u00a78\\u00a7oDanwei Cai\\nWeicheng Cai\\nMing Li\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2002.00924\\u00a7r\\n\\nVersion:\\u00a77v2 (Thu, 13 Feb 2020 04:23:31 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted at ICASSP 2020\\u00a7r"}']}
{title:'Chen et al. (§72020§r)', author: 'Chengwei Chen; Pan Chen; Lingyu Yang; Jinyuan Mo; Haichuan Song; Yuan Xie; Lizhuang Ma', display:{Lore:['[{"text": "arXiv:2002.01107", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CV\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAcoustic anomaly detection via latent regularized gaussian mixture generative adversarial networks\\u00a7r\\n\\n\\u00a78\\u00a7oChengwei Chen\\nPan Chen\\nLingyu Yang\\n+ 3 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2002.01107\\u00a7r\\n\\nVersion:\\u00a77v2 (Wed, 5 Feb 2020 02:27:12 GMT)\\u00a7r"}']}
{title:'Lin et al. (§72020§r)', author: 'James Lin; Kevin Kilgour; Dominik Roblek; Matthew Sharifi', display:{Lore:['[{"text": "arXiv:2002.01322", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lTraining Keyword Spotters with Limited and Synthesized Speech Data\\u00a7r\\n\\n\\u00a78\\u00a7oJames Lin\\nKevin Kilgour\\nDominik Roblek\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2002.01322\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 31 Jan 2020 07:50:42 GMT)\\u00a7r"}']}
{title:'Kowtha et al. (§72020§r)', author: 'Vasudha Kowtha; Vikramjit Mitra; Chris Bartels; Erik Marchi; Sue Booker; William Caruso; Sachin Kajarekar; Devang Naik', display:{Lore:['[{"text": "arXiv:2002.01323", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDetecting Emotion Primitives from Speech and their use in discerning Categorical Emotions\\u00a7r\\n\\n\\u00a78\\u00a7oVasudha Kowtha\\nVikramjit Mitra\\nChris Bartels\\n+ 4 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2002.01323\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 31 Jan 2020 03:11:24 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages\\u00a7r"}']}
{title:'Grondin et al. (§72020§r)', author: 'Francois Grondin; Hao Tang; James Glass', display:{Lore:['[{"text": "arXiv:2002.01440", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7eeess.SP\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAudio-Visual Calibration with Polynomial Regression for 2-D Projection Using SVD-PHAT\\u00a7r\\n\\n\\u00a78\\u00a7oFrancois Grondin\\nHao Tang\\nJames Glass\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2002.01440\\u00a7r\\n\\nVersion:\\u00a77v2 (Wed, 12 Feb 2020 14:04:01 GMT)\\u00a7r"}']}
{title:'Fan et al. (§72020§r)', author: 'Cunhang Fan; Bin Liu; Jianhua Tao; Jiangyan Yi; Zhengqi Wen', display:{Lore:['[{"text": "arXiv:2002.01626", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSpatial and spectral deep attention fusion for multi-channel speech separation using deep embedding features\\u00a7r\\n\\n\\u00a78\\u00a7oCunhang Fan\\nBin Liu\\nJianhua Tao\\nJiangyan Yi\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2002.01626\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 5 Feb 2020 03:49:39 GMT)\\u00a7r"}']}
{title:'Lu et al. (§72020§r)', author: 'JinHong Lu; Hiroshi Shimodaira', display:{Lore:['[{"text": "arXiv:2002.01869", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lPrediction of head motion from speech waveforms with a canonical-correlation-constrained autoencoder\\u00a7r\\n\\n\\u00a78\\u00a7oJinHong Lu\\nHiroshi Shimodaira\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2002.01869\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.21437/Interspeech.2020-1218\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nProc. Interspeech 2020, 1301-1305\\u00a7r\\n\\nVersion:\\u00a77v2 (Mon, 2 Nov 2020 14:03:01 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7ohead motion synthesis, speech-driven animation, deep canonically correlatedautoencoder\\u00a7r"}']}
{title:'Moss et al. (§72020§r)', author: 'Henry B. Moss; Vatsal Aggarwal; Nishant Prateek; Javier González; Roberto Barra-Chicote', display:{Lore:['[{"text": "arXiv:2002.01953", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lBOFFIN TTS: Few-Shot Speaker Adaptation by Bayesian Optimization\\u00a7r\\n\\n\\u00a78\\u00a7oHenry B. Moss\\nVatsal Aggarwal\\nNishant Prateek\\nJavier Gonz\\u00e1lez\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2002.01953\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 4 Feb 2020 16:37:52 GMT)\\u00a7r"}']}
{title:'Zhang et al. (§72020§r)', author: 'Qian Zhang; Han Lu; Hasim Sak; Anshuman Tripathi; Erik McDermott; Stephen Koo; Shankar Kumar', display:{Lore:['[{"text": "arXiv:2002.02562", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lTransformer Transducer: A Streamable Speech Recognition Model with Transformer Encoders and RNN-T Loss\\u00a7r\\n\\n\\u00a78\\u00a7oQian Zhang\\nHan Lu\\nHasim Sak\\n+ 3 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2002.02562\\u00a7r\\n\\nVersion:\\u00a77v2 (Fri, 14 Feb 2020 21:47:10 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oThis is the final version of the paper submitted to the ICASSP 2020 on Oct 21, 2019\\u00a7r"}']}
{title:'Ramoji et al. (§72020§r)', author: 'Shreyas Ramoji; Prashant Krishnan; Bhargavram Mysore; Prachi Singh; Sriram Ganapathy', display:{Lore:['[{"text": "arXiv:2002.02735", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lLEAP System for SRE19 CTS Challenge \\u2013 Improvements and Error Analysis\\u00a7r\\n\\n\\u00a78\\u00a7oShreyas Ramoji\\nPrashant Krishnan\\nBhargavram Mysore\\nPrachi Singh\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2002.02735\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.21437/Odyssey.2020-40\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nin Proc. Odyssey 2020 The Speaker and Language Recognition\\n  Workshop, 281--288\\u00a7r\\n\\nVersion:\\u00a77v2 (Sun, 24 May 2020 05:28:06 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oPublished In Proc. Odyssey 2020, the Speaker and Language Recognition Workshop. Link to GitHubImplementation: https://github.com/iiscleap/NeuralPlda\\u00a7r"}']}
{title:'Rivière et al. (§72020§r)', author: 'Morgane Rivière; Armand Joulin; Pierre-Emmanuel Mazaré; Emmanuel Dupoux', display:{Lore:['[{"text": "arXiv:2002.02848", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lUnsupervised pretraining transfers well across languages\\u00a7r\\n\\n\\u00a78\\u00a7oMorgane Rivi\\u00e8re\\nArmand Joulin\\nPierre-Emmanuel Mazar\\u00e9\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2002.02848\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nICASSP 2020\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 7 Feb 2020 15:34:53 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o6 pages. Accepted at ICASSP 2020. However the 2 pages of supplementary materials will appear only in the arxiv version\\u00a7r"}']}
{title:'Peri et al. (§72020§r)', author: 'Raghuveer Peri; Haoqi Li; Krishna Somandepalli; Arindam Jati; Shrikanth Narayanan', display:{Lore:['[{"text": "arXiv:2002.03520", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAn empirical analysis of information encoded in disentangled neural speaker representations\\u00a7r\\n\\n\\u00a78\\u00a7oRaghuveer Peri\\nHaoqi Li\\nKrishna Somandepalli\\nArindam Jati\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2002.03520\\u00a7r\\n\\nVersion:\\u00a77v2 (Wed, 8 Apr 2020 01:59:48 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to Speaker Odyssey 2020\\u00a7r"}']}
{title:'Ramoji et al. (§72020§r)', author: 'Shreyas Ramoji; Prashant Krishnan; Sriram Ganapathy', display:{Lore:['[{"text": "arXiv:2002.03562", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lNPLDA: A Deep Neural PLDA Model for Speaker Verification\\u00a7r\\n\\n\\u00a78\\u00a7oShreyas Ramoji\\nPrashant Krishnan\\nSriram Ganapathy\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2002.03562\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.21437/Odyssey.2020-29\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nin Proc. Odyssey 2020 The Speaker and Language Recognition\\n  Workshop, Pages 202-209\\u00a7r\\n\\nVersion:\\u00a77v2 (Sun, 24 May 2020 05:40:56 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oPublished in Odyssey 2020, the Speaker and Language Recognition Workshop (VOiCES Special Session). Link to GitHub Implementation: https://github.com/iiscleap/NeuralPlda. arXiv admin note: substantial text overlap with "}','{"text": "arXiv:2001.07034\\u00a7r"}']}
{title:'Shahin (§72020§r)', author: 'Ismail Shahin', display:{Lore:['[{"text": "arXiv:2002.03566", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lEmotion Recognition Using Speaker Cues\\u00a7r\\n\\n\\u00a78\\u00a7oIsmail Shahin\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2002.03566\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 4 Feb 2020 08:20:30 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages\\u00a7r"}']}
{title:'Sun et al. (§72020§r)', author: 'Guangzhi Sun; Yu Zhang; Ron J. Weiss; Yuan Cao; Heiga Zen; Yonghui Wu', display:{Lore:['[{"text": "arXiv:2002.03785", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lFully-hierarchical fine-grained prosody modeling for interpretable speech synthesis\\u00a7r\\n\\n\\u00a78\\u00a7oGuangzhi Sun\\nYu Zhang\\nRon J. Weiss\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2002.03785\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 6 Feb 2020 12:52:03 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oto appear in ICASSP 2020\\u00a7r"}']}
{title:'Sun et al. (§72020§r)', author: 'Guangzhi Sun; Yu Zhang; Ron J. Weiss; Yuan Cao; Heiga Zen; Andrew Rosenberg; Bhuvana Ramabhadran; Yonghui Wu', display:{Lore:['[{"text": "arXiv:2002.03788", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lGenerating diverse and natural text-to-speech samples using a quantized fine-grained VAE and auto-regressive prosody prior\\u00a7r\\n\\n\\u00a78\\u00a7oGuangzhi Sun\\nYu Zhang\\nRon J. Weiss\\n+ 4 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2002.03788\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 6 Feb 2020 12:35:50 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oTo appear in ICASSP 2020\\u00a7r"}']}
{title:'Kanervisto et al. (§72020§r)', author: 'Anssi Kanervisto; Ville Hautamäki; Tomi Kinnunen; Junichi Yamagishi', display:{Lore:['[{"text": "arXiv:2002.03801", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAn initial investigation on optimizing tandem speaker verification and countermeasure systems using reinforcement learning\\u00a7r\\n\\n\\u00a78\\u00a7oAnssi Kanervisto\\nVille Hautam\\u00e4ki\\nTomi Kinnunen\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2002.03801\\u00a7r\\n\\nVersion:\\u00a77v2 (Wed, 8 Apr 2020 11:09:14 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oOdyssey 2020 The Speaker and Language Recognition Workshop. Code available at https://github.com/Miffyli/asv-cm-reinforce\\u00a7r"}']}
{title:'Ferrer et al. (§72020§r)', author: 'Luciana Ferrer; Mitchell McLaren', display:{Lore:['[{"text": "arXiv:2002.03802", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Speaker Verification Backend for Improved Calibration Performance across Varying Conditions\\u00a7r\\n\\n\\u00a78\\u00a7oLuciana Ferrer\\nMitchell McLaren\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2002.03802\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 5 Feb 2020 15:37:46 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oarXiv admin note: substantial text overlap with arXiv:1911.11622\\u00a7r"}']}
{title:'Kim et al. (§72020§r)', author: 'June-Woo Kim; Ho-Young Jung; Minho Lee', display:{Lore:['[{"text": "arXiv:2002.03808", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lVocoder-free End-to-End Voice Conversion with Transformer Network\\u00a7r\\n\\n\\u00a78\\u00a7oJune-Woo Kim\\nHo-Young Jung\\nMinho Lee\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2002.03808\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/IJCNN48605.2020.9207653\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7n2020 International Joint Conference on Neural Networks (IJCNN)\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 5 Feb 2020 06:19:24 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oWork inprogress\\u00a7r"}']}
{title:'Krishna et al. (§72020§r)', author: 'Gautam Krishna; Co Tran; Mason Carnahan; Ahmed Tewfik', display:{Lore:['[{"text": "arXiv:2002.03851", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lContinuous Silent Speech Recognition using EEG\\u00a7r\\n\\n\\u00a78\\u00a7oGautam Krishna\\nCo Tran\\nMason Carnahan\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2002.03851\\u00a7r\\n\\nVersion:\\u00a77v7 (Mon, 4 May 2020 20:37:29 GMT)\\u00a7r"}']}
{title:'Keerti et al. (§72020§r)', author: 'Gullapalli Keerti; A N Vaishnavi; Prerana Mukherjee; A Sree Vidya; Gattineni Sai Sreenithya; Deeksha Nayab', display:{Lore:['[{"text": "arXiv:2002.03854", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAttentional networks for music generation\\u00a7r\\n\\n\\u00a78\\u00a7oGullapalli Keerti\\nA N Vaishnavi\\nPrerana Mukherjee\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2002.03854\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 6 Feb 2020 13:26:17 GMT)\\u00a7r"}']}
{title:'Chang et al. (§72020§r)', author: 'Xuankai Chang; Wangyou Zhang; Yanmin Qian; Jonathan Le Roux; Shinji Watanabe', display:{Lore:['[{"text": "arXiv:2002.03921", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lEnd-to-End Multi-speaker Speech Recognition with Transformer\\u00a7r\\n\\n\\u00a78\\u00a7oXuankai Chang\\nWangyou Zhang\\nYanmin Qian\\nJonathan Le Roux\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2002.03921\\u00a7r\\n\\nVersion:\\u00a77v2 (Thu, 13 Feb 2020 00:50:39 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oTo appear in ICASSP 2020\\u00a7r"}']}
{title:'Pham et al. (§72020§r)', author: 'Lam Pham; Ian McLoughlin; Huy Phan; Ramaswamy Palaniappan; Alfred Mertins', display:{Lore:['[{"text": "arXiv:2002.04857", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDeep Feature Embedding and Hierarchical Classification for Audio Scene Classification\\u00a7r\\n\\n\\u00a78\\u00a7oLam Pham\\nIan McLoughlin\\nHuy Phan\\nRamaswamy Palaniappan\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2002.04857\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 12 Feb 2020 09:12:31 GMT)\\u00a7r"}']}
{title:'Chandna et al. (§72020§r)', author: 'Pritish Chandna; Merlijn Blaauw; Jordi Bonada; Emilia Gomez', display:{Lore:['[{"text": "arXiv:2002.04933", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lContent Based Singing Voice Extraction From a Musical Mixture\\u00a7r\\n\\n\\u00a78\\u00a7oPritish Chandna\\nMerlijn Blaauw\\nJordi Bonada\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2002.04933\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7n2020 IEEE International Conference on Acoustics, Speech and Signal\\n  Processing (ICASSP), Barcelona, Spain\\u00a7r\\n\\nVersion:\\u00a77v2 (Mon, 17 Feb 2020 12:21:58 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oTo be published in ICASSP 2020\\u00a7r"}']}
{title:'Hussain et al. (§72020§r)', author: 'Shehzeen Hussain; Mojan Javaheripi; Paarth Neekhara; Ryan Kastner; Farinaz Koushanfar', display:{Lore:['[{"text": "arXiv:2002.04971", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lFastWave: Accelerating Autoregressive Convolutional Neural Networks on FPGA\\u00a7r\\n\\n\\u00a78\\u00a7oShehzeen Hussain\\nMojan Javaheripi\\nPaarth Neekhara\\nRyan Kastner\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2002.04971\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/ICCAD45719.2019.8942122\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7n@inproceedings {1143,booktitle = {IEEE/ACM 2019 International\\n  Conference On Computer Aided Design (ICCAD)},year = {2019},month =\\n  {November}}\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 9 Feb 2020 06:15:09 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oPublished as a conference paper at ICCAD 2019\\u00a7r"}']}
{title:'Kreuk et al. (§72020§r)', author: 'Felix Kreuk; Yaniv Sheena; Joseph Keshet; Yossi Adi', display:{Lore:['[{"text": "arXiv:2002.04992", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lPhoneme Boundary Detection using Learnable Segmental Features\\u00a7r\\n\\n\\u00a78\\u00a7oFelix Kreuk\\nYaniv Sheena\\nJoseph Keshet\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2002.04992\\u00a7r\\n\\nVersion:\\u00a77v2 (Sun, 16 Feb 2020 07:26:42 GMT)\\u00a7r"}']}
{title:'Zhao et al. (§72020§r)', author: 'Shuyang Zhao; Toni Heittola; Tuomas Virtanen', display:{Lore:['[{"text": "arXiv:2002.05033", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lActive Learning for Sound Event Detection\\u00a7r\\n\\n\\u00a78\\u00a7oShuyang Zhao\\nToni Heittola\\nTuomas Virtanen\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2002.05033\\u00a7r\\n\\nVersion:\\u00a77v2 (Wed, 9 Sep 2020 14:49:55 GMT)\\u00a7r"}']}
{title:'Pappagari et al. (§72020§r)', author: 'Raghavendra Pappagari; Tianzi Wang; Jesus Villalba; Nanxin Chen; Najim Dehak', display:{Lore:['[{"text": "arXiv:2002.05039", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lx-vectors meet emotions: A study on dependencies between emotion and speaker recognition\\u00a7r\\n\\n\\u00a78\\u00a7oRaghavendra Pappagari\\nTianzi Wang\\nJesus Villalba\\nNanxin Chen\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2002.05039\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 12 Feb 2020 15:13:07 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o45th International Conference on Acoustics, Speech, and Signal Processing (ICASSP), 2020\\u00a7r"}']}
{title:'Keung et al. (§72020§r)', author: 'Phillip Keung; Wei Niu; Yichao Lu; Julian Salazar; Vikas Bhardwaj', display:{Lore:['[{"text": "arXiv:2002.05150", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAttentional Speech Recognition Models Misbehave on Out-of-domain Utterances\\u00a7r\\n\\n\\u00a78\\u00a7oPhillip Keung\\nWei Niu\\nYichao Lu\\nJulian Salazar\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2002.05150\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 12 Feb 2020 18:53:56 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oArtifacts like ourfiltered Audio BNC dataset can be found athttps://github.com/aws-samples/seq2seq-asr-misbehaves\\u00a7r"}']}
{title:'Ding et al. (§72020§r)', author: 'Yifan Ding; Yong Xu; Shi-Xiong Zhang; Yahuan Cong; Liqiang Wang', display:{Lore:['[{"text": "arXiv:2002.05314", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.MM\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSelf-supervised learning for audio-visual speaker diarization\\u00a7r\\n\\n\\u00a78\\u00a7oYifan Ding\\nYong Xu\\nShi-Xiong Zhang\\nYahuan Cong\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2002.05314\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 13 Feb 2020 02:36:32 GMT)\\u00a7r"}']}
{title:'Vasquez-Correa et al. (§72020§r)', author: 'J. C. Vasquez-Correa; T. Bocklet; J. R. Orozco-Arroyave; E. Nöth', display:{Lore:['[{"text": "arXiv:2002.05412", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lComparison of user models based on GMM-UBM and i-vectors for speech, handwriting, and gait assessment of Parkinson\'s disease patients\\u00a7r\\n\\n\\u00a78\\u00a7oJ. C. Vasquez-Correa\\nT. Bocklet\\nJ. R. Orozco-Arroyave\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2002.05412\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 13 Feb 2020 10:01:08 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oProceedings of ICASSP (2019)\\u00a7r"}']}
{title:'Zhen et al. (§72020§r)', author: 'Kai Zhen; Mi Suk Lee; Jongmo Sung; Seungkwon Beack; Minje Kim', display:{Lore:['[{"text": "arXiv:2002.05604", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.MM\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7eeess.SP\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lEfficient And Scalable Neural Residual Waveform Coding With Collaborative Quantization\\u00a7r\\n\\n\\u00a78\\u00a7oKai Zhen\\nMi Suk Lee\\nJongmo Sung\\nSeungkwon Beack\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2002.05604\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 13 Feb 2020 16:28:09 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted in Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP) , Barcelona, Spain, May 4-8, 2020\\u00a7r"}']}
{title:'Masuyama et al. (§72020§r)', author: 'Yoshiki Masuyama; Masahito Togami; Tatsuya Komatsu', display:{Lore:['[{"text": "arXiv:2002.05831", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lConsistency-aware multi-channel speech enhancement using deep neural networks\\u00a7r\\n\\n\\u00a78\\u00a7oYoshiki Masuyama\\nMasahito Togami\\nTatsuya Komatsu\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2002.05831\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 14 Feb 2020 01:08:28 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oTo appear at the 45th International Conference on Acoustics, Speech, and Signal Processing (ICASSP 2020)\\u00a7r"}']}
{title:'Masuyama et al. (§72020§r)', author: 'Yoshiki Masuyama; Kohei Yatabe; Yuma Koizumi; Yasuhiro Oikawa; Noboru Harada', display:{Lore:['[{"text": "arXiv:2002.05832", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lPhase reconstruction based on recurrent phase unwrapping with deep neural networks\\u00a7r\\n\\n\\u00a78\\u00a7oYoshiki Masuyama\\nKohei Yatabe\\nYuma Koizumi\\nYasuhiro Oikawa\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2002.05832\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 14 Feb 2020 01:10:06 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oTo appear at the 45th International Conference on Acoustics, Speech, and Signal Processing (ICASSP 2020)\\u00a7r"}']}
{title:'Takeuchi et al. (§72020§r)', author: 'Daiki Takeuchi; Kohei Yatabe; Yuma Koizumi; Yasuhiro Oikawa; Noboru Harada', display:{Lore:['[{"text": "arXiv:2002.05843", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lReal-time speech enhancement using equilibriated RNN\\u00a7r\\n\\n\\u00a78\\u00a7oDaiki Takeuchi\\nKohei Yatabe\\nYuma Koizumi\\nYasuhiro Oikawa\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2002.05843\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 14 Feb 2020 02:00:13 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oTo appear in Proc. IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP 2020)\\u00a7r"}']}
{title:'Nguyen et al. (§72020§r)', author: 'Thi Ngoc Tho Nguyen; Douglas L. Jones; Woon-Seng Gan', display:{Lore:['[{"text": "arXiv:2002.05865", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7eeess.SP\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Sequence Matching Network for Polyphonic Sound Event Localization and Detection\\u00a7r\\n\\n\\u00a78\\u00a7oThi Ngoc Tho Nguyen\\nDouglas L. Jones\\nWoon-Seng Gan\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2002.05865\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/ICASSP40776.2020.9053045\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 14 Feb 2020 04:08:01 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oto be published in 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\\u00a7r"}']}
{title:'Koizumi et al. (§72020§r)', author: 'Yuma Koizumi; Kohei Yatabe; Marc Delcroix; Yoshiki Masuyama; Daiki Takeuchi', display:{Lore:['[{"text": "arXiv:2002.05873", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSpeech Enhancement using Self-Adaptation and Multi-Head Self-Attention\\u00a7r\\n\\n\\u00a78\\u00a7oYuma Koizumi\\nKohei Yatabe\\nMarc Delcroix\\nYoshiki Masuyama\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2002.05873\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 14 Feb 2020 05:05:36 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, to appear in IEEE ICASSP 2020\\u00a7r"}']}
{title:'Kawanaka et al. (§72020§r)', author: 'Masaki Kawanaka; Yuma Koizumi; Ryoichi Miyazaki; Kohei Yatabe', display:{Lore:['[{"text": "arXiv:2002.05879", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lStable Training of DNN for Speech Enhancement based on Perceptually-Motivated Black-Box Cost Function\\u00a7r\\n\\n\\u00a78\\u00a7oMasaki Kawanaka\\nYuma Koizumi\\nRyoichi Miyazaki\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2002.05879\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 14 Feb 2020 05:44:17 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oaccepted to the 45th International Conference on Acoustics, Speech, and Signal Processing (ICASSP 2020)\\u00a7r"}']}
{title:'Yasuda et al. (§72020§r)', author: 'Masahiro Yasuda; Yuma Koizumi; Shoichiro Saito; Hisashi Uematsu; Keisuke Imoto', display:{Lore:['[{"text": "arXiv:2002.05994", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSound Event Localization based on Sound Intensity Vector Refined By DNN-Based Denoising and Source Separation\\u00a7r\\n\\n\\u00a78\\u00a7oMasahiro Yasuda\\nYuma Koizumi\\nShoichiro Saito\\nHisashi Uematsu\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2002.05994\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 14 Feb 2020 12:20:44 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 3 figures, to appear in IEEE ICASSP 2020\\u00a7r"}']}
{title:'Gu et al. (§72020§r)', author: 'Bin Gu; Wu Guo; Lirong Dai; Jun Du', display:{Lore:['[{"text": "arXiv:2002.06049", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7eeess.SP\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAn Adaptive X-vector Model for Text-independent Speaker Verification\\u00a7r\\n\\n\\u00a78\\u00a7oBin Gu\\nWu Guo\\nLirong Dai\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2002.06049\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 14 Feb 2020 14:28:23 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o6 pages, 3 figures\\u00a7r"}']}
{title:'Sarı et al. (§72020§r)', author: 'Leda Sarı; Niko Moritz; Takaaki Hori; Jonathan Le Roux', display:{Lore:['[{"text": "arXiv:2002.06165", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lUnsupervised Speaker Adaptation using Attention-based Speaker Memory for End-to-End ASR\\u00a7r\\n\\n\\u00a78\\u00a7oLeda Sar\\u0131\\nNiko Moritz\\nTakaaki Hori\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2002.06165\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 14 Feb 2020 18:31:31 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oTo appear in Proc. ICASSP 2020\\u00a7r"}']}
{title:'Huang et al. (§72020§r)', author: 'Zili Huang; Shinji Watanabe; Yusuke Fujita; Paola Garcia; Yiwen Shao; Daniel Povey; Sanjeev Khudanpur', display:{Lore:['[{"text": "arXiv:2002.06220", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSpeaker Diarization with Region Proposal Network\\u00a7r\\n\\n\\u00a78\\u00a7oZili Huang\\nShinji Watanabe\\nYusuke Fujita\\n+ 3 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2002.06220\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 14 Feb 2020 19:17:25 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted to ICASSP 2020\\u00a7r"}']}
{title:'Kim et al. (§72020§r)', author: 'Sunwoo Kim; Haici Yang; Minje Kim', display:{Lore:['[{"text": "arXiv:2002.06239", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lBoosted Locality Sensitive Hashing: Discriminative Binary Codes for Source Separation\\u00a7r\\n\\n\\u00a78\\u00a7oSunwoo Kim\\nHaici Yang\\nMinje Kim\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2002.06239\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nIEEE International Conference on Acoustics, Speech, and Signal\\n  Processing (ICASSP), 2020\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 14 Feb 2020 20:10:00 GMT)\\u00a7r"}']}
{title:'Kao et al. (§72020§r)', author: 'Chieh-Chi Kao; Ming Sun; Weiran Wang; Chao Wang', display:{Lore:['[{"text": "arXiv:2002.06279", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Comparison of Pooling Methods on LSTM Models for Rare Acoustic Event Classification\\u00a7r\\n\\n\\u00a78\\u00a7oChieh-Chi Kao\\nMing Sun\\nWeiran Wang\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2002.06279\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 14 Feb 2020 22:56:41 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted to ICASSP 2020\\u00a7r"}']}
{title:'Kim et al. (§72020§r)', author: 'Chanwoo Kim; Kwangyoun Kim; Sathish Reddy Indurthi', display:{Lore:['[{"text": "arXiv:2002.06312", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSmall energy masking for improved neural network training for end-to-end speech recognition\\u00a7r\\n\\n\\u00a78\\u00a7oChanwoo Kim\\nKwangyoun Kim\\nSathish Reddy Indurthi\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2002.06312\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 15 Feb 2020 03:36:46 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted at ICASSP 2020\\u00a7r"}']}
{title:'Parekh et al. (§72020§r)', author: 'Jayneel Parekh; Preeti Rao; Yi-Hsuan Yang', display:{Lore:['[{"text": "arXiv:2002.06595", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSpeech-to-Singing Conversion in an Encoder-Decoder Framework\\u00a7r\\n\\n\\u00a78\\u00a7oJayneel Parekh\\nPreeti Rao\\nYi-Hsuan Yang\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2002.06595\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 16 Feb 2020 15:33:41 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted at IEEEICASSP 2020\\u00a7r"}']}
{title:'Han et al. (§72020§r)', author: 'Cong Han; Yi Luo; Nima Mesgarani', display:{Lore:['[{"text": "arXiv:2002.06637", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lReal-time binaural speech separation with preserved spatial cues\\u00a7r\\n\\n\\u00a78\\u00a7oCong Han\\nYi Luo\\nNima Mesgarani\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2002.06637\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 16 Feb 2020 18:18:19 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oTo appear in ICASSP 2020\\u00a7r"}']}
{title:'Kek et al. (§72020§r)', author: 'Xing Yong Kek; Cheng Siong Chin; Ye Li', display:{Lore:['[{"text": "arXiv:2002.07065", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAcoustic Scene Classification Using Bilinear Pooling on Time-liked and Frequency-liked Convolution Neural Network\\u00a7r\\n\\n\\u00a78\\u00a7oXing Yong Kek\\nCheng Siong Chin\\nYe Li\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2002.07065\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 14 Feb 2020 04:06:32 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oinclusion in conference proceedings 2019 IEEE Symposium Series on Computational Intelligence (IEEE SSCI 2019), Xiamen\\u00a7r"}']}
{title:'Poncelet et al. (§72020§r)', author: 'Jakob Poncelet; Hugo Van hamme', display:{Lore:['[{"text": "arXiv:2002.07450", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMultitask Learning with Capsule Networks for Speech-to-Intent Applications\\u00a7r\\n\\n\\u00a78\\u00a7oJakob Poncelet\\nHugo Van hamme\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2002.07450\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 18 Feb 2020 09:43:54 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oTo be published in ICASSP 2020\\u00a7r"}']}
{title:'Jain et al. (§72020§r)', author: 'Manas Jain; Shruthi Narayan; Pratibha Balaji; Bharath K P; Abhijit Bhowmick; Karthik R; Rajesh Kumar Muthu', display:{Lore:['[{"text": "arXiv:2002.07590", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.IR\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSpeech Emotion Recognition using Support Vector Machine\\u00a7r\\n\\n\\u00a78\\u00a7oManas Jain\\nShruthi Narayan\\nPratibha Balaji\\n+ 3 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2002.07590\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 3 Feb 2020 09:56:56 GMT)\\u00a7r"}']}
{title:'von Platen et al. (§72020§r)', author: 'Patrick von Platen; Fei Tao; Gokhan Tur', display:{Lore:['[{"text": "arXiv:2002.07629", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMulti-Task Siamese Neural Network for Improving Replay Attack Detection\\u00a7r\\n\\n\\u00a78\\u00a7oPatrick von Platen\\nFei Tao\\nGokhan Tur\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2002.07629\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 16 Feb 2020 00:21:16 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmit to INTERSPEECH2020\\u00a7r"}']}
{title:'Frazao et al. (§72020§r)', author: 'Fabio Frazao; Bruno Padovese; Oliver S. Kirsebom', display:{Lore:['[{"text": "arXiv:2002.08249", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lWorkshop Report: Detection and Classification in Marine Bioacoustics with Deep Learning\\u00a7r\\n\\n\\u00a78\\u00a7oFabio Frazao\\nBruno Padovese\\nOliver S. Kirsebom\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2002.08249\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 18 Feb 2020 15:33:06 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o13 pages, 1 figure, 1 table\\u00a7r"}']}
{title:'Kadioglu et al. (§72020§r)', author: 'Berkan Kadioglu; Michael Horgan; Xiaoyu Liu; Jordi Pons; Dan Darcy; Vivek Kumar', display:{Lore:['[{"text": "arXiv:2002.08688", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CV\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAn empirical study of Conv-TasNet\\u00a7r\\n\\n\\u00a78\\u00a7oBerkan Kadioglu\\nMichael Horgan\\nXiaoyu Liu\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2002.08688\\u00a7r\\n\\nVersion:\\u00a77v2 (Mon, 24 Feb 2020 15:00:22 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oIn proceedings of ICASSP2020\\u00a7r"}']}
{title:'Nagrani et al. (§72020§r)', author: 'Arsha Nagrani; Joon Son Chung; Samuel Albanie; Andrew Zisserman', display:{Lore:['[{"text": "arXiv:2002.08742", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CV\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDisentangled Speech Embeddings using Cross-modal Self-supervision\\u00a7r\\n\\n\\u00a78\\u00a7oArsha Nagrani\\nJoon Son Chung\\nSamuel Albanie\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2002.08742\\u00a7r\\n\\nVersion:\\u00a77v2 (Mon, 4 May 2020 15:01:49 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oICASSP 2020. Thefirst three authors contributed equally to this work\\u00a7r"}']}
{title:'Baby (§72020§r)', author: 'Deepak Baby', display:{Lore:['[{"text": "arXiv:2002.08796", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7eeess.SP\\u00a7r\\u00a7r\\n\\u00a76\\u00a7liSEGAN: Improved Speech Enhancement Generative Adversarial Networks\\u00a7r\\n\\n\\u00a78\\u00a7oDeepak Baby\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2002.08796\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 20 Feb 2020 15:19:17 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oA short report on improving SEGAN performance\\u00a7r"}']}
{title:'Chan et al. (§72020§r)', author: 'William Chan; Chitwan Saharia; Geoffrey Hinton; Mohammad Norouzi; Navdeep Jaitly', display:{Lore:['[{"text": "arXiv:2002.08926", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lImputer: Sequence Modelling via Imputation and Dynamic Programming\\u00a7r\\n\\n\\u00a78\\u00a7oWilliam Chan\\nChitwan Saharia\\nGeoffrey Hinton\\nMohammad Norouzi\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2002.08926\\u00a7r\\n\\nVersion:\\u00a77v2 (Wed, 22 Apr 2020 17:32:18 GMT)\\u00a7r"}']}
{title:'Zeghidour et al. (§72020§r)', author: 'Neil Zeghidour; David Grangier', display:{Lore:['[{"text": "arXiv:2002.08933", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lWavesplit: End-to-End Speech Separation by Speaker Clustering\\u00a7r\\n\\n\\u00a78\\u00a7oNeil Zeghidour\\nDavid Grangier\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2002.08933\\u00a7r\\n\\nVersion:\\u00a77v2 (Thu, 2 Jul 2020 13:57:33 GMT)\\u00a7r"}']}
{title:'Fan et al. (§72020§r)', author: 'Jianyu Fan; Eric Nichols; Daniel Tompkins; Ana Elisa Mendez Mendez; Benjamin Elizalde; Philippe Pasquier', display:{Lore:['[{"text": "arXiv:2002.09026", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.IR\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMulti-label Sound Event Retrieval Using a Deep Learning-based Siamese Structure with a Pairwise Presence Matrix\\u00a7r\\n\\n\\u00a78\\u00a7oJianyu Fan\\nEric Nichols\\nDaniel Tompkins\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2002.09026\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 20 Feb 2020 21:33:07 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oPaper accepted for 45th International Conference on Acoustics, Speech, and Signal Processing (ICASSP 2020)\\u00a7r"}']}
{title:'Casebeer et al. (§72020§r)', author: 'Jonah Casebeer; Umut Isik; Shrikant Venkataramani; Arvindh Krishnaswamy', display:{Lore:['[{"text": "arXiv:2002.09286", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.NE\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lEfficient Trainable Front-Ends for Neural Speech Enhancement\\u00a7r\\n\\n\\u00a78\\u00a7oJonah Casebeer\\nUmut Isik\\nShrikant Venkataramani\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2002.09286\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 20 Feb 2020 01:51:15 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 5 figures, ICASSP 2020\\u00a7r"}']}
{title:'Huang et al. (§72020§r)', author: 'Yuxin Huang; Xiangdong Wang; Liwei Lin; Hong Liu; Yueliang Qian', display:{Lore:['[{"text": "arXiv:2002.09661", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMulti-Branch Learning for Weakly-Labeled Sound Event Detection\\u00a7r\\n\\n\\u00a78\\u00a7oYuxin Huang\\nXiangdong Wang\\nLiwei Lin\\nHong Liu\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2002.09661\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 22 Feb 2020 08:40:04 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted by ICASSP 2020\\u00a7r"}']}
{title:'Xu et al. (§72020§r)', author: 'Weitao Xu; Xiang Zhang; Lina Yao; Wanli Xue; Bo Wei', display:{Lore:['[{"text": "arXiv:2002.09821", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Multi-view CNN-based Acoustic Classification System for Automatic Animal Species Identification\\u00a7r\\n\\n\\u00a78\\u00a7oWeitao Xu\\nXiang Zhang\\nLina Yao\\nWanli Xue\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2002.09821\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1016/j.adhoc.2020.102115\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nAd Hoc Networks 2020\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 23 Feb 2020 03:51:08 GMT)\\u00a7r"}']}
{title:'Shechtman et al. (§72020§r)', author: 'Slava Shechtman; Carmel Rabinovitz; Alex Sorin; Zvi Kons; Ron Hoory', display:{Lore:['[{"text": "arXiv:2002.10708", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lControllable Sequence-To-Sequence Neural TTS with LPCNET Backend for Real-time Speech Synthesis on CPU\\u00a7r\\n\\n\\u00a78\\u00a7oSlava Shechtman\\nCarmel Rabinovitz\\nAlex Sorin\\nZvi Kons\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2002.10708\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 25 Feb 2020 07:43:11 GMT)\\u00a7r"}']}
{title:'Monesi et al. (§72020§r)', author: 'Mohammad Jalilpour Monesi; Bernd Accou; Jair Montoya-Martinez; Tom Francart; Hugo Van Hamme', display:{Lore:['[{"text": "arXiv:2002.10988", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAn LSTM Based Architecture to Relate Speech Stimulus to EEG\\u00a7r\\n\\n\\u00a78\\u00a7oMohammad Jalilpour Monesi\\nBernd Accou\\nJair Montoya-Martinez\\nTom Francart\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2002.10988\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 25 Feb 2020 16:00:47 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o3 figures, 6 pages\\u00a7r"}']}
{title:'Maldonado et al. (§72020§r)', author: 'Alejandro Maldonado; Caleb Rascon; Ivette Velez', display:{Lore:['[{"text": "arXiv:2002.11241", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lLightweight Online Separation of the Sound Source of Interest through BLSTM-Based Binary Masking\\u00a7r\\n\\n\\u00a78\\u00a7oAlejandro Maldonado\\nCaleb Rascon\\nIvette Velez\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2002.11241\\u00a7r\\n\\nVersion:\\u00a77v2 (Wed, 19 Aug 2020 18:56:44 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted for publication in Computaci\\u00f3n y Sistemas\\u00a7r"}']}
{title:'Usman et al. (§72020§r)', author: 'Mohammed Usman; Zeeshan Ahmad; Mohd Wajid', display:{Lore:['[{"text": "arXiv:2002.11250", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7eeess.SP\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDataset of raw and pre-processed speech signals, Mel Frequency Cepstral Coefficients of Speech and Heart Rate measurements\\u00a7r\\n\\n\\u00a78\\u00a7oMohammed Usman\\nZeeshan Ahmad\\nMohd Wajid\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2002.11250\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 25 Feb 2020 16:32:31 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oconference\\u00a7r"}']}
{title:'McDermott et al. (§72020§r)', author: 'Erik McDermott; Hasim Sak; Ehsan Variani', display:{Lore:['[{"text": "arXiv:2002.11268", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Density Ratio Approach to Language Model Fusion in End-To-End Automatic Speech Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oErik McDermott\\nHasim Sak\\nEhsan Variani\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2002.11268\\u00a7r\\n\\nVersion:\\u00a77v3 (Fri, 28 Feb 2020 01:40:54 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o8 pages, 4 figures, presented at 2019 IEEEAutomatic Speech Recognition and Understanding Workshop (ASRU 2019)\\u00a7r"}']}
{title:'Atmaja et al. (§72020§r)', author: 'Bagus Tris Atmaja; Masato Akagi', display:{Lore:['[{"text": "arXiv:2002.11312", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMultitask Learning and Multistage Fusion for Dimensional Audiovisual Emotion Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oBagus Tris Atmaja\\nMasato Akagi\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2002.11312\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/ICASSP40776.2020.9052916\\u00a7r\\n\\nVersion:\\u00a77v2 (Mon, 9 Mar 2020 08:13:30 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o3 figures, 3 tables, accepted at ICASSP 2020\\u00a7r"}']}
{title:'Landini et al. (§72020§r)', author: 'Federico Landini; Shuai Wang; Mireia Diez; Lukáš Burget; Pavel Matějka; Kateřina Žmolíková; Ladislav Mošner; Anna Silnova; Oldřich Plchot; Ondřej Novotný; Hossein Zeinali; Johan Rohdin', display:{Lore:['[{"text": "arXiv:2002.11356", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lBUT System for the Second DIHARD Speech Diarization Challenge\\u00a7r\\n\\n\\u00a78\\u00a7oFederico Landini\\nShuai Wang\\nMireia Diez\\n+ 8 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2002.11356\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 26 Feb 2020 08:41:15 GMT)\\u00a7r"}']}
{title:'McCarthy et al. (§72020§r)', author: 'Arya D. McCarthy; Liezl Puzon; Juan Pino', display:{Lore:['[{"text": "arXiv:2002.12231", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSkinAugment: Auto-Encoding Speaker Conversions for Automatic Speech Translation\\u00a7r\\n\\n\\u00a78\\u00a7oArya D. McCarthy\\nLiezl Puzon\\nJuan Pino\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2002.12231\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 27 Feb 2020 16:22:42 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted to ICASSP 2020\\u00a7r"}']}
{title:'Krishna et al. (§72020§r)', author: 'Gautam Krishna; Co Tran; Yan Han; Mason Carnahan', display:{Lore:['[{"text": "arXiv:2002.12756", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7bq-bio.QM\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSpeech Synthesis using EEG\\u00a7r\\n\\n\\u00a78\\u00a7oGautam Krishna\\nCo Tran\\nYan Han\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2002.12756\\u00a7r\\n\\nVersion:\\u00a77v2 (Sun, 3 May 2020 20:30:33 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted for publication at IEEE ICASSP 2020\\u00a7r"}']}
{title:'Liu et al. (§72020§r)', author: 'Zhenyu Liu; Dongyu Wang; Lan Zhang; Bin Hu', display:{Lore:['[{"text": "arXiv:2002.12759", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7bq-bio.QM\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Novel Decision Tree for Depression Recognition in Speech\\u00a7r\\n\\n\\u00a78\\u00a7oZhenyu Liu\\nDongyu Wang\\nLan Zhang\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2002.12759\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 22 Feb 2020 10:46:38 GMT)\\u00a7r"}']}
{title:'Lin et al. (§72020§r)', author: 'Qingjian Lin; Weicheng Cai; Lin Yang; Junjie Wang; Jun Zhang; Ming Li', display:{Lore:['[{"text": "arXiv:2002.12761", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDIHARD II is Still Hard: Experimental Results and Discussions from the DKU-LENOVO Team\\u00a7r\\n\\n\\u00a78\\u00a7oQingjian Lin\\nWeicheng Cai\\nLin Yang\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2002.12761\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 5 May 2020 02:46:24 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to Odyssesy 2020\\u00a7r"}']}
{title:'Shor et al. (§72020§r)', author: 'Joel Shor; Aren Jansen; Ronnie Maor; Oran Lang; Omry Tuval; Felix de Chaumont Quitry; Marco Tagliasacchi; Ira Shavitt; Dotan Emanuel; Yinnon Haviv', display:{Lore:['[{"text": "arXiv:2002.12764", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lTowards Learning a Universal Non-Semantic Representation of Speech\\u00a7r\\n\\n\\u00a78\\u00a7oJoel Shor\\nAren Jansen\\nRonnie Maor\\n+ 6 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2002.12764\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.21437/Interspeech.2020-1242\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nProceedings of INTERSPEECH 2020\\u00a7r\\n\\nVersion:\\u00a77v6 (Thu, 6 Aug 2020 04:53:37 GMT)\\u00a7r"}']}
{title:'Rasipuram et al. (§72020§r)', author: 'Sowmya Rasipuram; Junaid Hamid Bhat; Anutosh Maitra', display:{Lore:['[{"text": "arXiv:2002.12766", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMulti-Modal Continuous Valence And Arousal Prediction in the Wild Using Deep 3D Features and Sequence Modeling\\u00a7r\\n\\n\\u00a78\\u00a7oSowmya Rasipuram\\nJunaid Hamid Bhat\\nAnutosh Maitra\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2002.12766\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 26 Feb 2020 06:58:51 GMT)\\u00a7r"}']}
{title:'Chakraborty et al. (§72020§r)', author: 'Rupayan Chakraborty; Meghna Pandharipande; Chitralekha Bhat; Sunil Kumar Kopparapu', display:{Lore:['[{"text": "arXiv:2002.12788", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.AI\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lIdentification of Dementia Using Audio Biomarkers\\u00a7r\\n\\n\\u00a78\\u00a7oRupayan Chakraborty\\nMeghna Pandharipande\\nChitralekha Bhat\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2002.12788\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 27 Feb 2020 13:54:00 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 3 figures\\u00a7r"}']}
{title:'Nikzad et al. (§72020§r)', author: 'Mohammad Nikzad; Aaron Nicolson; Yongsheng Gao; Jun Zhou; Kuldip K. Paliwal; Fanhua Shang', display:{Lore:['[{"text": "arXiv:2002.12794", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDeep Residual-Dense Lattice Network for Speech Enhancement\\u00a7r\\n\\n\\u00a78\\u00a7oMohammad Nikzad\\nAaron Nicolson\\nYongsheng Gao\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2002.12794\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 27 Feb 2020 04:36:30 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o8 pages, Accepted by AAAI-2020\\u00a7r"}']}
{title:'Firmansyah et al. (§72020§r)', author: 'Muhammad Hafidh Firmansyah; Anand Paul; Deblina Bhattacharya; Gul Malik Urfa', display:{Lore:['[{"text": "arXiv:2002.12830", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA.I. based Embedded Speech to Text Using Deepspeech\\u00a7r\\n\\n\\u00a78\\u00a7oMuhammad Hafidh Firmansyah\\nAnand Paul\\nDeblina Bhattacharya\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2002.12830\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 25 Feb 2020 08:27:41 GMT)\\u00a7r"}']}
{title:'Krishna et al. (§72020§r)', author: 'Gautam Krishna; Co Tran; Mason Carnahan; Yan Han; Ahmed H Tewfik', display:{Lore:['[{"text": "arXiv:2003.00007", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lGenerating EEG features from Acoustic features\\u00a7r\\n\\n\\u00a78\\u00a7oGautam Krishna\\nCo Tran\\nMason Carnahan\\nYan Han\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2003.00007\\u00a7r\\n\\nVersion:\\u00a77v2 (Thu, 19 Mar 2020 01:33:53 GMT)\\u00a7r"}']}
{title:'Rasipuram et al. (§72020§r)', author: 'Sowmya Rasipuram; Junaid Hamid Bhat; Anutosh Maitra', display:{Lore:['[{"text": "arXiv:2003.00170", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lExpression Recognition in the Wild Using Sequence Modeling\\u00a7r\\n\\n\\u00a78\\u00a7oSowmya Rasipuram\\nJunaid Hamid Bhat\\nAnutosh Maitra\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2003.00170\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 26 Feb 2020 07:03:06 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oarXiv admin note: substantial text overlap with arXiv:2002.12766\\u00a7r"}']}
{title:'Botelho et al. (§72020§r)', author: 'Catarina Botelho; Francisco Teixeira; Thomas Rolland; Alberto Abad; Isabel Trancoso', display:{Lore:['[{"text": "arXiv:2003.00864", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lPathological speech detection using x-vector embeddings\\u00a7r\\n\\n\\u00a78\\u00a7oCatarina Botelho\\nFrancisco Teixeira\\nThomas Rolland\\nAlberto Abad\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2003.00864\\u00a7r\\n\\nVersion:\\u00a77v3 (Sun, 31 May 2020 14:31:31 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oRejected for publication by peer review\\u00a7r"}']}
{title:'Zaccà et al. (§72020§r)', author: 'Vincenzo Zaccà; Pablo Martinez-Nuevo; Martin Møller; Jorge Martínez; Richard Heusdens', display:{Lore:['[{"text": "arXiv:2003.01117", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lInferring the location of reflecting surfaces exploiting loudspeaker directivity\\u00a7r\\n\\n\\u00a78\\u00a7oVincenzo Zacc\\u00e0\\nPablo Martinez-Nuevo\\nMartin M\\u00f8ller\\nJorge Mart\\u00ednez\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2003.01117\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 2 Mar 2020 17:42:54 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to EUSIPCO 2020\\u00a7r"}']}
{title:'Muñoz-Montoro et al. (§72020§r)', author: 'Antonio J. Muñoz-Montoro; Julio J. Carabias-Orti; Archontis Politis; Konstantinos Drossos', display:{Lore:['[{"text": "arXiv:2003.01162", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMultichannel Singing Voice Separation by Deep Neural Network Informed DOA Constrained CNMF\\u00a7r\\n\\n\\u00a78\\u00a7oAntonio J. Mu\\u00f1oz-Montoro\\nJulio J. Carabias-Orti\\nArchontis Politis\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2003.01162\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 2 Mar 2020 19:46:53 GMT)\\u00a7r"}']}
{title:'Bous et al. (§72020§r)', author: 'Frederik Bous; Luc Ardaillon; Axel Roebel', display:{Lore:['[{"text": "arXiv:2003.01220", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSemi-supervised learning of glottal pulse positions in a neural analysis-synthesis framework\\u00a7r\\n\\n\\u00a78\\u00a7oFrederik Bous\\nLuc Ardaillon\\nAxel Roebel\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2003.01220\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 2 Mar 2020 22:18:10 GMT)\\u00a7r"}']}
{title:'Atmaja et al. (§72020§r)', author: 'Bagus Tris Atmaja; Masato Akagi', display:{Lore:['[{"text": "arXiv:2003.01277", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lThe Effect of Silence Feature in Dimensional Speech Emotion Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oBagus Tris Atmaja\\nMasato Akagi\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2003.01277\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.21437/SpeechProsody.2020-6\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7n10th International Conference on Speech Prosody 2020, 26-30\\u00a7r\\n\\nVersion:\\u00a77v3 (Wed, 22 Apr 2020 01:05:27 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o6 pages, 4 figures, 2 tables, accepted at speech prosody 2020\\u00a7r"}']}
{title:'Uddin et al. (§72020§r)', author: 'Zahoor Uddin; Muhammad Altaf; Muhammad Bilal; Lewis Nkenyereye; Ali Kashif Bashir', display:{Lore:['[{"text": "arXiv:2003.01519", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7eeess.SP\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAmateur Drones Detection: A machine learning approach utilizing the acoustic signals in the presence of strong interference\\u00a7r\\n\\n\\u00a78\\u00a7oZahoor Uddin\\nMuhammad Altaf\\nMuhammad Bilal\\nLewis Nkenyereye\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2003.01519\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1016/j.comcom.2020.02.065\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 28 Feb 2020 17:28:17 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o25 pages, 10 figures, accepted for the publication in future issue of \\"Computer Communications (2020)\\"\\u00a7r"}']}
{title:'Nachmani et al. (§72020§r)', author: 'Eliya Nachmani; Yossi Adi; Lior Wolf', display:{Lore:['[{"text": "arXiv:2003.01531", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lVoice Separation with an Unknown Number of Multiple Speakers\\u00a7r\\n\\n\\u00a78\\u00a7oEliya Nachmani\\nYossi Adi\\nLior Wolf\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2003.01531\\u00a7r\\n\\nVersion:\\u00a77v4 (Tue, 1 Sep 2020 14:12:16 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted to ICML2020. For associated audio samples, see http://enk100.github.io/speaker_separation\\u00a7r"}']}
{title:'Mimilakis et al. (§72020§r)', author: 'Stylianos I. Mimilakis; Konstantinos Drossos; Gerald Schuller', display:{Lore:['[{"text": "arXiv:2003.01567", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lUnsupervised Interpretable Representation Learning for Singing Voice Separation\\u00a7r\\n\\n\\u00a78\\u00a7oStylianos I. Mimilakis\\nKonstantinos Drossos\\nGerald Schuller\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2003.01567\\u00a7r\\n\\nVersion:\\u00a77v4 (Wed, 1 Jul 2020 14:17:38 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oCamera-ready version for EUSIPCO 2020\\u00a7r"}']}
{title:'Guirguis et al. (§72020§r)', author: 'Karim Guirguis; Christoph Schorn; Andre Guntoro; Sherif Abdulatif; Bin Yang', display:{Lore:['[{"text": "arXiv:2003.01609", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSELD-TCN: Sound Event Localization     Detection via Temporal Convolutional Networks\\u00a7r\\n\\n\\u00a78\\u00a7oKarim Guirguis\\nChristoph Schorn\\nAndre Guntoro\\nSherif Abdulatif\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2003.01609\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.23919/Eusipco47968.2020.9287716\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 3 Mar 2020 15:48:57 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 3 tables, 2 figures. Submitted to EUSIPCO 2020\\u00a7r"}']}
{title:'Plantinga et al. (§72020§r)', author: 'Peter Plantinga; Eric Fosler-Lussier', display:{Lore:['[{"text": "arXiv:2003.01765", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lTowards Real-time Mispronunciation Detection in Kids\' Speech\\u00a7r\\n\\n\\u00a78\\u00a7oPeter Plantinga\\nEric Fosler-Lussier\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2003.01765\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 3 Mar 2020 19:58:43 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o6 pages + 1 page for references, accepted at ASRU 2019\\u00a7r"}']}
{title:'Plantinga et al. (§72020§r)', author: 'Peter Plantinga; Deblin Bagchi; Eric Fosler-Lussier', display:{Lore:['[{"text": "arXiv:2003.01769", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lPhonetic Feedback for Speech Enhancement With and Without Parallel Speech Data\\u00a7r\\n\\n\\u00a78\\u00a7oPeter Plantinga\\nDeblin Bagchi\\nEric Fosler-Lussier\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2003.01769\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 3 Mar 2020 20:06:24 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o4 pages + 1 page for references, accepted to ICASSP 2020\\u00a7r"}']}
{title:'Wang et al. (§72020§r)', author: 'Zhong-Qiu Wang; DeLiang Wang', display:{Lore:['[{"text": "arXiv:2003.01861", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMulti-Microphone Complex Spectral Mapping for Speech Dereverberation\\u00a7r\\n\\n\\u00a78\\u00a7oZhong-Qiu Wang\\nDeLiang Wang\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2003.01861\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 4 Mar 2020 02:21:37 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oto appear in ICASSP 2020\\u00a7r"}']}
{title:'Winata et al. (§72020§r)', author: 'Genta Indra Winata; Samuel Cahyawijaya; Zihan Liu; Zhaojiang Lin; Andrea Madotto; Peng Xu; Pascale Fung', display:{Lore:['[{"text": "arXiv:2003.01901", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lLearning Fast Adaptation on Cross-Accented Speech Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oGenta Indra Winata\\nSamuel Cahyawijaya\\nZihan Liu\\n+ 3 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2003.01901\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 4 Mar 2020 05:37:25 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oThe first three authors contributed equally to this work\\u00a7r"}']}
{title:'Sun et al. (§72020§r)', author: 'Aolan Sun; Jianzong Wang; Ning Cheng; Huayi Peng; Zhen Zeng; Jing Xiao', display:{Lore:['[{"text": "arXiv:2003.01924", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lGraphTTS: graph-to-sequence modelling in neural text-to-speech\\u00a7r\\n\\n\\u00a78\\u00a7oAolan Sun\\nJianzong Wang\\nNing Cheng\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2003.01924\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 4 Mar 2020 07:44:55 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted to ICASSP 2020\\u00a7r"}']}
{title:'Zeng et al. (§72020§r)', author: 'Zhen Zeng; Jianzong Wang; Ning Cheng; Tian Xia; Jing Xiao', display:{Lore:['[{"text": "arXiv:2003.01950", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAlignTTS: Efficient Feed-Forward Text-to-Speech System without Explicit Alignment\\u00a7r\\n\\n\\u00a78\\u00a7oZhen Zeng\\nJianzong Wang\\nNing Cheng\\nTian Xia\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2003.01950\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 4 Mar 2020 08:44:32 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7owill be presented in ICASSP 2020\\u00a7r"}']}
{title:'Feng et al. (§72020§r)', author: 'Chen Feng; Jianzong Wang; Tongxu Li; Junqing Peng; Jing Xiao', display:{Lore:['[{"text": "arXiv:2003.01955", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Robust Speaker Clustering Method Based on Discrete Tied Variational Autoencoder\\u00a7r\\n\\n\\u00a78\\u00a7oChen Feng\\nJianzong Wang\\nTongxu Li\\nJunqing Peng\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2003.01955\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 4 Mar 2020 08:54:38 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7owill be presented in ICASSP 2020\\u00a7r"}']}
{title:'Xie et al. (§72020§r)', author: 'Yi Xie; Cong Shi; Zhuohang Li; Jian Liu; Yingying Chen; Bo Yuan', display:{Lore:['[{"text": "arXiv:2003.02301", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lReal-time, Universal, and Robust Adversarial Attacks Against Speaker Recognition Systems\\u00a7r\\n\\n\\u00a78\\u00a7oYi Xie\\nCong Shi\\nZhuohang Li\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2003.02301\\u00a7r\\n\\nVersion:\\u00a77v2 (Fri, 1 May 2020 02:33:22 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oPublished as a conference paper at ICASSP 2020\\u00a7r"}']}
{title:'Park et al. (§72020§r)', author: 'Tae Jin Park; Kyu J. Han; Manoj Kumar; Shrikanth Narayanan', display:{Lore:['[{"text": "arXiv:2003.02405", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAuto-Tuning Spectral Clustering for Speaker Diarization Using Normalized Maximum Eigengap\\u00a7r\\n\\n\\u00a78\\u00a7oTae Jin Park\\nKyu J. Han\\nManoj Kumar\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2003.02405\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/LSP.2019.2961071\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 5 Mar 2020 02:50:37 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oin IEEESignal Processing Letters, 2020\\u00a7r"}']}
{title:'Ikeshita et al. (§72020§r)', author: 'Rintaro Ikeshita; Tomohiro Nakatani; Shoko Araki', display:{Lore:['[{"text": "arXiv:2003.02458", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7eeess.SP\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lOverdetermined independent vector analysis\\u00a7r\\n\\n\\u00a78\\u00a7oRintaro Ikeshita\\nTomohiro Nakatani\\nShoko Araki\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2003.02458\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/ICASSP40776.2020.9053790\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 5 Mar 2020 07:01:05 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oTo appear at the 45th International Conference on Acoustics, Speech, and Signal Processing (ICASSP 2020)\\u00a7r"}']}
{title:'Haque et al. (§72020§r)', author: 'Kazi Nazmul Haque; Rajib Rana; John H. L. Hansen; Björn Schuller', display:{Lore:['[{"text": "arXiv:2003.02836", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lGuided Generative Adversarial Neural Network for Representation Learning and High Fidelity Audio Generation using Fewer Labelled Audio Data\\u00a7r\\n\\n\\u00a78\\u00a7oKazi Nazmul Haque\\nRajib Rana\\nJohn H. L. Hansen\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2003.02836\\u00a7r\\n\\nVersion:\\u00a77v2 (Mon, 1 Jun 2020 12:05:25 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o10 pages\\u00a7r"}']}
{title:'Zito et al. (§72020§r)', author: 'Claudio Zito; Fabio Tesser; Mauro Nicolao; Piero Cosi', display:{Lore:['[{"text": "arXiv:2003.02837", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lStatistical Context-Dependent Units Boundary Correction for Corpus-based Unit-Selection Text-to-Speech\\u00a7r\\n\\n\\u00a78\\u00a7oClaudio Zito\\nFabio Tesser\\nMauro Nicolao\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2003.02837\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nIn Proc. of 7th Conference of Associazione Italiana di Scienze\\n  della Voce, pp. 392:403, 2011\\u00a7r\\n\\nVersion:\\u00a77v2 (Wed, 29 Apr 2020 15:52:05 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oisbn:978-88-7870-619-4\\u00a7r"}']}
{title:'Fujita et al. (§72020§r)', author: 'Yusuke Fujita; Shinji Watanabe; Shota Horiguchi; Yawen Xue; Kenji Nagamatsu', display:{Lore:['[{"text": "arXiv:2003.02966", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lEnd-to-End Neural Diarization: Reformulating Speaker Diarization as Simple Multi-label Classification\\u00a7r\\n\\n\\u00a78\\u00a7oYusuke Fujita\\nShinji Watanabe\\nShota Horiguchi\\nYawen Xue\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2003.02966\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 24 Feb 2020 14:53:32 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmission to IEEE TASLP. This articledraws from our previous conference papers: arxiv:1909.06247 and arxiv:1909.05952\\u00a7r"}']}
{title:'Wu et al. (§72020§r)', author: 'Haibin Wu; Songxiang Liu; Helen Meng; Hung-yi Lee', display:{Lore:['[{"text": "arXiv:2003.03065", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDefense against adversarial attacks on spoofing countermeasures of ASV\\u00a7r\\n\\n\\u00a78\\u00a7oHaibin Wu\\nSongxiang Liu\\nHelen Meng\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2003.03065\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 6 Mar 2020 08:08:54 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted by ICASSP 2020\\u00a7r"}']}
{title:'Biswas et al. (§72020§r)', author: 'Astik Biswas; Emre Yılmaz; Febe de Wet; Ewald van der Westhuizen; Thomas Niesler', display:{Lore:['[{"text": "arXiv:2003.03135", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSemi-supervised Development of ASR Systems for Multilingual Code-switched Speech in Under-resourced Languages\\u00a7r\\n\\n\\u00a78\\u00a7oAstik Biswas\\nEmre Y\\u0131lmaz\\nFebe de Wet\\nEwald van der Westhuizen\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2003.03135\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 6 Mar 2020 11:08:38 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oConference\\u00a7r"}']}
{title:'Guizzo et al. (§72020§r)', author: 'Eric Guizzo; Tillman Weyde; Jack Barnett Leveson', display:{Lore:['[{"text": "arXiv:2003.03375", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMulti-Time-Scale Convolution for Emotion Recognition from Speech Audio Signals\\u00a7r\\n\\n\\u00a78\\u00a7oEric Guizzo\\nTillman Weyde\\nJack Barnett Leveson\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2003.03375\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 6 Mar 2020 12:28:04 GMT)\\u00a7r"}']}
{title:'Velez et al. (§72020§r)', author: 'Ivette Velez; Caleb Rascon; Gibran Fuentes-Pineda', display:{Lore:['[{"text": "arXiv:2003.03432", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lLightweight Speaker Verification for Online Identification of New Speakers with Short Segments\\u00a7r\\n\\n\\u00a78\\u00a7oIvette Velez\\nCaleb Rascon\\nGibran Fuentes-Pineda\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2003.03432\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1016/j.asoc.2020.106704\\u00a7r\\n\\nVersion:\\u00a77v2 (Fri, 23 Oct 2020 03:58:41 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oThis paper has been accepted for publication in Applied Soft Computing Journal\\u00a7r"}']}
{title:'Gu et al. (§72020§r)', author: 'Rongzhi Gu; Shi-Xiong Zhang; Lianwu Chen; Yong Xu; Meng Yu; Dan Su; Yuexian Zou; Dong Yu', display:{Lore:['[{"text": "arXiv:2003.03927", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lEnhancing End-to-End Multi-channel Speech Separation via Spatial Feature Learning\\u00a7r\\n\\n\\u00a78\\u00a7oRongzhi Gu\\nShi-Xiong Zhang\\nLianwu Chen\\n+ 4 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2003.03927\\u00a7r\\n\\nVersion:\\u00a77v2 (Fri, 13 Mar 2020 04:25:21 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oaccepted in ICASSP 2020\\u00a7r"}']}
{title:'Kinoshita et al. (§72020§r)', author: 'Keisuke Kinoshita; Marc Delcroix; Shoko Araki; Tomohiro Nakatani', display:{Lore:['[{"text": "arXiv:2003.03987", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lTackling real noisy reverberant meetings with all-neural source separation, counting, and diarization system\\u00a7r\\n\\n\\u00a78\\u00a7oKeisuke Kinoshita\\nMarc Delcroix\\nShoko Araki\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2003.03987\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 9 Mar 2020 09:25:38 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o8 pages, to appear in ICASSP2020\\u00a7r"}']}
{title:'Kinoshita et al. (§72020§r)', author: 'Keisuke Kinoshita; Tsubasa Ochiai; Marc Delcroix; Tomohiro Nakatani', display:{Lore:['[{"text": "arXiv:2003.03998", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lImproving noise robust automatic speech recognition with single-channel time-domain enhancement network\\u00a7r\\n\\n\\u00a78\\u00a7oKeisuke Kinoshita\\nTsubasa Ochiai\\nMarc Delcroix\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2003.03998\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 9 Mar 2020 09:36:31 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, to appear in ICASSP2020\\u00a7r"}']}
{title:'Nguyen et al. (§72020§r)', author: 'Thai-Son Nguyen; Sebastian Stüker; Alex Waibel', display:{Lore:['[{"text": "arXiv:2003.04194", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CV\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lToward Cross-Domain Speech Recognition with End-to-End Models\\u00a7r\\n\\n\\u00a78\\u00a7oThai-Son Nguyen\\nSebastian St\\u00fcker\\nAlex Waibel\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2003.04194\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 9 Mar 2020 15:19:53 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oPresented in Life-Long Learning forSpoken Language Systems Workshop - ASRU 2019\\u00a7r"}']}
{title:'Roger et al. (§72020§r)', author: 'Vincent Roger; Jérôme Farinas; Julien Pinquier', display:{Lore:['[{"text": "arXiv:2003.04241", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDeep Neural Networks for Automatic Speech Processing: A Survey from Large Corpora to Limited Data\\u00a7r\\n\\n\\u00a78\\u00a7oVincent Roger\\nJ\\u00e9r\\u00f4me Farinas\\nJulien Pinquier\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2003.04241\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 9 Mar 2020 16:26:30 GMT)\\u00a7r"}']}
{title:'Agbolade (§72020§r)', author: 'Olaide Agbolade', display:{Lore:['[{"text": "arXiv:2003.04640", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lVowels and Prosody Contribution in Neural Network Based Voice Conversion Algorithm with Noisy Training Data\\u00a7r\\n\\n\\u00a78\\u00a7oOlaide Agbolade\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2003.04640\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.24018/ejers.2020.5.3.1802\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nEuropean Journal of Engineering Research and Science, 5(3),\\n  pp.229-233 (2020)\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 10 Mar 2020 11:29:43 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages\\u00a7r"}']}
{title:'N. et al. (§72020§r)', author: 'Amirgaliyev E. N.; Kuanyshbay D. N.; Baimuratov O', display:{Lore:['[{"text": "arXiv:2003.04710", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDevelopment of Automatic Speech Recognition for Kazakh Language using Transfer Learning\\u00a7r\\n\\n\\u00a78\\u00a7oAmirgaliyev E. N.\\nKuanyshbay D. N.\\nBaimuratov O\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2003.04710\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 8 Mar 2020 20:38:56 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o9 pages, 3 fig., 1 table\\u00a7r"}']}
{title:'Krishna et al. (§72020§r)', author: 'Gautam Krishna; Co Tran; Mason Carnahan; Ahmed Tewfik', display:{Lore:['[{"text": "arXiv:2003.04733", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7eeess.SP\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSpeaker Identification using EEG\\u00a7r\\n\\n\\u00a78\\u00a7oGautam Krishna\\nCo Tran\\nMason Carnahan\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2003.04733\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 7 Mar 2020 04:04:19 GMT)\\u00a7r"}']}
{title:'Agbolade et al. (§72020§r)', author: 'Olaide Ayodeji Agbolade; Samson A. Oyetunji', display:{Lore:['[{"text": "arXiv:2003.05184", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lVoice conversion using coefficient mapping and neural network\\u00a7r\\n\\n\\u00a78\\u00a7oOlaide Ayodeji Agbolade\\nSamson A. Oyetunji\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2003.05184\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/ICSAE.2016.7810239\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nIn 2016 International Conference for Students on Applied\\n  Engineering (ICSAE) (pp. 479-483) IEEE\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 11 Mar 2020 09:30:21 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages\\u00a7r"}']}
{title:'Farzaneh et al. (§72020§r)', author: 'Majid Farzaneh; Rahil Mahdian Toroghi', display:{Lore:['[{"text": "arXiv:2003.05223", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lRobust Audio Watermarking Using Graph-based Transform and Singular Value Decomposition\\u00a7r\\n\\n\\u00a78\\u00a7oMajid Farzaneh\\nRahil Mahdian Toroghi\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2003.05223\\u00a7r\\n\\nVersion:\\u00a77v2 (Wed, 18 Mar 2020 15:49:38 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 5 images, 4 tables, submitted to an IRED conference\\u00a7r"}']}
{title:'Wang et al. (§72020§r)', author: 'Jiaxi Wang; Karel Mundnich; Allison T. Knoll; Pat Levitt; Shrikanth Narayanan', display:{Lore:['[{"text": "arXiv:2003.05897", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lBringing in the outliers: A sparse subspace clustering approach to learn a dictionary of mouse ultrasonic vocalizations\\u00a7r\\n\\n\\u00a78\\u00a7oJiaxi Wang\\nKarel Mundnich\\nAllison T. Knoll\\nPat Levitt\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2003.05897\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 12 Mar 2020 16:55:37 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 4 figures, conference paper, accepted in ICASSP 2020\\u00a7r"}']}
{title:'Guezenoc et al. (§72020§r)', author: 'Corentin Guezenoc; Renaud Seguier', display:{Lore:['[{"text": "arXiv:2003.06182", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a75physics.class-ph\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Wide Dataset of Ear Shapes and Pinna-Related Transfer Functions Generated by Random Ear Drawings\\u00a7r\\n\\n\\u00a78\\u00a7oCorentin Guezenoc\\nRenaud Seguier\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2003.06182\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1121/10.0001461\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 13 Mar 2020 10:10:59 GMT)\\u00a7r"}']}
{title:'Guezenoc et al. (§72020§r)', author: 'Corentin Guezenoc; Renaud Seguier', display:{Lore:['[{"text": "arXiv:2003.06183", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7eeess.SP\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lHRTF Individualization: A Survey\\u00a7r\\n\\n\\u00a78\\u00a7oCorentin Guezenoc\\nRenaud Seguier\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2003.06183\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.17743/aesconv.2018.978-1-942220-25-1\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 13 Mar 2020 10:13:17 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAudio Engineering Society Convention 145, Audio Engineering Society, Oct 2018, New York, United States\\u00a7r"}']}
{title:'Ens et al. (§72020§r)', author: 'Jeff Ens; Philippe Pasquier', display:{Lore:['[{"text": "arXiv:2003.06226", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lQuantifying Musical Style: Ranking Symbolic Music based on Similarity to a Style\\u00a7r\\n\\n\\u00a78\\u00a7oJeff Ens\\nPhilippe Pasquier\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2003.06226\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nIn Proceedings of the International Symposium on Music Information\\n  Retrieval. Vol. 20. 2019, 870-877\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 10 Mar 2020 05:20:15 GMT)\\u00a7r"}']}
{title:'Hu et al. (§72020§r)', author: 'Ting-Yao Hu; Ashish Shrivastava; Oncel Tuzel; Chandra Dhir', display:{Lore:['[{"text": "arXiv:2003.06227", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CV\\u00a7r, \\u00a7acs.IT\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a72math.IT\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lUnsupervised Style and Content Separation by Minimizing Mutual Information for Speech Synthesis\\u00a7r\\n\\n\\u00a78\\u00a7oTing-Yao Hu\\nAshish Shrivastava\\nOncel Tuzel\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2003.06227\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 9 Mar 2020 23:47:41 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted at ICASSP 2020 (for presentation in a lecture session)\\u00a7r"}']}
{title:'Berghi et al. (§72020§r)', author: 'Davide Berghi; Hanne Stenzel; Marco Volino; Adrian Hilton; Philip J. B. Jackson', display:{Lore:['[{"text": "arXiv:2003.06656", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7eeess.IV\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAudio-Visual Spatial Aligment Requirements of Central and Peripheral Object Events\\u00a7r\\n\\n\\u00a78\\u00a7oDavide Berghi\\nHanne Stenzel\\nMarco Volino\\nAdrian Hilton\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2003.06656\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nIEEE VR 2020\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 14 Mar 2020 15:19:52 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oTwo-pages poster abstract\\u00a7r"}']}
{title:'Hodari et al. (§72020§r)', author: 'Zack Hodari; Catherine Lai; Simon King', display:{Lore:['[{"text": "arXiv:2003.06686", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lPerception of prosodic variation for speech synthesis using an unsupervised discrete representation of F0\\u00a7r\\n\\n\\u00a78\\u00a7oZack Hodari\\nCatherine Lai\\nSimon King\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2003.06686\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.21437/SpeechProsody.2020-197\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 14 Mar 2020 19:17:42 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oPublished to the 10th ISCA InternationalConference on Speech Prosody (SP2020)\\u00a7r"}']}
{title:'Ramenahalli (§72020§r)', author: 'Sudarshan Ramenahalli', display:{Lore:['[{"text": "arXiv:2003.06779", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CV\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA proto-object based audiovisual saliency map\\u00a7r\\n\\n\\u00a78\\u00a7oSudarshan Ramenahalli\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2003.06779\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 15 Mar 2020 08:34:35 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o50 pages, 12 figures\\u00a7r"}']}
{title:'Tomashenko et al. (§72020§r)', author: 'Natalia Tomashenko; Yuri Khokhlov; Yannick Esteve', display:{Lore:['[{"text": "arXiv:2003.06894", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lExploring Gaussian mixture model framework for speaker adaptation of deep neural network acoustic models\\u00a7r\\n\\n\\u00a78\\u00a7oNatalia Tomashenko\\nYuri Khokhlov\\nYannick Esteve\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2003.06894\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 15 Mar 2020 18:56:19 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o36 pages; originally was submitted to CSL in February 2017\\u00a7r"}']}
{title:'Gu et al. (§72020§r)', author: 'Rongzhi Gu; Shi-Xiong Zhang; Yong Xu; Lianwu Chen; Yuexian Zou; Dong Yu', display:{Lore:['[{"text": "arXiv:2003.07032", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7eeess.IV\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMulti-modal Multi-channel Target Speech Separation\\u00a7r\\n\\n\\u00a78\\u00a7oRongzhi Gu\\nShi-Xiong Zhang\\nYong Xu\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2003.07032\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/JSTSP.2020.2980956\\u00a7r\\n\\nVersion:\\u00a77v2 (Fri, 23 Oct 2020 05:40:39 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oaccepted in IEEE Journal of Selcted Topics in Signal Processing\\u00a7r"}']}
{title:'Alonso-Jiménez et al. (§72020§r)', author: 'Pablo Alonso-Jiménez; Dmitry Bogdanov; Jordi Pons; Xavier Serra', display:{Lore:['[{"text": "arXiv:2003.07393", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lTensorFlow Audio Models in Essentia\\u00a7r\\n\\n\\u00a78\\u00a7oPablo Alonso-Jim\\u00e9nez\\nDmitry Bogdanov\\nJordi Pons\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2003.07393\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 16 Mar 2020 18:23:30 GMT)\\u00a7r"}']}
{title:'Li et al. (§72020§r)', author: 'Jinyu Li; Rui Zhao; Eric Sun; Jeremy H. M. Wong; Amit Das; Zhong Meng; Yifan Gong', display:{Lore:['[{"text": "arXiv:2003.07482", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lHigh-Accuracy and Low-Latency Speech Recognition with Two-Head Contextual Layer Trajectory LSTM Model\\u00a7r\\n\\n\\u00a78\\u00a7oJinyu Li\\nRui Zhao\\nEric Sun\\n+ 3 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2003.07482\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 17 Mar 2020 00:52:11 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted by ICASSP 2020\\u00a7r"}']}
{title:'Fan et al. (§72020§r)', author: 'Cunhang Fan; Jianhua Tao; Bin Liu; Jiangyan Yi; Zhengqi Wen; Xuefei Liu', display:{Lore:['[{"text": "arXiv:2003.07544", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.MM\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDeep Attention Fusion Feature for Speech Separation with End-to-End Post-filter Method\\u00a7r\\n\\n\\u00a78\\u00a7oCunhang Fan\\nJianhua Tao\\nBin Liu\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2003.07544\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 17 Mar 2020 05:43:12 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oACCEPTED by IEEE/ACM Transactionson Audio, Speech, and Language Processing (TASLP)\\u00a7r"}']}
{title:'Mani et al. (§72020§r)', author: 'Anirudh Mani; Shruti Palaskar; Nimshi Venkat Meripo; Sandeep Konam; Florian Metze', display:{Lore:['[{"text": "arXiv:2003.07692", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lASR Error Correction and Domain Adaptation Using Machine Translation\\u00a7r\\n\\n\\u00a78\\u00a7oAnirudh Mani\\nShruti Palaskar\\nNimshi Venkat Meripo\\nSandeep Konam\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2003.07692\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 13 Mar 2020 20:05:38 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted for Oral Presentation at ICASSP 2020\\u00a7r"}']}
{title:'Ebner et al. (§72020§r)', author: 'P. P. Ebner; A. Eltelt', display:{Lore:['[{"text": "arXiv:2003.07704", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAudio inpainting with generative adversarial network\\u00a7r\\n\\n\\u00a78\\u00a7oP. P. Ebner\\nA. Eltelt\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2003.07704\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 13 Mar 2020 09:17:01 GMT)\\u00a7r"}']}
{title:'Variani et al. (§72020§r)', author: 'Ehsan Variani; David Rybach; Cyril Allauzen; Michael Riley', display:{Lore:['[{"text": "arXiv:2003.07705", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lHybrid Autoregressive Transducer (hat)\\u00a7r\\n\\n\\u00a78\\u00a7oEhsan Variani\\nDavid Rybach\\nCyril Allauzen\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2003.07705\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 12 Mar 2020 20:47:06 GMT)\\u00a7r"}']}
{title:'Hu et al. (§72020§r)', author: 'Ke Hu; Tara N. Sainath; Ruoming Pang; Rohit Prabhavalkar', display:{Lore:['[{"text": "arXiv:2003.07962", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDeliberation Model Based Two-Pass End-to-End Speech Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oKe Hu\\nTara N. Sainath\\nRuoming Pang\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2003.07962\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 17 Mar 2020 22:01:12 GMT)\\u00a7r"}']}
{title:'Liu et al. (§72020§r)', author: 'Yuzhou Liu; Balaji Thoshkahna; Ali Milani; Trausti Kristjansson', display:{Lore:['[{"text": "arXiv:2003.08954", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lVoice and accompaniment separation in music using self-attention convolutional neural network\\u00a7r\\n\\n\\u00a78\\u00a7oYuzhou Liu\\nBalaji Thoshkahna\\nAli Milani\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2003.08954\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 19 Mar 2020 18:00:56 GMT)\\u00a7r"}']}
{title:'Tao et al. (§72020§r)', author: 'Fei Tao; Gokhan Tur', display:{Lore:['[{"text": "arXiv:2003.09125", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lImproving Embedding Extraction for Speaker Verification with Ladder Network\\u00a7r\\n\\n\\u00a78\\u00a7oFei Tao\\nGokhan Tur\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2003.09125\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 20 Mar 2020 07:08:38 GMT)\\u00a7r"}']}
{title:'Jung et al. (§72020§r)', author: 'Jee-weon Jung; Hye-jin Shim; Ju-ho Kim; Seung-bin Kim; Ha-Jin Yu', display:{Lore:['[{"text": "arXiv:2003.09164", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAcoustic Scene Classification using Audio Tagging\\u00a7r\\n\\n\\u00a78\\u00a7oJee-weon Jung\\nHye-jin Shim\\nJu-ho Kim\\nSeung-bin Kim\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2003.09164\\u00a7r\\n\\nVersion:\\u00a77v2 (Sun, 19 Apr 2020 10:32:04 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 2 figures, 6 tables, submitted to Interspeech 2020 as a conference paper\\u00a7r"}']}
{title:'Jeong et al. (§72020§r)', author: 'Yoonjae Jeong; Hoon-Young Cho', display:{Lore:['[{"text": "arXiv:2003.09180", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDetecting Mismatch between Text Script and Voice-over Using Utterance Verification Based on Phoneme Recognition Ranking\\u00a7r\\n\\n\\u00a78\\u00a7oYoonjae Jeong\\nHoon-Young Cho\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2003.09180\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 20 Mar 2020 10:35:35 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted by ICASSP 2020\\u00a7r"}']}
{title:'Chettri et al. (§72020§r)', author: 'Bhusan Chettri; Tomi Kinnunen; Emmanouil Benetos', display:{Lore:['[{"text": "arXiv:2003.09542", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDeep Generative Variational Autoencoding for Replay Spoof Detection in Automatic Speaker Verification\\u00a7r\\n\\n\\u00a78\\u00a7oBhusan Chettri\\nTomi Kinnunen\\nEmmanouil Benetos\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2003.09542\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 21 Mar 2020 00:56:05 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted to Computer Speech and Language Special issueon Advances in Automatic Speaker Verification Anti-spoofing, 2020\\u00a7r"}']}
{title:'Ragano et al. (§72020§r)', author: 'Alessandro Ragano; Emmanouil Benetos; Andrew Hines', display:{Lore:['[{"text": "arXiv:2003.09889", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAudio Impairment Recognition Using a Correlation-Based Feature Representation\\u00a7r\\n\\n\\u00a78\\u00a7oAlessandro Ragano\\nEmmanouil Benetos\\nAndrew Hines\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2003.09889\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/QoMEX48832.2020.9123111\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 24 Mar 2020 14:54:21 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oThis publication has been accepted in 2020 Twelfth International Conference on Quality of Multimedia Experience (QoMEX)\\u00a7r"}']}
{title:'Nguyen et al. (§72020§r)', author: 'Thai Son Nguyen; Jan Niehues; Eunah Cho; Thanh-Le Ha; Kevin Kilgour; Markus Muller; Matthias Sperber; Sebastian Stueker; Alex Waibel', display:{Lore:['[{"text": "arXiv:2003.09891", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lLow Latency ASR for Simultaneous Speech Translation\\u00a7r\\n\\n\\u00a78\\u00a7oThai Son Nguyen\\nJan Niehues\\nEunah Cho\\n+ 5 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2003.09891\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 22 Mar 2020 13:37:05 GMT)\\u00a7r"}']}
{title:'Nguyen et al. (§72020§r)', author: 'Thai-Son Nguyen; Ngoc-Quan Pham; Sebastian Stueker; Alex Waibel', display:{Lore:['[{"text": "arXiv:2003.10022", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lHigh Performance Sequence-to-Sequence Model for Streaming Speech Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oThai-Son Nguyen\\nNgoc-Quan Pham\\nSebastian Stueker\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2003.10022\\u00a7r\\n\\nVersion:\\u00a77v2 (Sun, 26 Jul 2020 21:32:22 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oTo appear in Interspeech 2020\\u00a7r"}']}
{title:'Kakouros et al. (§72020§r)', author: 'Sofoklis Kakouros; Katri Hiovain; Martti Vainio; Juraj Šimko', display:{Lore:['[{"text": "arXiv:2003.10183", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDialect Identification of Spoken North S\\u00e1mi Language Varieties Using Prosodic Features\\u00a7r\\n\\n\\u00a78\\u00a7oSofoklis Kakouros\\nKatri Hiovain\\nMartti Vainio\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2003.10183\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.21437/SpeechProsody.2020-128\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 23 Mar 2020 11:16:45 GMT)\\u00a7r"}']}
{title:'Wang et al. (§72020§r)', author: 'Chengyi Wang; Yu Wu; Shujie Liu; Jinyu Li; Liang Lu; Guoli Ye; Ming Zhou', display:{Lore:['[{"text": "arXiv:2003.10369", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lLow Latency End-to-End Streaming Speech Recognition with a Scout Network\\u00a7r\\n\\n\\u00a78\\u00a7oChengyi Wang\\nYu Wu\\nShujie Liu\\n+ 3 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2003.10369\\u00a7r\\n\\nVersion:\\u00a77v4 (Sun, 3 May 2020 16:10:18 GMT)\\u00a7r"}']}
{title:'Atmaja et al. (§72020§r)', author: 'Bagus Tris Atmaja; Masato Akagi', display:{Lore:['[{"text": "arXiv:2003.10724", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lEvaluation of Error and Correlation-Based Loss Functions For Multitask Learning Dimensional Speech Emotion Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oBagus Tris Atmaja\\nMasato Akagi\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2003.10724\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1088/1742-6596/1896/1/012004\\u00a7r\\n\\nVersion:\\u00a77v2 (Wed, 18 Nov 2020 07:38:01 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o3 figures, 3 tables, submitted to ANV 2020\\u00a7r"}']}
{title:'Wu et al. (§72020§r)', author: 'Yi-Chiao Wu; Patrick Lumban Tobing; Kazuhiro Kobayashi; Tomoki Hayashi; Tomoki Toda', display:{Lore:['[{"text": "arXiv:2003.11750", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lNon-parallel Voice Conversion System with WaveNet Vocoder and Collapsed Speech Suppression\\u00a7r\\n\\n\\u00a78\\u00a7oYi-Chiao Wu\\nPatrick Lumban Tobing\\nKazuhiro Kobayashi\\nTomoki Hayashi\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2003.11750\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/ACCESS.2020.2984007\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 7 Apr 2020 00:27:13 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o13 pages, 13 figures, 1 table, accepted to publish in IEEE Access\\u00a7r"}']}
{title:'Jassim et al. (§72020§r)', author: 'Wissam A. Jassim; Jan Skoglund; Michael Chinen; Andrew Hines', display:{Lore:['[{"text": "arXiv:2003.11882", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSpeech Quality Factors for Traditional and Neural-Based Low Bit Rate Vocoders\\u00a7r\\n\\n\\u00a78\\u00a7oWissam A. Jassim\\nJan Skoglund\\nMichael Chinen\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2003.11882\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 26 Mar 2020 13:19:43 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o6 pages, 11 figures, conference\\u00a7r"}']}
{title:'Chung et al. (§72020§r)', author: 'Joon Son Chung; Jaesung Huh; Seongkyu Mun; Minjae Lee; Hee Soo Heo; Soyeon Choe; Chiheon Ham; Sunghwan Jung; Bong-Jin Lee; Icksang Han', display:{Lore:['[{"text": "arXiv:2003.11982", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lIn defence of metric learning for speaker recognition\\u00a7r\\n\\n\\u00a78\\u00a7oJoon Son Chung\\nJaesung Huh\\nSeongkyu Mun\\n+ 6 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2003.11982\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.21437/Interspeech.2020-1064\\u00a7r\\n\\nVersion:\\u00a77v2 (Fri, 24 Apr 2020 05:52:11 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oThe code can be found at https://github.com/clovaai/voxceleb_trainer\\u00a7r"}']}
{title:'Azarang et al. (§72020§r)', author: 'Arian Azarang; Nasser Kehtarnavaz', display:{Lore:['[{"text": "arXiv:2003.12108", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7eeess.SP\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Review of Multi-Objective Deep Learning Speech Denoising Methods\\u00a7r\\n\\n\\u00a78\\u00a7oArian Azarang\\nNasser Kehtarnavaz\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2003.12108\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 26 Mar 2020 18:55:31 GMT)\\u00a7r"}']}
{title:'Lee et al. (§72020§r)', author: 'Joohyung Lee; Youngmoon Jung; Hoirin Kim', display:{Lore:['[{"text": "arXiv:2003.12266", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDual Attention in Time and Frequency Domain for Voice Activity Detection\\u00a7r\\n\\n\\u00a78\\u00a7oJoohyung Lee\\nYoungmoon Jung\\nHoirin Kim\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2003.12266\\u00a7r\\n\\nVersion:\\u00a77v3 (Tue, 25 Aug 2020 08:55:20 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted to Interspeech 2020\\u00a7r"}']}
{title:'Luo et al. (§72020§r)', author: 'Yi Luo; Nima Mesgarani', display:{Lore:['[{"text": "arXiv:2003.12326", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSeparating Varying Numbers of Sources with Auxiliary Autoencoding Loss\\u00a7r\\n\\n\\u00a78\\u00a7oYi Luo\\nNima Mesgarani\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2003.12326\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 18 Aug 2020 04:07:21 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oInterspeech 2020\\u00a7r"}']}
{title:'Baunsgaard et al. (§72020§r)', author: 'Sebastian Baunsgaard; Sebastian B. Wrede; Pınar Tozun', display:{Lore:['[{"text": "arXiv:2003.12366", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lTraining for Speech Recognition on Coprocessors\\u00a7r\\n\\n\\u00a78\\u00a7oSebastian Baunsgaard\\nSebastian B. Wrede\\nP\\u0131nar Tozun\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2003.12366\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 22 Mar 2020 11:21:29 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7ounder submission to pvldb even though used acm style to submit here\\u00a7r"}']}
{title:'Mathur et al. (§72020§r)', author: 'Akhil Mathur; Anton Isopoussu; Fahim Kawsar; Nadia Berthouze; Nicholas D. Lane', display:{Lore:['[{"text": "arXiv:2003.12425", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMic2Mic: Using Cycle-Consistent Generative Adversarial Networks to Overcome Microphone Variability in Speech Systems\\u00a7r\\n\\n\\u00a78\\u00a7oAkhil Mathur\\nAnton Isopoussu\\nFahim Kawsar\\nNadia Berthouze\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2003.12425\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1145/3302506.3310398\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 27 Mar 2020 14:06:36 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oPublished at ACM IPSN 2019\\u00a7r"}']}
{title:'Yoshida et al. (§72020§r)', author: 'Akito Yoshida; Shigeru Shinomoto', display:{Lore:['[{"text": "arXiv:2003.13033", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMechanical classification of voice quality\\u00a7r\\n\\n\\u00a78\\u00a7oAkito Yoshida\\nShigeru Shinomoto\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2003.13033\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 29 Mar 2020 14:09:08 GMT)\\u00a7r"}']}
{title:'Subramani et al. (§72020§r)', author: "Krishna Subramani; Preeti Rao; Alexandre D'Hooge", display:{Lore:['[{"text": "arXiv:2004.00001", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lVaPar Synth \\u2013 A Variational Parametric Model for Audio Synthesis\\u00a7r\\n\\n\\u00a78\\u00a7oKrishna Subramani\\nPreeti Rao\\nAlexandre D\'Hooge\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2004.00001\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/ICASSP40776.2020.9054181\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 30 Mar 2020 16:05:47 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7ohttps://github.com/SubramaniKrishna/VaPar-Synth , Accepted in ICASSP 2020\\u00a7r"}']}
{title:'Xiao et al. (§72020§r)', author: 'Yiming Xiao; Haijian Zhang', display:{Lore:['[{"text": "arXiv:2004.00175", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lImproved Source Counting and Separation for Monaural Mixture\\u00a7r\\n\\n\\u00a78\\u00a7oYiming Xiao\\nHaijian Zhang\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2004.00175\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 1 Apr 2020 00:19:41 GMT)\\u00a7r"}']}
{title:'Atmaja et al. (§72020§r)', author: 'Bagus Tris Atmaja; Masato Akagi', display:{Lore:['[{"text": "arXiv:2004.00200", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lOn The Differences Between Song and Speech Emotion Recognition: Effect of Feature Sets, Feature Types, and Classifiers\\u00a7r\\n\\n\\u00a78\\u00a7oBagus Tris Atmaja\\nMasato Akagi\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2004.00200\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/TENCON50793.2020.9293852\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7n2020 IEEE REGION 10 CONFERENCE (TENCON), 968-972\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 1 Apr 2020 02:16:38 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o2 Figures, 2 Tables\\u00a7r"}']}
{title:'Jung et al. (§72020§r)', author: 'Jee-weon Jung; Seung-bin Kim; Hye-jin Shim; Ju-ho Kim; Ha-Jin Yu', display:{Lore:['[{"text": "arXiv:2004.00526", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lImproved RawNet with Feature Map Scaling for Text-independent Speaker Verification using Raw Waveforms\\u00a7r\\n\\n\\u00a78\\u00a7oJee-weon Jung\\nSeung-bin Kim\\nHye-jin Shim\\nJu-ho Kim\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2004.00526\\u00a7r\\n\\nVersion:\\u00a77v2 (Thu, 7 May 2020 04:45:41 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 1 figure, 5 tables, submitted to Interspeech 2020 as a conference paper\\u00a7r"}']}
{title:'Aroudi et al. (§72020§r)', author: 'Ali Aroudi; Tobias de Taillez; Simon Doclo', display:{Lore:['[{"text": "arXiv:2004.00910", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7eeess.SP\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lImproving auditory attention decoding performance of linear and non-linear methods using state-space model\\u00a7r\\n\\n\\u00a78\\u00a7oAli Aroudi\\nTobias de Taillez\\nSimon Doclo\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2004.00910\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 2 Apr 2020 09:56:06 GMT)\\u00a7r"}']}
{title:'Li et al. (§72020§r)', author: 'Haoyu Li; Szu-Wei Fu; Yu Tsao; Junichi Yamagishi', display:{Lore:['[{"text": "arXiv:2004.00932", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7liMetricGAN: Intelligibility Enhancement for Speech-in-Noise using Generative Adversarial Network-based Metric Learning\\u00a7r\\n\\n\\u00a78\\u00a7oHaoyu Li\\nSzu-Wei Fu\\nYu Tsao\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2004.00932\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 7 Apr 2020 11:02:09 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, Submitted to INTERSPEECH 2020\\u00a7r"}']}
{title:'Zhou et al. (§72020§r)', author: 'Wei Zhou; Wilfried Michel; Kazuki Irie; Markus Kitza; Ralf Schlüter; Hermann Ney', display:{Lore:['[{"text": "arXiv:2004.00960", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lThe RWTH ASR System for TED-LIUM Release 2: Improving Hybrid HMM with SpecAugment\\u00a7r\\n\\n\\u00a78\\u00a7oWei Zhou\\nWilfried Michel\\nKazuki Irie\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2004.00960\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 2 Apr 2020 12:41:15 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oaccepted at ICASSP 2020\\u00a7r"}']}
{title:'Zhou et al. (§72020§r)', author: 'Wei Zhou; Ralf Schlüter; Hermann Ney', display:{Lore:['[{"text": "arXiv:2004.00967", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lFull-Sum Decoding for Hybrid HMM based Speech Recognition using LSTM Language Model\\u00a7r\\n\\n\\u00a78\\u00a7oWei Zhou\\nRalf Schl\\u00fcter\\nHermann Ney\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2004.00967\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 2 Apr 2020 13:07:05 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oaccepted at ICASSP 2020\\u00a7r"}']}
{title:'Padi et al. (§72020§r)', author: 'Bharat Padi; Anand Mohan; Sriram Ganapathy', display:{Lore:['[{"text": "arXiv:2004.01221", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lTowards Relevance and Sequence Modeling in Language Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oBharat Padi\\nAnand Mohan\\nSriram Ganapathy\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2004.01221\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 2 Apr 2020 18:31:18 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7ohttps://github.com/iiscleap/lre-relevance-weighting Accepted to IEEE Transactions on Audio, Speech and Language Processing\\u00a7r"}']}
{title:'Imran et al. (§72020§r)', author: 'Ali Imran; Iryna Posokhova; Haneya N. Qureshi; Usama Masood; Muhammad Sajid Riaz; Kamran Ali; Charles N. John; MD Iftikhar Hussain; Muhammad Nabeel', display:{Lore:['[{"text": "arXiv:2004.01275", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7bq-bio.QM\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAI4COVID-19: AI Enabled Preliminary Diagnosis for COVID-19 from Cough Samples via an App\\u00a7r\\n\\n\\u00a78\\u00a7oAli Imran\\nIryna Posokhova\\nHaneya N. Qureshi\\n+ 5 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2004.01275\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1016/j.imu.2020.100378\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nInformatics in Medicine Unlocked, vol. 20, p. 100378, 2020\\u00a7r\\n\\nVersion:\\u00a77v6 (Sun, 27 Sep 2020 21:32:17 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted in Informatics in Medicine Unlocked 2020\\u00a7r"}']}
{title:'Bales et al. (§72020§r)', author: 'Charles Bales; Muhammad Nabeel; Charles N. John; Usama Masood; Haneya N. Qureshi; Hasan Farooq; Iryna Posokhova; Ali Imran', display:{Lore:['[{"text": "arXiv:2004.01495", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lCan Machine Learning Be Used to Recognize and Diagnose Coughs?\\u00a7r\\n\\n\\u00a78\\u00a7oCharles Bales\\nMuhammad Nabeel\\nCharles N. John\\n+ 4 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2004.01495\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/EHB50910.2020.9280115\\u00a7r\\n\\nVersion:\\u00a77v3 (Sun, 4 Oct 2020 04:00:50 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted in IEEE International Conference on E-Health and Bioengineering - EHB 2020\\u00a7r"}']}
{title:'Tokui (§72020§r)', author: 'Nao Tokui', display:{Lore:['[{"text": "arXiv:2004.01525", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lTowards democratizing music production with AI-Design of Variational Autoencoder-based Rhythm Generator as a DAW plugin\\u00a7r\\n\\n\\u00a78\\u00a7oNao Tokui\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2004.01525\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 1 Apr 2020 10:50:14 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o4 pages\\u00a7r"}']}
{title:'Fernando et al. (§72020§r)', author: 'Tharindu Fernando; Sridha Sridharan; Mitchell McLaren; Darshana Priyasad; Simon Denman; Clinton Fookes', display:{Lore:['[{"text": "arXiv:2004.01546", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lTemporarily-Aware Context Modelling using Generative Adversarial Networks for Speech Activity Detection\\u00a7r\\n\\n\\u00a78\\u00a7oTharindu Fernando\\nSridha Sridharan\\nMitchell McLaren\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2004.01546\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/TASLP.2020.2982297\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nIEEE/ACM Transactions on Audio, Speech and Language Processing,\\n  2020\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 2 Apr 2020 02:33:13 GMT)\\u00a7r"}']}
{title:'Vestman et al. (§72020§r)', author: 'Ville Vestman; Kong Aik Lee; Tomi H. Kinnunen', display:{Lore:['[{"text": "arXiv:2004.01559", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lNeural i-vectors\\u00a7r\\n\\n\\u00a78\\u00a7oVille Vestman\\nKong Aik Lee\\nTomi H. Kinnunen\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2004.01559\\u00a7r\\n\\nVersion:\\u00a77v2 (Sat, 18 Apr 2020 14:47:50 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted to Odyssey 2020: The Speaker and Language Recognition Workshop. Version 2 (bugfix)\\u00a7r"}']}
{title:'Chettri et al. (§72020§r)', author: 'Bhusan Chettri; Tomi Kinnunen; Emmanouil Benetos', display:{Lore:['[{"text": "arXiv:2004.01922", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSubband modeling for spoofing detection in automatic speaker verification\\u00a7r\\n\\n\\u00a78\\u00a7oBhusan Chettri\\nTomi Kinnunen\\nEmmanouil Benetos\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2004.01922\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 4 Apr 2020 12:49:21 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted to the Speaker Odyssey (The Speaker and Language Recognition Workshop) 2020 conference. 8 pages\\u00a7r"}']}
{title:'Wang et al. (§72020§r)', author: 'Xin Wang; Junichi Yamagishi', display:{Lore:['[{"text": "arXiv:2004.02191", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lUsing Cyclic Noise as the Source Signal for Neural Source-Filter-based Speech Waveform Model\\u00a7r\\n\\n\\u00a78\\u00a7oXin Wang\\nJunichi Yamagishi\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2004.02191\\u00a7r\\n\\nVersion:\\u00a77v2 (Fri, 10 Apr 2020 14:48:56 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to Interspeech 2020\\u00a7r"}']}
{title:'Atmaja et al. (§72020§r)', author: 'Bagus Tris Atmaja; Masato Akagi', display:{Lore:['[{"text": "arXiv:2004.02355", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDeep Multilayer Perceptrons for Dimensional Speech Emotion Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oBagus Tris Atmaja\\nMasato Akagi\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2004.02355\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nAsia-Pacific Signal and Information Processing Association Annual\\n  Summit and Conference, APSIPA ASC 2020\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 6 Apr 2020 00:03:43 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o2 figures, 4 tables, submitted to EUSIPCO 2020\\u00a7r"}']}
{title:'Fan et al. (§72020§r)', author: 'Cunhang Fan; Jianhua Tao; Bin Liu; Jiangyan Yi; Zhengqi Wen', display:{Lore:['[{"text": "arXiv:2004.02420", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSimultaneous Denoising and Dereverberation Using Deep Embedding Features\\u00a7r\\n\\n\\u00a78\\u00a7oCunhang Fan\\nJianhua Tao\\nBin Liu\\nJiangyan Yi\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2004.02420\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 6 Apr 2020 06:34:01 GMT)\\u00a7r"}']}
{title:'Boscain et al. (§72020§r)', author: 'Ugo Boscain; Dario Prandi; Ludovic Sacchelli; Giuseppina Turco', display:{Lore:['[{"text": "arXiv:2004.02450", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a72math.AP\\u00a7r, \\u00a72math.OC\\u00a7r, \\u00a7bq-bio.NC\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA bio-inspired geometric model for sound reconstruction\\u00a7r\\n\\n\\u00a78\\u00a7oUgo Boscain\\nDario Prandi\\nLudovic Sacchelli\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2004.02450\\u00a7r\\n\\nVersion:\\u00a77v2 (Mon, 19 Oct 2020 13:10:07 GMT)\\u00a7r"}']}
{title:'Michelsanti et al. (§72020§r)', author: 'Daniel Michelsanti; Olga Slizovskaia; Gloria Haro; Emilia Gómez; Zheng-Hua Tan; Jesper Jensen', display:{Lore:['[{"text": "arXiv:2004.02541", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CV\\u00a7r, \\u00a7acs.LG\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lVocoder-Based Speech Synthesis from Silent Videos\\u00a7r\\n\\n\\u00a78\\u00a7oDaniel Michelsanti\\nOlga Slizovskaia\\nGloria Haro\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2004.02541\\u00a7r\\n\\nVersion:\\u00a77v2 (Sat, 15 Aug 2020 22:00:42 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted to Interspeech 2020\\u00a7r"}']}
{title:'Kye et al. (§72020§r)', author: 'Seong Min Kye; Youngmoon Jung; Hae Beom Lee; Sung Ju Hwang; Hoirin Kim', display:{Lore:['[{"text": "arXiv:2004.02863", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMeta-Learning for Short Utterance Speaker Recognition with Imbalance Length Pairs\\u00a7r\\n\\n\\u00a78\\u00a7oSeong Min Kye\\nYoungmoon Jung\\nHae Beom Lee\\nSung Ju Hwang\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2004.02863\\u00a7r\\n\\nVersion:\\u00a77v5 (Tue, 11 Aug 2020 02:21:51 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted to Interspeech 2020. The codes are available at https://github.com/seongmin-kye/meta-SR\\u00a7r"}']}
{title:'Jung et al. (§72020§r)', author: 'Youngmoon Jung; Seong Min Kye; Yeunju Choi; Myunghun Jung; Hoirin Kim', display:{Lore:['[{"text": "arXiv:2004.03194", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lImproving Multi-Scale Aggregation Using Feature Pyramid Module for Robust Speaker Verification of Variable-Duration Utterances\\u00a7r\\n\\n\\u00a78\\u00a7oYoungmoon Jung\\nSeong Min Kye\\nYeunju Choi\\nMyunghun Jung\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2004.03194\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.21437/Interspeech.2020-1025\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nProc. Interspeech 2020, pp. 1501-1505\\u00a7r\\n\\nVersion:\\u00a77v4 (Thu, 6 Aug 2020 06:09:29 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted to Interspeech 2020\\u00a7r"}']}
{title:'Li et al. (§72020§r)', author: 'Jiguo Li; Xinfeng Zhang; Chuanmin Jia; Jizheng Xu; Li Zhang; Yue Wang; Siwei Ma; Wen Gao', display:{Lore:['[{"text": "arXiv:2004.03428", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CR\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lUniversal Adversarial Perturbations Generative Network for Speaker Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oJiguo Li\\nXinfeng Zhang\\nChuanmin Jia\\n+ 4 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2004.03428\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 7 Apr 2020 14:22:10 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted by ICME2020\\u00a7r"}']}
{title:'Li et al. (§72020§r)', author: 'Jiguo Li; Xinfeng Zhang; Jizheng Xu; Li Zhang; Yue Wang; Siwei Ma; Wen Gao', display:{Lore:['[{"text": "arXiv:2004.03434", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CR\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lLearning to fool the speaker recognition\\u00a7r\\n\\n\\u00a78\\u00a7oJiguo Li\\nXinfeng Zhang\\nJizheng Xu\\n+ 3 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2004.03434\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 7 Apr 2020 14:29:28 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted by ICASSP2020\\u00a7r"}']}
{title:'Zheng et al. (§72020§r)', author: 'Yi Zheng; Xianjie Yang; Xuyong Dang', display:{Lore:['[{"text": "arXiv:2004.03437", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lHomophone-based Label Smoothing in End-to-End Automatic Speech Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oYi Zheng\\nXianjie Yang\\nXuyong Dang\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2004.03437\\u00a7r\\n\\nVersion:\\u00a77v2 (Thu, 14 May 2020 07:13:13 GMT)\\u00a7r"}']}
{title:'Briot (§72020§r)', author: 'Jean-Pierre Briot', display:{Lore:['[{"text": "arXiv:2004.03586", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.MM\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lFrom Artificial Neural Networks to Deep Learning for Music Generation \\u2013 History, Concepts and Trends\\u00a7r\\n\\n\\u00a78\\u00a7oJean-Pierre Briot\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2004.03586\\u00a7r\\n\\nVersion:\\u00a77v2 (Mon, 5 Oct 2020 22:33:16 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oTo appear in the Special Issue on Art, Sound andDesign in the Neural Computing and Applications Journal\\u00a7r"}']}
{title:'Liu et al. (§72020§r)', author: 'Songxiang Liu; Yuewen Cao; Helen Meng', display:{Lore:['[{"text": "arXiv:2004.03781", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lEmotional Voice Conversion With Cycle-consistent Adversarial Network\\u00a7r\\n\\n\\u00a78\\u00a7oSongxiang Liu\\nYuewen Cao\\nHelen Meng\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2004.03781\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 8 Apr 2020 02:50:46 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages\\u00a7r"}']}
{title:'Liu et al. (§72020§r)', author: 'Songxiang Liu; Yuewen Cao; Helen Meng', display:{Lore:['[{"text": "arXiv:2004.03782", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMulti-Target Emotional Voice Conversion With Neural Vocoders\\u00a7r\\n\\n\\u00a78\\u00a7oSongxiang Liu\\nYuewen Cao\\nHelen Meng\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2004.03782\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 8 Apr 2020 03:00:27 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o7 pages\\u00a7r"}']}
{title:'Li et al. (§72020§r)', author: 'Haoyu Li; Junichi Yamagishi', display:{Lore:['[{"text": "arXiv:2004.04001", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lNoise Tokens: Learning Neural Noise Templates for Environment-Aware Speech Enhancement\\u00a7r\\n\\n\\u00a78\\u00a7oHaoyu Li\\nJunichi Yamagishi\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2004.04001\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 8 Apr 2020 14:17:31 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, Submitted to Interspeech 2020\\u00a7r"}']}
{title:'Li et al. (§72020§r)', author: 'Xu Li; Jinghua Zhong; Jianwei Yu; Shoukang Hu; Xixin Wu; Xunying Liu; Helen Meng', display:{Lore:['[{"text": "arXiv:2004.04014", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lBayesian x-vector: Bayesian Neural Network based x-vector System for Speaker Verification\\u00a7r\\n\\n\\u00a78\\u00a7oXu Li\\nJinghua Zhong\\nJianwei Yu\\n+ 3 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2004.04014\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 8 Apr 2020 14:35:12 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted by Speaker Odyssey 2020\\u00a7r"}']}
{title:'Biswas et al. (§72020§r)', author: 'A. Biswas; F. de Wet; E. van der Westhuizen; T. R. Niesler', display:{Lore:['[{"text": "arXiv:2004.04054", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSemi-supervised acoustic and language model training for English-isiZulu code-switched speech recognition\\u00a7r\\n\\n\\u00a78\\u00a7oA. Biswas\\nF. de Wet\\nE. van der Westhuizen\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2004.04054\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 5 Apr 2020 06:27:29 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o4th Code-Switch workshop, France\\u00a7r"}']}
{title:'Pham et al. (§72020§r)', author: 'Lam Pham; Huy Phan; Ramaswamy Palaniappan; Alfred Mertins; Ian McLoughlin', display:{Lore:['[{"text": "arXiv:2004.04072", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lCNN-MoE based framework for classification of respiratory anomalies and lung disease detection\\u00a7r\\n\\n\\u00a78\\u00a7oLam Pham\\nHuy Phan\\nRamaswamy Palaniappan\\nAlfred Mertins\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2004.04072\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 2 Jun 2020 19:55:28 GMT)\\u00a7r"}']}
{title:'Cai et al. (§72020§r)', author: 'Yunqi Cai; Lantian Li; Dong Wang; Andrew Abel', display:{Lore:['[{"text": "arXiv:2004.04095", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDeep Normalization for Speaker Vectors\\u00a7r\\n\\n\\u00a78\\u00a7oYunqi Cai\\nLantian Li\\nDong Wang\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2004.04095\\u00a7r\\n\\nVersion:\\u00a77v2 (Mon, 2 Nov 2020 02:27:10 GMT)\\u00a7r"}']}
{title:'Silnova et al. (§72020§r)', author: 'Anna Silnova; Niko Brümmer; Johan Rohdin; Themos Stafylakis; Lukáš Burget', display:{Lore:['[{"text": "arXiv:2004.04096", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lProbabilistic embeddings for speaker diarization\\u00a7r\\n\\n\\u00a78\\u00a7oAnna Silnova\\nNiko Br\\u00fcmmer\\nJohan Rohdin\\nThemos Stafylakis\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2004.04096\\u00a7r\\n\\nVersion:\\u00a77v3 (Fri, 6 Nov 2020 06:16:16 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAwarded: Jack Godfrey Best Student Paper Award, at Odyssey 2020: The Speaker and Language Recognition Workshop, Tokio\\u00a7r"}']}
{title:'Hsieh et al. (§72020§r)', author: 'Tsun-An Hsieh; Hsin-Min Wang; Xugang Lu; Yu Tsao', display:{Lore:['[{"text": "arXiv:2004.04098", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lWaveCRN: An Efficient Convolutional Recurrent Neural Network for End-to-end Speech Enhancement\\u00a7r\\n\\n\\u00a78\\u00a7oTsun-An Hsieh\\nHsin-Min Wang\\nXugang Lu\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2004.04098\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/LSP.2020.3040693\\u00a7r\\n\\nVersion:\\u00a77v3 (Thu, 26 Nov 2020 07:28:32 GMT)\\u00a7r"}']}
{title:'Shukla (§72020§r)', author: 'Rachit Shukla', display:{Lore:['[{"text": "arXiv:2004.04099", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7eeess.SP\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lKeywords Extraction and Sentiment Analysis using Automatic Speech Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oRachit Shukla\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2004.04099\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 7 Apr 2020 05:37:36 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o23 pages, 20 figures. Based on the work doneas a part of the ScienceAcademies\' Summer Research Fellowship Programme (SRFP \'19) at Vij\\u00f1a Labs\\u00a7r"}']}
{title:'Moine et al. (§72020§r)', author: 'Clément Le Moine; Nicolas Obin', display:{Lore:['[{"text": "arXiv:2004.04410", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAtt-HACK: An Expressive Speech Database with Social Attitudes\\u00a7r\\n\\n\\u00a78\\u00a7oCl\\u00e9ment Le Moine\\nNicolas Obin\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2004.04410\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 9 Apr 2020 08:09:59 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 5 figures\\u00a7r"}']}
{title:'Lee et al. (§72020§r)', author: 'Woo Seok Lee; Hyunjae Kim; Andrew N. Cleland; Kang-Hun Ahn', display:{Lore:['[{"text": "arXiv:2004.04459", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a75physics.bio-ph\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lFast frequency discrimination and phoneme recognition using a biomimetic membrane coupled to a neural network\\u00a7r\\n\\n\\u00a78\\u00a7oWoo Seok Lee\\nHyunjae Kim\\nAndrew N. Cleland\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2004.04459\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 9 Apr 2020 10:07:12 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o7 pages, 4 figures\\u00a7r"}']}
{title:'Krishna et al. (§72020§r)', author: 'Gautam Krishna; Co Tran; Mason Carnahan; Ahmed Tewfik', display:{Lore:['[{"text": "arXiv:2004.04731", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAdvancing Speech Synthesis using EEG\\u00a7r\\n\\n\\u00a78\\u00a7oGautam Krishna\\nCo Tran\\nMason Carnahan\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2004.04731\\u00a7r\\n\\nVersion:\\u00a77v2 (Sun, 3 May 2020 20:33:36 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oUnder review\\u00a7r"}']}
{title:'Chung et al. (§72020§r)', author: 'Yu-An Chung; James Glass', display:{Lore:['[{"text": "arXiv:2004.05274", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lImproved Speech Representations with Multi-Target Autoregressive Predictive Coding\\u00a7r\\n\\n\\u00a78\\u00a7oYu-An Chung\\nJames Glass\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2004.05274\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 11 Apr 2020 01:09:36 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted to ACL 2020\\u00a7r"}']}
{title:'Choi et al. (§72020§r)', author: 'Hyeong-Seok Choi; Changdae Park; Kyogu Lee', display:{Lore:['[{"text": "arXiv:2004.05830", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CV\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7eeess.IV\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lFrom Inference to Generation: End-to-end Fully Self-supervised Generation of Human Face from Speech\\u00a7r\\n\\n\\u00a78\\u00a7oHyeong-Seok Choi\\nChangdae Park\\nKyogu Lee\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2004.05830\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 13 Apr 2020 09:01:49 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o18 pages, 12 figures, Published as a conference paper at International Conference on Learning Representations (ICLR)2020. (camera-ready version)\\u00a7r"}']}
{title:'Mirheidari et al. (§72020§r)', author: "Bahman Mirheidari; Yilin Pan; Daniel Blackburn; Ronan O'Malley; Traci Walker; Annalena Venneri; Markus Reuber; Heidi Christensen", display:{Lore:['[{"text": "arXiv:2004.05989", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lData augmentation using generative networks to identify dementia\\u00a7r\\n\\n\\u00a78\\u00a7oBahman Mirheidari\\nYilin Pan\\nDaniel Blackburn\\n+ 4 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2004.05989\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 13 Apr 2020 15:05:24 GMT)\\u00a7r"}']}
{title:'Ma et al. (§72020§r)', author: 'Chao Ma; Dongmei Li; Xupeng Jia', display:{Lore:['[{"text": "arXiv:2004.06332", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lTwo-stage model and optimal SI-SNR for monaural multi-speaker speech separation in noisy environment\\u00a7r\\n\\n\\u00a78\\u00a7oChao Ma\\nDongmei Li\\nXupeng Jia\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2004.06332\\u00a7r\\n\\nVersion:\\u00a77v2 (Sat, 1 Aug 2020 08:47:17 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oThis paper has been rejectted by INTERSPEECH 2020. It has been modified extensively and submitted to APSIPA ASC2020\\u00a7r"}']}
{title:'Yolchuyeva et al. (§72020§r)', author: 'Sevinj Yolchuyeva; Géza Németh; Bálint Gyires-Tóth', display:{Lore:['[{"text": "arXiv:2004.06338", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lTransformer based Grapheme-to-Phoneme Conversion\\u00a7r\\n\\n\\u00a78\\u00a7oSevinj Yolchuyeva\\nG\\u00e9za N\\u00e9meth\\nB\\u00e1lint Gyires-T\\u00f3th\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2004.06338\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.21437/Interspeech.2019-1954\\u00a7r\\n\\nVersion:\\u00a77v2 (Fri, 26 Jun 2020 21:09:53 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oINTERSPEECH 2019\\u00a7r"}']}
{title:'Tak et al. (§72020§r)', author: 'Hemlata Tak; Jose Patino; Andreas Nautsch; Nicholas Evans; Massimiliano Todisco', display:{Lore:['[{"text": "arXiv:2004.06422", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAn explainability study of the constant Q cepstral coefficient spoofing countermeasure for automatic speaker verification\\u00a7r\\n\\n\\u00a78\\u00a7oHemlata Tak\\nJose Patino\\nAndreas Nautsch\\nNicholas Evans\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2004.06422\\u00a7r\\n\\nVersion:\\u00a77v3 (Sun, 19 Apr 2020 13:23:20 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted to Speaker Odyssey (The Speaker and Language Recognition Workshop), 2020, 8 pages\\u00a7r"}']}
{title:'Wilkinson et al. (§72020§r)', author: 'N. Wilkinson; A. Biswas; E. Yılmaz; F. de Wet; E. van der Westhuizen; T. R. Niesler', display:{Lore:['[{"text": "arXiv:2004.06480", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSemi-supervised acoustic modelling for five-lingual code-switched ASR using automatically-segmented soap opera speech\\u00a7r\\n\\n\\u00a78\\u00a7oN. Wilkinson\\nA. Biswas\\nE. Y\\u0131lmaz\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2004.06480\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 8 Apr 2020 04:36:25 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSLTU 2020. arXiv admin note: text overlap with arXiv:2003.03135\\u00a7r"}']}
{title:'Denk et al. (§72020§r)', author: 'Florian Denk; Birger Kollmeier', display:{Lore:['[{"text": "arXiv:2004.06579", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lThe Hearpiece database of individual transfer functions of an openly available in-the-ear earpiece for hearing device research\\u00a7r\\n\\n\\u00a78\\u00a7oFlorian Denk\\nBirger Kollmeier\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2004.06579\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 14 Apr 2020 15:04:18 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o14 pages, 13 figures\\u00a7r"}']}
{title:'Park et al. (§72020§r)', author: 'Tae Jin Park; Kyu J. Han; Jing Huang; Xiaodong He; Bowen Zhou; Panayiotis Georgiou; Shrikanth Narayanan', display:{Lore:['[{"text": "arXiv:2004.06756", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSpeaker Diarization with Lexical Information\\u00a7r\\n\\n\\u00a78\\u00a7oTae Jin Park\\nKyu J. Han\\nJing Huang\\n+ 3 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2004.06756\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.21437/Interspeech.2019-1947\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nInterspeech 2019, 391-395\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 13 Apr 2020 17:16:56 GMT)\\u00a7r"}']}
{title:'Luz et al. (§72020§r)', author: 'Saturnino Luz; Fasih Haider; Sofia de la Fuente; Davida Fromm; Brian MacWhinney', display:{Lore:['[{"text": "arXiv:2004.06833", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAlzheimer\'s Dementia Recognition through Spontaneous Speech: The ADReSS Challenge\\u00a7r\\n\\n\\u00a78\\u00a7oSaturnino Luz\\nFasih Haider\\nSofia de la Fuente\\nDavida Fromm\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2004.06833\\u00a7r\\n\\nVersion:\\u00a77v3 (Wed, 5 Aug 2020 22:44:29 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oTo appear in the Proceedings of INTERSPEECH 2020, Oct 2020, Shanghai, China\\u00a7r"}']}
{title:'Qian et al. (§72020§r)', author: 'Kaizhi Qian; Zeyu Jin; Mark Hasegawa-Johnson; Gautham J. Mysore', display:{Lore:['[{"text": "arXiv:2004.07370", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lF0-consistent many-to-many non-parallel voice conversion via conditional autoencoder\\u00a7r\\n\\n\\u00a78\\u00a7oKaizhi Qian\\nZeyu Jin\\nMark Hasegawa-Johnson\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2004.07370\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/ICASSP40776.2020.9054734\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 15 Apr 2020 22:00:06 GMT)\\u00a7r"}']}
{title:'Ai et al. (§72020§r)', author: 'Yang Ai; Zhen-Hua Ling', display:{Lore:['[{"text": "arXiv:2004.07832", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lKnowledge-and-Data-Driven Amplitude Spectrum Prediction for Hierarchical Neural Vocoders\\u00a7r\\n\\n\\u00a78\\u00a7oYang Ai\\nZhen-Hua Ling\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2004.07832\\u00a7r\\n\\nVersion:\\u00a77v2 (Mon, 18 May 2020 07:35:35 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to Interspeech 2020\\u00a7r"}']}
{title:'Makiuchi et al. (§72020§r)', author: 'Mariana Rodrigues Makiuchi; Tifani Warnita; Nakamasa Inoue; Koichi Shinoda; Michitaka Yoshimura; Momoko Kitazawa; Kei Funaki; Yoko Eguchi; Taishiro Kishimoto', display:{Lore:['[{"text": "arXiv:2004.07992", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7bq-bio.QM\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSpeech Paralinguistic Approach for Detecting Dementia Using Gated Convolutional Neural Network\\u00a7r\\n\\n\\u00a78\\u00a7oMariana Rodrigues Makiuchi\\nTifani Warnita\\nNakamasa Inoue\\n+ 5 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2004.07992\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1587/transinf.2020EDP7196\\u00a7r\\n\\nVersion:\\u00a77v3 (Tue, 6 Oct 2020 13:00:27 GMT)\\u00a7r"}']}
{title:'Bhattacharyya et al. (§72020§r)', author: 'Chirayata Bhattacharyya; Sourya Sengupta; Sayan Nag; Shankha Sanyal; Archi Banerjee; Ranjan Sengupta; Dipak Ghosh', display:{Lore:['[{"text": "arXiv:2004.08248", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a75nlin.CD\\u00a7r, \\u00a7bq-bio.NC\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAcoustical classification of different speech acts using nonlinear methods\\u00a7r\\n\\n\\u00a78\\u00a7oChirayata Bhattacharyya\\nSourya Sengupta\\nSayan Nag\\n+ 3 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2004.08248\\u00a7r\\n\\nVersion:\\u00a77v2 (Wed, 5 Aug 2020 09:11:36 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o6 pages, 2 figures; Proceedings of WESPAC2018, New Delhi, India, November 11-15, 2018\\u00a7r"}']}
{title:'Sterpu et al. (§72020§r)', author: 'George Sterpu; Christian Saam; Naomi Harte', display:{Lore:['[{"text": "arXiv:2004.08250", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lHow to Teach DNNs to Pay Attention to the Visual Modality in Speech Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oGeorge Sterpu\\nChristian Saam\\nNaomi Harte\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2004.08250\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/TASLP.2020.2980436\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 17 Apr 2020 13:59:19 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oin IEEE/ACM Transactionson Audio, Speech, and Language Processing (to appear)\\u00a7r"}']}
{title:'Acharya et al. (§72020§r)', author: 'Jyotibdha Acharya; Arindam Basu', display:{Lore:['[{"text": "arXiv:2004.08287", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDeep Neural Network for Respiratory Sound Classification in Wearable Devices Enabled by Patient Specific Model Tuning\\u00a7r\\n\\n\\u00a78\\u00a7oJyotibdha Acharya\\nArindam Basu\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2004.08287\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/TBCAS.2020.2981172\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 16 Apr 2020 15:42:58 GMT)\\u00a7r"}']}
{title:'Xu et al. (§72020§r)', author: 'Chenglin Xu; Wei Rao; Eng Siong Chng; Haizhou Li', display:{Lore:['[{"text": "arXiv:2004.08326", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSpEx: Multi-Scale Time Domain Speaker Extraction Network\\u00a7r\\n\\n\\u00a78\\u00a7oChenglin Xu\\nWei Rao\\nEng Siong Chng\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2004.08326\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/TASLP.2020.2987429\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nIEEE/ACM Transactions on Audio, Speech, and Language Processing,\\n  2020\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 17 Apr 2020 16:13:06 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oACCEPTED in IEEE/ACM Transactionson Audio, Speech, and Language Processing (TASLP)\\u00a7r"}']}
{title:'Majumdar et al. (§72020§r)', author: 'Somshubra Majumdar; Boris Ginsburg', display:{Lore:['[{"text": "arXiv:2004.08531", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMatchboxNet: 1D Time-Channel Separable Convolutional Neural Network Architecture for Speech Commands Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oSomshubra Majumdar\\nBoris Ginsburg\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2004.08531\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.21437/Interspeech.2020-1058\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 21 Apr 2020 04:46:22 GMT)\\u00a7r"}']}
{title:'Das et al. (§72020§r)', author: 'Rohan Kumar Das; Xiaohai Tian; Tomi Kinnunen; Haizhou Li', display:{Lore:['[{"text": "arXiv:2004.08849", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CR\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lThe Attacker\'s Perspective on Automatic Speaker Verification: An Overview\\u00a7r\\n\\n\\u00a78\\u00a7oRohan Kumar Das\\nXiaohai Tian\\nTomi Kinnunen\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2004.08849\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 19 Apr 2020 13:27:25 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 1 figure, Submitted to Interspeech 2020\\u00a7r"}']}
{title:'Datta et al. (§72020§r)', author: 'Arindrima Datta; Bhuvana Ramabhadran; Jesse Emond; Anjuli Kannan; Brian Roark', display:{Lore:['[{"text": "arXiv:2004.09571", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lLanguage-agnostic Multilingual Modeling\\u00a7r\\n\\n\\u00a78\\u00a7oArindrima Datta\\nBhuvana Ramabhadran\\nJesse Emond\\nAnjuli Kannan\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2004.09571\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 20 Apr 2020 18:57:43 GMT)\\u00a7r"}']}
{title:'Chinen et al. (§72020§r)', author: "Michael Chinen; Felicia S. C. Lim; Jan Skoglund; Nikita Gureev; Feargus O'Gorman; Andrew Hines", display:{Lore:['[{"text": "arXiv:2004.09584", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7eeess.SP\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lViSQOL v3: An Open Source Production Ready Objective Speech and Audio Metric\\u00a7r\\n\\n\\u00a78\\u00a7oMichael Chinen\\nFelicia S. C. Lim\\nJan Skoglund\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2004.09584\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 20 Apr 2020 19:19:26 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o2020 Twelfth International Conference on Quality of Multimedia Experience (QoMEX)\\u00a7r"}']}
{title:'Phung et al. (§72020§r)', author: 'Viet Lam Phung; Phan Huy Kinh; Anh Tuan Dinh; Quoc Bao Nguyen', display:{Lore:['[{"text": "arXiv:2004.09607", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lData Processing for Optimizing Naturalness of Vietnamese Text-to-speech System\\u00a7r\\n\\n\\u00a78\\u00a7oViet Lam Phung\\nPhan Huy Kinh\\nAnh Tuan Dinh\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2004.09607\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 20 Apr 2020 20:11:53 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o8 pages, 2 figures, submitto Oriental Cocosda\\u00a7r"}']}
{title:'Hadjeres et al. (§72020§r)', author: 'Gaëtan Hadjeres; Léopold Crestel', display:{Lore:['[{"text": "arXiv:2004.10120", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lVector Quantized Contrastive Predictive Coding for Template-based Music Generation\\u00a7r\\n\\n\\u00a78\\u00a7oGa\\u00ebtan Hadjeres\\nL\\u00e9opold Crestel\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2004.10120\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 21 Apr 2020 15:58:17 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o15 pages, 13 figures\\u00a7r"}']}
{title:'Raja (§72020§r)', author: 'Shakeel Raja', display:{Lore:['[{"text": "arXiv:2004.10246", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMusic Generation with Temporal Structure Augmentation\\u00a7r\\n\\n\\u00a78\\u00a7oShakeel Raja\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2004.10246\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 21 Apr 2020 19:19:58 GMT)\\u00a7r"}']}
{title:'Tsai (§72020§r)', author: 'TJ Tsai', display:{Lore:['[{"text": "arXiv:2004.10391", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.MM\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7eeess.IV\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lTowards Linking the Lakh and IMSLP Datasets\\u00a7r\\n\\n\\u00a78\\u00a7oTJ Tsai\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2004.10391\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/ICASSP40776.2020.9053815\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 22 Apr 2020 04:13:10 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 4 figures, 1 table. Accepted paper at the International Conference on Acoustics, Speech, and Signal Processing (ICASSP) 2020\\u00a7r"}']}
{title:'Andrusenko et al. (§72020§r)', author: 'Andrei Andrusenko; Aleksandr Laptev; Ivan Medennikov', display:{Lore:['[{"text": "arXiv:2004.10799", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lTowards a Competitive End-to-End Speech Recognition for CHiME-6 Dinner Party Transcription\\u00a7r\\n\\n\\u00a78\\u00a7oAndrei Andrusenko\\nAleksandr Laptev\\nIvan Medennikov\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2004.10799\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.21437/Interspeech.2020-1074\\u00a7r\\n\\nVersion:\\u00a77v3 (Fri, 7 Aug 2020 19:36:44 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted by Interspeech 2020\\u00a7r"}']}
{title:'Koriyama et al. (§72020§r)', author: 'Tomoki Koriyama; Hiroshi Saruwatari', display:{Lore:['[{"text": "arXiv:2004.10823", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lUtterance-level Sequential Modeling For Deep Gaussian Process Based Speech Synthesis Using Simple Recurrent Unit\\u00a7r\\n\\n\\u00a78\\u00a7oTomoki Koriyama\\nHiroshi Saruwatari\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2004.10823\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 22 Apr 2020 19:51:36 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages. Accepted by ICASSP2020\\u00a7r"}']}
{title:'Mokrý et al. (§72020§r)', author: 'Ondřej Mokrý; Pavel Rajmic; Pavel Záviška', display:{Lore:['[{"text": "arXiv:2004.11162", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lFlexible framework for audio reconstruction\\u00a7r\\n\\n\\u00a78\\u00a7oOnd\\u0159ej Mokr\\u00fd\\nPavel Rajmic\\nPavel Z\\u00e1vi\\u0161ka\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2004.11162\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7n23rd International Conference on Digital Audio Effects (eDAFx2020)\\u00a7r\\n\\nVersion:\\u00a77v2 (Wed, 29 Jul 2020 13:17:57 GMT)\\u00a7r"}']}
{title:'Li et al. (§72020§r)', author: 'Bo Li; Shuo-yiin Chang; Tara N. Sainath; Ruoming Pang; Yanzhang He; Trevor Strohman; Yonghui Wu', display:{Lore:['[{"text": "arXiv:2004.11544", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lTowards Fast and Accurate Streaming End-to-End ASR\\u00a7r\\n\\n\\u00a78\\u00a7oBo Li\\nShuo-yiin Chang\\nTara N. Sainath\\n+ 3 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2004.11544\\u00a7r\\n\\nVersion:\\u00a77v2 (Wed, 13 May 2020 00:52:57 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted in ICASSP 2020\\u00a7r"}']}
{title:'Corey et al. (§72020§r)', author: 'Ryan M. Corey; Andrew C. Singer', display:{Lore:['[{"text": "arXiv:2004.11956", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lBinaural Audio Source Remixing with Microphone Array Listening Devices\\u00a7r\\n\\n\\u00a78\\u00a7oRyan M. Corey\\nAndrew C. Singer\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2004.11956\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 24 Apr 2020 19:34:38 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oTo appear at ICASSP 2020\\u00a7r"}']}
{title:'Imoto et al. (§72020§r)', author: 'Keisuke Imoto; Seisuke Kyochi', display:{Lore:['[{"text": "arXiv:2004.12046", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSound Event Detection Utilizing Graph Laplacian Regularization with Event Co-occurrence\\u00a7r\\n\\n\\u00a78\\u00a7oKeisuke Imoto\\nSeisuke Kyochi\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2004.12046\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1587/transinf.2019EDP7323\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 25 Apr 2020 03:14:53 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted to IEICE Transactions on Information and Systems\\u00a7r"}']}
{title:'Meng et al. (§72020§r)', author: 'Zhong Meng; M Umair Bin Altaf; Biing-Hwang; Juang', display:{Lore:['[{"text": "arXiv:2004.12071", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7eeess.SP\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lActive Voice Authentication\\u00a7r\\n\\n\\u00a78\\u00a7oZhong Meng\\nM Umair Bin Altaf\\nBiing-Hwang\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2004.12071\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nDigital Signal Processing, Volume 101, June 2020, 102672, ISSN\\n  1051-2004\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 25 Apr 2020 07:08:41 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o39 pages, 4 figures\\u00a7r"}']}
{title:'Yiallourides et al. (§72020§r)', author: 'Costas Yiallourides; Patrick A. Naylor', display:{Lore:['[{"text": "arXiv:2004.12745", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lTime-Frequency Analysis and Parameterisation of Knee Sounds for Non-invasive Detection of Osteoarthritis\\u00a7r\\n\\n\\u00a78\\u00a7oCostas Yiallourides\\nPatrick A. Naylor\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2004.12745\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 27 Apr 2020 12:40:47 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to IEEETransactions on Biomedical Engineering\\u00a7r"}']}
{title:'Colonel et al. (§72020§r)', author: 'Joseph Colonel; Christopher Curro; Sam Keene', display:{Lore:['[{"text": "arXiv:2004.13172", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAutoencoding Neural Networks as Musical Audio Synthesizers\\u00a7r\\n\\n\\u00a78\\u00a7oJoseph Colonel\\nChristopher Curro\\nSam Keene\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2004.13172\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nProceedings of the 21st International Conference on Digital Audio\\n  Effects (DAFx-18), 2018, pp40-44\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 27 Apr 2020 20:58:03 GMT)\\u00a7r"}']}
{title:'Meng et al. (§72020§r)', author: 'Zhong Meng; Hu Hu; Jinyu Li; Changliang Liu; Yan Huang; Yifan Gong; Chin-Hui Lee', display:{Lore:['[{"text": "arXiv:2004.13480", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lL-Vector: Neural Label Embedding for Domain Adaptation\\u00a7r\\n\\n\\u00a78\\u00a7oZhong Meng\\nHu Hu\\nJinyu Li\\n+ 3 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2004.13480\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7n2019 IEEE International Conference on Acoustics, Speech and Signal\\n  Processing (ICASSP), Barcelona, Spain\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 25 Apr 2020 06:40:31 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 2 figure, ICASSP 2020\\u00a7r"}']}
{title:'Sen (§72020§r)', author: 'Sourav Sen', display:{Lore:['[{"text": "arXiv:2004.13521", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDetect Language of Transliterated Texts\\u00a7r\\n\\n\\u00a78\\u00a7oSourav Sen\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2004.13521\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 26 Apr 2020 10:28:02 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o10 pages, 8 figures, 3 tables\\u00a7r"}']}
{title:'Fu et al. (§72020§r)', author: 'Li Fu; Xiaoxiao Li; Libo Zi', display:{Lore:['[{"text": "arXiv:2004.13522", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lResearch on Modeling Units of Transformer Transducer for Mandarin Speech Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oLi Fu\\nXiaoxiao Li\\nLibo Zi\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2004.13522\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 26 Apr 2020 05:12:52 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 3 figures\\u00a7r"}']}
{title:'Wang et al. (§72020§r)', author: 'Dongmei Wang; Zhuo Chen; Takuya Yoshioka', display:{Lore:['[{"text": "arXiv:2004.13670", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lNeural Speech Separation Using Spatially Distributed Microphones\\u00a7r\\n\\n\\u00a78\\u00a7oDongmei Wang\\nZhuo Chen\\nTakuya Yoshioka\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2004.13670\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 28 Apr 2020 17:16:31 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 2 figures, Interspeech2020\\u00a7r"}']}
{title:'Palkama et al. (§72020§r)', author: 'Kasperi Palkama; Lauri Juvela; Alexander Ilin', display:{Lore:['[{"text": "arXiv:2004.13764", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lConditional Spoken Digit Generation with StyleGAN\\u00a7r\\n\\n\\u00a78\\u00a7oKasperi Palkama\\nLauri Juvela\\nAlexander Ilin\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2004.13764\\u00a7r\\n\\nVersion:\\u00a77v3 (Tue, 15 Sep 2020 18:46:37 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oInterspeech2020 accepted version\\u00a7r"}']}
{title:'Karlapati et al. (§72020§r)', author: 'Sri Karlapati; Alexis Moinet; Arnaud Joly; Viacheslav Klimkov; Daniel Sáez-Trigueros; Thomas Drugman', display:{Lore:['[{"text": "arXiv:2004.14617", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lCopyCat: Many-to-Many Fine-Grained Prosody Transfer for Neural Text-to-Speech\\u00a7r\\n\\n\\u00a78\\u00a7oSri Karlapati\\nAlexis Moinet\\nArnaud Joly\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2004.14617\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.21437/Interspeech.2020-1251\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nINTERSPEECH 2020: 4387-4391\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 30 Apr 2020 07:42:29 GMT)\\u00a7r"}']}
{title:'Xu et al. (§72020§r)', author: 'Chenglin Xu; Wei Rao; Eng Siong Chng; Haizhou Li', display:{Lore:['[{"text": "arXiv:2004.14762", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lTime-domain speaker extraction network\\u00a7r\\n\\n\\u00a78\\u00a7oChenglin Xu\\nWei Rao\\nEng Siong Chng\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2004.14762\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/ASRU46091.2019.9004016\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 29 Apr 2020 07:42:31 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oPublished in ASRU2019. arXiv admin note: text overlap with arXiv:2004.08326\\u00a7r"}']}
{title:'Baby et al. (§72020§r)', author: 'Deepak Baby; Arthur Van Den Broucke; Sarah Verhulst', display:{Lore:['[{"text": "arXiv:2004.14832", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CE\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA convolutional neural-network model of human cochlear mechanics and filter tuning for real-time applications\\u00a7r\\n\\n\\u00a78\\u00a7oDeepak Baby\\nArthur Van Den Broucke\\nSarah Verhulst\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2004.14832\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1038/s42256-020-00286-8\\u00a7r\\n\\nVersion:\\u00a77v4 (Fri, 4 Dec 2020 20:08:14 GMT)\\u00a7r"}']}
{title:'Paraskevopoulos et al. (§72020§r)', author: 'Georgios Paraskevopoulos; Srinivas Parthasarathy; Aparna Khare; Shiva Sundaram', display:{Lore:['[{"text": "arXiv:2004.14840", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CV\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMultiresolution and Multimodal Speech Recognition with Transformers\\u00a7r\\n\\n\\u00a78\\u00a7oGeorgios Paraskevopoulos\\nSrinivas Parthasarathy\\nAparna Khare\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2004.14840\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 29 Apr 2020 09:32:11 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted for ACL 2020\\u00a7r"}']}
{title:'Vachhani et al. (§72020§r)', author: 'Bhavik Vachhani; Chitralekha Bhat; Sunil Kopparapu', display:{Lore:['[{"text": "arXiv:2004.14859", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lRobust Phonetic Segmentation Using Spectral Transition measure for Non-Standard Recording Environments\\u00a7r\\n\\n\\u00a78\\u00a7oBhavik Vachhani\\nChitralekha Bhat\\nSunil Kopparapu\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2004.14859\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 29 Apr 2020 16:32:52 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o6 pages, 6 figures\\u00a7r"}']}
{title:'Han et al. (§72020§r)', author: 'Jing Han; Kun Qian; Meishu Song; Zijiang Yang; Zhao Ren; Shuo Liu; Juan Liu; Huaiyuan Zheng; Wei Ji; Tomoya Koike; Xiao Li; Zixing Zhang; Yoshiharu Yamamoto; Björn W. Schuller', display:{Lore:['[{"text": "arXiv:2005.00096", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAn Early Study on Intelligent Analysis of Speech under COVID-19: Severity, Sleep Quality, Fatigue, and Anxiety\\u00a7r\\n\\n\\u00a78\\u00a7oJing Han\\nKun Qian\\nMeishu Song\\n+ 10 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.00096\\u00a7r\\n\\nVersion:\\u00a77v2 (Thu, 14 May 2020 10:00:08 GMT)\\u00a7r"}']}
{title:'Mezza et al. (§72020§r)', author: 'Alessandro Ilic Mezza; Emanuël A. P. Habets; Meinard Müller; Augusto Sarti', display:{Lore:['[{"text": "arXiv:2005.00145", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lUnsupervised Domain Adaptation for Acoustic Scene Classification Using Band-Wise Statistics Matching\\u00a7r\\n\\n\\u00a78\\u00a7oAlessandro Ilic Mezza\\nEmanu\\u00ebl A. P. Habets\\nMeinard M\\u00fcller\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.00145\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 30 Apr 2020 23:56:05 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 1 figure, 3 tables, submitted to EUSIPCO 2020\\u00a7r"}']}
{title:'Dhariwal et al. (§72020§r)', author: 'Prafulla Dhariwal; Heewoo Jun; Christine Payne; Jong Wook Kim; Alec Radford; Ilya Sutskever', display:{Lore:['[{"text": "arXiv:2005.00341", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lJukebox: A Generative Model for Music\\u00a7r\\n\\n\\u00a78\\u00a7oPrafulla Dhariwal\\nHeewoo Jun\\nChristine Payne\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.00341\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 30 Apr 2020 09:02:45 GMT)\\u00a7r"}']}
{title:'Cooper et al. (§72020§r)', author: 'Erica Cooper; Cheng-I Lai; Yusuke Yasuda; Junichi Yamagishi', display:{Lore:['[{"text": "arXiv:2005.01245", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lCan Speaker Augmentation Improve Multi-Speaker End-to-End TTS?\\u00a7r\\n\\n\\u00a78\\u00a7oErica Cooper\\nCheng-I Lai\\nYusuke Yasuda\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.01245\\u00a7r\\n\\nVersion:\\u00a77v2 (Fri, 7 Aug 2020 04:14:20 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted to Interspeech 2020\\u00a7r"}']}
{title:'Ibrahim et al. (§72020§r)', author: 'Omar Adel Ibrahim; Savio Sciancalepore; Roberto Di Pietro', display:{Lore:['[{"text": "arXiv:2005.01347", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7eeess.SP\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lNoise2Weight: On Detecting Payload Weight from Drones Acoustic Emissions\\u00a7r\\n\\n\\u00a78\\u00a7oOmar Adel Ibrahim\\nSavio Sciancalepore\\nRoberto Di Pietro\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.01347\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 4 May 2020 09:44:18 GMT)\\u00a7r"}']}
{title:'Mokrý et al. (§72020§r)', author: 'Ondřej Mokrý; Pavel Rajmic', display:{Lore:['[{"text": "arXiv:2005.01437", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7eeess.SP\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lApproximal operator with application to audio inpainting\\u00a7r\\n\\n\\u00a78\\u00a7oOnd\\u0159ej Mokr\\u00fd\\nPavel Rajmic\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.01437\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1016/j.sigpro.2020.107807\\u00a7r\\n\\nVersion:\\u00a77v3 (Mon, 14 Sep 2020 13:17:24 GMT)\\u00a7r"}']}
{title:'Han et al. (§72020§r)', author: 'Wei Han; Zhengdong Zhang; Yu Zhang; Jiahui Yu; Chung-Cheng Chiu; James Qin; Anmol Gulati; Ruoming Pang; Yonghui Wu', display:{Lore:['[{"text": "arXiv:2005.03191", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lContextNet: Improving Convolutional Neural Networks for Automatic Speech Recognition with Global Context\\u00a7r\\n\\n\\u00a78\\u00a7oWei Han\\nZhengdong Zhang\\nYu Zhang\\n+ 5 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.03191\\u00a7r\\n\\nVersion:\\u00a77v3 (Sat, 16 May 2020 00:49:21 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to Interspeech 2020\\u00a7r"}']}
{title:'Ding et al. (§72020§r)', author: 'Shaojin Ding; Tianlong Chen; Xinyu Gong; Weiwei Zha; Zhangyang Wang', display:{Lore:['[{"text": "arXiv:2005.03215", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAutoSpeech: Neural Architecture Search for Speaker Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oShaojin Ding\\nTianlong Chen\\nXinyu Gong\\nWeiwei Zha\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.03215\\u00a7r\\n\\nVersion:\\u00a77v2 (Mon, 31 Aug 2020 15:53:27 GMT)\\u00a7r"}']}
{title:'Chiu et al. (§72020§r)', author: 'Chung-Cheng Chiu; Arun Narayanan; Wei Han; Rohit Prabhavalkar; Yu Zhang; Navdeep Jaitly; Ruoming Pang; Tara N. Sainath; Patrick Nguyen; Liangliang Cao; Yonghui Wu', display:{Lore:['[{"text": "arXiv:2005.03271", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lRNN-T Models Fail to Generalize to Out-of-Domain Audio: Causes and Solutions\\u00a7r\\n\\n\\u00a78\\u00a7oChung-Cheng Chiu\\nArun Narayanan\\nWei Han\\n+ 7 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.03271\\u00a7r\\n\\nVersion:\\u00a77v3 (Thu, 24 Dec 2020 00:48:31 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSLT camera-ready version\\u00a7r"}']}
{title:'Park et al. (§72020§r)', author: 'Seung-won Park; Doo-young Kim; Myun-chul Joe', display:{Lore:['[{"text": "arXiv:2005.03295", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lCotatron: Transcription-Guided Speech Encoder for Any-to-Many Voice Conversion without Parallel Data\\u00a7r\\n\\n\\u00a78\\u00a7oSeung-won Park\\nDoo-young Kim\\nMyun-chul Joe\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.03295\\u00a7r\\n\\nVersion:\\u00a77v2 (Fri, 14 Aug 2020 06:01:38 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oTo appear in INTERSPEECH 2020\\u00a7r"}']}
{title:'Kim et al. (§72020§r)', author: 'Seung-bin Kim; Jee-weon Jung; Hye-jin Shim; Ju-ho Kim; Ha-Jin Yu', display:{Lore:['[{"text": "arXiv:2005.03329", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSegment Aggregation for short utterances speaker verification using raw waveforms\\u00a7r\\n\\n\\u00a78\\u00a7oSeung-bin Kim\\nJee-weon Jung\\nHye-jin Shim\\nJu-ho Kim\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.03329\\u00a7r\\n\\nVersion:\\u00a77v3 (Tue, 4 Aug 2020 05:40:15 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, accepted by INTERSPEECH 2020\\u00a7r"}']}
{title:'Tanaka et al. (§72020§r)', author: 'Masaya Tanaka; Takashi Nose; Aoi Kanagaki; Ryohei Shimizu; Akira Ito', display:{Lore:['[{"text": "arXiv:2005.03334", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lScyclone: High-Quality and Parallel-Data-Free Voice Conversion Using Spectrogram and Cycle-Consistent Adversarial Networks\\u00a7r\\n\\n\\u00a78\\u00a7oMasaya Tanaka\\nTakashi Nose\\nAoi Kanagaki\\nRyohei Shimizu\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.03334\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 7 May 2020 09:05:34 GMT)\\u00a7r"}']}
{title:'Wu et al. (§72020§r)', author: 'Haiwei Wu; Yan Jia; Yuanfei Nie; Ming Li', display:{Lore:['[{"text": "arXiv:2005.03633", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDomain Aware Training for Far-field Small-footprint Keyword Spotting\\u00a7r\\n\\n\\u00a78\\u00a7oHaiwei Wu\\nYan Jia\\nYuanfei Nie\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.03633\\u00a7r\\n\\nVersion:\\u00a77v3 (Fri, 7 Aug 2020 16:19:46 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to INTERSPEECH 2020\\u00a7r"}']}
{title:'Jung et al. (§72020§r)', author: 'Myunghun Jung; Youngmoon Jung; Jahyun Goo; Hoirin Kim', display:{Lore:['[{"text": "arXiv:2005.03867", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMulti-Task Network for Noise-Robust Keyword Spotting and Speaker Verification using CTC-based Soft VAD and Global Query Attention\\u00a7r\\n\\n\\u00a78\\u00a7oMyunghun Jung\\nYoungmoon Jung\\nJahyun Goo\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.03867\\u00a7r\\n\\nVersion:\\u00a77v4 (Fri, 7 Aug 2020 07:23:57 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted to Interspeech 2020\\u00a7r"}']}
{title:'Xu et al. (§72020§r)', author: 'Yong Xu; Meng Yu; Shi-Xiong Zhang; Lianwu Chen; Chao Weng; Jianming Liu; Dong Yu', display:{Lore:['[{"text": "arXiv:2005.03889", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lNeural Spatio-Temporal Beamformer for Target Speech Separation\\u00a7r\\n\\n\\u00a78\\u00a7oYong Xu\\nMeng Yu\\nShi-Xiong Zhang\\n+ 3 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.03889\\u00a7r\\n\\nVersion:\\u00a77v5 (Fri, 31 Jul 2020 08:19:07 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oaccepted to Interspeech2020, Demo: https://yongxuustc.github.io/mtmvdr/\\u00a7r"}']}
{title:'Pariente et al. (§72020§r)', author: 'Manuel Pariente; Samuele Cornell; Joris Cosentino; Sunit Sivasankaran; Efthymios Tzinis; Jens Heitkaemper; Michel Olvera; Fabian-Robert Stöter; Mathieu Hu; Juan M. Martín-Doñas; David Ditter; Ariel Frank; Antoine Deleforge; Emmanuel Vincent', display:{Lore:['[{"text": "arXiv:2005.04132", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAsteroid: the PyTorch-based audio source separation toolkit for researchers\\u00a7r\\n\\n\\u00a78\\u00a7oManuel Pariente\\nSamuele Cornell\\nJoris Cosentino\\n+ 10 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.04132\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 8 May 2020 16:18:34 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to Interspeech 2020\\u00a7r"}']}
{title:'Huang et al. (§72020§r)', author: "Jocelyn Huang; Oleksii Kuchaiev; Patrick O'Neill; Vitaly Lavrukhin; Jason Li; Adriana Flores; Georg Kucsko; Boris Ginsburg", display:{Lore:['[{"text": "arXiv:2005.04290", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lCross-Language Transfer Learning, Continuous Learning, and Domain Adaptation for End-to-End Automatic Speech Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oJocelyn Huang\\nOleksii Kuchaiev\\nPatrick O\'Neill\\n+ 4 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.04290\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 8 May 2020 21:04:36 GMT)\\u00a7r"}']}
{title:'Wang et al. (§72020§r)', author: 'Hao Wang; Kai Chen; Jing Lu', display:{Lore:['[{"text": "arXiv:2005.04376", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lU-net Based Direct-path Dominance Test for Robust Direction-of-arrival Estimation\\u00a7r\\n\\n\\u00a78\\u00a7oHao Wang\\nKai Chen\\nJing Lu\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.04376\\u00a7r\\n\\nVersion:\\u00a77v3 (Sat, 1 Aug 2020 05:04:15 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 4 figures, 3 tables. submitted to INTERSPEECH 2020\\u00a7r"}']}
{title:'Cai et al. (§72020§r)', author: 'Zexin Cai; Chuxiong Zhang; Ming Li', display:{Lore:['[{"text": "arXiv:2005.04587", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lFrom Speaker Verification to Multispeaker Speech Synthesis, Deep Transfer with Feedback Constraint\\u00a7r\\n\\n\\u00a78\\u00a7oZexin Cai\\nChuxiong Zhang\\nMing Li\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.04587\\u00a7r\\n\\nVersion:\\u00a77v3 (Tue, 4 Aug 2020 13:55:25 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted by INTERSPEECH 2020\\u00a7r"}']}
{title:'Ge et al. (§72020§r)', author: 'Meng Ge; Chenglin Xu; Longbiao Wang; Eng Siong Chng; Jianwu Dang; Haizhou Li', display:{Lore:['[{"text": "arXiv:2005.04686", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSpEx+: A Complete Time Domain Speaker Extraction Network\\u00a7r\\n\\n\\u00a78\\u00a7oMeng Ge\\nChenglin Xu\\nLongbiao Wang\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.04686\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 18 Aug 2020 03:03:01 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oaccepted in INTERSPEECH 2020\\u00a7r"}']}
{title:'Bai et al. (§72020§r)', author: 'Ye Bai; Jiangyan Yi; Jianhua Tao; Zhengkun Tian; Zhengqi Wen; Shuai Zhang', display:{Lore:['[{"text": "arXiv:2005.04862", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lListen Attentively, and Spell Once: Whole Sentence Generation via a Non-Autoregressive Architecture for Low-Latency Speech Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oYe Bai\\nJiangyan Yi\\nJianhua Tao\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.04862\\u00a7r\\n\\nVersion:\\u00a77v4 (Thu, 6 Aug 2020 01:26:15 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oaccepted by INTERSPEECH2020\\u00a7r"}']}
{title:'Drugman et al. (§72020§r)', author: 'Thomas Drugman; Jerome Urbain; Nathalie Bauwens; Ricardo Chessini; Anne-Sophie Aubriot; Patrick Lebecque; Thierry Dutoit', display:{Lore:['[{"text": "arXiv:2005.05313", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAudio and Contact Microphones for Cough Detection\\u00a7r\\n\\n\\u00a78\\u00a7oThomas Drugman\\nJerome Urbain\\nNathalie Bauwens\\n+ 3 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.05313\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 10 May 2020 17:58:21 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oarXiv admin note: substantial text overlap with arXiv:2001.00537\\u00a7r"}']}
{title:'Beliaev et al. (§72020§r)', author: 'Stanislav Beliaev; Yurii Rebryk; Boris Ginsburg', display:{Lore:['[{"text": "arXiv:2005.05514", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lTalkNet: Fully-Convolutional Non-Autoregressive Speech Synthesis Model\\u00a7r\\n\\n\\u00a78\\u00a7oStanislav Beliaev\\nYurii Rebryk\\nBoris Ginsburg\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.05514\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 12 May 2020 01:52:28 GMT)\\u00a7r"}']}
{title:'Abavisani et al. (§72020§r)', author: 'Ali Abavisani; Mark Hasegawa-Johnson', display:{Lore:['[{"text": "arXiv:2005.06065", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAutomatic Estimation of Intelligibility Measure for Consonants in Speech\\u00a7r\\n\\n\\u00a78\\u00a7oAli Abavisani\\nMark Hasegawa-Johnson\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.06065\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.21437/Interspeech.2020-2121\\u00a7r\\n\\nVersion:\\u00a77v2 (Sun, 28 Jun 2020 21:37:58 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 1 figure, 7 tables, submitted to Inter Speech 2020 Conference\\u00a7r"}']}
{title:'Pankajakshan et al. (§72020§r)', author: 'Arjun Pankajakshan; Helen L. Bear; Vinod Subramanian; Emmanouil Benetos', display:{Lore:['[{"text": "arXiv:2005.06650", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMemory Controlled Sequential Self Attention for Sound Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oArjun Pankajakshan\\nHelen L. Bear\\nVinod Subramanian\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.06650\\u00a7r\\n\\nVersion:\\u00a77v4 (Thu, 6 Aug 2020 00:32:51 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted to INTERSPEECH 2020\\u00a7r"}']}
{title:'Rybakov et al. (§72020§r)', author: 'Oleg Rybakov; Natasha Kononenko; Niranjan Subrahmanya; Mirko Visontai; Stella Laurenzo', display:{Lore:['[{"text": "arXiv:2005.06720", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lStreaming keyword spotting on mobile devices\\u00a7r\\n\\n\\u00a78\\u00a7oOleg Rybakov\\nNatasha Kononenko\\nNiranjan Subrahmanya\\nMirko Visontai\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.06720\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.21437/Interspeech.2020-1003\\u00a7r\\n\\nVersion:\\u00a77v2 (Wed, 29 Jul 2020 01:53:16 GMT)\\u00a7r"}']}
{title:'Di Benedetto et al. (§72020§r)', author: 'Maria Gabriella Di Benedetto; Luca De Nardis', display:{Lore:['[{"text": "arXiv:2005.06959", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lConsonant gemination in Italian: the affricate and fricative case\\u00a7r\\n\\n\\u00a78\\u00a7oMaria Gabriella Di Benedetto\\nLuca De Nardis\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.06959\\u00a7r\\n\\nVersion:\\u00a77v2 (Wed, 30 Sep 2020 09:46:00 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to Speech Communication. arXiv admin note: substantial text overlap with arXiv:2005.06960\\u00a7r"}']}
{title:'Di Benedetto et al. (§72020§r)', author: 'Maria-Gabriella Di Benedetto; Luca De Nardis', display:{Lore:['[{"text": "arXiv:2005.06960", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lConsonant gemination in Italian: the nasal and liquid case\\u00a7r\\n\\n\\u00a78\\u00a7oMaria-Gabriella Di Benedetto\\nLuca De Nardis\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.06960\\u00a7r\\n\\nVersion:\\u00a77v2 (Wed, 30 Sep 2020 09:44:15 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to Speech Communication. arXiv admin note: substantial text overlap with arXiv:2005.06959\\u00a7r"}']}
{title:'Olvera et al. (§72020§r)', author: 'Michel Olvera; Emmanuel Vincent; Romain Serizel; Gilles Gasso', display:{Lore:['[{"text": "arXiv:2005.07006", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7eeess.SP\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lForeground-Background Ambient Sound Scene Separation\\u00a7r\\n\\n\\u00a78\\u00a7oMichel Olvera\\nEmmanuel Vincent\\nRomain Serizel\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.07006\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7n28th European Signal Processing Conference (EUSIPCO), Jan 2021,\\n  Amsterdam, Netherlands\\u00a7r\\n\\nVersion:\\u00a77v2 (Mon, 27 Jul 2020 14:00:00 GMT)\\u00a7r"}']}
{title:'Chen et al. (§72020§r)', author: 'Yi-Chen Chen; Jui-Yang Hsu; Cheng-Kuang Lee; Hung-yi Lee', display:{Lore:['[{"text": "arXiv:2005.07029", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDARTS-ASR: Differentiable Architecture Search for Multilingual Speech Recognition and Adaptation\\u00a7r\\n\\n\\u00a78\\u00a7oYi-Chen Chen\\nJui-Yang Hsu\\nCheng-Kuang Lee\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.07029\\u00a7r\\n\\nVersion:\\u00a77v2 (Sun, 26 Jul 2020 02:40:53 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted at INTERSPEECH 2020\\u00a7r"}']}
{title:'Pinedo-Sanchez et al. (§72020§r)', author: 'Luis A. Pinedo-Sanchez; Diego A. Mercado-Ravell; Carlos A. Carballo-Monsivais', display:{Lore:['[{"text": "arXiv:2005.07057", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7eeess.SP\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lVibration Analysis in Bearings for Failure Prevention using CNN\\u00a7r\\n\\n\\u00a78\\u00a7oLuis A. Pinedo-Sanchez\\nDiego A. Mercado-Ravell\\nCarlos A. Carballo-Monsivais\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.07057\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1007/s40430-020-02711-w\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nJ Braz. Soc. Mech. Sci. Eng. 42, 628 (2020)\\u00a7r\\n\\nVersion:\\u00a77v2 (Thu, 16 Jul 2020 15:52:55 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oThis paper is a preprint of apaper submitted to Journal of the BrazilianSociety of Mechanical Sciences and Engineering\\u00a7r"}']}
{title:'Desplanques et al. (§72020§r)', author: 'Brecht Desplanques; Jenthe Thienpondt; Kris Demuynck', display:{Lore:['[{"text": "arXiv:2005.07143", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lECAPA-TDNN: Emphasized Channel Attention, Propagation and Aggregation in TDNN Based Speaker Verification\\u00a7r\\n\\n\\u00a78\\u00a7oBrecht Desplanques\\nJenthe Thienpondt\\nKris Demuynck\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.07143\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.21437/Interspeech.2020-2650\\u00a7r\\n\\nVersion:\\u00a77v3 (Mon, 10 Aug 2020 13:50:24 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oproceedings of INTERSPEECH 2020\\u00a7r"}']}
{title:'Laptev et al. (§72020§r)', author: 'Aleksandr Laptev; Roman Korostik; Aleksey Svischev; Andrei Andrusenko; Ivan Medennikov; Sergey Rybin', display:{Lore:['[{"text": "arXiv:2005.07157", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lYou Do Not Need More Data: Improving End-To-End Speech Recognition by Text-To-Speech Data Augmentation\\u00a7r\\n\\n\\u00a78\\u00a7oAleksandr Laptev\\nRoman Korostik\\nAleksey Svischev\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.07157\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/CISP-BMEI51763.2020.9263564\\u00a7r\\n\\nVersion:\\u00a77v2 (Thu, 30 Jul 2020 20:26:57 GMT)\\u00a7r"}']}
{title:'Medennikov et al. (§72020§r)', author: 'Ivan Medennikov; Maxim Korenevsky; Tatiana Prisyach; Yuri Khokhlov; Mariya Korenevskaya; Ivan Sorokin; Tatiana Timofeeva; Anton Mitrofanov; Andrei Andrusenko; Ivan Podluzhny; Aleksandr Laptev; Aleksei Romanenko', display:{Lore:['[{"text": "arXiv:2005.07272", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lTarget-Speaker Voice Activity Detection: a Novel Approach for Multi-Speaker Diarization in a Dinner Party Scenario\\u00a7r\\n\\n\\u00a78\\u00a7oIvan Medennikov\\nMaxim Korenevsky\\nTatiana Prisyach\\n+ 8 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.07272\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.21437/Interspeech.2020-1602\\u00a7r\\n\\nVersion:\\u00a77v2 (Mon, 27 Jul 2020 13:28:20 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted to Interspeech 2020\\u00a7r"}']}
{title:'Sarkar et al. (§72020§r)', author: 'Achintya Kumar Sarkar; Zheng-Hua Tan', display:{Lore:['[{"text": "arXiv:2005.07383", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lOn Bottleneck Features for Text-Dependent Speaker Verification Using X-vectors\\u00a7r\\n\\n\\u00a78\\u00a7oAchintya Kumar Sarkar\\nZheng-Hua Tan\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.07383\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 1 Sep 2020 14:21:11 GMT)\\u00a7r"}']}
{title:'Hsu et al. (§72020§r)', author: 'Po-chun Hsu; Hung-yi Lee', display:{Lore:['[{"text": "arXiv:2005.07412", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lWG-WaveNet: Real-Time High-Fidelity Speech Synthesis without GPU\\u00a7r\\n\\n\\u00a78\\u00a7oPo-chun Hsu\\nHung-yi Lee\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.07412\\u00a7r\\n\\nVersion:\\u00a77v3 (Thu, 20 Aug 2020 10:18:19 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oINTERSPEECH 2020\\u00a7r"}']}
{title:'Li et al. (§72020§r)', author: 'Hang Li; Zhiwei Wang; Jiliang Tang; Wenbiao Ding; Zitao Liu', display:{Lore:['[{"text": "arXiv:2005.07549", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSiamese Neural Networks for Class Activity Detection\\u00a7r\\n\\n\\u00a78\\u00a7oHang Li\\nZhiwei Wang\\nJiliang Tang\\nWenbiao Ding\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.07549\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 15 May 2020 14:03:35 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oThe 21th International Conference on Artificial Intelligence in Education(AIED), 2020\\u00a7r"}']}
{title:'Westhausen et al. (§72020§r)', author: 'Nils L. Westhausen; Bernd T. Meyer', display:{Lore:['[{"text": "arXiv:2005.07551", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDual-Signal Transformation LSTM Network for Real-Time Noise Suppression\\u00a7r\\n\\n\\u00a78\\u00a7oNils L. Westhausen\\nBernd T. Meyer\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.07551\\u00a7r\\n\\nVersion:\\u00a77v2 (Thu, 22 Oct 2020 15:29:44 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted by Interspeech 2020\\u00a7r"}']}
{title:'Kohlsdorf et al. (§72020§r)', author: 'Daniel Kohlsdorf; Denise Herzing; Thad Starner', display:{Lore:['[{"text": "arXiv:2005.07623", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAn Auto Encoder For Audio Dolphin Communication\\u00a7r\\n\\n\\u00a78\\u00a7oDaniel Kohlsdorf\\nDenise Herzing\\nThad Starner\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.07623\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 15 May 2020 16:30:04 GMT)\\u00a7r"}']}
{title:'Chen et al. (§72020§r)', author: 'Hongsheng Chen; Teng Xiang; Kai Chen; Jing Lu', display:{Lore:['[{"text": "arXiv:2005.07631", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lNonlinear Residual Echo Suppression Based on Multi-stream Conv-TasNet\\u00a7r\\n\\n\\u00a78\\u00a7oHongsheng Chen\\nTeng Xiang\\nKai Chen\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.07631\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 15 May 2020 16:41:16 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 3 figures\\u00a7r"}']}
{title:'Mohamed et al. (§72020§r)', author: 'Mostafa M. Mohamed; Björn W. Schuller', display:{Lore:['[{"text": "arXiv:2005.07757", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7l\\"I have vxxx bxx connexxxn!\\": Facing Packet Loss in Deep Speech Emotion Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oMostafa M. Mohamed\\nBj\\u00f6rn W. Schuller\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.07757\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 15 May 2020 19:33:40 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to INTERSPEECH 2020. 4 Pages + 1 page for references. 4 Figures and 2 Tables\\u00a7r"}']}
{title:'Mohamed et al. (§72020§r)', author: 'Mostafa M. Mohamed; Björn W. Schuller', display:{Lore:['[{"text": "arXiv:2005.07777", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lConcealNet: An End-to-end Neural Network for Packet Loss Concealment in Deep Speech Emotion Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oMostafa M. Mohamed\\nBj\\u00f6rn W. Schuller\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.07777\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 15 May 2020 20:43:02 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmission for INTERSPEECH 2020. 4 Pages + 1 references page. 4 Tables, 3 Figures\\u00a7r"}']}
{title:'Mishra et al. (§72020§r)', author: 'Saumitra Mishra; Emmanouil Benetos; Bob L. Sturm; Simon Dixon', display:{Lore:['[{"text": "arXiv:2005.07788", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lReliable Local Explanations for Machine Listening\\u00a7r\\n\\n\\u00a78\\u00a7oSaumitra Mishra\\nEmmanouil Benetos\\nBob L. Sturm\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.07788\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 15 May 2020 21:17:06 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o8 pages plus references. Accepted at the IJCNN 2020 Special Session on Explainable Computational/ArtificialIntelligence. Camera-ready version\\u00a7r"}']}
{title:'Mohamed et al. (§72020§r)', author: 'Mostafa M. Mohamed; Mina A. Nessiem; Björn W. Schuller', display:{Lore:['[{"text": "arXiv:2005.07794", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lOn Deep Speech Packet Loss Concealment: A Mini-Survey\\u00a7r\\n\\n\\u00a78\\u00a7oMostafa M. Mohamed\\nMina A. Nessiem\\nBj\\u00f6rn W. Schuller\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.07794\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 15 May 2020 21:37:13 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmission for INTERSPEECH 2020. 4 pages + 1 references page. 3 Figures and 1 Table\\u00a7r"}']}
{title:'Lim et al. (§72020§r)', author: 'Dan Lim; Won Jang; Gyeonghwan O; Heayoung Park; Bongwan Kim; Jaesam Yoon', display:{Lore:['[{"text": "arXiv:2005.07799", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lJDI-T: Jointly trained Duration Informed Transformer for Text-To-Speech without Explicit Alignment\\u00a7r\\n\\n\\u00a78\\u00a7oDan Lim\\nWon Jang\\nGyeonghwan O\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.07799\\u00a7r\\n\\nVersion:\\u00a77v3 (Mon, 5 Oct 2020 02:48:58 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted for publication in Interspeech 2020\\u00a7r"}']}
{title:'Chen et al. (§72020§r)', author: 'Zhuohao Chen; Nikolaos Flemotomos; Victor Ardulov; Torrey A. Creed; Zac E. Imel; David C. Atkins; Shrikanth Narayanan', display:{Lore:['[{"text": "arXiv:2005.07809", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lFeature Fusion Strategies for End-to-End Evaluation of Cognitive Behavior Therapy Sessions\\u00a7r\\n\\n\\u00a78\\u00a7oZhuohao Chen\\nNikolaos Flemotomos\\nVictor Ardulov\\n+ 3 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.07809\\u00a7r\\n\\nVersion:\\u00a77v2 (Wed, 14 Oct 2020 20:53:36 GMT)\\u00a7r"}']}
{title:'Khan et al. (§72020§r)', author: 'Mohammad Asif Khan; Fabien Cardinaux; Stefan Uhlich; Marc Ferras; Asja Fischer', display:{Lore:['[{"text": "arXiv:2005.07810", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lUnsupervised Cross-Domain Speech-to-Speech Conversion with Time-Frequency Consistency\\u00a7r\\n\\n\\u00a78\\u00a7oMohammad Asif Khan\\nFabien Cardinaux\\nStefan Uhlich\\nMarc Ferras\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.07810\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 19 May 2020 01:16:49 GMT)\\u00a7r"}']}
{title:'Rebryk et al. (§72020§r)', author: 'Yurii Rebryk; Stanislav Beliaev', display:{Lore:['[{"text": "arXiv:2005.07815", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lConVoice: Real-Time Zero-Shot Voice Style Transfer with Convolutional Network\\u00a7r\\n\\n\\u00a78\\u00a7oYurii Rebryk\\nStanislav Beliaev\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.07815\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 15 May 2020 22:41:16 GMT)\\u00a7r"}']}
{title:'Shi et al. (§72020§r)', author: 'Yanpei Shi; Qiang Huang; Thomas Hain', display:{Lore:['[{"text": "arXiv:2005.07817", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lWeakly Supervised Training of Hierarchical Attention Networks for Speaker Identification\\u00a7r\\n\\n\\u00a78\\u00a7oYanpei Shi\\nQiang Huang\\nThomas Hain\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.07817\\u00a7r\\n\\nVersion:\\u00a77v3 (Thu, 27 Aug 2020 07:38:52 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAcceptted for presentation at Interspeech2020\\u00a7r"}']}
{title:'Shi et al. (§72020§r)', author: 'Yanpei Shi; Qiang Huang; Thomas Hain', display:{Lore:['[{"text": "arXiv:2005.07818", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSpeaker Re-identification with Speaker Dependent Speech Enhancement\\u00a7r\\n\\n\\u00a78\\u00a7oYanpei Shi\\nQiang Huang\\nThomas Hain\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.07818\\u00a7r\\n\\nVersion:\\u00a77v3 (Thu, 27 Aug 2020 07:36:12 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAcceptted for presentation at Interspeech2020\\u00a7r"}']}
{title:'Singh et al. (§72020§r)', author: 'Kritika Singh; Vimal Manohar; Alex Xiao; Sergey Edunov; Ross Girshick; Vitaliy Liptchinsky; Christian Fuegen; Yatharth Saraf; Geoffrey Zweig; Abdelrahman Mohamed', display:{Lore:['[{"text": "arXiv:2005.07850", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lLarge scale weakly and semi-supervised learning for low-resource video ASR\\u00a7r\\n\\n\\u00a78\\u00a7oKritika Singh\\nVimal Manohar\\nAlex Xiao\\n+ 6 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.07850\\u00a7r\\n\\nVersion:\\u00a77v2 (Fri, 7 Aug 2020 01:17:55 GMT)\\u00a7r"}']}
{title:'Zhao et al. (§72020§r)', author: 'Yi Zhao; Haoyu Li; Cheng-I Lai; Jennifer Williams; Erica Cooper; Junichi Yamagishi', display:{Lore:['[{"text": "arXiv:2005.07884", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lImproved Prosody from Learned F0 Codebook Representations for VQ-VAE Speech Waveform Reconstruction\\u00a7r\\n\\n\\u00a78\\u00a7oYi Zhao\\nHaoyu Li\\nCheng-I Lai\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.07884\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 16 May 2020 06:12:48 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to Interspeech 2020\\u00a7r"}']}
{title:'Tian et al. (§72020§r)', author: 'Zhengkun Tian; Jiangyan Yi; Jianhua Tao; Ye Bai; Shuai Zhang; Zhengqi Wen', display:{Lore:['[{"text": "arXiv:2005.07903", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSpike-Triggered Non-Autoregressive Transformer for End-to-End Speech Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oZhengkun Tian\\nJiangyan Yi\\nJianhua Tao\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.07903\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 16 May 2020 08:27:20 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages\\u00a7r"}']}
{title:'Ahamad et al. (§72020§r)', author: 'Afroz Ahamad; Ankit Anand; Pranesh Bhargava', display:{Lore:['[{"text": "arXiv:2005.07973", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAccentDB: A Database of Non-Native English Accents to Assist Neural Speech Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oAfroz Ahamad\\nAnkit Anand\\nPranesh Bhargava\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.07973\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 16 May 2020 12:38:30 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oProceedings of the 12th Language Resources and Evaluation Conference - LREC, 2020\\u00a7r"}']}
{title:'Gu et al. (§72020§r)', author: 'Zhaoyi Gu; Lele Liao; Kai Chen; Jing Lu', display:{Lore:['[{"text": "arXiv:2005.07976", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7eeess.SP\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lTarget Speech Extraction Based on Blind Source Separation and X-vector-based Speaker Selection Trained with Data Augmentation\\u00a7r\\n\\n\\u00a78\\u00a7oZhaoyi Gu\\nLele Liao\\nKai Chen\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.07976\\u00a7r\\n\\nVersion:\\u00a77v2 (Fri, 30 Oct 2020 13:38:45 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 2 figures, section 3-5 of the original submission are replaced with new experiments and conclusions\\u00a7r"}']}
{title:'Tu et al. (§72020§r)', author: 'Tao Tu; Yuan-Jui Chen; Alexander H. Liu; Hung-yi Lee', display:{Lore:['[{"text": "arXiv:2005.08024", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSemi-supervised Learning for Multi-speaker Text-to-speech Synthesis Using Discrete Speech Representation\\u00a7r\\n\\n\\u00a78\\u00a7oTao Tu\\nYuan-Jui Chen\\nAlexander H. Liu\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.08024\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 4 Aug 2020 07:55:34 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oInterspeech 2020, https://github.com/ttaoREtw/semi-tts\\u00a7r"}']}
{title:'Wu et al. (§72020§r)', author: 'Chunyang Wu; Yongqiang Wang; Yangyang Shi; Ching-Feng Yeh; Frank Zhang', display:{Lore:['[{"text": "arXiv:2005.08042", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lStreaming Transformer-based Acoustic Models Using Self-attention with Augmented Memory\\u00a7r\\n\\n\\u00a78\\u00a7oChunyang Wu\\nYongqiang Wang\\nYangyang Shi\\nChing-Feng Yeh\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.08042\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 16 May 2020 16:54:52 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7osubmitted to Interspeech 2020\\u00a7r"}']}
{title:'Qin et al. (§72020§r)', author: 'Xiaoyi Qin; Ming Li; Hui Bu; Wei Rao; Rohan Kumar Das; Shrikanth Narayanan; Haizhou Li', display:{Lore:['[{"text": "arXiv:2005.08046", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lThe INTERSPEECH 2020 Far-Field Speaker Verification Challenge\\u00a7r\\n\\n\\u00a78\\u00a7oXiaoyi Qin\\nMing Li\\nHui Bu\\n+ 3 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.08046\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 16 May 2020 17:13:28 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to INTERSPEECH 2020\\u00a7r"}']}
{title:'Huang et al. (§72020§r)', author: 'Qiang Huang; Thomas Hain', display:{Lore:['[{"text": "arXiv:2005.08053", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lExploration of Audio Quality Assessment and Anomaly Localisation Using Attention Models\\u00a7r\\n\\n\\u00a78\\u00a7oQiang Huang\\nThomas Hain\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.08053\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 16 May 2020 17:54:07 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to InterSpeech 2020\\u00a7r"}']}
{title:'Mao et al. (§72020§r)', author: 'Huanru Henry Mao; Shuyang Li; Julian McAuley; Garrison Cottrell', display:{Lore:['[{"text": "arXiv:2005.08072", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSpeech Recognition and Multi-Speaker Diarization of Long Conversations\\u00a7r\\n\\n\\u00a78\\u00a7oHuanru Henry Mao\\nShuyang Li\\nJulian McAuley\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.08072\\u00a7r\\n\\nVersion:\\u00a77v2 (Thu, 5 Nov 2020 03:28:08 GMT)\\u00a7r"}']}
{title:'Gulati et al. (§72020§r)', author: 'Anmol Gulati; James Qin; Chung-Cheng Chiu; Niki Parmar; Yu Zhang; Jiahui Yu; Wei Han; Shibo Wang; Zhengdong Zhang; Yonghui Wu; Ruoming Pang', display:{Lore:['[{"text": "arXiv:2005.08100", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lConformer: Convolution-augmented Transformer for Speech Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oAnmol Gulati\\nJames Qin\\nChung-Cheng Chiu\\n+ 7 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.08100\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 16 May 2020 20:56:25 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to Interspeech 2020\\u00a7r"}']}
{title:'Żelasko et al. (§72020§r)', author: 'Piotr Żelasko; Laureano Moro-Velázquez; Mark Hasegawa-Johnson; Odette Scharenborg; Najim Dehak', display:{Lore:['[{"text": "arXiv:2005.08118", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lThat Sounds Familiar: an Analysis of Phonetic Representations Transfer Across Languages\\u00a7r\\n\\n\\u00a78\\u00a7oPiotr \\u017belasko\\nLaureano Moro-Vel\\u00e1zquez\\nMark Hasegawa-Johnson\\nOdette Scharenborg\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.08118\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 16 May 2020 22:28:09 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to Interspeech 2020. For some reason, the ArXiv Latex engine rendered it in more than 4 pages\\u00a7r"}']}
{title:'Sivaraman et al. (§72020§r)', author: 'Aswin Sivaraman; Minje Kim', display:{Lore:['[{"text": "arXiv:2005.08128", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSparse Mixture of Local Experts for Efficient Speech Enhancement\\u00a7r\\n\\n\\u00a78\\u00a7oAswin Sivaraman\\nMinje Kim\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.08128\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nPublished in Interspeech 2020\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 16 May 2020 23:23:22 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 5 figures\\u00a7r"}']}
{title:'Naderi et al. (§72020§r)', author: 'Babak Naderi; Ross Cutler', display:{Lore:['[{"text": "arXiv:2005.08138", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAn Open source Implementation of ITU-T Recommendation P.808 with Validation\\u00a7r\\n\\n\\u00a78\\u00a7oBabak Naderi\\nRoss Cutler\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.08138\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.21437/Interspeech.2020-2665\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 17 May 2020 00:41:22 GMT)\\u00a7r"}']}
{title:'Bhowmick et al. (§72020§r)', author: 'Anirban Bhowmick; Astik Biswas', display:{Lore:['[{"text": "arXiv:2005.08229", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lIdentification/Segmentation of Indian Regional Languages with Singular Value Decomposition based Feature Embedding\\u00a7r\\n\\n\\u00a78\\u00a7oAnirban Bhowmick\\nAstik Biswas\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.08229\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 17 May 2020 11:42:51 GMT)\\u00a7r"}']}
{title:'Nidadavolu et al. (§72020§r)', author: 'Phani Sankar Nidadavolu; Saurabh Kataria; Paola García-Perera; Jesús Villalba; Najim Dehak', display:{Lore:['[{"text": "arXiv:2005.08331", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSingle Channel Far Field Feature Enhancement For Speaker Verification In The Wild\\u00a7r\\n\\n\\u00a78\\u00a7oPhani Sankar Nidadavolu\\nSaurabh Kataria\\nPaola Garc\\u00eda-Perera\\nJes\\u00fas Villalba\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.08331\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 17 May 2020 18:15:12 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7osubmitted to INTERSPEECH 2020\\u00a7r"}']}
{title:'Qu et al. (§72020§r)', author: 'Leyuan Qu; Cornelius Weber; Stefan Wermter', display:{Lore:['[{"text": "arXiv:2005.08335", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMultimodal Target Speech Separation with Voice and Face References\\u00a7r\\n\\n\\u00a78\\u00a7oLeyuan Qu\\nCornelius Weber\\nStefan Wermter\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.08335\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 17 May 2020 18:35:28 GMT)\\u00a7r"}']}
{title:'Wang et al. (§72020§r)', author: 'Yiming Wang; Hang Lv; Daniel Povey; Lei Xie; Sanjeev Khudanpur', display:{Lore:['[{"text": "arXiv:2005.08347", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lWake Word Detection with Alignment-Free Lattice-Free MMI\\u00a7r\\n\\n\\u00a78\\u00a7oYiming Wang\\nHang Lv\\nDaniel Povey\\nLei Xie\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.08347\\u00a7r\\n\\nVersion:\\u00a77v3 (Tue, 28 Jul 2020 22:06:14 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted at Interspeech 2020. 5 pages, 3 figures\\u00a7r"}']}
{title:'Ibrahim et al. (§72020§r)', author: "Ali K Ibrahim; Hanqi Zhuang; Laurent M. Ch'erubin; Nurgun Erdol; Gregory O Corry-Crowe; Ali Muhamed Ali", display:{Lore:['[{"text": "arXiv:2005.08356", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lNorth Atlantic Right Whales Up-call Detection Using Multimodel Deep Learning\\u00a7r\\n\\n\\u00a78\\u00a7oAli K Ibrahim\\nHanqi Zhuang\\nLaurent M. Ch\'erubin\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.08356\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 17 May 2020 19:52:26 GMT)\\u00a7r"}']}
{title:'Chung et al. (§72020§r)', author: 'Yu-An Chung; Hao Tang; James Glass', display:{Lore:['[{"text": "arXiv:2005.08392", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lVector-Quantized Autoregressive Predictive Coding\\u00a7r\\n\\n\\u00a78\\u00a7oYu-An Chung\\nHao Tang\\nJames Glass\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.08392\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 17 May 2020 23:06:09 GMT)\\u00a7r"}']}
{title:'Lo et al. (§72020§r)', author: 'Tien-Hong Lo; Fu-An Chao; Shi-Yan Weng; Berlin Chen', display:{Lore:['[{"text": "arXiv:2005.08433", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lThe NTNU System at the Interspeech 2020 Non-Native Children\'s Speech ASR Challenge\\u00a7r\\n\\n\\u00a78\\u00a7oTien-Hong Lo\\nFu-An Chao\\nShi-Yan Weng\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.08433\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 2 Jun 2020 19:07:08 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to Interspeech 2020 Special Session: SharedTask on Automatic Speech Recognition forNon-Native Children\'s Speech\\u00a7r"}']}
{title:'Lo et al. (§72020§r)', author: 'Tien-Hong Lo; Shi-Yan Weng; Hsiu-Jui Chang; Berlin Chen', display:{Lore:['[{"text": "arXiv:2005.08440", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAn Effective End-to-End Modeling Approach for Mispronunciation Detection\\u00a7r\\n\\n\\u00a78\\u00a7oTien-Hong Lo\\nShi-Yan Weng\\nHsiu-Jui Chang\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.08440\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 18 May 2020 03:37:21 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to Interspeech 2020\\u00a7r"}']}
{title:'Kameoka et al. (§72020§r)', author: 'Hirokazu Kameoka; Wen-Chin Huang; Kou Tanaka; Takuhiro Kaneko; Nobukatsu Hojo; Tomoki Toda', display:{Lore:['[{"text": "arXiv:2005.08445", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMany-to-Many Voice Transformer Network\\u00a7r\\n\\n\\u00a78\\u00a7oHirokazu Kameoka\\nWen-Chin Huang\\nKou Tanaka\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.08445\\u00a7r\\n\\nVersion:\\u00a77v4 (Fri, 6 Nov 2020 22:46:52 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7osubmitted to IEEE/ACM Trans. ASLP. Please also refer to our related article: arXiv:1811.01609\\u00a7r"}']}
{title:'Choi et al. (§72020§r)', author: 'Seungwoo Choi; Seungju Han; Dongyoung Kim; Sungjoo Ha', display:{Lore:['[{"text": "arXiv:2005.08484", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAttentron: Few-Shot Text-to-Speech Utilizing Attention-Based Variable-Length Embedding\\u00a7r\\n\\n\\u00a78\\u00a7oSeungwoo Choi\\nSeungju Han\\nDongyoung Kim\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.08484\\u00a7r\\n\\nVersion:\\u00a77v2 (Wed, 12 Aug 2020 05:55:21 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted to INTERSPEECH 2020\\u00a7r"}']}
{title:'Wang et al. (§72020§r)', author: 'Bin Wang; Yan Yin; Hui Lin', display:{Lore:['[{"text": "arXiv:2005.08497", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAttention-based Transducer for Online Speech Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oBin Wang\\nYan Yin\\nHui Lin\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.08497\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 18 May 2020 07:26:33 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7osubmitted to Interspeech 2020\\u00a7r"}']}
{title:'Liu et al. (§72020§r)', author: 'Jen-Yu Liu; Yu-Hua Chen; Yin-Cheng Yeh; Yi-Hsuan Yang', display:{Lore:['[{"text": "arXiv:2005.08526", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lUnconditional Audio Generation with Generative Adversarial Networks and Cycle Regularization\\u00a7r\\n\\n\\u00a78\\u00a7oJen-Yu Liu\\nYu-Hua Chen\\nYin-Cheng Yeh\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.08526\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.21437/Interspeech.2020-1137\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 18 May 2020 08:35:16 GMT)\\u00a7r"}']}
{title:'Li et al. (§72020§r)', author: 'Naihan Li; Shujie Liu; Yanqing Liu; Sheng Zhao; Ming Liu; Ming Zhou', display:{Lore:['[{"text": "arXiv:2005.08528", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMoBoAligner: a Neural Alignment Model for Non-autoregressive TTS with Monotonic Boundary Search\\u00a7r\\n\\n\\u00a78\\u00a7oNaihan Li\\nShujie Liu\\nYanqing Liu\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.08528\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 9 Jun 2020 05:01:20 GMT)\\u00a7r"}']}
{title:'Qiu et al. (§72020§r)', author: 'Xinchi Qiu; Titouan Parcollet; Mirco Ravanelli; Nicholas Lane; Mohamed Morchid', display:{Lore:['[{"text": "arXiv:2005.08566", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lQuaternion Neural Networks for Multi-channel Distant Speech Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oXinchi Qiu\\nTitouan Parcollet\\nMirco Ravanelli\\nNicholas Lane\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.08566\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.13140/RG.2.2.17061.52969\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 19 May 2020 10:06:54 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o4 pages\\u00a7r"}']}
{title:'Yu et al. (§72020§r)', author: 'Jianwei Yu; Bo Wu; Rongzhi Gu; Shi-Xiong Zhang; Lianwu Chen; Yong Xu. Meng Yu; Dan Su; Dong Yu; Xunying Liu; Helen Meng', display:{Lore:['[{"text": "arXiv:2005.08571", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAudio-visual Multi-channel Recognition of Overlapped Speech\\u00a7r\\n\\n\\u00a78\\u00a7oJianwei Yu\\nBo Wu\\nRongzhi Gu\\n+ 6 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.08571\\u00a7r\\n\\nVersion:\\u00a77v2 (Wed, 18 Nov 2020 12:30:54 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7osubmitted to Interspeech 2020\\u00a7r"}']}
{title:'Srivastava et al. (§72020§r)', author: 'Brij Mohan Lal Srivastava; Natalia Tomashenko; Xin Wang; Emmanuel Vincent; Junichi Yamagishi; Mohamed Maouche; Aurélien Bellet; Marc Tommasi', display:{Lore:['[{"text": "arXiv:2005.08601", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDesign Choices for X-vector Based Speaker Anonymization\\u00a7r\\n\\n\\u00a78\\u00a7oBrij Mohan Lal Srivastava\\nNatalia Tomashenko\\nXin Wang\\n+ 4 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.08601\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 18 May 2020 11:32:14 GMT)\\u00a7r"}']}
{title:'Wu et al. (§72020§r)', author: 'Yi-Chiao Wu; Tomoki Hayashi; Takuma Okamoto; Hisashi Kawai; Tomoki Toda', display:{Lore:['[{"text": "arXiv:2005.08654", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lQuasi-Periodic Parallel WaveGAN Vocoder: A Non-autoregressive Pitch-dependent Dilated Convolution Model for Parametric Speech Generation\\u00a7r\\n\\n\\u00a78\\u00a7oYi-Chiao Wu\\nTomoki Hayashi\\nTakuma Okamoto\\nHisashi Kawai\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.08654\\u00a7r\\n\\nVersion:\\u00a77v2 (Fri, 7 Aug 2020 02:55:23 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 page, 6 figures, 2 tables. Proc. Interspeech, 2020\\u00a7r"}']}
{title:'Wu et al. (§72020§r)', author: 'Yi-Chiao Wu; Patrick Lumban Tobing; Kazuki Yasuhara; Noriyuki Matsunaga; Yamato Ohtani; Tomoki Toda', display:{Lore:['[{"text": "arXiv:2005.08659", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Cyclical Post-filtering Approach to Mismatch Refinement of Neural Vocoder for Text-to-speech Systems\\u00a7r\\n\\n\\u00a78\\u00a7oYi-Chiao Wu\\nPatrick Lumban Tobing\\nKazuki Yasuhara\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.08659\\u00a7r\\n\\nVersion:\\u00a77v2 (Fri, 7 Aug 2020 02:58:25 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 8 figures, 1 table. Proc. Interspeech, 2020\\u00a7r"}']}
{title:'Higuchi et al. (§72020§r)', author: 'Yosuke Higuchi; Shinji Watanabe; Nanxin Chen; Tetsuji Ogawa; Tetsunori Kobayashi', display:{Lore:['[{"text": "arXiv:2005.08700", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMask CTC: Non-Autoregressive End-to-End ASR with CTC and Mask Predict\\u00a7r\\n\\n\\u00a78\\u00a7oYosuke Higuchi\\nShinji Watanabe\\nNanxin Chen\\nTetsuji Ogawa\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.08700\\u00a7r\\n\\nVersion:\\u00a77v2 (Mon, 17 Aug 2020 09:15:58 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted to INTERSPEECH2020\\u00a7r"}']}
{title:'Amiriparian et al. (§72020§r)', author: 'Shahin Amiriparian; Pawel Winokurow; Vincent Karas; Sandra Ottl; Maurice Gerczuk; Björn W. Schuller', display:{Lore:['[{"text": "arXiv:2005.08722", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Novel Fusion of Attention and Sequence to Sequence Autoencoders to Predict Sleepiness From Speech\\u00a7r\\n\\n\\u00a78\\u00a7oShahin Amiriparian\\nPawel Winokurow\\nVincent Karas\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.08722\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 19 May 2020 16:30:41 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 2 figures, submitted to INTERSPEECH 2020\\u00a7r"}']}
{title:'Mao et al. (§72020§r)', author: 'Tingzhi Mao; Yerbolat Khassanov; Van Tung Pham; Haihua Xu; Hao Huang; Eng Siong Chng', display:{Lore:['[{"text": "arXiv:2005.08742", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lApproaches to Improving Recognition of Underrepresented Named Entities in Hybrid ASR Systems\\u00a7r\\n\\n\\u00a78\\u00a7oTingzhi Mao\\nYerbolat Khassanov\\nVan Tung Pham\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.08742\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 18 May 2020 14:11:20 GMT)\\u00a7r"}']}
{title:'Huh et al. (§72020§r)', author: 'Jaesung Huh; Minjae Lee; Heesoo Heo; Seongkyu Mun; Joon Son Chung', display:{Lore:['[{"text": "arXiv:2005.08776", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMetric Learning for Keyword Spotting\\u00a7r\\n\\n\\u00a78\\u00a7oJaesung Huh\\nMinjae Lee\\nHeesoo Heo\\nSeongkyu Mun\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.08776\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 18 May 2020 14:47:04 GMT)\\u00a7r"}']}
{title:'Shi et al. (§72020§r)', author: 'Yangyang Shi; Yongqiang Wang; Chunyang Wu; Christian Fuegen; Frank Zhang; Duc Le; Ching-Feng Yeh; Michael L. Seltzer', display:{Lore:['[{"text": "arXiv:2005.09137", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lWeak-Attention Suppression For Transformer Based Speech Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oYangyang Shi\\nYongqiang Wang\\nChunyang Wu\\n+ 4 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.09137\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 18 May 2020 23:49:40 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7osubmitted to interspeech 2020\\u00a7r"}']}
{title:'Zhang et al. (§72020§r)', author: 'Frank Zhang; Yongqiang Wang; Xiaohui Zhang; Chunxi Liu; Yatharth Saraf; Geoffrey Zweig', display:{Lore:['[{"text": "arXiv:2005.09150", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lFaster, Simpler and More Accurate Hybrid ASR Systems Using Wordpieces\\u00a7r\\n\\n\\u00a78\\u00a7oFrank Zhang\\nYongqiang Wang\\nXiaohui Zhang\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.09150\\u00a7r\\n\\nVersion:\\u00a77v2 (Sun, 16 Aug 2020 21:22:34 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oIn proceedings Interspeech 2020\\u00a7r"}']}
{title:'Liu et al. (§72020§r)', author: 'Songxiang Liu; Yuewen Cao; Shiyin Kang; Na Hu; Xunying Liu; Dan Su; Dong Yu; Helen Meng', display:{Lore:['[{"text": "arXiv:2005.09178", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lTransferring Source Style in Non-Parallel Voice Conversion\\u00a7r\\n\\n\\u00a78\\u00a7oSongxiang Liu\\nYuewen Cao\\nShiyin Kang\\n+ 4 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.09178\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 19 May 2020 02:58:58 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 8 figures, submitted to INTERSPEECH 2020\\u00a7r"}']}
{title:'Li et al. (§72020§r)', author: 'Tingle Li; Qingjian Lin; Yuanyuan Bao; Ming Li', display:{Lore:['[{"text": "arXiv:2005.09200", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAtss-Net: Target Speaker Separation via Attention-based Neural Network\\u00a7r\\n\\n\\u00a78\\u00a7oTingle Li\\nQingjian Lin\\nYuanyuan Bao\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.09200\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 19 May 2020 03:58:27 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to Interspeech 2020\\u00a7r"}']}
{title:'Suefusa et al. (§72020§r)', author: 'Kaori Suefusa; Tomoya Nishida; Harsh Purohit; Ryo Tanabe; Takashi Endo; Yohei Kawaguchi', display:{Lore:['[{"text": "arXiv:2005.09234", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAnomalous sound detection based on interpolation deep neural network\\u00a7r\\n\\n\\u00a78\\u00a7oKaori Suefusa\\nTomoya Nishida\\nHarsh Purohit\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.09234\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 19 May 2020 06:12:41 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 8 figures, published in ICASSP 2020\\u00a7r"}']}
{title:'Matsuura et al. (§72020§r)', author: 'Kohei Matsuura; Masato Mimura; Shinsuke Sakai; Tatsuya Kawahara', display:{Lore:['[{"text": "arXiv:2005.09256", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lGenerative Adversarial Training Data Adaptation for Very Low-resource Automatic Speech Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oKohei Matsuura\\nMasato Mimura\\nShinsuke Sakai\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.09256\\u00a7r\\n\\nVersion:\\u00a77v2 (Fri, 31 Jul 2020 08:38:46 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted for Interspeech 2020\\u00a7r"}']}
{title:'Zhou et al. (§72020§r)', author: 'Wei Zhou; Ralf Schlüter; Hermann Ney', display:{Lore:['[{"text": "arXiv:2005.09265", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lRobust Beam Search for Encoder-Decoder Attention Based Speech Recognition without Length Bias\\u00a7r\\n\\n\\u00a78\\u00a7oWei Zhou\\nRalf Schl\\u00fcter\\nHermann Ney\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.09265\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.21437/Interspeech.2020-1958\\u00a7r\\n\\nVersion:\\u00a77v2 (Thu, 6 Aug 2020 13:34:44 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oaccepted at INTERSPEECH2020\\u00a7r"}']}
{title:'Yusuf et al. (§72020§r)', author: 'Bolaji Yusuf; Lucas Ondel', display:{Lore:['[{"text": "arXiv:2005.09282", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lBayesian Subspace HMM for the Zerospeech 2020 Challenge\\u00a7r\\n\\n\\u00a78\\u00a7oBolaji Yusuf\\nLucas Ondel\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.09282\\u00a7r\\n\\nVersion:\\u00a77v2 (Mon, 27 Jul 2020 12:24:11 GMT)\\u00a7r"}']}
{title:'Sterpu et al. (§72020§r)', author: 'George Sterpu; Christian Saam; Naomi Harte', display:{Lore:['[{"text": "arXiv:2005.09297", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lShould we hard-code the recurrence concept or learn it instead ? Exploring the Transformer architecture for Audio-Visual Speech Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oGeorge Sterpu\\nChristian Saam\\nNaomi Harte\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.09297\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 19 May 2020 09:06:39 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to INTERSPEECH 2020\\u00a7r"}']}
{title:'Zeyer et al. (§72020§r)', author: 'Albert Zeyer; André Merboldt; Ralf Schlüter; Hermann Ney', display:{Lore:['[{"text": "arXiv:2005.09319", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.NE\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA New Training Pipeline for an Improved Neural Transducer\\u00a7r\\n\\n\\u00a78\\u00a7oAlbert Zeyer\\nAndr\\u00e9 Merboldt\\nRalf Schl\\u00fcter\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.09319\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.21437/Interspeech.2020-1855\\u00a7r\\n\\nVersion:\\u00a77v2 (Wed, 18 Nov 2020 22:13:01 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7opublished at Interspeech 2020\\u00a7r"}']}
{title:'Inaguma et al. (§72020§r)', author: 'Hirofumi Inaguma; Masato Mimura; Tatsuya Kawahara', display:{Lore:['[{"text": "arXiv:2005.09394", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lEnhancing Monotonic Multihead Attention for Streaming ASR\\u00a7r\\n\\n\\u00a78\\u00a7oHirofumi Inaguma\\nMasato Mimura\\nTatsuya Kawahara\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.09394\\u00a7r\\n\\nVersion:\\u00a77v3 (Wed, 30 Sep 2020 12:20:25 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted to Interspeech 2020\\u00a7r"}']}
{title:'van Niekerk et al. (§72020§r)', author: 'Benjamin van Niekerk; Leanne Nortje; Herman Kamper', display:{Lore:['[{"text": "arXiv:2005.09409", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lVector-quantized neural networks for acoustic unit discovery in the ZeroSpeech 2020 challenge\\u00a7r\\n\\n\\u00a78\\u00a7oBenjamin van Niekerk\\nLeanne Nortje\\nHerman Kamper\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.09409\\u00a7r\\n\\nVersion:\\u00a77v2 (Wed, 19 Aug 2020 12:41:55 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 3 figures, 2 tables, accepted to Interspeech 2020\\u00a7r"}']}
{title:'Saha et al. (§72020§r)', author: 'Pramit Saha; Sidney Fels', display:{Lore:['[{"text": "arXiv:2005.09463", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lLearning Joint Articulatory-Acoustic Representations with Normalizing Flows\\u00a7r\\n\\n\\u00a78\\u00a7oPramit Saha\\nSidney Fels\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.09463\\u00a7r\\n\\nVersion:\\u00a77v2 (Thu, 1 Oct 2020 03:54:41 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 4 figures, accepted for publication in Interspeech 2020\\u00a7r"}']}
{title:'Grondin et al. (§72020§r)', author: 'Francois Grondin; Jean-Samuel Lauzon; Jonathan Vincent; Francois Michaud', display:{Lore:['[{"text": "arXiv:2005.09587", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lGEV Beamforming Supported by DOA-based Masks Generated on Pairs of Microphones\\u00a7r\\n\\n\\u00a78\\u00a7oFrancois Grondin\\nJean-Samuel Lauzon\\nJonathan Vincent\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.09587\\u00a7r\\n\\nVersion:\\u00a77v2 (Wed, 5 Aug 2020 16:11:57 GMT)\\u00a7r"}']}
{title:'Park et al. (§72020§r)', author: 'Daniel S. Park; Yu Zhang; Ye Jia; Wei Han; Chung-Cheng Chiu; Bo Li; Yonghui Wu; Quoc V. Le', display:{Lore:['[{"text": "arXiv:2005.09629", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lImproved Noisy Student Training for Automatic Speech Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oDaniel S. Park\\nYu Zhang\\nYe Jia\\n+ 4 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.09629\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.21437/Interspeech.2020-1470\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nProc. Interspeech 2020, 2817-2821\\u00a7r\\n\\nVersion:\\u00a77v2 (Thu, 29 Oct 2020 23:26:24 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 5 figures, 4 tables; v2: minor revisions, reference added\\u00a7r"}']}
{title:'Lu et al. (§72020§r)', author: 'Liang Lu; Changliang Liu; Jinyu Li; Yifan Gong', display:{Lore:['[{"text": "arXiv:2005.09684", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lExploring Transformers for Large-Scale Speech Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oLiang Lu\\nChangliang Liu\\nJinyu Li\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.09684\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 11 Aug 2020 18:51:37 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 1 figure, Interspeech 2020 Camera Ready\\u00a7r"}']}
{title:'Peyser et al. (§72020§r)', author: 'Cal Peyser; Tara N. Sainath; Golan Pundak', display:{Lore:['[{"text": "arXiv:2005.09756", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lImproving Proper Noun Recognition in End-to-End ASR By Customization of the MWER Loss Criterion\\u00a7r\\n\\n\\u00a78\\u00a7oCal Peyser\\nTara N. Sainath\\nGolan Pundak\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.09756\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 19 May 2020 21:10:50 GMT)\\u00a7r"}']}
{title:'Vecchi et al. (§72020§r)', author: 'Alejandro Osses Vecchi; Armin Kohlrausch', display:{Lore:['[{"text": "arXiv:2005.09768", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lPerceptual similarity between piano notes: Simulations with a template-based perception model\\u00a7r\\n\\n\\u00a78\\u00a7oAlejandro Osses Vecchi\\nArmin Kohlrausch\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.09768\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1121/10.0004818\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nThe Journal of the Acoustical Society of America 149 (5),\\n  3534-3552 (2021)\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 19 May 2020 21:44:51 GMT)\\u00a7r"}']}
{title:'Shao et al. (§72020§r)', author: 'Yiwen Shao; Yiming Wang; Daniel Povey; Sanjeev Khudanpur', display:{Lore:['[{"text": "arXiv:2005.09824", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lPyChain: A Fully Parallelized PyTorch Implementation of LF-MMI for End-to-End ASR\\u00a7r\\n\\n\\u00a78\\u00a7oYiwen Shao\\nYiming Wang\\nDaniel Povey\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.09824\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 20 May 2020 02:10:21 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmtted to Interspeech 2020\\u00a7r"}']}
{title:'Nakatani et al. (§72020§r)', author: 'Tomohiro Nakatani; Christoph Boeddeker; Keisuke Kinoshita; Rintaro Ikeshita; Marc Delcroix; Reinhold Haeb-Umbach', display:{Lore:['[{"text": "arXiv:2005.09843", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lJointly optimal denoising, dereverberation, and source separation\\u00a7r\\n\\n\\u00a78\\u00a7oTomohiro Nakatani\\nChristoph Boeddeker\\nKeisuke Kinoshita\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.09843\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/TASLP.2020.3013118\\u00a7r\\n\\nVersion:\\u00a77v3 (Sun, 2 Aug 2020 22:55:16 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to IEEE/ACM Trans. Audio, Speech, and Language Processing on 12 Feb 2020, Accepted to IEEE/ACM Trans. Audio, Speech, and Language Processing on 14 July 2020\\u00a7r"}']}
{title:'Jiang et al. (§72020§r)', author: 'Dongwei Jiang; Wubo Li; Ruixiong Zhang; Miao Cao; Ne Luo; Yang Han; Wei Zou; Xiangang Li', display:{Lore:['[{"text": "arXiv:2005.09862", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Further Study of Unsupervised Pre-training for Transformer Based Speech Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oDongwei Jiang\\nWubo Li\\nRuixiong Zhang\\n+ 4 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.09862\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 23 Jun 2020 03:57:48 GMT)\\u00a7r"}']}
{title:'Yatabe (§72020§r)', author: 'Kohei Yatabe', display:{Lore:['[{"text": "arXiv:2005.09873", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7eeess.SP\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lConsistent ICA: Determined BSS meets spectrogram consistency\\u00a7r\\n\\n\\u00a78\\u00a7oKohei Yatabe\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.09873\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/LSP.2020.2996904\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 20 May 2020 06:46:14 GMT)\\u00a7r"}']}
{title:'Heitkaemper et al. (§72020§r)', author: 'Jens Heitkaemper; Joerg Schmalenstroeer; Reinhold Haeb-Umbach', display:{Lore:['[{"text": "arXiv:2005.09913", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lStatistical and Neural Network Based Speech Activity Detection in Non-Stationary Acoustic Environments\\u00a7r\\n\\n\\u00a78\\u00a7oJens Heitkaemper\\nJoerg Schmalenstroeer\\nReinhold Haeb-Umbach\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.09913\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 28 Jul 2020 08:03:35 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted to Interspeech 2020\\u00a7r"}']}
{title:'Horiguchi et al. (§72020§r)', author: 'Shota Horiguchi; Yusuke Fujita; Shinji Watanabe; Yawen Xue; Kenji Nagamatsu', display:{Lore:['[{"text": "arXiv:2005.09921", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lEnd-to-End Speaker Diarization for an Unknown Number of Speakers with Encoder-Decoder Based Attractors\\u00a7r\\n\\n\\u00a78\\u00a7oShota Horiguchi\\nYusuke Fujita\\nShinji Watanabe\\nYawen Xue\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.09921\\u00a7r\\n\\nVersion:\\u00a77v3 (Mon, 5 Oct 2020 07:12:42 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted to INTERSPEECH 2020\\u00a7r"}']}
{title:'Pham et al. (§72020§r)', author: 'Ngoc-Quan Pham; Thanh-Le Ha; Tuan-Nam Nguyen; Thai-Son Nguyen; Elizabeth Salesky; Sebastian Stueker; Jan Niehues; Alexander Waibel', display:{Lore:['[{"text": "arXiv:2005.09940", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lRelative Positional Encoding for Speech Recognition and Direct Translation\\u00a7r\\n\\n\\u00a78\\u00a7oNgoc-Quan Pham\\nThanh-Le Ha\\nTuan-Nam Nguyen\\n+ 4 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.09940\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 20 May 2020 09:53:06 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to Interspeech 2020\\u00a7r"}']}
{title:'Michel et al. (§72020§r)', author: 'Wilfried Michel; Ralf Schlüter; Hermann Ney', display:{Lore:['[{"text": "arXiv:2005.10049", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lEarly Stage LM Integration Using Local and Global Log-Linear Combination\\u00a7r\\n\\n\\u00a78\\u00a7oWilfried Michel\\nRalf Schl\\u00fcter\\nHermann Ney\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.10049\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 20 May 2020 13:49:55 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to Interspeech 2020\\u00a7r"}']}
{title:'Dong et al. (§72020§r)', author: 'Linhao Dong; Cheng Yi; Jianzong Wang; Shiyu Zhou; Shuang Xu; Xueli Jia; Bo Xu', display:{Lore:['[{"text": "arXiv:2005.10113", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Comparison of Label-Synchronous and Frame-Synchronous End-to-End Models for Speech Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oLinhao Dong\\nCheng Yi\\nJianzong Wang\\n+ 3 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.10113\\u00a7r\\n\\nVersion:\\u00a77v2 (Mon, 25 May 2020 08:56:51 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o4 pages, 2 figures\\u00a7r"}']}
{title:'Stamenovic (§72020§r)', author: 'Marko Stamenovic', display:{Lore:['[{"text": "arXiv:2005.10294", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lTowards Cover Song Detection with Siamese Convolutional Neural Networks\\u00a7r\\n\\n\\u00a78\\u00a7oMarko Stamenovic\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.10294\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nProceedings of the 35th International Conference on Machine\\n  Learning, Stockholm, Sweden, PMLR 80, 2018\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 20 May 2020 18:14:41 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oCode available at https://github.com/markostam/coversongs-dual-convnet\\u00a7r"}']}
{title:'Yu et al. (§72020§r)', author: 'Meng Yu; Xuan Ji; Bo Wu; Dan Su; Dong Yu', display:{Lore:['[{"text": "arXiv:2005.10386", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lEnd-to-End Multi-Look Keyword Spotting\\u00a7r\\n\\n\\u00a78\\u00a7oMeng Yu\\nXuan Ji\\nBo Wu\\nDan Su\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.10386\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 20 May 2020 22:59:10 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to Interspeech2020\\u00a7r"}']}
{title:'Yasuda et al. (§72020§r)', author: 'Yusuke Yasuda; Xin Wang; Junichi Yamagishi', display:{Lore:['[{"text": "arXiv:2005.10390", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lInvestigation of learning abilities on linguistic features in sequence-to-sequence text-to-speech synthesis\\u00a7r\\n\\n\\u00a78\\u00a7oYusuke Yasuda\\nXin Wang\\nJunichi Yamagishi\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.10390\\u00a7r\\n\\nVersion:\\u00a77v2 (Wed, 7 Oct 2020 04:18:56 GMT)\\u00a7r"}']}
{title:'Tak et al. (§72020§r)', author: 'Hemlata Tak; Jose Patino; Andreas Nautsch; Nicholas Evans; Massimiliano Todisco', display:{Lore:['[{"text": "arXiv:2005.10393", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSpoofing Attack Detection using the Non-linear Fusion of Sub-band Classifiers\\u00a7r\\n\\n\\u00a78\\u00a7oHemlata Tak\\nJose Patino\\nAndreas Nautsch\\nNicholas Evans\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.10393\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 20 May 2020 23:37:28 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to Interspeech 2020 conference, 5 pages\\u00a7r"}']}
{title:'Hard et al. (§72020§r)', author: 'Andrew Hard; Kurt Partridge; Cameron Nguyen; Niranjan Subrahmanya; Aishanee Shah; Pai Zhu; Ignacio Lopez Moreno; Rajiv Mathews', display:{Lore:['[{"text": "arXiv:2005.10406", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lTraining Keyword Spotting Models on Non-IID Data with Federated Learning\\u00a7r\\n\\n\\u00a78\\u00a7oAndrew Hard\\nKurt Partridge\\nCameron Nguyen\\n+ 4 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.10406\\u00a7r\\n\\nVersion:\\u00a77v2 (Thu, 4 Jun 2020 17:52:52 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to Interspeech 2020\\u00a7r"}']}
{title:'Zeng et al. (§72020§r)', author: 'Zhiping Zeng; Van Tung Pham; Haihua Xu; Yerbolat Khassanov; Eng Siong Chng; Chongjia Ni; Bin Ma', display:{Lore:['[{"text": "arXiv:2005.10407", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lLeveraging Text Data Using Hybrid Transformer-LSTM Based End-to-End ASR in Transfer Learning\\u00a7r\\n\\n\\u00a78\\u00a7oZhiping Zeng\\nVan Tung Pham\\nHaihua Xu\\n+ 3 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.10407\\u00a7r\\n\\nVersion:\\u00a77v2 (Thu, 28 May 2020 09:35:42 GMT)\\u00a7r"}']}
{title:'Cai et al. (§72020§r)', author: 'Zexin Cai; Yaogen Yang; Ming Li', display:{Lore:['[{"text": "arXiv:2005.10441", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lCross-lingual Multispeaker Text-to-Speech under Limited-Data Scenario\\u00a7r\\n\\n\\u00a78\\u00a7oZexin Cai\\nYaogen Yang\\nMing Li\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.10441\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 21 May 2020 03:03:34 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oin preparation for NeuralNetworks journal Special issue on Advances in Deep Learning Based SpeechProcessing\\u00a7r"}']}
{title:'Jung et al. (§72020§r)', author: 'Sunghee Jung; Hoirin Kim', display:{Lore:['[{"text": "arXiv:2005.10456", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lPitchtron: Towards audiobook generation from ordinary people\'s voices\\u00a7r\\n\\n\\u00a78\\u00a7oSunghee Jung\\nHoirin Kim\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.10456\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 21 May 2020 04:11:15 GMT)\\u00a7r"}']}
{title:'Pan et al. (§72020§r)', author: 'Jing Pan; Joshua Shapiro; Jeremy Wohlwend; Kyu J. Han; Tao Lei; Tao Ma', display:{Lore:['[{"text": "arXiv:2005.10469", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lASAPP-ASR: Multistream CNN and Self-Attentive SRU for SOTA Speech Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oJing Pan\\nJoshua Shapiro\\nJeremy Wohlwend\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.10469\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 21 May 2020 05:18:34 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to Interspeech 2020\\u00a7r"}']}
{title:'Zhang et al. (§72020§r)', author: 'Wangyou Zhang; Aswin Shanmugam Subramanian; Xuankai Chang; Shinji Watanabe; Yanmin Qian', display:{Lore:['[{"text": "arXiv:2005.10479", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lEnd-to-End Far-Field Speech Recognition with Unified Dereverberation and Beamforming\\u00a7r\\n\\n\\u00a78\\u00a7oWangyou Zhang\\nAswin Shanmugam Subramanian\\nXuankai Chang\\nShinji Watanabe\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.10479\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.21437/Interspeech.2020-2432\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 27 Oct 2020 03:46:49 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 3 figures, conference\\u00a7r"}']}
{title:'Sharma et al. (§72020§r)', author: 'Neeraj Sharma; Prashant Krishnan; Rohit Kumar; Shreyas Ramoji; Srikanth Raj Chetupalli; Nirmala R.; Prasanta Kumar Ghosh; Sriram Ganapathy', display:{Lore:['[{"text": "arXiv:2005.10548", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lCoswara \\u2013 A Database of Breathing, Cough, and Voice Sounds for COVID-19 Diagnosis\\u00a7r\\n\\n\\u00a78\\u00a7oNeeraj Sharma\\nPrashant Krishnan\\nRohit Kumar\\n+ 4 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.10548\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.21437/Interspeech.2020-2768\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 11 Aug 2020 06:45:40 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oA description of Coswaradataset to evaluate COVID-19 diagnosis using respiratory sounds\\u00a7r"}']}
{title:'Dai et al. (§72020§r)', author: 'Wang Dai; Jinsong Zhang; Yingming Gao; Wei Wei; Dengfeng Ke; Binghuai Lin; Yanlu Xie', display:{Lore:['[{"text": "arXiv:2005.10803", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lFormant Tracking Using Dilated Convolutional Networks Through Dense Connection with Gating Mechanism\\u00a7r\\n\\n\\u00a78\\u00a7oWang Dai\\nJinsong Zhang\\nYingming Gao\\n+ 3 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.10803\\u00a7r\\n\\nVersion:\\u00a77v3 (Sat, 8 Aug 2020 12:24:50 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted by Interspeech 2020\\u00a7r"}']}
{title:'Luong et al. (§72020§r)', author: 'Hieu-Thi Luong; Junichi Yamagishi', display:{Lore:['[{"text": "arXiv:2005.11004", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lNAUTILUS: a Versatile Voice Cloning System\\u00a7r\\n\\n\\u00a78\\u00a7oHieu-Thi Luong\\nJunichi Yamagishi\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.11004\\u00a7r\\n\\nVersion:\\u00a77v2 (Wed, 7 Oct 2020 01:12:22 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to The IEEE/ACM Transactionson Audio, Speech, and Language Processing\\u00a7r"}']}
{title:'Kim et al. (§72020§r)', author: 'Jaehyeon Kim; Sungwon Kim; Jungil Kong; Sungroh Yoon', display:{Lore:['[{"text": "arXiv:2005.11129", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lGlow-TTS: A Generative Flow for Text-to-Speech via Monotonic Alignment Search\\u00a7r\\n\\n\\u00a78\\u00a7oJaehyeon Kim\\nSungwon Kim\\nJungil Kong\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.11129\\u00a7r\\n\\nVersion:\\u00a77v2 (Fri, 23 Oct 2020 01:53:58 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted by NeurIPS2020\\u00a7r"}']}
{title:'Fedorov et al. (§72020§r)', author: 'Igor Fedorov; Marko Stamenovic; Carl Jensen; Li-Chia Yang; Ari Mandell; Yiming Gan; Matthew Mattina; Paul N. Whatmough', display:{Lore:['[{"text": "arXiv:2005.11138", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lTinyLSTMs: Efficient Neural Speech Enhancement for Hearing Aids\\u00a7r\\n\\n\\u00a78\\u00a7oIgor Fedorov\\nMarko Stamenovic\\nCarl Jensen\\n+ 4 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.11138\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.21437/Interspeech.2020-1864\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 20 May 2020 20:37:47 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oFirst four authors contributed equally. For audio samples, see https://github.com/BoseCorp/efficient-neural-speech-enhancement\\u00a7r"}']}
{title:'Rajapakshe et al. (§72020§r)', author: 'Thejan Rajapakshe; Siddique Latif; Rajib Rana; Sara Khalifa; Björn W. Schuller', display:{Lore:['[{"text": "arXiv:2005.11172", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDeep Reinforcement Learning with Pre-training for Time-efficient Training of Automatic Speech Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oThejan Rajapakshe\\nSiddique Latif\\nRajib Rana\\nSara Khalifa\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.11172\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 21 May 2020 06:07:30 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oarXiv admin note: substantial text overlap with arXiv:1910.11256\\u00a7r"}']}
{title:'Sreeram et al. (§72020§r)', author: 'Anirudh Sreeram; Anurenjan Purushothaman; Rohit Kumar; Sriram Ganapathy', display:{Lore:['[{"text": "arXiv:2005.11258", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lLEAP Submission to CHiME-6 ASR Challenge}\\u00a7r\\n\\n\\u00a78\\u00a7oAnirudh Sreeram\\nAnurenjan Purushothaman\\nRohit Kumar\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.11258\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 22 May 2020 16:14:06 GMT)\\u00a7r"}']}
{title:'Cosentino et al. (§72020§r)', author: 'Joris Cosentino; Manuel Pariente; Samuele Cornell; Antoine Deleforge; Emmanuel Vincent', display:{Lore:['[{"text": "arXiv:2005.11262", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lLibriMix: An Open-Source Dataset for Generalizable Speech Separation\\u00a7r\\n\\n\\u00a78\\u00a7oJoris Cosentino\\nManuel Pariente\\nSamuele Cornell\\nAntoine Deleforge\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.11262\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 22 May 2020 16:26:54 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7osubmitted to INTERSPEECH 2020\\u00a7r"}']}
{title:'Silva et al. (§72020§r)', author: 'Dimitri Leandro de Oliveira Silva; Tito Spadini; Ricardo Suyama', display:{Lore:['[{"text": "arXiv:2005.11348", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.SP\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMicrophone Array Based Surveillance Audio Classification\\u00a7r\\n\\n\\u00a78\\u00a7oDimitri Leandro de Oliveira Silva\\nTito Spadini\\nRicardo Suyama\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.11348\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 22 May 2020 18:35:08 GMT)\\u00a7r"}']}
{title:'Wang et al. (§72020§r)', author: 'Jixuan Wang; Xiong Xiao; Jian Wu; Ranjani Ramamurthy; Frank Rudzicz; Michael Brudno', display:{Lore:['[{"text": "arXiv:2005.11371", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSpeaker diarization with session-level speaker embedding refinement using graph neural networks\\u00a7r\\n\\n\\u00a78\\u00a7oJixuan Wang\\nXiong Xiao\\nJian Wu\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.11371\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 22 May 2020 19:52:51 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oICASSP 2020 (45th International Conference on Acoustics, Speech, and Signal Processing)\\u00a7r"}']}
{title:'Zhu et al. (§72020§r)', author: 'Junzhe Zhu; Mark Hasegawa-Johnson; Leda Sari', display:{Lore:['[{"text": "arXiv:2005.11408", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lIdentify Speakers in Cocktail Parties with End-to-End Attention\\u00a7r\\n\\n\\u00a78\\u00a7oJunzhe Zhu\\nMark Hasegawa-Johnson\\nLeda Sari\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.11408\\u00a7r\\n\\nVersion:\\u00a77v2 (Sun, 9 Aug 2020 09:24:35 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted by Interspeech 2020 for presentation; https://github.com/JunzheJosephZhu/Identify-Speakers-in-Cocktail-Parties-with-E2E-Attention\\u00a7r"}']}
{title:'Koyama et al. (§72020§r)', author: 'Yuichiro Koyama; Tyler Vuong; Stefan Uhlich; Bhiksha Raj', display:{Lore:['[{"text": "arXiv:2005.11611", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lExploring the Best Loss Function for DNN-Based Low-latency Speech Enhancement with Temporal Convolutional Networks\\u00a7r\\n\\n\\u00a78\\u00a7oYuichiro Koyama\\nTyler Vuong\\nStefan Uhlich\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.11611\\u00a7r\\n\\nVersion:\\u00a77v3 (Thu, 20 Aug 2020 05:12:35 GMT)\\u00a7r"}']}
{title:'Koyama et al. (§72020§r)', author: 'Yuichiro Koyama; Oluwafemi Azeez; Bhiksha Raj', display:{Lore:['[{"text": "arXiv:2005.11612", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lEfficient Integration of Multi-channel Information for Speaker-independent Speech Separation\\u00a7r\\n\\n\\u00a78\\u00a7oYuichiro Koyama\\nOluwafemi Azeez\\nBhiksha Raj\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.11612\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 11 Aug 2020 08:01:47 GMT)\\u00a7r"}']}
{title:'Drugman et al. (§72020§r)', author: "Thomas Drugman; Thomas Dubuisson; Alexis Moinet; Nicolas D'Alessandro; Thierry Dutoit", display:{Lore:['[{"text": "arXiv:2005.11682", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lGlottal source estimation robustness: A comparison of sensitivity of voice source estimation techniques\\u00a7r\\n\\n\\u00a78\\u00a7oThomas Drugman\\nThomas Dubuisson\\nAlexis Moinet\\nNicolas D\'Alessandro\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.11682\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 24 May 2020 08:13:47 GMT)\\u00a7r"}']}
{title:'Lee et al. (§72020§r)', author: 'Chi-Chang Lee; Yu-Chen Lin; Hsuan-Tien Lin; Hsin-Min Wang; Yu Tsao', display:{Lore:['[{"text": "arXiv:2005.11760", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSERIL: Noise Adaptive Speech Enhancement using Regularization-based Incremental Learning\\u00a7r\\n\\n\\u00a78\\u00a7oChi-Chang Lee\\nYu-Chen Lin\\nHsuan-Tien Lin\\nHsin-Min Wang\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.11760\\u00a7r\\n\\nVersion:\\u00a77v2 (Thu, 17 Sep 2020 20:08:40 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted to Interspeech 2020\\u00a7r"}']}
{title:'Chuang et al. (§72020§r)', author: 'Shang-Yi Chuang; Yu Tsao; Chen-Chou Lo; Hsin-Min Wang', display:{Lore:['[{"text": "arXiv:2005.11769", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lLite Audio-Visual Speech Enhancement\\u00a7r\\n\\n\\u00a78\\u00a7oShang-Yi Chuang\\nYu Tsao\\nChen-Chou Lo\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.11769\\u00a7r\\n\\nVersion:\\u00a77v3 (Tue, 18 Aug 2020 13:33:54 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted to Interspeech 2020\\u00a7r"}']}
{title:'Ma et al. (§72020§r)', author: 'Murong Ma; Haiwei Wu; Xuyang Wang; Lin Yang; Junjie Wang; Ming Li', display:{Lore:['[{"text": "arXiv:2005.11777", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAcoustic Word Embedding System for Code-Switching Query-by-example Spoken Term Detection\\u00a7r\\n\\n\\u00a78\\u00a7oMurong Ma\\nHaiwei Wu\\nXuyang Wang\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.11777\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 24 May 2020 15:27:56 GMT)\\u00a7r"}']}
{title:'Kang et al. (§72020§r)', author: 'Jiawen Kang; Ruiqi Liu; Lantian Li; Yunqi Cai; Dong Wang; Thomas Fang Zheng', display:{Lore:['[{"text": "arXiv:2005.11900", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDomain-Invariant Speaker Vector Projection by Model-Agnostic Meta-Learning\\u00a7r\\n\\n\\u00a78\\u00a7oJiawen Kang\\nRuiqi Liu\\nLantian Li\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.11900\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 25 May 2020 03:02:09 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7osubmitted to INTERSPEECH 2020\\u00a7r"}']}
{title:'Cheng et al. (§72020§r)', author: 'Sitong Cheng; Zhixin Liu; Lantian Li; Zhiyuan Tang; Dong Wang; Thomas Fang Zheng', display:{Lore:['[{"text": "arXiv:2005.11902", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lASR-Free Pronunciation Assessment\\u00a7r\\n\\n\\u00a78\\u00a7oSitong Cheng\\nZhixin Liu\\nLantian Li\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.11902\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 25 May 2020 03:10:29 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7osubmitted to INTRESPEECH 2020\\u00a7r"}']}
{title:'Li et al. (§72020§r)', author: 'Lantian Li; Dong Wang; Thomas Fang Zheng', display:{Lore:['[{"text": "arXiv:2005.11905", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lNeural Discriminant Analysis for Deep Speaker Embedding\\u00a7r\\n\\n\\u00a78\\u00a7oLantian Li\\nDong Wang\\nThomas Fang Zheng\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.11905\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 25 May 2020 03:17:12 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7osubmitted to INTERSPEECH 2020\\u00a7r"}']}
{title:'Yan et al. (§72020§r)', author: 'Bi-Cheng Yan; Meng-Che Wu; Hsiao-Tsung Hung; Berlin Chen', display:{Lore:['[{"text": "arXiv:2005.11950", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAn End-to-End Mispronunciation Detection System for L2 English Speech Leveraging Novel Anti-Phone Modeling\\u00a7r\\n\\n\\u00a78\\u00a7oBi-Cheng Yan\\nMeng-Che Wu\\nHsiao-Tsung Hung\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.11950\\u00a7r\\n\\nVersion:\\u00a77v2 (Fri, 28 Aug 2020 07:41:49 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted by Interspeech2020\\u00a7r"}']}
{title:'Liu et al. (§72020§r)', author: 'Lu Liu; Yiheng Huang', display:{Lore:['[{"text": "arXiv:2005.11978", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMasked Pre-trained Encoder base on Joint CTC-Transformer\\u00a7r\\n\\n\\u00a78\\u00a7oLu Liu\\nYiheng Huang\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.11978\\u00a7r\\n\\nVersion:\\u00a77v2 (Thu, 13 Aug 2020 12:55:32 GMT)\\u00a7r"}']}
{title:'Dai et al. (§72020§r)', author: 'Dongyang Dai; Li Chen; Yuping Wang; Mu Wang; Rui Xia; Xuchen Song; Zhiyong Wu; Yuxuan Wang', display:{Lore:['[{"text": "arXiv:2005.12531", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lNoise Robust TTS for Low Resource Speakers using Pre-trained Model and Speech Enhancement\\u00a7r\\n\\n\\u00a78\\u00a7oDongyang Dai\\nLi Chen\\nYuping Wang\\n+ 4 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.12531\\u00a7r\\n\\nVersion:\\u00a77v2 (Thu, 22 Oct 2020 11:36:56 GMT)\\u00a7r"}']}
{title:'Gref et al. (§72020§r)', author: 'Michael Gref; Oliver Walter; Christoph Schmidt; Sven Behnke; Joachim Köhler', display:{Lore:['[{"text": "arXiv:2005.12562", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMulti-Staged Cross-Lingual Acoustic Model Adaption for Robust Speech Recognition in Real-World Applications \\u2013 A Case Study on German Oral History Interviews\\u00a7r\\n\\n\\u00a78\\u00a7oMichael Gref\\nOliver Walter\\nChristoph Schmidt\\nSven Behnke\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.12562\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7n12th International Conference on Language Resources and Evaluation\\n  (LREC 2020), pages 6354-6362\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 26 May 2020 08:05:25 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oPublished version of the paper can be accessed via https://www.aclweb.org/anthology/2020.lrec-1.780\\u00a7r"}']}
{title:'Koyama et al. (§72020§r)', author: 'Yuichiro Koyama; Bhiksha Raj', display:{Lore:['[{"text": "arXiv:2005.12683", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lExploring Optimal DNN Architecture for End-to-End Beamformers Based on Time-frequency References\\u00a7r\\n\\n\\u00a78\\u00a7oYuichiro Koyama\\nBhiksha Raj\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.12683\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 11 Aug 2020 08:04:39 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oarXiv admin note: substantial text overlap with arXiv:1910.14262\\u00a7r"}']}
{title:'Phan et al. (§72020§r)', author: 'Huy Kinh Phan; Viet Lam Phung; Tuan Anh Dinh; Bao Quoc Nguyen', display:{Lore:['[{"text": "arXiv:2005.12962", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA comparison of Vietnamese Statistical Parametric Speech Synthesis Systems\\u00a7r\\n\\n\\u00a78\\u00a7oHuy Kinh Phan\\nViet Lam Phung\\nTuan Anh Dinh\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.12962\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 26 May 2020 18:32:03 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o9 pages, submitted to KSE 2020\\u00a7r"}']}
{title:'Chen et al. (§72020§r)', author: 'Hangting Chen; Zuozhen Liu; Zongming Liu; Pengyuan Zhang', display:{Lore:['[{"text": "arXiv:2005.13146", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lACGAN-based Data Augmentation Integrated with Long-term Scalogram for Acoustic Scene Classification\\u00a7r\\n\\n\\u00a78\\u00a7oHangting Chen\\nZuozhen Liu\\nZongming Liu\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.13146\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1121/10.0005202\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nThe Journal of the Acoustical Society of America 149, 4198 (2021)\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 27 May 2020 04:01:03 GMT)\\u00a7r"}']}
{title:'Fujita et al. (§72020§r)', author: 'Yuya Fujita; Shinji Watanabe; Motoi Omachi; Xuankai Chan', display:{Lore:['[{"text": "arXiv:2005.13211", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lInsertion-Based Modeling for End-to-End Automatic Speech Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oYuya Fujita\\nShinji Watanabe\\nMotoi Omachi\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.13211\\u00a7r\\n\\nVersion:\\u00a77v2 (Mon, 16 Nov 2020 01:15:49 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oINTERSPEECH 2020\\u00a7r"}']}
{title:'An et al. (§72020§r)', author: 'Keyu An; Hongyu Xiang; Zhijian Ou', display:{Lore:['[{"text": "arXiv:2005.13326", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lCAT: A CTC-CRF based ASR Toolkit Bridging the Hybrid and the End-to-end Approaches towards Data Efficiency and Low Latency\\u00a7r\\n\\n\\u00a78\\u00a7oKeyu An\\nHongyu Xiang\\nZhijian Ou\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.13326\\u00a7r\\n\\nVersion:\\u00a77v2 (Wed, 5 Aug 2020 02:00:08 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted into INTERSPEECH 2020. arXiv admin note: text overlap with arXiv:1911.08747\\u00a7r"}']}
{title:'Abdelaziz et al. (§72020§r)', author: 'Ahmed Hussen Abdelaziz; Barry-John Theobald; Paul Dixon; Reinhard Knothe; Nicholas Apostoloff; Sachin Kajareker', display:{Lore:['[{"text": "arXiv:2005.13616", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lModality Dropout for Improved Performance-driven Talking Faces\\u00a7r\\n\\n\\u00a78\\u00a7oAhmed Hussen Abdelaziz\\nBarry-John Theobald\\nPaul Dixon\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.13616\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 27 May 2020 19:55:33 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oPre-print\\u00a7r"}']}
{title:'Narayanaswamy et al. (§72020§r)', author: 'Vivek Narayanaswamy; Jayaraman J. Thiagarajan; Rushil Anirudh; Andreas Spanias', display:{Lore:['[{"text": "arXiv:2005.13769", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lUnsupervised Audio Source Separation using Generative Priors\\u00a7r\\n\\n\\u00a78\\u00a7oVivek Narayanaswamy\\nJayaraman J. Thiagarajan\\nRushil Anirudh\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.13769\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 28 May 2020 03:57:16 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 2 figures\\u00a7r"}']}
{title:'Wang et al. (§72020§r)', author: 'Run Wang; Felix Juefei-Xu; Yihao Huang; Qing Guo; Xiaofei Xie; Lei Ma; Yang Liu', display:{Lore:['[{"text": "arXiv:2005.13770", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CR\\u00a7r, \\u00a7acs.MM\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDeepSonar: Towards Effective and Robust Detection of AI-Synthesized Fake Voices\\u00a7r\\n\\n\\u00a78\\u00a7oRun Wang\\nFelix Juefei-Xu\\nYihao Huang\\n+ 3 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.13770\\u00a7r\\n\\nVersion:\\u00a77v3 (Sat, 15 Aug 2020 13:37:57 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted by ACM MM\'20\\u00a7r"}']}
{title:'Wu et al. (§72020§r)', author: 'Da-Yi Wu; Yi-Hsuan Yang', display:{Lore:['[{"text": "arXiv:2005.13835", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSpeech-to-Singing Conversion based on Boundary Equilibrium GAN\\u00a7r\\n\\n\\u00a78\\u00a7oDa-Yi Wu\\nYi-Hsuan Yang\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.13835\\u00a7r\\n\\nVersion:\\u00a77v3 (Wed, 5 Aug 2020 13:21:32 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted for publication at INTERSPEECH 2020\\u00a7r"}']}
{title:'Zhang et al. (§72020§r)', author: 'Shucong Zhang; Erfan Loweimi; Peter Bell; Steve Renals', display:{Lore:['[{"text": "arXiv:2005.13895", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lWhen Can Self-Attention Be Replaced by Feed Forward Layers?\\u00a7r\\n\\n\\u00a78\\u00a7oShucong Zhang\\nErfan Loweimi\\nPeter Bell\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.13895\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 28 May 2020 10:35:49 GMT)\\u00a7r"}']}
{title:'Reddy et al. (§72020§r)', author: 'Chandan K. A. Reddy; Vishak Gopal; Ross Cutler; Ebrahim Beyrami; Roger Cheng; Harishchandra Dubey; Sergiy Matusevych; Robert Aichner; Ashkan Aazami; Sebastian Braun; Puneet Rana; Sriram Srinivasan; Johannes Gehrke', display:{Lore:['[{"text": "arXiv:2005.13981", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lThe INTERSPEECH 2020 Deep Noise Suppression Challenge: Datasets, Subjective Testing Framework, and Challenge Results\\u00a7r\\n\\n\\u00a78\\u00a7oChandan K. A. Reddy\\nVishak Gopal\\nRoss Cutler\\n+ 9 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.13981\\u00a7r\\n\\nVersion:\\u00a77v3 (Sun, 18 Oct 2020 04:36:21 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oInterspeech 2020. arXiv admin note: substantial text overlap with arXiv:2001.08662\\u00a7r"}']}
{title:'de Carvalho et al. (§72020§r)', author: 'Hugo Tremonte de Carvalho; Flávio Rainho Ávila; Luiz Wagner Pereira Biscainho', display:{Lore:['[{"text": "arXiv:2005.14181", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7eeess.SP\\u00a7r, \\u00a7cstat.AP\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lBayesian Restoration of Audio Degraded by Low-Frequency Pulses Modeled via Gaussian Process\\u00a7r\\n\\n\\u00a78\\u00a7oHugo Tremonte de Carvalho\\nFl\\u00e1vio Rainho \\u00c1vila\\nLuiz Wagner Pereira Biscainho\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.14181\\u00a7r\\n\\nVersion:\\u00a77v2 (Sat, 26 Sep 2020 14:11:51 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o14 pages, 7 figures, 4 tables. Submitted to IEEE Journal of Selected Topics in Signal Processing - Special Issue \\"Reconstruction of audio from incomplete or highly degraded observations\\"\\u00a7r"}']}
{title:'Iman et al. (§72020§r)', author: 'Mohammadreza Iman; Amy Giuntini; Hamid Reza Arabnia; Khaled Rasheed', display:{Lore:['[{"text": "arXiv:2005.14257", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7bq-bio.QM\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Comparative Study of Machine Learning Models for Tabular Data Through Challenge of Monitoring Parkinson\'s Disease Progression Using Voice Recordings\\u00a7r\\n\\n\\u00a78\\u00a7oMohammadreza Iman\\nAmy Giuntini\\nHamid Reza Arabnia\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.14257\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1007/978-3-030-71051-4_38\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nAdvances in Computer Vision and Computational Biology 2021.\\n  Transactions on Computational Science and Computational Intelligence.\\n  Springer, Cham\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 27 May 2020 16:09:26 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted at \\"HIMS\'20 - The 6th Int\'l Conf on Health Informatics and MedicalSystems\\"; https://americancse.org/events/csce2020/conferences/hims20\\u00a7r"}']}
{title:'Li et al. (§72020§r)', author: 'Jinyu Li; Yu Wu; Yashesh Gaur; Chengyi Wang; Rui Zhao; Shujie Liu', display:{Lore:['[{"text": "arXiv:2005.14327", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lOn the Comparison of Popular End-to-End Models for Large Scale Speech Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oJinyu Li\\nYu Wu\\nYashesh Gaur\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.14327\\u00a7r\\n\\nVersion:\\u00a77v2 (Thu, 30 Jul 2020 01:57:22 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted by Interspeech 2020\\u00a7r"}']}
{title:'Hao et al. (§72020§r)', author: 'Xiang Hao; Shixue Wen; Xiangdong Su; Yun Liu; Guanglai Gao; Xiaofei Li', display:{Lore:['[{"text": "arXiv:2005.14435", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSub-Band Knowledge Distillation Framework for Speech Enhancement\\u00a7r\\n\\n\\u00a78\\u00a7oXiang Hao\\nShixue Wen\\nXiangdong Su\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.14435\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.21437/Interspeech.2020-1539\\u00a7r\\n\\nVersion:\\u00a77v2 (Thu, 29 Oct 2020 12:14:59 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oPublished in Interspeech 2020\\u00a7r"}']}
{title:'Hao et al. (§72020§r)', author: 'Xiang Hao; Xiangdong Su; Zhiyu Wang; Qiang Zhang; Huali Xu; Guanglai Gao', display:{Lore:['[{"text": "arXiv:2005.14441", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSNR-Based Teachers-Student Technique for Speech Enhancement\\u00a7r\\n\\n\\u00a78\\u00a7oXiang Hao\\nXiangdong Su\\nZhiyu Wang\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.14441\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/ICME46284.2020.9102846\\u00a7r\\n\\nVersion:\\u00a77v2 (Thu, 29 Oct 2020 12:12:20 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oPublished in 2020IEEE International Conference on Multimedia and Expo (ICME 2020)\\u00a7r"}']}
{title:'Milde et al. (§72020§r)', author: 'Benjamin Milde; Chris Biemann', display:{Lore:['[{"text": "arXiv:2005.14578", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lImproving Unsupervised Sparsespeech Acoustic Models with Categorical Reparameterization\\u00a7r\\n\\n\\u00a78\\u00a7oBenjamin Milde\\nChris Biemann\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.14578\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 29 May 2020 13:58:36 GMT)\\u00a7r"}']}
{title:'Däubener et al. (§72020§r)', author: 'Sina Däubener; Lea Schönherr; Asja Fischer; Dorothea Kolossa', display:{Lore:['[{"text": "arXiv:2005.14611", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CR\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDetecting Adversarial Examples for Speech Recognition via Uncertainty Quantification\\u00a7r\\n\\n\\u00a78\\u00a7oSina D\\u00e4ubener\\nLea Sch\\u00f6nherr\\nAsja Fischer\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.14611\\u00a7r\\n\\nVersion:\\u00a77v2 (Sun, 2 Aug 2020 16:37:01 GMT)\\u00a7r"}']}
{title:'Heittola et al. (§72020§r)', author: 'Toni Heittola; Annamaria Mesaros; Tuomas Virtanen', display:{Lore:['[{"text": "arXiv:2005.14623", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAcoustic scene classification in DCASE 2020 Challenge: generalization across devices and low complexity solutions\\u00a7r\\n\\n\\u00a78\\u00a7oToni Heittola\\nAnnamaria Mesaros\\nTuomas Virtanen\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.14623\\u00a7r\\n\\nVersion:\\u00a77v2 (Mon, 2 Nov 2020 13:49:36 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7opublished in DCASE 2020 Workshop\\u00a7r"}']}
{title:'Pompili et al. (§72020§r)', author: 'Anna Pompili; Thomas Rolland; Alberto Abad', display:{Lore:['[{"text": "arXiv:2005.14646", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lThe INESC-ID Multi-Modal System for the ADReSS 2020 Challenge\\u00a7r\\n\\n\\u00a78\\u00a7oAnna Pompili\\nThomas Rolland\\nAlberto Abad\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.14646\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 29 May 2020 16:16:02 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 1 figure. Submitted to INTERSPEECH2020\\u00a7r"}']}
{title:'Pompili et al. (§72020§r)', author: 'Anna Pompili; Rubén Solera-Ureña; Alberto Abad; Rita Cardoso; Isabel Guimarães; Margherita Fabbri; Isabel P. Martins; Joaquim Ferreira', display:{Lore:['[{"text": "arXiv:2005.14647", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAssessment of Parkinson\'s Disease Medication State through Automatic Speech Analysis\\u00a7r\\n\\n\\u00a78\\u00a7oAnna Pompili\\nRub\\u00e9n Solera-Ure\\u00f1a\\nAlberto Abad\\n+ 4 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2005.14647\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 25 Aug 2020 09:16:32 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages. In proceedings of INTERSPEECH2020\\u00a7r"}']}
{title:'López-Espejo et al. (§72020§r)', author: 'Iván López-Espejo; Zheng-Hua Tan; Jesper Jensen', display:{Lore:['[{"text": "arXiv:2006.00217", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lExploring Filterbank Learning for Keyword Spotting\\u00a7r\\n\\n\\u00a78\\u00a7oIv\\u00e1n L\\u00f3pez-Espejo\\nZheng-Hua Tan\\nJesper Jensen\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.00217\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 30 May 2020 08:11:58 GMT)\\u00a7r"}']}
{title:'Tatar et al. (§72020§r)', author: 'K. Tatar; D. Bisig; P. Pasquier', display:{Lore:['[{"text": "arXiv:2006.00408", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lIntroducing Latent Timbre Synthesis\\u00a7r\\n\\n\\u00a78\\u00a7oK. Tatar\\nD. Bisig\\nP. Pasquier\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.00408\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1007/s00521-020-05424-2\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 31 May 2020 01:54:50 GMT)\\u00a7r"}']}
{title:'Drugman et al. (§72020§r)', author: 'Thomas Drugman; John Kane; Christer Gobl', display:{Lore:['[{"text": "arXiv:2006.00518", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lData-driven Detection and Analysis of the Patterns of Creaky Voice\\u00a7r\\n\\n\\u00a78\\u00a7oThomas Drugman\\nJohn Kane\\nChrister Gobl\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.00518\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 31 May 2020 13:34:30 GMT)\\u00a7r"}']}
{title:'Drugman et al. (§72020§r)', author: 'Thomas Drugman; Yannis Stylianou', display:{Lore:['[{"text": "arXiv:2006.00521", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMaximum Voiced Frequency Estimation: Exploiting Amplitude and Phase Spectra\\u00a7r\\n\\n\\u00a78\\u00a7oThomas Drugman\\nYannis Stylianou\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.00521\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 31 May 2020 13:40:46 GMT)\\u00a7r"}']}
{title:'Drugman (§72020§r)', author: 'Thomas Drugman', display:{Lore:['[{"text": "arXiv:2006.00525", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lResidual Excitation Skewness for Automatic Speech Polarity Detection\\u00a7r\\n\\n\\u00a78\\u00a7oThomas Drugman\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.00525\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 31 May 2020 13:56:07 GMT)\\u00a7r"}']}
{title:'Choi et al. (§72020§r)', author: 'Hyeong-Seok Choi; Hoon Heo; Jie Hwan Lee; Kyogu Lee', display:{Lore:['[{"text": "arXiv:2006.00687", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lPhase-aware Single-stage Speech Denoising and Dereverberation with U-Net\\u00a7r\\n\\n\\u00a78\\u00a7oHyeong-Seok Choi\\nHoon Heo\\nJie Hwan Lee\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.00687\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 1 Jun 2020 03:23:51 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 3 figures, Submitted to Interspeech2020\\u00a7r"}']}
{title:'Chandak et al. (§72020§r)', author: 'Chander Chandak; Zeynab Raeesy; Ariya Rastrow; Yuzong Liu; Xiangyang Huang; Siyu Wang; Dong Kwon Joo; Roland Maas', display:{Lore:['[{"text": "arXiv:2006.00703", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lStreaming Language Identification using Combination of Acoustic Representations and ASR Hypotheses\\u00a7r\\n\\n\\u00a78\\u00a7oChander Chandak\\nZeynab Raeesy\\nAriya Rastrow\\n+ 4 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.00703\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 1 Jun 2020 04:08:55 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 2 figures\\u00a7r"}']}
{title:'Won et al. (§72020§r)', author: 'Minz Won; Andres Ferraro; Dmitry Bogdanov; Xavier Serra', display:{Lore:['[{"text": "arXiv:2006.00751", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lEvaluation of CNN-based Automatic Music Tagging Models\\u00a7r\\n\\n\\u00a78\\u00a7oMinz Won\\nAndres Ferraro\\nDmitry Bogdanov\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.00751\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 1 Jun 2020 07:03:26 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o7 pages, 2 figures, Soundand Music Computing 2020 (SMC 2020)\\u00a7r"}']}
{title:'Hiroe (§72020§r)', author: 'Atsuo Hiroe', display:{Lore:['[{"text": "arXiv:2006.00772", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7eeess.SP\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSimilarity-and-Independence-Aware Beamformer: Method for Target Source Extraction using Magnitude Spectrogram as Reference\\u00a7r\\n\\n\\u00a78\\u00a7oAtsuo Hiroe\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.00772\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.21437/Interspeech.2020-1365\\u00a7r\\n\\nVersion:\\u00a77v3 (Mon, 24 Aug 2020 06:30:38 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted in INTERSPEECH 2020\\u00a7r"}']}
{title:'Shah et al. (§72020§r)', author: 'Sanket Shah; Basil Abraham; Gurunath Reddy M; Sunayana Sitaram; Vikas Joshi', display:{Lore:['[{"text": "arXiv:2006.00782", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lLearning to Recognize Code-switched Speech Without Forgetting Monolingual Speech Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oSanket Shah\\nBasil Abraham\\nGurunath Reddy M\\nSunayana Sitaram\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.00782\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 1 Jun 2020 08:16:24 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages (4 pages + 1 page references), 5 tables, 1 figure, 1 algorithm, 16 references\\u00a7r"}']}
{title:'Roberts et al. (§72020§r)', author: 'Timothy Roberts; Kuldip K. Paliwal', display:{Lore:['[{"text": "arXiv:2006.00848", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA time-scale modification dataset with subjective quality labels\\u00a7r\\n\\n\\u00a78\\u00a7oTimothy Roberts\\nKuldip K. Paliwal\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.00848\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1121/10.0001567\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nJ. Acoust. Soc. Am. 148(1). pp. 201-210 (2020)\\u00a7r\\n\\nVersion:\\u00a77v2 (Thu, 16 Jul 2020 00:39:59 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o12 Pages, 13 Figures, Published in The Journal of the Acoustical Society of America (Vol.148, Issue 1), For associated dataset, see http://ieee-dataport.org/1987\\u00a7r"}']}
{title:'Haque et al. (§72020§r)', author: 'Kazi Nazmul Haque; Rajib Rana; Björn W Schuller', display:{Lore:['[{"text": "arXiv:2006.00877", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lHigh-Fidelity Audio Generation and Representation Learning with Guided Adversarial Autoencoder\\u00a7r\\n\\n\\u00a78\\u00a7oKazi Nazmul Haque\\nRajib Rana\\nBj\\u00f6rn W Schuller\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.00877\\u00a7r\\n\\nVersion:\\u00a77v2 (Sat, 17 Oct 2020 12:53:36 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oThe paper is submitted to IEEE Access for review\\u00a7r"}']}
{title:'Krishna et al. (§72020§r)', author: 'Gautam Krishna; Co Tran; Mason Carnahan; Ahmed Tewfik', display:{Lore:['[{"text": "arXiv:2006.01260", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lImproving EEG based continuous speech recognition using GAN\\u00a7r\\n\\n\\u00a78\\u00a7oGautam Krishna\\nCo Tran\\nMason Carnahan\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.01260\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 29 May 2020 06:11:33 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oUnder Review\\u00a7r"}']}
{title:'Krishna et al. (§72020§r)', author: 'Gautam Krishna; Co Tran; Mason Carnahan; Ahmed Tewfik', display:{Lore:['[{"text": "arXiv:2006.01261", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7eeess.SP\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lUnderstanding effect of speech perception in EEG based speech recognition systems\\u00a7r\\n\\n\\u00a78\\u00a7oGautam Krishna\\nCo Tran\\nMason Carnahan\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.01261\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 29 May 2020 05:56:09 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oUnder Review\\u00a7r"}']}
{title:'Krishna et al. (§72020§r)', author: 'Gautam Krishna; Co Tran; Mason Carnahan; Ahmed Tewfik', display:{Lore:['[{"text": "arXiv:2006.01262", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7eeess.SP\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lPredicting Different Acoustic Features from EEG and towards direct synthesis of Audio Waveform from EEG\\u00a7r\\n\\n\\u00a78\\u00a7oGautam Krishna\\nCo Tran\\nMason Carnahan\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.01262\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 29 May 2020 05:50:03 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oUnder Review\\u00a7r"}']}
{title:'Fayek et al. (§72020§r)', author: 'Haytham M. Fayek; Anurag Kumar', display:{Lore:['[{"text": "arXiv:2006.01595", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7eeess.IV\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lLarge Scale Audiovisual Learning of Sounds with Weakly Labeled Data\\u00a7r\\n\\n\\u00a78\\u00a7oHaytham M. Fayek\\nAnurag Kumar\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.01595\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 29 May 2020 01:30:14 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o29th International Joint Conference on Artificial Intelligence (IJCAI 2020)\\u00a7r"}']}
{title:'Bosca et al. (§72020§r)', author: 'Amélie Bosca; Alexandre Guérin; Lauréline Perotin; Srđan Kitić', display:{Lore:['[{"text": "arXiv:2006.01708", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7eeess.SP\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDilated U-net based approach for multichannel speech enhancement from First-Order Ambisonics recordings\\u00a7r\\n\\n\\u00a78\\u00a7oAm\\u00e9lie Bosca\\nAlexandre Gu\\u00e9rin\\nLaur\\u00e9line Perotin\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.01708\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 2 Jun 2020 15:26:07 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted for EUSIPCO 2020\\u00a7r"}']}
{title:'Fujita et al. (§72020§r)', author: 'Yusuke Fujita; Shinji Watanabe; Shota Horiguchi; Yawen Xue; Jing Shi; Kenji Nagamatsu', display:{Lore:['[{"text": "arXiv:2006.01796", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lNeural Speaker Diarization with Speaker-Wise Chain Rule\\u00a7r\\n\\n\\u00a78\\u00a7oYusuke Fujita\\nShinji Watanabe\\nShota Horiguchi\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.01796\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 2 Jun 2020 17:28:12 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to Interspeech 2020\\u00a7r"}']}
{title:'Jayashankar et al. (§72020§r)', author: 'Tejas Jayashankar; Jonathan Le Roux; Pierre Moulin', display:{Lore:['[{"text": "arXiv:2006.01906", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CR\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDetecting Audio Attacks on ASR Systems with Dropout Uncertainty\\u00a7r\\n\\n\\u00a78\\u00a7oTejas Jayashankar\\nJonathan Le Roux\\nPierre Moulin\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.01906\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 15 Sep 2020 01:41:59 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted for publication at Interspeech 2020\\u00a7r"}']}
{title:'Politis et al. (§72020§r)', author: 'Archontis Politis; Sharath Adavanne; Tuomas Virtanen', display:{Lore:['[{"text": "arXiv:2006.01919", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Dataset of Reverberant Spatial Sound Scenes with Moving Sources for Sound Event Localization and Detection\\u00a7r\\n\\n\\u00a78\\u00a7oArchontis Politis\\nSharath Adavanne\\nTuomas Virtanen\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.01919\\u00a7r\\n\\nVersion:\\u00a77v2 (Sat, 27 Jun 2020 11:43:22 GMT)\\u00a7r"}']}
{title:'Daniel et al. (§72020§r)', author: 'Jérôme Daniel; Srđan Kitić', display:{Lore:['[{"text": "arXiv:2006.02099", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lTime Domain Velocity Vector for Retracing the Multipath Propagation\\u00a7r\\n\\n\\u00a78\\u00a7oJ\\u00e9r\\u00f4me Daniel\\nSr\\u0111an Kiti\\u0107\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.02099\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 3 Jun 2020 08:30:06 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oPresented at ICASSP 2020\\u00a7r"}']}
{title:'Khurana et al. (§72020§r)', author: 'Sameer Khurana; Antoine Laurent; Wei-Ning Hsu; Jan Chorowski; Adrian Lancucki; Ricard Marxer; James Glass', display:{Lore:['[{"text": "arXiv:2006.02547", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Convolutional Deep Markov Model for Unsupervised Speech Representation Learning\\u00a7r\\n\\n\\u00a78\\u00a7oSameer Khurana\\nAntoine Laurent\\nWei-Ning Hsu\\n+ 3 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.02547\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 8 Sep 2020 14:09:58 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oProceedings of Interspeech, 2020\\u00a7r"}']}
{title:'von Neumann et al. (§72020§r)', author: 'Thilo von Neumann; Christoph Boeddeker; Lukas Drude; Keisuke Kinoshita; Marc Delcroix; Tomohiro Nakatani; Reinhold Haeb-Umbach', display:{Lore:['[{"text": "arXiv:2006.02786", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMulti-talker ASR for an unknown number of sources: Joint training of source counting, separation and ASR\\u00a7r\\n\\n\\u00a78\\u00a7oThilo von Neumann\\nChristoph Boeddeker\\nLukas Drude\\n+ 3 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.02786\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.21437/Interspeech.2020-2519\\u00a7r\\n\\nVersion:\\u00a77v3 (Mon, 21 Dec 2020 12:27:40 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, INTERSPEECH 2020\\u00a7r"}']}
{title:'Khurana et al. (§72020§r)', author: 'Sameer Khurana; Antoine Laurent; James Glass', display:{Lore:['[{"text": "arXiv:2006.02814", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lCSTNet: Contrastive Speech Translation Network for Self-Supervised Speech Representation Learning\\u00a7r\\n\\n\\u00a78\\u00a7oSameer Khurana\\nAntoine Laurent\\nJames Glass\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.02814\\u00a7r\\n\\nVersion:\\u00a77v2 (Wed, 5 Aug 2020 07:28:36 GMT)\\u00a7r"}']}
{title:'Krishna et al. (§72020§r)', author: 'Gautam Krishna; Co Tran; Mason Carnahan; Ahmed Tewfik', display:{Lore:['[{"text": "arXiv:2006.02902", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7eeess.SP\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lConstrained Variational Autoencoder for improving EEG based Speech Recognition Systems\\u00a7r\\n\\n\\u00a78\\u00a7oGautam Krishna\\nCo Tran\\nMason Carnahan\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.02902\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 1 Jun 2020 06:03:50 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oUnder Review. arXiv admin note: substantial text overlap with arXiv:2006.01260\\u00a7r"}']}
{title:'Singh et al. (§72020§r)', author: 'Abhayjeet Singh; Aravind Illa; Prasanta Kumar Ghosh', display:{Lore:['[{"text": "arXiv:2006.03107", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAttention and Encoder-Decoder based models for transforming articulatory movements at different speaking rates\\u00a7r\\n\\n\\u00a78\\u00a7oAbhayjeet Singh\\nAravind Illa\\nPrasanta Kumar Ghosh\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.03107\\u00a7r\\n\\nVersion:\\u00a77v2 (Thu, 20 Aug 2020 05:00:07 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 4 figures, InterSpeech 2020\\u00a7r"}']}
{title:'Wu et al. (§72020§r)', author: 'Haibin Wu; Andy T. Liu; Hung-yi Lee', display:{Lore:['[{"text": "arXiv:2006.03214", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDefense for Black-box Attacks on Anti-spoofing Models by Self-Supervised Learning\\u00a7r\\n\\n\\u00a78\\u00a7oHaibin Wu\\nAndy T. Liu\\nHung-yi Lee\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.03214\\u00a7r\\n\\nVersion:\\u00a77v3 (Mon, 7 Dec 2020 08:13:50 GMT)\\u00a7r"}']}
{title:'Jain et al. (§72020§r)', author: 'Mahaveer Jain; Gil Keren; Jay Mahadeokar; Geoffrey Zweig; Florian Metze; Yatharth Saraf', display:{Lore:['[{"text": "arXiv:2006.03411", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lContextual RNN-T For Open Domain ASR\\u00a7r\\n\\n\\u00a78\\u00a7oMahaveer Jain\\nGil Keren\\nJay Mahadeokar\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.03411\\u00a7r\\n\\nVersion:\\u00a77v2 (Wed, 12 Aug 2020 23:17:13 GMT)\\u00a7r"}']}
{title:'Müller et al. (§72020§r)', author: 'Robert Müller; Fabian Ritz; Steffen Illium; Claudia Linnhoff-Popien', display:{Lore:['[{"text": "arXiv:2006.03429", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CV\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAcoustic Anomaly Detection for Machine Sounds based on Image Transfer Learning\\u00a7r\\n\\n\\u00a78\\u00a7oRobert M\\u00fcller\\nFabian Ritz\\nSteffen Illium\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.03429\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.5220/0010185800490056\\u00a7r\\n\\nVersion:\\u00a77v2 (Fri, 11 Dec 2020 12:06:30 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oICAART 2021, 8 pages, 2 figures, 1 table\\u00a7r"}']}
{title:'Li et al. (§72020§r)', author: 'Zheng Li; Miao Zhao; Qingyang Hong; Lin Li; Zhiyuan Tang; Dong Wang; Liming Song; Cheng Yang', display:{Lore:['[{"text": "arXiv:2006.03473", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAP20-OLR Challenge: Three Tasks and Their Baselines\\u00a7r\\n\\n\\u00a78\\u00a7oZheng Li\\nMiao Zhao\\nQingyang Hong\\n+ 4 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.03473\\u00a7r\\n\\nVersion:\\u00a77v4 (Fri, 9 Oct 2020 09:08:08 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oarXiv admin note: substantial text overlap with arXiv:1907.07626, arXiv:1806.00616, arXiv:1706.09742\\u00a7r"}']}
{title:'Picart et al. (§72020§r)', author: 'Benjamin Picart; Thomas Drugman; Thierry Dutoit', display:{Lore:['[{"text": "arXiv:2006.04136", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAnalysis and Synthesis of Hypo and Hyperarticulated Speech\\u00a7r\\n\\n\\u00a78\\u00a7oBenjamin Picart\\nThomas Drugman\\nThierry Dutoit\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.04136\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 7 Jun 2020 12:21:16 GMT)\\u00a7r"}']}
{title:'Drugman (§72020§r)', author: 'Thomas Drugman', display:{Lore:['[{"text": "arXiv:2006.04138", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMaximum Phase Modeling for Sparse Linear Prediction of Speech\\u00a7r\\n\\n\\u00a78\\u00a7oThomas Drugman\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.04138\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 7 Jun 2020 12:34:20 GMT)\\u00a7r"}']}
{title:'Babacan et al. (§72020§r)', author: 'Onur Babacan; Thomas Drugman; Tuomo Raitio; Daniel Erro; Thierry Dutoit', display:{Lore:['[{"text": "arXiv:2006.04142", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lParametric Representation for Singing Voice Synthesis: a Comparative Evaluation\\u00a7r\\n\\n\\u00a78\\u00a7oOnur Babacan\\nThomas Drugman\\nTuomo Raitio\\nDaniel Erro\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.04142\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 7 Jun 2020 13:06:30 GMT)\\u00a7r"}']}
{title:'Wu et al. (§72020§r)', author: 'Da-Yi Wu; Yen-Hao Chen; Hung-Yi Lee', display:{Lore:['[{"text": "arXiv:2006.04154", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lVQVC+: One-Shot Voice Conversion by Vector Quantization and U-Net architecture\\u00a7r\\n\\n\\u00a78\\u00a7oDa-Yi Wu\\nYen-Hao Chen\\nHung-Yi Lee\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.04154\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 7 Jun 2020 14:01:16 GMT)\\u00a7r"}']}
{title:'Inoue et al. (§72020§r)', author: 'Nakamasa Inoue; Keita Goto', display:{Lore:['[{"text": "arXiv:2006.04326", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSemi-Supervised Contrastive Learning with Generalized Contrastive Loss and Its Application to Speaker Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oNakamasa Inoue\\nKeita Goto\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.04326\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 8 Jun 2020 02:33:25 GMT)\\u00a7r"}']}
{title:'S et al. (§72020§r)', author: 'Karthik Pandia D S; Hema A Murthy', display:{Lore:['[{"text": "arXiv:2006.04372", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lZero resource speech synthesis using transcripts derived from perceptual acoustic units\\u00a7r\\n\\n\\u00a78\\u00a7oKarthik Pandia D S\\nHema A Murthy\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.04372\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.21437/Interspeech.2019-2336\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 8 Jun 2020 06:11:01 GMT)\\u00a7r"}']}
{title:'Shifas et al. (§72020§r)', author: 'Muhammed PV Shifas; Nagaraj Adiga; Vassilis Tsiaras; Yannis Stylianou', display:{Lore:['[{"text": "arXiv:2006.04469", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA non-causal FFTNet architecture for speech enhancement\\u00a7r\\n\\n\\u00a78\\u00a7oMuhammed PV Shifas\\nNagaraj Adiga\\nVassilis Tsiaras\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.04469\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.21437/Interspeech.2019-2622\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 8 Jun 2020 10:49:04 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages\\u00a7r"}']}
{title:'Chen et al. (§72020§r)', author: 'Mingjian Chen; Xu Tan; Yi Ren; Jin Xu; Hao Sun; Sheng Zhao; Tao Qin; Tie-Yan Liu', display:{Lore:['[{"text": "arXiv:2006.04664", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMultiSpeech: Multi-Speaker Text to Speech with Transformer\\u00a7r\\n\\n\\u00a78\\u00a7oMingjian Chen\\nXu Tan\\nYi Ren\\n+ 4 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.04664\\u00a7r\\n\\nVersion:\\u00a77v2 (Sat, 1 Aug 2020 03:45:03 GMT)\\u00a7r"}']}
{title:'Sterpu et al. (§72020§r)', author: 'George Sterpu; Christian Saam; Naomi Harte', display:{Lore:['[{"text": "arXiv:2006.04928", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lLearning to Count Words in Fluent Speech enables Online Speech Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oGeorge Sterpu\\nChristian Saam\\nNaomi Harte\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.04928\\u00a7r\\n\\nVersion:\\u00a77v3 (Tue, 24 Nov 2020 13:59:17 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted at the 8th IEEE Spoken Language Technology Workshop (SLT 2021)\\u00a7r"}']}
{title:'Tarján et al. (§72020§r)', author: 'Balázs Tarján; György Szaszák; Tibor Fegyó; Péter Mihajlik', display:{Lore:['[{"text": "arXiv:2006.05129", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lOn the Effectiveness of Neural Text Generation based Data Augmentation for Recognition of Morphologically Rich Speech\\u00a7r\\n\\n\\u00a78\\u00a7oBal\\u00e1zs Tarj\\u00e1n\\nGy\\u00f6rgy Szasz\\u00e1k\\nTibor Fegy\\u00f3\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.05129\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1007/978-3-030-58323-1_47\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 9 Jun 2020 09:01:04 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o8 pages, 2 figures, accepted for publication at TSD 2020\\u00a7r"}']}
{title:'Wu et al. (§72020§r)', author: 'Tsung-Han Wu; Chun-Chen Hsieh; Yen-Hao Chen; Po-Han Chi; Hung-yi Lee', display:{Lore:['[{"text": "arXiv:2006.05174", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lInput-independent Attention Weights Are Expressive Enough: A Study of Attention in Self-supervised Audio Transformers\\u00a7r\\n\\n\\u00a78\\u00a7oTsung-Han Wu\\nChun-Chen Hsieh\\nYen-Hao Chen\\nPo-Han Chi\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.05174\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 3 Nov 2020 06:32:17 GMT)\\u00a7r"}']}
{title:'Madhumani et al. (§72020§r)', author: 'Gurunath Reddy Madhumani; Sanket Shah; Basil Abraham; Vikas Joshi; Sunayana Sitaram', display:{Lore:['[{"text": "arXiv:2006.05257", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lLearning not to Discriminate: Task Agnostic Learning for Improving Monolingual and Code-switched Speech Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oGurunath Reddy Madhumani\\nSanket Shah\\nBasil Abraham\\nVikas Joshi\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.05257\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 9 Jun 2020 13:45:30 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages (4 pages + 1 reference), 3 tables, 2 figures\\u00a7r"}']}
{title:'Riad et al. (§72020§r)', author: 'Rachid Riad; Hadrien Titeux; Laurie Lemoine; Justine Montillot; Jennifer Hamet Bagnou; Xuan Nga Cao; Emmanuel Dupoux; Anne-Catherine Bachoud-Lévi', display:{Lore:['[{"text": "arXiv:2006.05365", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lVocal markers from sustained phonation in Huntington\'s Disease\\u00a7r\\n\\n\\u00a78\\u00a7oRachid Riad\\nHadrien Titeux\\nLaurie Lemoine\\n+ 4 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.05365\\u00a7r\\n\\nVersion:\\u00a77v3 (Fri, 31 Jul 2020 13:20:04 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oTo appear at INTERSPEECH2020. 1 pages of supplementary materialappear only in the arxivversion. Code to replicate https://github.com/bootphon/sustained-phonation-features\\u00a7r"}']}
{title:'Wang et al. (§72020§r)', author: 'Changhan Wang; Juan Pino; Jiatao Gu', display:{Lore:['[{"text": "arXiv:2006.05474", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lImproving Cross-Lingual Transfer Learning for End-to-End Speech Recognition with Speech Translation\\u00a7r\\n\\n\\u00a78\\u00a7oChanghan Wang\\nJuan Pino\\nJiatao Gu\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.05474\\u00a7r\\n\\nVersion:\\u00a77v2 (Fri, 9 Oct 2020 04:07:38 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted to INTERSPEECH 2020\\u00a7r"}']}
{title:'Mitchell et al. (§72020§r)', author: 'William Mitchell; Scott H. Hawley', display:{Lore:['[{"text": "arXiv:2006.05584", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lExploring Quality and Generalizability in Parameterized Neural Audio Effects\\u00a7r\\n\\n\\u00a78\\u00a7oWilliam Mitchell\\nScott H. Hawley\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.05584\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 10 Jun 2020 00:52:08 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o7 pages, 5 figures\\u00a7r"}']}
{title:'Sharma et al. (§72020§r)', author: 'Vishal Sharma; Zekun Zhang; Zachary Neubert; Curtis Dyreson', display:{Lore:['[{"text": "arXiv:2006.05596", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSpeaker Diarization: Using Recurrent Neural Networks\\u00a7r\\n\\n\\u00a78\\u00a7oVishal Sharma\\nZekun Zhang\\nZachary Neubert\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.05596\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 10 Jun 2020 01:19:18 GMT)\\u00a7r"}']}
{title:'Shim et al. (§72020§r)', author: 'Hye-jin Shim; Jee-weon Jung; Ju-ho Kim; Seung-bin Kim; Ha-Jin Yu', display:{Lore:['[{"text": "arXiv:2006.05599", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lIntegrated Replay Spoofing-aware Text-independent Speaker Verification\\u00a7r\\n\\n\\u00a78\\u00a7oHye-jin Shim\\nJee-weon Jung\\nJu-ho Kim\\nSeung-bin Kim\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.05599\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.3390/app10186292\\u00a7r\\n\\nVersion:\\u00a77v2 (Sun, 27 Sep 2020 10:28:08 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o9 pages, 2 figures, 6 tables, Published in MDPI Applied Sciences (SCIE)\\u00a7r"}']}
{title:'Su et al. (§72020§r)', author: 'Jiaqi Su; Zeyu Jin; Adam Finkelstein', display:{Lore:['[{"text": "arXiv:2006.05694", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lHiFi-GAN: High-Fidelity Denoising and Dereverberation Based on Speech Deep Features in Adversarial Networks\\u00a7r\\n\\n\\u00a78\\u00a7oJiaqi Su\\nZeyu Jin\\nAdam Finkelstein\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.05694\\u00a7r\\n\\nVersion:\\u00a77v2 (Mon, 21 Sep 2020 20:37:02 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted by INTERSPEECH 2020\\u00a7r"}']}
{title:'Ochiai et al. (§72020§r)', author: 'Tsubasa Ochiai; Marc Delcroix; Yuma Koizumi; Hiroaki Ito; Keisuke Kinoshita; Shoko Araki', display:{Lore:['[{"text": "arXiv:2006.05712", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lListen to What You Want: Neural Network-based Universal Sound Selector\\u00a7r\\n\\n\\u00a78\\u00a7oTsubasa Ochiai\\nMarc Delcroix\\nYuma Koizumi\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.05712\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 10 Jun 2020 08:06:02 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 2 figures, submitted to INTERSPEECH 2020\\u00a7r"}']}
{title:'S et al. (§72020§r)', author: 'Karthik Pandia D S; Cosimo Spera', display:{Lore:['[{"text": "arXiv:2006.05747", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lUniphore\'s submission to Fearless Steps Challenge Phase-2\\u00a7r\\n\\n\\u00a78\\u00a7oKarthik Pandia D S\\nCosimo Spera\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.05747\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 10 Jun 2020 09:34:46 GMT)\\u00a7r"}']}
{title:'Ryant et al. (§72020§r)', author: 'Neville Ryant; Kenneth Church; Christopher Cieri; Jun Du; Sriram Ganapathy; Mark Liberman', display:{Lore:['[{"text": "arXiv:2006.05815", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lThird DIHARD Challenge Evaluation Plan\\u00a7r\\n\\n\\u00a78\\u00a7oNeville Ryant\\nKenneth Church\\nChristopher Cieri\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.05815\\u00a7r\\n\\nVersion:\\u00a77v3 (Wed, 2 Dec 2020 20:14:57 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oVersion 1.2 - Planned schedule updated - Updated numbers in tables from final versions of development/evaluation sets- Corrected typo\\u00a7r"}']}
{title:'Koizumi et al. (§72020§r)', author: 'Yuma Koizumi; Yohei Kawaguchi; Keisuke Imoto; Toshiki Nakamura; Yuki Nikaido; Ryo Tanabe; Harsh Purohit; Kaori Suefusa; Takashi Endo; Masahiro Yasuda; Noboru Harada', display:{Lore:['[{"text": "arXiv:2006.05822", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDescription and Discussion on DCASE2020 Challenge Task2: Unsupervised Anomalous Sound Detection for Machine Condition Monitoring\\u00a7r\\n\\n\\u00a78\\u00a7oYuma Koizumi\\nYohei Kawaguchi\\nKeisuke Imoto\\n+ 7 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.05822\\u00a7r\\n\\nVersion:\\u00a77v2 (Sat, 8 Aug 2020 06:38:07 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to DCASE2020 Workshop\\u00a7r"}']}
{title:'Roberts et al. (§72020§r)', author: 'Timothy Roberts; Kuldip K. Paliwal', display:{Lore:['[{"text": "arXiv:2006.06153", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAn Objective Measure of Quality for Time-Scale Modification of Audio\\u00a7r\\n\\n\\u00a78\\u00a7oTimothy Roberts\\nKuldip K. Paliwal\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.06153\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1121/10.0003753\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 11 Jun 2020 02:11:44 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o12 pages, 7 figures, Submitted to The Journal of the Acoustical Society of America, Currently under review\\u00a7r"}']}
{title:'Li et al. (§72020§r)', author: 'Xu Li; Na Li; Jinghua Zhong; Xixin Wu; Xunying Liu; Dan Su; Dong Yu; Helen Meng', display:{Lore:['[{"text": "arXiv:2006.06186", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lInvestigating Robustness of Adversarial Samples Detection for Automatic Speaker Verification\\u00a7r\\n\\n\\u00a78\\u00a7oXu Li\\nNa Li\\nJinghua Zhong\\n+ 4 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.06186\\u00a7r\\n\\nVersion:\\u00a77v2 (Fri, 7 Aug 2020 15:27:42 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oaccepted by Interspeech2020\\u00a7r"}']}
{title:'Lu et al. (§72020§r)', author: 'Peiling Lu; Jie Wu; Jian Luan; Xu Tan; Li Zhou', display:{Lore:['[{"text": "arXiv:2006.06261", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lXiaoiceSing: A High-Quality and Integrated Singing Voice Synthesis System\\u00a7r\\n\\n\\u00a78\\u00a7oPeiling Lu\\nJie Wu\\nJian Luan\\nXu Tan\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.06261\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 11 Jun 2020 09:09:59 GMT)\\u00a7r"}']}
{title:'Huzaifah et al. (§72020§r)', author: 'M. Huzaifah; L. Wyse', display:{Lore:['[{"text": "arXiv:2006.06426", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDeep generative models for musical audio synthesis\\u00a7r\\n\\n\\u00a78\\u00a7oM. Huzaifah\\nL. Wyse\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.06426\\u00a7r\\n\\nVersion:\\u00a77v2 (Wed, 25 Nov 2020 09:01:31 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oThis is the authors\' own pre-submission version of a chapter for Handbook of Artificial Intelligence for Music: Foundations, Advanced Approaches, and Developments for Creativity, edited by Eduardo R. Miranda, for"}','{"text": "Springer\\u00a7r"}']}
{title:'Jung et al. (§72020§r)', author: 'Sunghee Jung; Youngjoo Suh; Yeunju Choi; Hoirin Kim', display:{Lore:['[{"text": "arXiv:2006.06937", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lNon-parallel voice conversion based on source-to-target direct mapping\\u00a7r\\n\\n\\u00a78\\u00a7oSunghee Jung\\nYoungjoo Suh\\nYeunju Choi\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.06937\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 12 Jun 2020 04:21:21 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to Interspeech 2019\\u00a7r"}']}
{title:'Jung et al. (§72020§r)', author: 'Sunghee Jung; Hoirin Kim', display:{Lore:['[{"text": "arXiv:2006.06940", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lNeural voice cloning with a few low-quality samples\\u00a7r\\n\\n\\u00a78\\u00a7oSunghee Jung\\nHoirin Kim\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.06940\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 12 Jun 2020 04:42:07 GMT)\\u00a7r"}']}
{title:'Jung et al. (§72020§r)', author: 'Sunghee Jung; Hoirin Kim', display:{Lore:['[{"text": "arXiv:2006.06942", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDomain-adversarial training of multi-speaker TTS\\u00a7r\\n\\n\\u00a78\\u00a7oSunghee Jung\\nHoirin Kim\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.06942\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 12 Jun 2020 04:44:22 GMT)\\u00a7r"}']}
{title:'Prakash et al. (§72020§r)', author: 'Anusha Prakash; Hema A Murthy', display:{Lore:['[{"text": "arXiv:2006.06971", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lGeneric Indic Text-to-speech Synthesisers with Rapid Adaptation in an End-to-end Framework\\u00a7r\\n\\n\\u00a78\\u00a7oAnusha Prakash\\nHema A Murthy\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.06971\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.21437/Interspeech.2020-2663\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nINTERSPEECH (2002) 2962-2966\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 12 Jun 2020 07:17:41 GMT)\\u00a7r"}']}
{title:'Zhang et al. (§72020§r)', author: 'Haobo Zhang; Haihua Xu; Van Tung Pham; Hao Huang; Eng Siong Chng', display:{Lore:['[{"text": "arXiv:2006.07094", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMonolingual Data Selection Analysis for English-Mandarin Hybrid Code-switching Speech Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oHaobo Zhang\\nHaihua Xu\\nVan Tung Pham\\nHao Huang\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.07094\\u00a7r\\n\\nVersion:\\u00a77v2 (Mon, 14 Sep 2020 03:55:42 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, conference, Accepted by Interspeech2020\\u00a7r"}']}
{title:'Chkhetiani et al. (§72020§r)', author: 'Luka Chkhetiani; Levan Bejanidze', display:{Lore:['[{"text": "arXiv:2006.07637", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSE-MelGAN \\u2013 Speaker Agnostic Rapid Speech Enhancement\\u00a7r\\n\\n\\u00a78\\u00a7oLuka Chkhetiani\\nLevan Bejanidze\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.07637\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 13 Jun 2020 13:26:37 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o4 pages, 1 image, 1 table, 1page for references\\u00a7r"}']}
{title:'Arora et al. (§72020§r)', author: 'Ashish Arora; Desh Raj; Aswin Shanmugam Subramanian; Ke Li; Bar Ben-Yair; Matthew Maciejewski; Piotr Żelasko; Paola García; Shinji Watanabe; Sanjeev Khudanpur', display:{Lore:['[{"text": "arXiv:2006.07898", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lThe JHU Multi-Microphone Multi-Speaker ASR System for the CHiME-6 Challenge\\u00a7r\\n\\n\\u00a78\\u00a7oAshish Arora\\nDesh Raj\\nAswin Shanmugam Subramanian\\n+ 6 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.07898\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 14 Jun 2020 13:24:09 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oPresented at theCHiME-6 workshop (colocated with ICASSP 2020)\\u00a7r"}']}
{title:'Zhang et al. (§72020§r)', author: 'Chen Zhang; Xu Tan; Yi Ren; Tao Qin; Kejun Zhang; Tie-Yan Liu', display:{Lore:['[{"text": "arXiv:2006.07926", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lUWSpeech: Speech to Speech Translation for Unwritten Languages\\u00a7r\\n\\n\\u00a78\\u00a7oChen Zhang\\nXu Tan\\nYi Ren\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.07926\\u00a7r\\n\\nVersion:\\u00a77v2 (Thu, 17 Dec 2020 12:39:06 GMT)\\u00a7r"}']}
{title:'Montesinos et al. (§72020§r)', author: 'Juan F. Montesinos; Olga Slizovskaia; Gloria Haro', display:{Lore:['[{"text": "arXiv:2006.07931", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.DB\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSolos: A Dataset for Audio-Visual Music Analysis\\u00a7r\\n\\n\\u00a78\\u00a7oJuan F. Montesinos\\nOlga Slizovskaia\\nGloria Haro\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.07931\\u00a7r\\n\\nVersion:\\u00a77v2 (Thu, 6 Aug 2020 23:37:27 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oRephrased some sentenced. Explanationabout OpenPose. Minor grammatical errors\\u00a7r"}']}
{title:'Singh et al. (§72020§r)', author: 'Mandeep Singh; Yuan Fang', display:{Lore:['[{"text": "arXiv:2006.08129", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CV\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lEmotion Recognition in Audio and Video Using Deep Neural Networks\\u00a7r\\n\\n\\u00a78\\u00a7oMandeep Singh\\nYuan Fang\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.08129\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 15 Jun 2020 04:50:18 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o9 pages, 9 figures, 3 tables\\u00a7r"}']}
{title:'Andrusenko et al. (§72020§r)', author: 'Andrei Andrusenko; Aleksandr Laptev; Ivan Medennikov', display:{Lore:['[{"text": "arXiv:2006.08274", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lExploration of End-to-End ASR for OpenSTT \\u2013 Russian Open Speech-to-Text Dataset\\u00a7r\\n\\n\\u00a78\\u00a7oAndrei Andrusenko\\nAleksandr Laptev\\nIvan Medennikov\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.08274\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1007/978-3-030-60276-5_4\\u00a7r\\n\\nVersion:\\u00a77v2 (Sun, 26 Jul 2020 20:21:09 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted by SPECOM 2020\\u00a7r"}']}
{title:'Yan et al. (§72020§r)', author: 'Xue Yan; Zhen Yang; Tingting Wang; Haiyan Guo', display:{Lore:['[{"text": "arXiv:2006.08497", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7eeess.SP\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAn Iterative Graph Spectral Subtraction Method for Speech Enhancement\\u00a7r\\n\\n\\u00a78\\u00a7oXue Yan\\nZhen Yang\\nTingting Wang\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.08497\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1016/j.specom.2020.06.005\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nSPECOM_SPECOM_2020_15\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 15 Jun 2020 15:55:39 GMT)\\u00a7r"}']}
{title:'Watzel et al. (§72020§r)', author: 'Tobias Watzel; Ludwig Kürzinger; Lujun Li; Gerhard Rigoll', display:{Lore:['[{"text": "arXiv:2006.08506", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lRegularized Forward-Backward Decoder for Attention Models\\u00a7r\\n\\n\\u00a78\\u00a7oTobias Watzel\\nLudwig K\\u00fcrzinger\\nLujun Li\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.08506\\u00a7r\\n\\nVersion:\\u00a77v2 (Wed, 28 Oct 2020 14:00:52 GMT)\\u00a7r"}']}
{title:'Diaz-Guerra et al. (§72020§r)', author: 'David Diaz-Guerra; Antonio Miguel; Jose R. Beltran', display:{Lore:['[{"text": "arXiv:2006.09006", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7eeess.SP\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lRobust Sound Source Tracking Using SRP-PHAT and 3D Convolutional Neural Networks\\u00a7r\\n\\n\\u00a78\\u00a7oDavid Diaz-Guerra\\nAntonio Miguel\\nJose R. Beltran\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.09006\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/TASLP.2020.3040031\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nin IEEE/ACM Transactions on Audio, Speech, and Language\\n  Processing, vol. 29, pp. 300-311, 2021\\u00a7r\\n\\nVersion:\\u00a77v2 (Wed, 16 Dec 2020 19:07:34 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oThis is a pre-print of an article published in IEEE/ACM Transactionson Audio Speech and Language Processing. The code to reproduce this work can be found in our GitHub repository: https://github.com/DavidDiazGuerr"}','{"text": "a/Cross3D\\u00a7r"}']}
{title:'Prasad et al. (§72020§r)', author: 'Amrutha Prasad; Petr Motlicek; Srikanth Madikeri', display:{Lore:['[{"text": "arXiv:2006.09054", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lQuantization of Acoustic Model Parameters in Automatic Speech Recognition Framework\\u00a7r\\n\\n\\u00a78\\u00a7oAmrutha Prasad\\nPetr Motlicek\\nSrikanth Madikeri\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.09054\\u00a7r\\n\\nVersion:\\u00a77v2 (Fri, 20 Nov 2020 12:08:48 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to ICASSP21\\u00a7r"}']}
{title:'Ericsson et al. (§72020§r)', author: 'David Ericsson; Adam Östberg; Edvin Listo Zec; John Martinsson; Olof Mogren', display:{Lore:['[{"text": "arXiv:2006.09114", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAdversarial representation learning for private speech generation\\u00a7r\\n\\n\\u00a78\\u00a7oDavid Ericsson\\nAdam \\u00d6stberg\\nEdvin Listo Zec\\nJohn Martinsson\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.09114\\u00a7r\\n\\nVersion:\\u00a77v2 (Wed, 17 Jun 2020 09:28:18 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to ICML2020 Workshop on Self-supervision in Audio and Speech (SAS)\\u00a7r"}']}
{title:'Nistal et al. (§72020§r)', author: 'Javier Nistal; Stefan Lattner; Gaël Richard', display:{Lore:['[{"text": "arXiv:2006.09266", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lComparing Representations for Audio Synthesis Using Generative Adversarial Networks\\u00a7r\\n\\n\\u00a78\\u00a7oJavier Nistal\\nStefan Lattner\\nGa\\u00ebl Richard\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.09266\\u00a7r\\n\\nVersion:\\u00a77v2 (Wed, 17 Jun 2020 11:28:17 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 1 figure, 5 tables, to be published in European Signal Processing Conference (EUSIPCO)\\u00a7r"}']}
{title:'Watcharasupat et al. (§72020§r)', author: 'Karn Watcharasupat; Siddharth Gururani; Alexander Lerch', display:{Lore:['[{"text": "arXiv:2006.09640", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.IR\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lVisual Attention for Musical Instrument Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oKarn Watcharasupat\\nSiddharth Gururani\\nAlexander Lerch\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.09640\\u00a7r\\n\\nVersion:\\u00a77v2 (Sun, 21 Jun 2020 15:53:37 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o6 pages, 7 figures. Karn Watcharasupat is currently with the School of Electrical and Electronic Engineering, Nanyang Technological University. This work was done while she was with the Center for Music Technology, "}','{"text": "Georgia Institute of Technology on an exchange semester\\u00a7r"}']}
{title:'Lu et al. (§72020§r)', author: 'Haoye Lu; Haolong Zhang; Amit Nayak', display:{Lore:['[{"text": "arXiv:2006.09815", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Deep Neural Network for Audio Classification with a Classifier Attention Mechanism\\u00a7r\\n\\n\\u00a78\\u00a7oHaoye Lu\\nHaolong Zhang\\nAmit Nayak\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.09815\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 14 Jun 2020 21:29:44 GMT)\\u00a7r"}']}
{title:'Tan et al. (§72020§r)', author: 'Hao Hao Tan; Yin-Jyun Luo; Dorien Herremans', display:{Lore:['[{"text": "arXiv:2006.09833", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.MM\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lGenerative Modelling for Controllable Audio Synthesis of Expressive Piano Performance\\u00a7r\\n\\n\\u00a78\\u00a7oHao Hao Tan\\nYin-Jyun Luo\\nDorien Herremans\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.09833\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nPublished at ICML Workshop on Machine Learning for Media Discovery\\n  Workshop (ML4MD) 2020\\u00a7r\\n\\nVersion:\\u00a77v2 (Mon, 13 Jul 2020 03:44:38 GMT)\\u00a7r"}']}
{title:'Xu (§72020§r)', author: 'Xin Xu', display:{Lore:['[{"text": "arXiv:2006.09838", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lLSTM Networks for Music Generation\\u00a7r\\n\\n\\u00a78\\u00a7oXin Xu\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.09838\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 16 Jun 2020 04:44:30 GMT)\\u00a7r"}']}
{title:'Ristea et al. (§72020§r)', author: 'Nicolae-Cătălin Ristea; Radu Tudor Ionescu', display:{Lore:['[{"text": "arXiv:2006.10147", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CV\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAre you wearing a mask? Improving mask detection from speech using augmentation by cycle-consistent GANs\\u00a7r\\n\\n\\u00a78\\u00a7oNicolae-C\\u0103t\\u0103lin Ristea\\nRadu Tudor Ionescu\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.10147\\u00a7r\\n\\nVersion:\\u00a77v2 (Sat, 25 Jul 2020 21:52:21 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted at INTERSPEECH 2020\\u00a7r"}']}
{title:'Wu et al. (§72020§r)', author: 'Jie Wu; Jian Luan', display:{Lore:['[{"text": "arXiv:2006.10317", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAdversarially Trained Multi-Singer Sequence-To-Sequence Singing Synthesizer\\u00a7r\\n\\n\\u00a78\\u00a7oJie Wu\\nJian Luan\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.10317\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 18 Jun 2020 07:20:11 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to INTERSPEECH2020\\u00a7r"}']}
{title:'Wang et al. (§72020§r)', author: 'Yu-Che Wang; Shrikant Venkataramani; Paris Smaragdis', display:{Lore:['[{"text": "arXiv:2006.10388", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSelf-supervised Learning for Speech Enhancement\\u00a7r\\n\\n\\u00a78\\u00a7oYu-Che Wang\\nShrikant Venkataramani\\nParis Smaragdis\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.10388\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 18 Jun 2020 09:47:20 GMT)\\u00a7r"}']}
{title:'Zhou et al. (§72020§r)', author: 'Xinyuan Zhou; Grandee Lee; Emre Yılmaz; Yanhua Long; Jiaen Liang; Haizhou Li', display:{Lore:['[{"text": "arXiv:2006.10407", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSelf-and-Mixed Attention Decoder with Deep Acoustic Structure for Transformer-based LVCSR\\u00a7r\\n\\n\\u00a78\\u00a7oXinyuan Zhou\\nGrandee Lee\\nEmre Y\\u0131lmaz\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.10407\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 15 Sep 2020 09:12:10 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted by INTERSPEECH 2020\\u00a7r"}']}
{title:'Zhou et al. (§72020§r)', author: 'Xinyuan Zhou; Emre Yılmaz; Yanhua Long; Yijie Li; Haizhou Li', display:{Lore:['[{"text": "arXiv:2006.10414", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMulti-Encoder-Decoder Transformer for Code-Switching Speech Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oXinyuan Zhou\\nEmre Y\\u0131lmaz\\nYanhua Long\\nYijie Li\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.10414\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 18 Jun 2020 10:42:52 GMT)\\u00a7r"}']}
{title:'Ribeiro et al. (§72020§r)', author: 'Alexandrine Ribeiro; Luis Miguel Matos; Pedro Jose Pereira; Eduardo C. Nunes; Andre L. Ferreira; Paulo Cortez; Andre Pilastri', display:{Lore:['[{"text": "arXiv:2006.10417", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDeep Dense and Convolutional Autoencoders for Unsupervised Anomaly Detection in Machine Condition Sounds\\u00a7r\\n\\n\\u00a78\\u00a7oAlexandrine Ribeiro\\nLuis Miguel Matos\\nPedro Jose Pereira\\n+ 3 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.10417\\u00a7r\\n\\nVersion:\\u00a77v2 (Fri, 19 Jun 2020 09:06:35 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 3 figures, submitted for DCase 2020 challenge\\u00a7r"}']}
{title:'Kanda et al. (§72020§r)', author: 'Naoyuki Kanda; Yashesh Gaur; Xiaofei Wang; Zhong Meng; Zhuo Chen; Tianyan Zhou; Takuya Yoshioka', display:{Lore:['[{"text": "arXiv:2006.10930", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lJoint Speaker Counting, Speech Recognition, and Speaker Identification for Overlapped Speech of Any Number of Speakers\\u00a7r\\n\\n\\u00a78\\u00a7oNaoyuki Kanda\\nYashesh Gaur\\nXiaofei Wang\\n+ 3 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.10930\\u00a7r\\n\\nVersion:\\u00a77v2 (Sat, 8 Aug 2020 20:25:22 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted to INTERSPEECH 2020\\u00a7r"}']}
{title:'Bang et al. (§72020§r)', author: 'Jihwan Bang; Heesu Kim; YoungJoon Yoo; Jung-Woo Ha', display:{Lore:['[{"text": "arXiv:2006.11021", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lBoosting Active Learning for Speech Recognition with Noisy Pseudo-labeled Samples\\u00a7r\\n\\n\\u00a78\\u00a7oJihwan Bang\\nHeesu Kim\\nYoungJoon Yoo\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.11021\\u00a7r\\n\\nVersion:\\u00a77v2 (Thu, 5 Nov 2020 14:41:47 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o8 pages, 4 figures, 2 tables\\u00a7r"}']}
{title:'Brazier et al. (§72020§r)', author: 'Charles Brazier; Gerhard Widmer', display:{Lore:['[{"text": "arXiv:2006.11033", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lTowards Reliable Real-time Opera Tracking: Combining Alignment with Audio Event Detectors to Increase Robustness\\u00a7r\\n\\n\\u00a78\\u00a7oCharles Brazier\\nGerhard Widmer\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.11033\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 19 Jun 2020 09:31:07 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o7 pages, 4 figures, In Proceedings of the 17th Sound and Music Computing Conference (SMC 2020), Torino, Italy\\u00a7r"}']}
{title:'Yu et al. (§72020§r)', author: 'Cheng Yu; Kuo-Hsuan Hung; I-Fan Lin; Szu-Wei Fu; Yu Tsao; Jeih-weih Hung', display:{Lore:['[{"text": "arXiv:2006.11139", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lWaveform-based Voice Activity Detection Exploiting Fully Convolutional networks with Multi-Branched Encoders\\u00a7r\\n\\n\\u00a78\\u00a7oCheng Yu\\nKuo-Hsuan Hung\\nI-Fan Lin\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.11139\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 19 Jun 2020 13:50:06 GMT)\\u00a7r"}']}
{title:'Graetzer et al. (§72020§r)', author: 'Simone Graetzer; Michael Akeroyd; Jon P. Barker; Trevor J. Cox; John F. Culling; Graham Naylor; Eszter Porter; Rhoddy Viveros Muñoz', display:{Lore:['[{"text": "arXiv:2006.11140", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lClarity: Machine Learning Challenges to Revolutionise Hearing Device Processing\\u00a7r\\n\\n\\u00a78\\u00a7oSimone Graetzer\\nMichael Akeroyd\\nJon P. Barker\\n+ 4 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.11140\\u00a7r\\n\\nVersion:\\u00a77v2 (Mon, 17 Aug 2020 09:24:02 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o3 pages, 2 figures\\u00a7r"}']}
{title:'Illa et al. (§72020§r)', author: 'Aravind Illa; Prasanta Kumar Ghosh', display:{Lore:['[{"text": "arXiv:2006.11536", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSpeaker conditioned acoustic-to-articulatory inversion using x-vectors\\u00a7r\\n\\n\\u00a78\\u00a7oAravind Illa\\nPrasanta Kumar Ghosh\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.11536\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 20 Jun 2020 10:08:06 GMT)\\u00a7r"}']}
{title:'Huang et al. (§72020§r)', author: 'Huirong Huang; Zhiyong Wu; Shiyin Kang; Dongyang Dai; Jia Jia; Tianxiao Fu; Deyi Tuo; Guangzhi Lei; Peng Liu; Dan Su; Dong Yu; Helen Meng', display:{Lore:['[{"text": "arXiv:2006.11610", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.MM\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSpeaker Independent and Multilingual/Mixlingual Speech-Driven Talking Head Generation Using Phonetic Posteriorgrams\\u00a7r\\n\\n\\u00a78\\u00a7oHuirong Huang\\nZhiyong Wu\\nShiyin Kang\\n+ 8 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.11610\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 20 Jun 2020 16:32:43 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 5 figures\\u00a7r"}']}
{title:'Chennoor et al. (§72020§r)', author: 'Sai Nikhil Chennoor; B. R. K. Madhur; Moujiz Ali; T. Kishore Kumar', display:{Lore:['[{"text": "arXiv:2006.11871", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lHuman Emotion Detection from Audio and Video Signals\\u00a7r\\n\\n\\u00a78\\u00a7oSai Nikhil Chennoor\\nB. R. K. Madhur\\nMoujiz Ali\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.11871\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 21 Jun 2020 18:36:23 GMT)\\u00a7r"}']}
{title:'Shimada et al. (§72020§r)', author: 'Kazuki Shimada; Naoya Takahashi; Shusuke Takahashi; Yuki Mitsufuji', display:{Lore:['[{"text": "arXiv:2006.12014", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSound Event Localization and Detection Using Activity-Coupled Cartesian DOA Vector and RD3net\\u00a7r\\n\\n\\u00a78\\u00a7oKazuki Shimada\\nNaoya Takahashi\\nShusuke Takahashi\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.12014\\u00a7r\\n\\nVersion:\\u00a77v2 (Thu, 8 Oct 2020 00:43:49 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to DCASE2020 task3\\u00a7r"}']}
{title:'Wu et al. (§72020§r)', author: 'Anne Wu; Changhan Wang; Juan Pino; Jiatao Gu', display:{Lore:['[{"text": "arXiv:2006.12124", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSelf-Supervised Representations Improve End-to-End Speech Translation\\u00a7r\\n\\n\\u00a78\\u00a7oAnne Wu\\nChanghan Wang\\nJuan Pino\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.12124\\u00a7r\\n\\nVersion:\\u00a77v2 (Sun, 25 Oct 2020 03:31:15 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted to INTERSPEECH 2020\\u00a7r"}']}
{title:'Bozorg et al. (§72020§r)', author: 'Narjes Bozorg; Michael T. Johnson', display:{Lore:['[{"text": "arXiv:2006.12594", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lArticulatory-WaveNet: Autoregressive Model For Acoustic-to-Articulatory Inversion\\u00a7r\\n\\n\\u00a78\\u00a7oNarjes Bozorg\\nMichael T. Johnson\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.12594\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 22 Jun 2020 20:10:35 GMT)\\u00a7r"}']}
{title:'Wisdom et al. (§72020§r)', author: 'Scott Wisdom; Efthymios Tzinis; Hakan Erdogan; Ron J. Weiss; Kevin Wilson; John R. Hershey', display:{Lore:['[{"text": "arXiv:2006.12701", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lUnsupervised Sound Separation Using Mixture Invariant Training\\u00a7r\\n\\n\\u00a78\\u00a7oScott Wisdom\\nEfthymios Tzinis\\nHakan Erdogan\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.12701\\u00a7r\\n\\nVersion:\\u00a77v2 (Sat, 24 Oct 2020 02:03:02 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted for spotlight presentation at NeurIPS 2020\\u00a7r"}']}
{title:'Defossez et al. (§72020§r)', author: 'Alexandre Defossez; Gabriel Synnaeve; Yossi Adi', display:{Lore:['[{"text": "arXiv:2006.12847", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lReal Time Speech Enhancement in the Waveform Domain\\u00a7r\\n\\n\\u00a78\\u00a7oAlexandre Defossez\\nGabriel Synnaeve\\nYossi Adi\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.12847\\u00a7r\\n\\nVersion:\\u00a77v3 (Sun, 6 Sep 2020 14:32:59 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oInterspeech 2020 Paper\\u00a7r"}']}
{title:'Schröter et al. (§72020§r)', author: 'Hendrik Schröter; Tobias Rosenkranz; Alberto N. Escalante-B.; Pascal Zobel; Andreas Maier', display:{Lore:['[{"text": "arXiv:2006.13067", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lLightweight Online Noise Reduction on Embedded Devices using Hierarchical Recurrent Neural Networks\\u00a7r\\n\\n\\u00a78\\u00a7oHendrik Schr\\u00f6ter\\nTobias Rosenkranz\\nAlberto N. Escalante-B.\\nPascal Zobel\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.13067\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 23 Jun 2020 14:41:51 GMT)\\u00a7r"}']}
{title:'Schröter et al. (§72020§r)', author: 'Hendrik Schröter; Tobias Rosenkranz; Alberto N. Escalante-B.; Andreas Maier', display:{Lore:['[{"text": "arXiv:2006.13077", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lCLC: Complex Linear Coding for the DNS 2020 Challenge\\u00a7r\\n\\n\\u00a78\\u00a7oHendrik Schr\\u00f6ter\\nTobias Rosenkranz\\nAlberto N. Escalante-B.\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.13077\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 23 Jun 2020 14:58:35 GMT)\\u00a7r"}']}
{title:'Kim et al. (§72020§r)', author: 'Chelhwon Kim; Andrew Port; Mitesh Patel', display:{Lore:['[{"text": "arXiv:2006.13469", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lFace-to-Music Translation Using a Distance-Preserving Generative Adversarial Network with an Auxiliary Discriminator\\u00a7r\\n\\n\\u00a78\\u00a7oChelhwon Kim\\nAndrew Port\\nMitesh Patel\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.13469\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 24 Jun 2020 04:17:40 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o15 pages, 3 figures\\u00a7r"}']}
{title:'Khandelwal et al. (§72020§r)', author: 'Kartik Khandelwal; Preethi Jyothi; Abhijeet Awasthi; Sunita Sarawagi', display:{Lore:['[{"text": "arXiv:2006.13519", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lBlack-box Adaptation of ASR for Accented Speech\\u00a7r\\n\\n\\u00a78\\u00a7oKartik Khandelwal\\nPreethi Jyothi\\nAbhijeet Awasthi\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.13519\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 24 Jun 2020 07:07:49 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oA slightly different version submitted to INTERSPEECH 2020 (currently under review)\\u00a7r"}']}
{title:'Kinoshita et al. (§72020§r)', author: 'Keisuke Kinoshita; Thilo von Neumann; Marc Delcroix; Tomohiro Nakatani; Reinhold Haeb-Umbach', display:{Lore:['[{"text": "arXiv:2006.13579", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMulti-path RNN for hierarchical modeling of long sequential data and its application to speaker stream separation\\u00a7r\\n\\n\\u00a78\\u00a7oKeisuke Kinoshita\\nThilo von Neumann\\nMarc Delcroix\\nTomohiro Nakatani\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.13579\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 24 Jun 2020 09:45:11 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 4 figures\\u00a7r"}']}
{title:'Nakashika et al. (§72020§r)', author: 'Toru Nakashika; Kohei Yatabe', display:{Lore:['[{"text": "arXiv:2006.13590", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lGamma Boltzmann Machine for Simultaneously Modeling Linear- and Log-amplitude Spectra\\u00a7r\\n\\n\\u00a78\\u00a7oToru Nakashika\\nKohei Yatabe\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.13590\\u00a7r\\n\\nVersion:\\u00a77v2 (Thu, 25 Jun 2020 11:35:49 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to APSIPA2020\\u00a7r"}']}
{title:'Gburrek et al. (§72020§r)', author: 'Tobias Gburrek; Joerg Schmalenstroeer; Andreas Brendel; Walter Kellermann; Reinhold Haeb-Umbach', display:{Lore:['[{"text": "arXiv:2006.13769", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDeep Neural Network based Distance Estimation for Geometry Calibration in Acoustic Sensor Networks\\u00a7r\\n\\n\\u00a78\\u00a7oTobias Gburrek\\nJoerg Schmalenstroeer\\nAndreas Brendel\\nWalter Kellermann\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.13769\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 24 Jun 2020 14:33:15 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted for EUSIPCO 2020\\u00a7r"}']}
{title:'Shi et al. (§72020§r)', author: 'Jing Shi; Jiaming Xu; Yusuke Fujita; Shinji Watanabe; Bo Xu', display:{Lore:['[{"text": "arXiv:2006.14149", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSpeaker-Conditional Chain Model for Speech Separation and Extraction\\u00a7r\\n\\n\\u00a78\\u00a7oJing Shi\\nJiaming Xu\\nYusuke Fujita\\nShinji Watanabe\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.14149\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 25 Jun 2020 03:13:41 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o7pages, 3 figures\\u00a7r"}']}
{title:'Shi et al. (§72020§r)', author: 'Jing Shi; Xuankai Chang; Pengcheng Guo; Shinji Watanabe; Yusuke Fujita; Jiaming Xu; Bo Xu; Lei Xie', display:{Lore:['[{"text": "arXiv:2006.14150", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSequence to Multi-Sequence Learning via Conditional Chain Mapping for Mixture Signals\\u00a7r\\n\\n\\u00a78\\u00a7oJing Shi\\nXuankai Chang\\nPengcheng Guo\\n+ 4 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.14150\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 25 Jun 2020 03:16:13 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o15 pages, 5 figures\\u00a7r"}']}
{title:'Straninger (§72020§r)', author: 'Davide Straninger', display:{Lore:['[{"text": "arXiv:2006.14282", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDialogue Enhancement in Object-based Audio \\u2013 Evaluating the Benefit on People above 65\\u00a7r\\n\\n\\u00a78\\u00a7oDavide Straninger\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.14282\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 25 Jun 2020 09:57:00 GMT)\\u00a7r"}']}
{title:'Tsunoo et al. (§72020§r)', author: 'Emiru Tsunoo; Yosuke Kashiwagi; Shinji Watanabe', display:{Lore:['[{"text": "arXiv:2006.14941", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lStreaming Transformer ASR with Blockwise Synchronous Beam Search\\u00a7r\\n\\n\\u00a78\\u00a7oEmiru Tsunoo\\nYosuke Kashiwagi\\nShinji Watanabe\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.14941\\u00a7r\\n\\nVersion:\\u00a77v4 (Wed, 18 Nov 2020 01:03:24 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted for SLT 2021\\u00a7r"}']}
{title:'Perez-Castanos et al. (§72020§r)', author: 'Sergi Perez-Castanos; Javier Naranjo-Alcazar; Pedro Zuccarello; Maximo Cobos', display:{Lore:['[{"text": "arXiv:2006.15321", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAnomalous Sound Detection using unsupervised and semi-supervised autoencoders and gammatone audio representation\\u00a7r\\n\\n\\u00a78\\u00a7oSergi Perez-Castanos\\nJavier Naranjo-Alcazar\\nPedro Zuccarello\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.15321\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 27 Jun 2020 08:25:47 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to DCASE2020 Workshop, Workshop on Detection and Classification of Acoustic Scenes and Events\\u00a7r"}']}
{title:'Perez-Castanos et al. (§72020§r)', author: 'Sergi Perez-Castanos; Javier Naranjo-Alcazar; Pedro Zuccarello; Maximo Cobos', display:{Lore:['[{"text": "arXiv:2006.15406", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lListen carefully and tell: an audio captioning system based on residual learning and gammatone audio representation\\u00a7r\\n\\n\\u00a78\\u00a7oSergi Perez-Castanos\\nJavier Naranjo-Alcazar\\nPedro Zuccarello\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.15406\\u00a7r\\n\\nVersion:\\u00a77v4 (Wed, 8 Jul 2020 06:13:10 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to DCASE2020 Workshop, Workshop on Detection and Classification of Acoustic Scenes and Events\\u00a7r"}']}
{title:'Suni et al. (§72020§r)', author: 'Antti Suni; Sofoklis Kakouros; Martti Vainio; Juraj Šimko', display:{Lore:['[{"text": "arXiv:2006.15967", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lProsodic Prominence and Boundaries in Sequence-to-Sequence Speech Synthesis\\u00a7r\\n\\n\\u00a78\\u00a7oAntti Suni\\nSofoklis Kakouros\\nMartti Vainio\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.15967\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.21437/SpeechProsody.2020-192\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 29 Jun 2020 12:09:21 GMT)\\u00a7r"}']}
{title:'Xiang et al. (§72020§r)', author: 'Yang Xiang; Liming Shi; Jesper Lisby Højvang; Morten Højfeldt Rasmussen; Mads Græsbøll Christensen', display:{Lore:['[{"text": "arXiv:2006.16689", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Speech Enhancement Algorithm based on Non-negative Hidden Markov Model and Kullback-Leibler Divergence\\u00a7r\\n\\n\\u00a78\\u00a7oYang Xiang\\nLiming Shi\\nJesper Lisby H\\u00f8jvang\\nMorten H\\u00f8jfeldt Rasmussen\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2006.16689\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 30 Jun 2020 11:26:48 GMT)\\u00a7r"}']}
{title:'Van Segbroeck et al. (§72020§r)', author: 'Maarten Van Segbroeck; Harish Mallidih; Brian King; I-Fan Chen; Gurpreet Chadha; Roland Maas', display:{Lore:['[{"text": "arXiv:2007.00131", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMulti-view Frequency LSTM: An Efficient Frontend for Automatic Speech Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oMaarten Van Segbroeck\\nHarish Mallidih\\nBrian King\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2007.00131\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 30 Jun 2020 22:19:53 GMT)\\u00a7r"}']}
{title:'Shi et al. (§72020§r)', author: 'Bowen Shi; Shane Settle; Karen Livescu', display:{Lore:['[{"text": "arXiv:2007.00183", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lWhole-Word Segmental Speech Recognition with Acoustic Word Embeddings\\u00a7r\\n\\n\\u00a78\\u00a7oBowen Shi\\nShane Settle\\nKaren Livescu\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2007.00183\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 24 Nov 2020 17:03:52 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSLT 2021\\u00a7r"}']}
{title:'Alamdari et al. (§72020§r)', author: 'Nasim Alamdari; Edward Lobarinas; Nasser Kehtarnavaz', display:{Lore:['[{"text": "arXiv:2007.00192", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7eeess.SP\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lPersonalization of Hearing Aid Compression by Human-In-Loop Deep Reinforcement Learning\\u00a7r\\n\\n\\u00a78\\u00a7oNasim Alamdari\\nEdward Lobarinas\\nNasser Kehtarnavaz\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2007.00192\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 1 Jul 2020 02:50:33 GMT)\\u00a7r"}']}
{title:'Koizumi et al. (§72020§r)', author: 'Yuma Koizumi; Ryo Masumura; Kyosuke Nishida; Masahiro Yasuda; Shoichiro Saito', display:{Lore:['[{"text": "arXiv:2007.00222", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Transformer-based Audio Captioning Model with Keyword Estimation\\u00a7r\\n\\n\\u00a78\\u00a7oYuma Koizumi\\nRyo Masumura\\nKyosuke Nishida\\nMasahiro Yasuda\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2007.00222\\u00a7r\\n\\nVersion:\\u00a77v2 (Sat, 8 Aug 2020 06:38:00 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted to Interspeech 2020\\u00a7r"}']}
{title:'Koizumi et al. (§72020§r)', author: 'Yuma Koizumi; Daiki Takeuchi; Yasunori Ohishi; Noboru Harada; Kunio Kashino', display:{Lore:['[{"text": "arXiv:2007.00225", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lThe NTT DCASE2020 Challenge Task 6 system: Automated Audio Captioning with Keywords and Sentence Length Estimation\\u00a7r\\n\\n\\u00a78\\u00a7oYuma Koizumi\\nDaiki Takeuchi\\nYasunori Ohishi\\nNoboru Harada\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2007.00225\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 1 Jul 2020 04:26:27 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oTechnical Reportof DCASE2020 Challenge Task 6\\u00a7r"}']}
{title:'Dietzen et al. (§72020§r)', author: 'Thomas Dietzen; Marc Moonen; Toon van Waterschoot', display:{Lore:['[{"text": "arXiv:2007.00542", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lInstantaneous PSD Estimation for Speech Enhancement based on Generalized Principal Components\\u00a7r\\n\\n\\u00a78\\u00a7oThomas Dietzen\\nMarc Moonen\\nToon van Waterschoot\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2007.00542\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.23919/Eusipco47968.2020.9287839\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nProc. 28th European Signal Process. Conf. (EUSIPCO 2020),\\n  Amsterdam, Netherlands, Jan 2021, pp. 1-5\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 1 Jul 2020 15:10:54 GMT)\\u00a7r"}']}
{title:'Bird et al. (§72020§r)', author: 'Jordan J. Bird; Diego R. Faria; Anikó Ekárt; Cristiano Premebida; Pedro P. S. Ayrosa', display:{Lore:['[{"text": "arXiv:2007.00659", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lLSTM and GPT-2 Synthetic Speech Transfer Learning for Speaker Recognition to Overcome Data Scarcity\\u00a7r\\n\\n\\u00a78\\u00a7oJordan J. Bird\\nDiego R. Faria\\nAnik\\u00f3 Ek\\u00e1rt\\nCristiano Premebida\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2007.00659\\u00a7r\\n\\nVersion:\\u00a77v2 (Fri, 3 Jul 2020 17:02:31 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o10 pages, 5 figures, 5 tables. Submitted to journal\\u00a7r"}']}
{title:'Chen et al. (§72020§r)', author: 'Zhuohao Chen; James Gibson; Ming-Chang Chiu; Qiaohong Hu; Tara K Knight; Daniella Meeker; James A Tulsky; Kathryn I Pollak; Shrikanth Narayanan', display:{Lore:['[{"text": "arXiv:2007.00809", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAutomated Empathy Detection for Oncology Encounters\\u00a7r\\n\\n\\u00a78\\u00a7oZhuohao Chen\\nJames Gibson\\nMing-Chang Chiu\\n+ 5 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2007.00809\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 1 Jul 2020 23:24:42 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted by the 8TH IEEE International Conference on Healthcare Informatics(ICHI2020)\\u00a7r"}']}
{title:'Kai et al. (§72020§r)', author: 'Chan Teck Kai; Chin Cheng Siong; Li Ye', display:{Lore:['[{"text": "arXiv:2007.00908", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSemi-Supervised NMF-CNN For Sound Event Detection\\u00a7r\\n\\n\\u00a78\\u00a7oChan Teck Kai\\nChin Cheng Siong\\nLi Ye\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2007.00908\\u00a7r\\n\\nVersion:\\u00a77v2 (Mon, 21 Sep 2020 11:46:54 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 2 tables\\u00a7r"}']}
{title:'Kim et al. (§72020§r)', author: 'Nam Kyun Kim; Hong Kook Kim', display:{Lore:['[{"text": "arXiv:2007.00947", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lPolyphonic sound event detection based on convolutional recurrent neural networks with semi-supervised loss function for DCASE challenge 2020 task 4\\u00a7r\\n\\n\\u00a78\\u00a7oNam Kyun Kim\\nHong Kook Kim\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2007.00947\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 2 Jul 2020 07:55:18 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o4 pages, DCASE challenge2020 task4 technical report\\u00a7r"}']}
{title:'Kharitonov et al. (§72020§r)', author: 'Eugene Kharitonov; Morgane Rivière; Gabriel Synnaeve; Lior Wolf; Pierre-Emmanuel Mazaré; Matthijs Douze; Emmanuel Dupoux', display:{Lore:['[{"text": "arXiv:2007.00991", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lData Augmenting Contrastive Learning of Speech Representations in the Time Domain\\u00a7r\\n\\n\\u00a78\\u00a7oEugene Kharitonov\\nMorgane Rivi\\u00e8re\\nGabriel Synnaeve\\n+ 3 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2007.00991\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 2 Jul 2020 09:59:51 GMT)\\u00a7r"}']}
{title:'Haubner et al. (§72020§r)', author: 'Thomas Haubner; Andreas Brendel; Walter Kellermann', display:{Lore:['[{"text": "arXiv:2007.01543", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lOnline Supervised Acoustic System Identification exploiting Prelearned Local Affine Subspace Models\\u00a7r\\n\\n\\u00a78\\u00a7oThomas Haubner\\nAndreas Brendel\\nWalter Kellermann\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2007.01543\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 3 Jul 2020 08:05:03 GMT)\\u00a7r"}']}
{title:'Wu et al. (§72020§r)', author: 'Bo Wu; Meng Yu; Lianwu Chen; Yong Xu; Chao Weng; Dan Su; Dong Yu', display:{Lore:['[{"text": "arXiv:2007.01566", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDistortionless Multi-Channel Target Speech Enhancement for Overlapped Speech Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oBo Wu\\nMeng Yu\\nLianwu Chen\\n+ 3 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2007.01566\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 3 Jul 2020 09:23:46 GMT)\\u00a7r"}']}
{title:'Denisov et al. (§72020§r)', author: 'Pavel Denisov; Ngoc Thang Vu', display:{Lore:['[{"text": "arXiv:2007.01836", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lPretrained Semantic Speech Embeddings for End-to-End Spoken Language Understanding via Cross-Modal Teacher-Student Learning\\u00a7r\\n\\n\\u00a78\\u00a7oPavel Denisov\\nNgoc Thang Vu\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2007.01836\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 11 Aug 2020 23:32:56 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oInterspeech 2020\\u00a7r"}']}
{title:'Zhou et al. (§72020§r)', author: 'Tianyan Zhou; Yong Zhao; Jian Wu', display:{Lore:['[{"text": "arXiv:2007.02480", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lResNeXt and Res2Net Structures for Speaker Verification\\u00a7r\\n\\n\\u00a78\\u00a7oTianyan Zhou\\nYong Zhao\\nJian Wu\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2007.02480\\u00a7r\\n\\nVersion:\\u00a77v2 (Mon, 30 Nov 2020 00:51:03 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oto be published in IEEE Spoken Language Technology Workshop(SLT) 2021\\u00a7r"}']}
{title:'Nguyen et al. (§72020§r)', author: 'Khoa Nguyen; Konstantinos Drossos; Tuomas Virtanen', display:{Lore:['[{"text": "arXiv:2007.02676", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lTemporal Sub-sampling of Audio Feature Sequences for Automated Audio Captioning\\u00a7r\\n\\n\\u00a78\\u00a7oKhoa Nguyen\\nKonstantinos Drossos\\nTuomas Virtanen\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2007.02676\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 6 Jul 2020 12:19:23 GMT)\\u00a7r"}']}
{title:'Pyykkönen et al. (§72020§r)', author: 'Pyry Pyykkönen; Styliannos I. Mimilakis; Konstantinos Drossos; Tuomas Virtanen', display:{Lore:['[{"text": "arXiv:2007.02683", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDepthwise Separable Convolutions Versus Recurrent Neural Networks for Monaural Singing Voice Separation\\u00a7r\\n\\n\\u00a78\\u00a7oPyry Pyykk\\u00f6nen\\nStyliannos I. Mimilakis\\nKonstantinos Drossos\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2007.02683\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 6 Jul 2020 12:32:34 GMT)\\u00a7r"}']}
{title:'Pratap et al. (§72020§r)', author: 'Vineel Pratap; Anuroop Sriram; Paden Tomasello; Awni Hannun; Vitaliy Liptchinsky; Gabriel Synnaeve; Ronan Collobert', display:{Lore:['[{"text": "arXiv:2007.03001", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMassively Multilingual ASR: 50 Languages, 1 Model, 1 Billion Parameters\\u00a7r\\n\\n\\u00a78\\u00a7oVineel Pratap\\nAnuroop Sriram\\nPaden Tomasello\\n+ 3 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2007.03001\\u00a7r\\n\\nVersion:\\u00a77v2 (Wed, 8 Jul 2020 03:02:06 GMT)\\u00a7r"}']}
{title:'Pan et al. (§72020§r)', author: 'Zihan Pan; Malu Zhang; Jibin Wu; Haizhou Li', display:{Lore:['[{"text": "arXiv:2007.03274", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.NE\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMulti-Tones\' Phase Coding (MTPC) of Interaural Time Difference by Spiking Neural Network\\u00a7r\\n\\n\\u00a78\\u00a7oZihan Pan\\nMalu Zhang\\nJibin Wu\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2007.03274\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 7 Jul 2020 08:22:56 GMT)\\u00a7r"}']}
{title:'Jeancolas et al. (§72020§r)', author: 'Laetitia Jeancolas; Dijana Petrovska-Delacrétaz; Graziella Mangone; Badr-Eddine Benkelfat; Jean-Christophe Corvol; Marie Vidailhet; Stéphane Lehéricy; Habib Benali', display:{Lore:['[{"text": "arXiv:2007.03599", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7bq-bio.QM\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lX-vectors: New Quantitative Biomarkers for Early Parkinson\'s Disease Detection from Speech\\u00a7r\\n\\n\\u00a78\\u00a7oLaetitia Jeancolas\\nDijana Petrovska-Delacr\\u00e9taz\\nGraziella Mangone\\n+ 4 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2007.03599\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.3389/fninf.2021.578369\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nFrontiers in Neuroinformatics, 15 (2021)\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 7 Jul 2020 16:34:51 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted\\u00a7r"}']}
{title:'Punjabi et al. (§72020§r)', author: 'Surabhi Punjabi; Harish Arsikere; Zeynab Raeesy; Chander Chandak; Nikhil Bhave; Ankish Bansal; Markus Müller; Sergio Murillo; Ariya Rastrow; Sri Garimella; Roland Maas; Mat Hans; Athanasios Mouchtaris; Siegfried Kunzmann', display:{Lore:['[{"text": "arXiv:2007.03900", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lStreaming End-to-End Bilingual ASR Systems with Joint Language Identification\\u00a7r\\n\\n\\u00a78\\u00a7oSurabhi Punjabi\\nHarish Arsikere\\nZeynab Raeesy\\n+ 10 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2007.03900\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 8 Jul 2020 05:00:25 GMT)\\u00a7r"}']}
{title:'Shukla et al. (§72020§r)', author: 'Abhinav Shukla; Stavros Petridis; Maja Pantic', display:{Lore:['[{"text": "arXiv:2007.04134", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.CV\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.MM\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lLearning Speech Representations from Raw Audio by Joint Audiovisual Self-Supervision\\u00a7r\\n\\n\\u00a78\\u00a7oAbhinav Shukla\\nStavros Petridis\\nMaja Pantic\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2007.04134\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 8 Jul 2020 14:07:06 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted at the Workshop on Self-supervision in Audio and Speech at ICML 2020\\u00a7r"}']}
{title:'Ren et al. (§72020§r)', author: 'Yi Ren; Xu Tan; Tao Qin; Jian Luan; Zhou Zhao; Tie-Yan Liu', display:{Lore:['[{"text": "arXiv:2007.04590", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDeepSinger: Singing Voice Synthesis with Data Mined From the Web\\u00a7r\\n\\n\\u00a78\\u00a7oYi Ren\\nXu Tan\\nTao Qin\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2007.04590\\u00a7r\\n\\nVersion:\\u00a77v2 (Wed, 15 Jul 2020 14:37:45 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted by KDD2020 research track\\u00a7r"}']}
{title:'Shim et al. (§72020§r)', author: 'Hye-jin Shim; Jee-weon Jung; Ju-ho Kim; Ha-jin Yu', display:{Lore:['[{"text": "arXiv:2007.04631", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lCapturing scattered discriminative information using a deep architecture in acoustic scene classification\\u00a7r\\n\\n\\u00a78\\u00a7oHye-jin Shim\\nJee-weon Jung\\nJu-ho Kim\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2007.04631\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 9 Jul 2020 08:32:06 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to DCASE2020 workshop\\u00a7r"}']}
{title:'Kapka (§72020§r)', author: 'Sławomir Kapka', display:{Lore:['[{"text": "arXiv:2007.05314", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lID-Conditioned Auto-Encoder for Unsupervised Anomaly Detection\\u00a7r\\n\\n\\u00a78\\u00a7oS\\u0142awomir Kapka\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2007.05314\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.5281/zenodo.4061782\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nProceedings of the Fifth Workshop on Detection and Classification\\n  of Acoustic Scenes and Events (DCASE 2020)\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 8 Sep 2020 12:09:16 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 4 figures, conference\\u00a7r"}']}
{title:'Sharma et al. (§72020§r)', author: 'Ankit Sharma; Puneet Kumar; Vikas Maddukuri; Nagasai Madamshettib; Kishore KG; Sahit Sai Sriram Kavurub; Balasubramanian Raman; Partha Pratim Roy', display:{Lore:['[{"text": "arXiv:2007.05764", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.MM\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lFast Griffin Lim based Waveform Generation Strategy for Text-to-Speech Synthesis\\u00a7r\\n\\n\\u00a78\\u00a7oAnkit Sharma\\nPuneet Kumar\\nVikas Maddukuri\\n+ 4 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2007.05764\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 11 Jul 2020 13:10:09 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted for publication in Springer Multimedia Tools and Applications Journal\\u00a7r"}']}
{title:'Shi et al. (§72020§r)', author: 'Xian Shi; Qiangze Feng; Lei Xie', display:{Lore:['[{"text": "arXiv:2007.05916", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lThe ASRU 2019 Mandarin-English Code-Switching Speech Recognition Challenge: Open Datasets, Tracks, Methods and Results\\u00a7r\\n\\n\\u00a78\\u00a7oXian Shi\\nQiangze Feng\\nLei Xie\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2007.05916\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 12 Jul 2020 05:38:57 GMT)\\u00a7r"}']}
{title:'Kinnunen et al. (§72020§r)', author: 'Tomi Kinnunen; Héctor Delgado; Nicholas Evans; Kong Aik Lee; Ville Vestman; Andreas Nautsch; Massimiliano Todisco; Xin Wang; Md Sahidullah; Junichi Yamagishi; Douglas A. Reynolds', display:{Lore:['[{"text": "arXiv:2007.05979", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7eeess.SP\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lTandem Assessment of Spoofing Countermeasures and Automatic Speaker Verification: Fundamentals\\u00a7r\\n\\n\\u00a78\\u00a7oTomi Kinnunen\\nH\\u00e9ctor Delgado\\nNicholas Evans\\n+ 7 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2007.05979\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/TASLP.2020.3009494\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 25 Aug 2020 10:40:50 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oPublished in IEEE/ACM Transactionson Audio, Speech, and Language Processing (doi updated)\\u00a7r"}']}
{title:'Kalluri et al. (§72020§r)', author: 'Shareef Babu Kalluri; Deepu Vijayasenan; Sriram Ganapathy; Ragesh Rajan M; Prashant Krishnan', display:{Lore:['[{"text": "arXiv:2007.06021", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lNISP: A Multi-lingual Multi-accent Dataset for Speaker Profiling\\u00a7r\\n\\n\\u00a78\\u00a7oShareef Babu Kalluri\\nDeepu Vijayasenan\\nSriram Ganapathy\\nRagesh Rajan M\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2007.06021\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 12 Jul 2020 15:46:57 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5pages, Initial version submitted to Interspeech2020\\u00a7r"}']}
{title:'Verma et al. (§72020§r)', author: 'Mudit Verma; Arun Balaji Buduru', display:{Lore:['[{"text": "arXiv:2007.06078", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lFine-grained Language Identification with Multilingual CapsNet Model\\u00a7r\\n\\n\\u00a78\\u00a7oMudit Verma\\nArun Balaji Buduru\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2007.06078\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 12 Jul 2020 20:01:22 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 6 figures\\u00a7r"}']}
{title:'Bitton et al. (§72020§r)', author: 'Adrien Bitton; Philippe Esling; Tatsuya Harada', display:{Lore:['[{"text": "arXiv:2007.06349", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lVector-Quantized Timbre Representation\\u00a7r\\n\\n\\u00a78\\u00a7oAdrien Bitton\\nPhilippe Esling\\nTatsuya Harada\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2007.06349\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 13 Jul 2020 12:35:45 GMT)\\u00a7r"}']}
{title:'Demirel et al. (§72020§r)', author: 'Emir Demirel; Sven Ahlback; Simon Dixon', display:{Lore:['[{"text": "arXiv:2007.06486", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAutomatic Lyrics Transcription using Dilated Convolutional Neural Networks with Self-Attention\\u00a7r\\n\\n\\u00a78\\u00a7oEmir Demirel\\nSven Ahlback\\nSimon Dixon\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2007.06486\\u00a7r\\n\\nVersion:\\u00a77v2 (Fri, 24 Jul 2020 15:26:48 GMT)\\u00a7r"}']}
{title:'Tzinis et al. (§72020§r)', author: 'Efthymios Tzinis; Zhepei Wang; Paris Smaragdis', display:{Lore:['[{"text": "arXiv:2007.06833", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSudo rm -rf: Efficient Networks for Universal Audio Source Separation\\u00a7r\\n\\n\\u00a78\\u00a7oEfthymios Tzinis\\nZhepei Wang\\nParis Smaragdis\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2007.06833\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/MLSP49062.2020.9231900\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nPublished in 2020 IEEE 30th International Workshop on Machine\\n  Learning for Signal Processing (MLSP)\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 14 Jul 2020 05:46:38 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oaccepted to MLSP 2020\\u00a7r"}']}
{title:'Tarján et al. (§72020§r)', author: 'Balázs Tarján; György Szaszák; Tibor Fegyó; Péter Mihajlik', display:{Lore:['[{"text": "arXiv:2007.06949", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDeep Transformer based Data Augmentation with Subword Units for Morphologically Rich Online ASR\\u00a7r\\n\\n\\u00a78\\u00a7oBal\\u00e1zs Tarj\\u00e1n\\nGy\\u00f6rgy Szasz\\u00e1k\\nTibor Fegy\\u00f3\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2007.06949\\u00a7r\\n\\nVersion:\\u00a77v3 (Wed, 4 Nov 2020 09:03:13 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o7 pages, 4 figures\\u00a7r"}']}
{title:'Thienpondt et al. (§72020§r)', author: 'Jenthe Thienpondt; Brecht Desplanques; Kris Demuynck', display:{Lore:['[{"text": "arXiv:2007.07689", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lCross-Lingual Speaker Verification with Domain-Balanced Hard Prototype Mining and Language-Dependent Score Normalization\\u00a7r\\n\\n\\u00a78\\u00a7oJenthe Thienpondt\\nBrecht Desplanques\\nKris Demuynck\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2007.07689\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.21437/Interspeech.2020-2662\\u00a7r\\n\\nVersion:\\u00a77v2 (Mon, 10 Aug 2020 13:42:58 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oproceedings of INTERSPEECH 2020\\u00a7r"}']}
{title:'Sarkar et al. (§72020§r)', author: 'Achintya Kumar Sarkar; Himangshu Sarma; Priyanka Dwivedi; Zheng-Hua Tan', display:{Lore:['[{"text": "arXiv:2007.08004", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lData augmentation enhanced speaker enrollment for text-dependent speaker verification\\u00a7r\\n\\n\\u00a78\\u00a7oAchintya Kumar Sarkar\\nHimangshu Sarma\\nPriyanka Dwivedi\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2007.08004\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nProc. of ICEPE 2020\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 12 Jul 2020 09:04:03 GMT)\\u00a7r"}']}
{title:'Xu et al. (§72020§r)', author: 'Runxin Xu; Jun Cao; Mingxuan Wang; Jiaze Chen; Hao Zhou; Ying Zeng; Yuping Wang; Li Chen; Xiang Yin; Xijin Zhang; Songcheng Jiang; Yuxuan Wang; Lei Li', display:{Lore:['[{"text": "arXiv:2007.08005", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lXiaomingbot: A Multilingual Robot News Reporter\\u00a7r\\n\\n\\u00a78\\u00a7oRunxin Xu\\nJun Cao\\nMingxuan Wang\\n+ 9 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2007.08005\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 12 Jul 2020 14:49:41 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted to ACL 2020 - system demonstration\\u00a7r"}']}
{title:'Jiao (§72020§r)', author: 'Yang Jiao', display:{Lore:['[{"text": "arXiv:2007.08052", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lTranslate Reverberated Speech to Anechoic Ones: Speech Dereverberation with BERT\\u00a7r\\n\\n\\u00a78\\u00a7oYang Jiao\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2007.08052\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 16 Jul 2020 00:45:27 GMT)\\u00a7r"}']}
{title:'Zhu et al. (§72020§r)', author: 'Boqing Zhu; Kele Xu; Qiuqiang Kong; Huaimin Wang; Yuxing Peng', display:{Lore:['[{"text": "arXiv:2007.08165", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAudio Tagging by Cross Filtering Noisy Labels\\u00a7r\\n\\n\\u00a78\\u00a7oBoqing Zhu\\nKele Xu\\nQiuqiang Kong\\nHuaimin Wang\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2007.08165\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/TASLP.2020.3008832\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 16 Jul 2020 07:55:04 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted by IEEE/ACM Transactionson Audio, Speech and Language Processing\\u00a7r"}']}
{title:'Choi et al. (§72020§r)', author: 'Yeunju Choi; Youngmoon Jung; Hoirin Kim', display:{Lore:['[{"text": "arXiv:2007.08267", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lNeural MOS Prediction for Synthesized Speech Using Multi-Task Learning With Spoofing Detection and Spoofing Type Classification\\u00a7r\\n\\n\\u00a78\\u00a7oYeunju Choi\\nYoungmoon Jung\\nHoirin Kim\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2007.08267\\u00a7r\\n\\nVersion:\\u00a77v2 (Wed, 2 Dec 2020 07:56:32 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o8 pages, 5 figures, accepted to SLT 2021\\u00a7r"}']}
{title:'Hu et al. (§72020§r)', author: 'Hu Hu; Chao-Han Huck Yang; Xianjun Xia; Xue Bai; Xin Tang; Yajian Wang; Shutong Niu; Li Chai; Juanjuan Li; Hongning Zhu; Feng Bao; Yuanjun Zhao; Sabato Marco Siniscalchi; Yannan Wang; Jun Du; Chin-Hui Lee', display:{Lore:['[{"text": "arXiv:2007.08389", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDevice-Robust Acoustic Scene Classification Based on Two-Stage Categorization and Data Augmentation\\u00a7r\\n\\n\\u00a78\\u00a7oHu Hu\\nChao-Han Huck Yang\\nXianjun Xia\\n+ 12 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2007.08389\\u00a7r\\n\\nVersion:\\u00a77v2 (Thu, 27 Aug 2020 00:33:27 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oRevised Technical Report. Proposed systems attain 2nds in both Task-1a and Task-1b inthe official DCASE challenge 2020\\u00a7r"}']}
{title:'Kürzinger et al. (§72020§r)', author: 'Ludwig Kürzinger; Dominik Winkelbauer; Lujun Li; Tobias Watzel; Gerhard Rigoll', display:{Lore:['[{"text": "arXiv:2007.09127", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lCTC-Segmentation of Large Corpora for German End-to-end Speech Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oLudwig K\\u00fcrzinger\\nDominik Winkelbauer\\nLujun Li\\nTobias Watzel\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2007.09127\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1007/978-3-030-60276-5_27\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nSpeech and Computer (2020)\\u00a7r\\n\\nVersion:\\u00a77v2 (Mon, 5 Oct 2020 07:46:24 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oPublished at SPECOM 2020\\u00a7r"}']}
{title:'Kothapally et al. (§72020§r)', author: 'Vinay Kothapally; Wei Xia; Shahram Ghorbani; John H. L. Hansen; Wei Xue; Jing Huang', display:{Lore:['[{"text": "arXiv:2007.09131", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7eeess.SP\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSkipConvNet: Skip Convolutional Neural Network for Speech Dereverberation using Optimally Smoothed Spectral Mapping\\u00a7r\\n\\n\\u00a78\\u00a7oVinay Kothapally\\nWei Xia\\nShahram Ghorbani\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2007.09131\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.21437/Interspeech.2020-2048\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 17 Jul 2020 17:43:00 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to Interspeech2020\\u00a7r"}']}
{title:'Tong et al. (§72020§r)', author: 'Xiaosu Tong; Che-Wei Huang; Sri Harish Mallidi; Shaun Joseph; Sonal Pareek; Chander Chandak; Ariya Rastrow; Roland Maas', display:{Lore:['[{"text": "arXiv:2007.09245", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lStreaming ResLSTM with Causal Mean Aggregation for Device-Directed Utterance Detection\\u00a7r\\n\\n\\u00a78\\u00a7oXiaosu Tong\\nChe-Wei Huang\\nSri Harish Mallidi\\n+ 4 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2007.09245\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 17 Jul 2020 21:30:11 GMT)\\u00a7r"}']}
{title:'Pal et al. (§72020§r)', author: 'Monisankha Pal; Manoj Kumar; Raghuveer Peri; Tae Jin Park; So Hyun Kim; Catherine Lord; Somer Bishop; Shrikanth Narayanan', display:{Lore:['[{"text": "arXiv:2007.09635", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMeta-learning with Latent Space Clustering in Generative Adversarial Network for Speaker Diarization\\u00a7r\\n\\n\\u00a78\\u00a7oMonisankha Pal\\nManoj Kumar\\nRaghuveer Peri\\n+ 4 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2007.09635\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 19 Jul 2020 09:33:40 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to IEEE/ACM TRANSACTIONS ON AUDIOSPEECH AND LANGUAGE PROCESSING\\u00a7r"}']}
{title:'Xu et al. (§72020§r)', author: 'Jiwei Xu; Xinggang Wang; Bin Feng; Wenyu Liu', display:{Lore:['[{"text": "arXiv:2007.10479", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CV\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDeep multi-metric learning for text-independent speaker verification\\u00a7r\\n\\n\\u00a78\\u00a7oJiwei Xu\\nXinggang Wang\\nBin Feng\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2007.10479\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1016/j.neucom.2020.06.045\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nNeurocomputing, Volume 410, 14 October 2020, Pages 394-400\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 17 Jul 2020 13:19:44 GMT)\\u00a7r"}']}
{title:'Nouza et al. (§72020§r)', author: 'Jan Nouza; Petr Cerva; Jindrich Zdansky', display:{Lore:['[{"text": "arXiv:2007.10706", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lVery Fast Keyword Spotting System with Real Time Factor below 0.01\\u00a7r\\n\\n\\u00a78\\u00a7oJan Nouza\\nPetr Cerva\\nJindrich Zdansky\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2007.10706\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1007/978-3-030-58323-1_46\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nIn: Sojka P.Text, Speech, and Dialogue. TSD 2020. Lecture Notes in\\n  Computer Science, vol 12284. Springer, Cham\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 21 Jul 2020 10:55:07 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o11 pages, 3 figures\\u00a7r"}']}
{title:'Kürzinger et al. (§72020§r)', author: 'Ludwig Kürzinger; Edgar Ricardo Chavez Rosas; Lujun Li; Tobias Watzel; Gerhard Rigoll', display:{Lore:['[{"text": "arXiv:2007.10723", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAudio Adversarial Examples for Robust Hybrid CTC/Attention Speech Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oLudwig K\\u00fcrzinger\\nEdgar Ricardo Chavez Rosas\\nLujun Li\\nTobias Watzel\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2007.10723\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 21 Jul 2020 11:30:24 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oTo be published at SPECOM 2020\\u00a7r"}']}
{title:'Sarangi et al. (§72020§r)', author: 'Susanta Sarangi; Md Sahidullah; Goutam Saha', display:{Lore:['[{"text": "arXiv:2007.10729", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CV\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lOptimization of data-driven filterbank for automatic speaker verification\\u00a7r\\n\\n\\u00a78\\u00a7oSusanta Sarangi\\nMd Sahidullah\\nGoutam Saha\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2007.10729\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1016/j.dsp.2020.102795\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 21 Jul 2020 11:42:20 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oPublished in Digital Signal Processing journal (Elsevier)\\u00a7r"}']}
{title:'Michaud et al. (§72020§r)', author: 'Simon Michaud; Samuel Faucher; François Grondin; Jean-Samuel Lauzon; Mathieu Labbé; Dominic Létourneau; François Ferland; François Michaud', display:{Lore:['[{"text": "arXiv:2007.11079", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7l3D Localization of a Sound Source Using Mobile Microphone Arrays Referenced by SLAM\\u00a7r\\n\\n\\u00a78\\u00a7oSimon Michaud\\nSamuel Faucher\\nFran\\u00e7ois Grondin\\n+ 4 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2007.11079\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 21 Jul 2020 20:22:00 GMT)\\u00a7r"}']}
{title:'Pfeifenberger et al. (§72020§r)', author: 'Lukas Pfeifenberger; Matthias Zöhrer; Günther Schindler; Wolfgang Roth; Holger Fröning; Franz Pernkopf', display:{Lore:['[{"text": "arXiv:2007.11477", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lResource-Efficient Speech Mask Estimation for Multi-Channel Speech Enhancement\\u00a7r\\n\\n\\u00a78\\u00a7oLukas Pfeifenberger\\nMatthias Z\\u00f6hrer\\nG\\u00fcnther Schindler\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2007.11477\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 22 Jul 2020 14:58:29 GMT)\\u00a7r"}']}
{title:'Fahmy et al. (§72020§r)', author: 'Fady Fahmy; Mahmoud Khalil; Hazem Abbas', display:{Lore:['[{"text": "arXiv:2007.11541", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Transfer Learning End-to-End ArabicText-To-Speech (TTS) Deep Architecture\\u00a7r\\n\\n\\u00a78\\u00a7oFady Fahmy\\nMahmoud Khalil\\nHazem Abbas\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2007.11541\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 22 Jul 2020 17:03:18 GMT)\\u00a7r"}']}
{title:'Birnie et al. (§72020§r)', author: 'Lachlan Birnie; Thushara Abhayapala; Vladimir Tourbabin; Prasanga Samarasinghe', display:{Lore:['[{"text": "arXiv:2007.11795", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSound Field Translation and Mixed Source Model for Virtual Applications with Perceptual Validation\\u00a7r\\n\\n\\u00a78\\u00a7oLachlan Birnie\\nThushara Abhayapala\\nVladimir Tourbabin\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2007.11795\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 23 Jul 2020 05:16:01 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o12 pages, 11 figures This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\\u00a7r"}']}
{title:'Wager et al. (§72020§r)', author: 'Sanna Wager; Keunwoo Choi; Simon Durand', display:{Lore:['[{"text": "arXiv:2007.12581", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDereverberation using joint estimation of dry speech signal and acoustic system\\u00a7r\\n\\n\\u00a78\\u00a7oSanna Wager\\nKeunwoo Choi\\nSimon Durand\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2007.12581\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 24 Jul 2020 15:33:08 GMT)\\u00a7r"}']}
{title:'Andronic et al. (§72020§r)', author: 'Iustina Andronic; Ludwig Kürzinger; Edgar Ricardo Chavez Rosas; Gerhard Rigoll; Bernhard U. Seeber', display:{Lore:['[{"text": "arXiv:2007.12892", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CR\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMP3 Compression To Diminish Adversarial Noise in End-to-End Speech Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oIustina Andronic\\nLudwig K\\u00fcrzinger\\nEdgar Ricardo Chavez Rosas\\nGerhard Rigoll\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2007.12892\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 25 Jul 2020 09:25:32 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted and accepted at SPECOM 2020 conference\\u00a7r"}']}
{title:'Shankar et al. (§72020§r)', author: 'Ravi Shankar; Jacob Sager; Archana Venkataraman', display:{Lore:['[{"text": "arXiv:2007.12932", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lNon-parallel Emotion Conversion using a Deep-Generative Hybrid Network and an Adversarial Pair Discriminator\\u00a7r\\n\\n\\u00a78\\u00a7oRavi Shankar\\nJacob Sager\\nArchana Venkataraman\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2007.12932\\u00a7r\\n\\nVersion:\\u00a77v2 (Mon, 10 Aug 2020 19:20:44 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oPaper accepted in Interspeech 2020\\u00a7r"}']}
{title:'Shankar et al. (§72020§r)', author: 'Ravi Shankar; Hsi-Wei Hsieh; Nicolas Charon; Archana Venkataraman', display:{Lore:['[{"text": "arXiv:2007.12937", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMulti-speaker Emotion Conversion via Latent Variable Regularization and a Chained Encoder-Decoder-Predictor Network\\u00a7r\\n\\n\\u00a78\\u00a7oRavi Shankar\\nHsi-Wei Hsieh\\nNicolas Charon\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2007.12937\\u00a7r\\n\\nVersion:\\u00a77v2 (Mon, 10 Aug 2020 19:16:40 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oPaper Accepted in Interspeech 2020\\u00a7r"}']}
{title:'Setlur et al. (§72020§r)', author: 'Amrith Setlur; Barnabas Poczos; Alan W Black', display:{Lore:['[{"text": "arXiv:2007.12948", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lNonlinear ISA with Auxiliary Variables for Learning Speech Representations\\u00a7r\\n\\n\\u00a78\\u00a7oAmrith Setlur\\nBarnabas Poczos\\nAlan W Black\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2007.12948\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 25 Jul 2020 14:53:09 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oTo be presented at Interspeech 2020\\u00a7r"}']}
{title:'Feng et al. (§72020§r)', author: 'Siyuan Feng; Odette Scharenborg', display:{Lore:['[{"text": "arXiv:2007.13002", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lUnsupervised Subword Modeling Using Autoregressive Pretraining and Cross-Lingual Phone-Aware Modeling\\u00a7r\\n\\n\\u00a78\\u00a7oSiyuan Feng\\nOdette Scharenborg\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2007.13002\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.21437/Interspeech.2020-1170\\u00a7r\\n\\nVersion:\\u00a77v2 (Thu, 6 Aug 2020 19:15:48 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 3 figures. Accepted for publication in INTERSPEECH 2020, Shanghai, China\\u00a7r"}']}
{title:'Qi et al. (§72020§r)', author: 'Jun Qi; Hu Hu; Yannan Wang; Chao-Han Huck Yang; Sabato Marco Siniscalchi; Chin-Hui Lee', display:{Lore:['[{"text": "arXiv:2007.13024", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.NE\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lExploring Deep Hybrid Tensor-to-Vector Network Architectures for Regression Based Speech Enhancement\\u00a7r\\n\\n\\u00a78\\u00a7oJun Qi\\nHu Hu\\nYannan Wang\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2007.13024\\u00a7r\\n\\nVersion:\\u00a77v2 (Mon, 3 Aug 2020 00:07:39 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted to InterSpeech 2020\\u00a7r"}']}
{title:'Bhati et al. (§72020§r)', author: 'Saurabhchand Bhati; Jesús Villalba; Piotr Żelasko; Najim Dehak', display:{Lore:['[{"text": "arXiv:2007.13033", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSelf-Expressing Autoencoders for Unsupervised Spoken Term Discovery\\u00a7r\\n\\n\\u00a78\\u00a7oSaurabhchand Bhati\\nJes\\u00fas Villalba\\nPiotr \\u017belasko\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2007.13033\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 26 Jul 2020 00:04:17 GMT)\\u00a7r"}']}
{title:'Dinkel et al. (§72020§r)', author: 'Heinrich Dinkel; Nanxin Chen; Yanmin Qian; Kai Yu', display:{Lore:['[{"text": "arXiv:2007.13060", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lEnd-to-end spoofing detection with raw waveform CLDNNs\\u00a7r\\n\\n\\u00a78\\u00a7oHeinrich Dinkel\\nNanxin Chen\\nYanmin Qian\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2007.13060\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/ICASSP.2017.7953080\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7n2017 IEEE International Conference on Acoustics, Speech and Signal\\n  Processing (ICASSP)\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 26 Jul 2020 05:48:35 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages\\u00a7r"}']}
{title:'Sahidullah et al. (§72020§r)', author: 'Md Sahidullah; Achintya Kumar Sarkar; Ville Vestman; Xuechen Liu; Romain Serizel; Tomi Kinnunen; Zheng-Hua Tan; Emmanuel Vincent', display:{Lore:['[{"text": "arXiv:2007.13118", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CV\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lUIAI System for Short-Duration Speaker Verification Challenge 2020\\u00a7r\\n\\n\\u00a78\\u00a7oMd Sahidullah\\nAchintya Kumar Sarkar\\nVille Vestman\\n+ 4 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2007.13118\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 26 Jul 2020 12:32:34 GMT)\\u00a7r"}']}
{title:'Faraji et al. (§72020§r)', author: 'Farnood Faraji; Yazid Attabi; Benoit Champagne; Wei-Ping Zhu', display:{Lore:['[{"text": "arXiv:2007.13258", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lOn the Use of Audio Fingerprinting Features for Speech Enhancement with Generative Adversarial Network\\u00a7r\\n\\n\\u00a78\\u00a7oFarnood Faraji\\nYazid Attabi\\nBenoit Champagne\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2007.13258\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 27 Jul 2020 00:44:16 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o6 pages, 2020 IEEE Workshop on Signal Processing Systems (SiPS)\\u00a7r"}']}
{title:'Goel et al. (§72020§r)', author: 'Sharu Goel; Sandeep Kumar Pandey; Hanumant Singh Shekhawat', display:{Lore:['[{"text": "arXiv:2007.13325", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAnalysis of Emotional Content in Indian Political Speeches\\u00a7r\\n\\n\\u00a78\\u00a7oSharu Goel\\nSandeep Kumar Pandey\\nHanumant Singh Shekhawat\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2007.13325\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 27 Jul 2020 07:00:46 GMT)\\u00a7r"}']}
{title:'Seo et al. (§72020§r)', author: 'Soonshin Seo; Ji-Hwan Kim', display:{Lore:['[{"text": "arXiv:2007.13350", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSelf-Attentive Multi-Layer Aggregation with Feature Recalibration and Normalization for End-to-End Speaker Verification System\\u00a7r\\n\\n\\u00a78\\u00a7oSoonshin Seo\\nJi-Hwan Kim\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2007.13350\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 28 Jul 2020 07:20:40 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 1 figures, 4 tables\\u00a7r"}']}
{title:'Kreuk et al. (§72020§r)', author: 'Felix Kreuk; Joseph Keshet; Yossi Adi', display:{Lore:['[{"text": "arXiv:2007.13465", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSelf-Supervised Contrastive Learning for Unsupervised Phoneme Segmentation\\u00a7r\\n\\n\\u00a78\\u00a7oFelix Kreuk\\nJoseph Keshet\\nYossi Adi\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2007.13465\\u00a7r\\n\\nVersion:\\u00a77v2 (Thu, 6 Aug 2020 07:33:37 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oInterspeech 2020 paper\\u00a7r"}']}
{title:'Koutini et al. (§72020§r)', author: 'Khaled Koutini; Hamid Eghbal-Zadeh; Verena Haunschmid; Paul Primus; Shreyan Chowdhury; Gerhard Widmer', display:{Lore:['[{"text": "arXiv:2007.13503", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lReceptive-Field Regularized CNNs for Music Classification and Tagging\\u00a7r\\n\\n\\u00a78\\u00a7oKhaled Koutini\\nHamid Eghbal-Zadeh\\nVerena Haunschmid\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2007.13503\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 27 Jul 2020 12:48:12 GMT)\\u00a7r"}']}
{title:'Algayres et al. (§72020§r)', author: 'Robin Algayres; Mohamed Salah Zaiem; Benoit Sagot; Emmanuel Dupoux', display:{Lore:['[{"text": "arXiv:2007.13542", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lEvaluating the reliability of acoustic speech embeddings\\u00a7r\\n\\n\\u00a78\\u00a7oRobin Algayres\\nMohamed Salah Zaiem\\nBenoit Sagot\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2007.13542\\u00a7r\\n\\nVersion:\\u00a77v2 (Fri, 6 Nov 2020 13:08:49 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oConference paper at Interspeech 2020\\u00a7r"}']}
{title:'Guo et al. (§72020§r)', author: 'Jinxi Guo; Gautam Tiwari; Jasha Droppo; Maarten Van Segbroeck; Che-Wei Huang; Andreas Stolcke; Roland Maas', display:{Lore:['[{"text": "arXiv:2007.13802", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lEfficient minimum word error rate training of RNN-Transducer for end-to-end speech recognition\\u00a7r\\n\\n\\u00a78\\u00a7oJinxi Guo\\nGautam Tiwari\\nJasha Droppo\\n+ 3 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2007.13802\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 27 Jul 2020 18:33:35 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted to Interspeech 2020\\u00a7r"}']}
{title:'Weninger et al. (§72020§r)', author: 'Felix Weninger; Franco Mana; Roberto Gemello; Jesús Andrés-Ferrer; Puming Zhan', display:{Lore:['[{"text": "arXiv:2007.13876", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSemi-Supervised Learning with Data Augmentation for End-to-End ASR\\u00a7r\\n\\n\\u00a78\\u00a7oFelix Weninger\\nFranco Mana\\nRoberto Gemello\\nJes\\u00fas Andr\\u00e9s-Ferrer\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2007.13876\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 27 Jul 2020 21:24:52 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oTo appear in INTERSPEECH 2020\\u00a7r"}']}
{title:'Chen et al. (§72020§r)', author: 'Jingjing Chen; Qirong Mao; Dong Liu', display:{Lore:['[{"text": "arXiv:2007.13975", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDual-Path Transformer Network: Direct Context-Aware Modeling for End-to-End Monaural Speech Separation\\u00a7r\\n\\n\\u00a78\\u00a7oJingjing Chen\\nQirong Mao\\nDong Liu\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2007.13975\\u00a7r\\n\\nVersion:\\u00a77v3 (Fri, 14 Aug 2020 10:52:10 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages. Accepted by INTERSPEECH 2020\\u00a7r"}']}
{title:'Rozenberg et al. (§72020§r)', author: 'Shai Rozenberg; Hagai Aronowitz; Ron Hoory', display:{Lore:['[{"text": "arXiv:2007.14146", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSiamese x-vector reconstruction for domain adapted speaker recognition\\u00a7r\\n\\n\\u00a78\\u00a7oShai Rozenberg\\nHagai Aronowitz\\nRon Hoory\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2007.14146\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 28 Jul 2020 12:01:03 GMT)\\u00a7r"}']}
{title:'Halpern et al. (§72020§r)', author: 'Bence Mark Halpern; Rob van Son; Michiel van den Brekel; Odette Scharenborg', display:{Lore:['[{"text": "arXiv:2007.14205", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDetecting and analysing spontaneous oral cancer speech in the wild\\u00a7r\\n\\n\\u00a78\\u00a7oBence Mark Halpern\\nRob van Son\\nMichiel van den Brekel\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2007.14205\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 28 Jul 2020 13:38:33 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted to Interspeech 2020\\u00a7r"}']}
{title:'Yu et al. (§72020§r)', author: 'Wentao Yu; Steffen Zeiler; Dorothea Kolossa', display:{Lore:['[{"text": "arXiv:2007.14223", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMultimodal Integration for Large-Vocabulary Audio-Visual Speech Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oWentao Yu\\nSteffen Zeiler\\nDorothea Kolossa\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2007.14223\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nPublished in Proceedings of the 28th European Signal Processing\\n  Conference (EUSIPCO), 2020\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 28 Jul 2020 13:50:40 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages\\u00a7r"}']}
{title:'Agrawal et al. (§72020§r)', author: 'Ruchit Agrawal; Simon Dixon', display:{Lore:['[{"text": "arXiv:2007.14333", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Hybrid Approach to Audio-to-Score Alignment\\u00a7r\\n\\n\\u00a78\\u00a7oRuchit Agrawal\\nSimon Dixon\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2007.14333\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 28 Jul 2020 16:04:19 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oML4MD at ICML 2019\\u00a7r"}']}
{title:'Li et al. (§72020§r)', author: 'Jialu Li; Mark Hasegawa-Johnson', display:{Lore:['[{"text": "arXiv:2007.14351", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAutosegmental Neural Nets: Should Phones and Tones be Synchronous or Asynchronous?\\u00a7r\\n\\n\\u00a78\\u00a7oJialu Li\\nMark Hasegawa-Johnson\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2007.14351\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.21437/Interspeech.2020-1834\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 28 Jul 2020 16:32:09 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted to Interspeech 2020\\u00a7r"}']}
{title:'Parnami et al. (§72020§r)', author: 'Archit Parnami; Minwoo Lee', display:{Lore:['[{"text": "arXiv:2007.14463", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lFew-Shot Keyword Spotting With Prototypical Networks\\u00a7r\\n\\n\\u00a78\\u00a7oArchit Parnami\\nMinwoo Lee\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2007.14463\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1145/3529399.3529443\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7n2022 7th International Conference on Machine Learning Technologies\\n  (ICMLT), ACM, pages 277-283\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 25 Jul 2020 20:17:56 GMT)\\u00a7r"}']}
{title:'Seetharaman et al. (§72020§r)', author: 'Prem Seetharaman; Gordon Wichern; Bryan Pardo; Jonathan Le Roux', display:{Lore:['[{"text": "arXiv:2007.14469", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAutoClip: Adaptive Gradient Clipping for Source Separation Networks\\u00a7r\\n\\n\\u00a78\\u00a7oPrem Seetharaman\\nGordon Wichern\\nBryan Pardo\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2007.14469\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 25 Jul 2020 20:59:39 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted at 2020 IEEE InternationalWorkshop on Machine Learning for Signal Processing, Sept. 21\\u201324, 2020, Espoo, Finland\\u00a7r"}']}
{title:'Mittag et al. (§72020§r)', author: 'Gabriel Mittag; Ross Cutler; Yasaman Hosseinkashi; Michael Revow; Sriram Srinivasan; Naglakshmi Chande; Robert Aichner', display:{Lore:['[{"text": "arXiv:2007.14598", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDNN No-Reference PSTN Speech Quality Prediction\\u00a7r\\n\\n\\u00a78\\u00a7oGabriel Mittag\\nRoss Cutler\\nYasaman Hosseinkashi\\n+ 3 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2007.14598\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 29 Jul 2020 04:53:38 GMT)\\u00a7r"}']}
{title:'Prinz et al. (§72020§r)', author: 'Katharina Prinz; Arthur Flexer', display:{Lore:['[{"text": "arXiv:2007.14714", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lEnd-to-End Adversarial White Box Attacks on Music Instrument Classification\\u00a7r\\n\\n\\u00a78\\u00a7oKatharina Prinz\\nArthur Flexer\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2007.14714\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 29 Jul 2020 09:52:32 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o8 pages, 2 figures\\u00a7r"}']}
{title:'Zeng et al. (§72020§r)', author: 'Donghuo Zeng; Yi Yu; Keizo Oyama', display:{Lore:['[{"text": "arXiv:2007.14856", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.IR\\u00a7r, \\u00a7acs.MM\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lUnsupervised Generative Adversarial Alignment Representation for Sheet music, Audio and Lyrics\\u00a7r\\n\\n\\u00a78\\u00a7oDonghuo Zeng\\nYi Yu\\nKeizo Oyama\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2007.14856\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 29 Jul 2020 14:18:15 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 2 figures, 2 tables\\u00a7r"}']}
{title:'Zhang et al. (§72020§r)', author: 'Zhuohuang Zhang; Chengyun Deng; Yi Shen; Donald S. Williamson; Yongtao Sha; Yi Zhang; Hui Song; Xiangang Li', display:{Lore:['[{"text": "arXiv:2007.14974", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lOn Loss Functions and Recurrency Training for GAN-based Speech Enhancement Systems\\u00a7r\\n\\n\\u00a78\\u00a7oZhuohuang Zhang\\nChengyun Deng\\nYi Shen\\n+ 4 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2007.14974\\u00a7r\\n\\nVersion:\\u00a77v3 (Sat, 26 Dec 2020 21:07:03 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oaccepted by Interspeech2020, 5 pages, 2 figures\\u00a7r"}']}
{title:'Zhang et al. (§72020§r)', author: 'Zhuohuang Zhang; Donald S. Williamson; Yi Shen', display:{Lore:['[{"text": "arXiv:2007.14986", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lInvestigation of Phase Distortion on Perceived Speech Quality for Hearing-impaired Listeners\\u00a7r\\n\\n\\u00a78\\u00a7oZhuohuang Zhang\\nDonald S. Williamson\\nYi Shen\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2007.14986\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 29 Jul 2020 17:55:51 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oaccepted by Interspeech2020, 5 pages, 4 figures\\u00a7r"}']}
{title:'Aloufi et al. (§72020§r)', author: 'Ranya Aloufi; Hamed Haddadi; David Boyle', display:{Lore:['[{"text": "arXiv:2007.15064", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lPrivacy-preserving Voice Analysis via Disentangled Representations\\u00a7r\\n\\n\\u00a78\\u00a7oRanya Aloufi\\nHamed Haddadi\\nDavid Boyle\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2007.15064\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1145/3411495.3421355\\u00a7r\\n\\nVersion:\\u00a77v2 (Fri, 4 Sep 2020 15:48:35 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o14 pages, 7 figures, 2020 Cloud Computing Security Workshop (CCSW\'20) in conjunction with the ACM Conference on Computer and Communications Security (CCS)\\u00a7r"}']}
{title:'Feng (§72020§r)', author: 'Siyuan Feng', display:{Lore:['[{"text": "arXiv:2007.15074", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lExploiting Cross-Lingual Knowledge in Unsupervised Acoustic Modeling for Low-Resource Languages\\u00a7r\\n\\n\\u00a78\\u00a7oSiyuan Feng\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2007.15074\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 29 Jul 2020 19:45:17 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oPh.D. Thesis Submitted in May 2020 in partial fulfilment of the requirements for the Degree of Doctor of Philosophy in Electronic Engineering,The Chinese University of Hong Kong (CUHK) 134 pages\\u00a7r"}']}
{title:'Li et al. (§72020§r)', author: 'Jinyu Li; Rui Zhao; Zhong Meng; Yanqing Liu; Wenning Wei; Sarangarajan Parthasarathy; Vadim Mazalov; Zhenghao Wang; Lei He; Sheng Zhao; Yifan Gong', display:{Lore:['[{"text": "arXiv:2007.15188", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDeveloping RNN-T Models Surpassing High-Performance Hybrid Models with Customization Capability\\u00a7r\\n\\n\\u00a78\\u00a7oJinyu Li\\nRui Zhao\\nZhong Meng\\n+ 7 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2007.15188\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 30 Jul 2020 02:35:20 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted by Interspeech 2020\\u00a7r"}']}
{title:'Yang et al. (§72020§r)', author: 'Jinhyeok Yang; Junmo Lee; Youngik Kim; Hoonyoung Cho; Injung Kim', display:{Lore:['[{"text": "arXiv:2007.15256", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7eeess.SP\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lVocGAN: A High-Fidelity Real-time Vocoder with a Hierarchically-nested Adversarial Network\\u00a7r\\n\\n\\u00a78\\u00a7oJinhyeok Yang\\nJunmo Lee\\nYoungik Kim\\nHoonyoung Cho\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2007.15256\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 30 Jul 2020 06:33:53 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted to INTERSPEECH 2020\\u00a7r"}']}
{title:'Bae et al. (§72020§r)', author: 'Jae-Sung Bae; Hanbin Bae; Young-Sun Joo; Junmo Lee; Gyeong-Hoon Lee; Hoon-Young Cho', display:{Lore:['[{"text": "arXiv:2007.15281", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSpeaking Speed Control of End-to-End Speech Synthesis using Sentence-Level Conditioning\\u00a7r\\n\\n\\u00a78\\u00a7oJae-Sung Bae\\nHanbin Bae\\nYoung-Sun Joo\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2007.15281\\u00a7r\\n\\nVersion:\\u00a77v2 (Thu, 13 Aug 2020 06:22:13 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted to INTERSPEECH 2020\\u00a7r"}']}
{title:'Liu et al. (§72020§r)', author: 'Xuechen Liu; Md Sahidullah; Tomi Kinnunen', display:{Lore:['[{"text": "arXiv:2007.15283", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Comparative Re-Assessment of Feature Extractors for Deep Speaker Embeddings\\u00a7r\\n\\n\\u00a78\\u00a7oXuechen Liu\\nMd Sahidullah\\nTomi Kinnunen\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2007.15283\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 30 Jul 2020 07:55:58 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted to Interspeech 2020\\u00a7r"}']}
{title:'Tan et al. (§72020§r)', author: 'Hao Hao Tan; Dorien Herremans', display:{Lore:['[{"text": "arXiv:2007.15474", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMusic FaderNets: Controllable Music Generation Based On High-Level Features via Low-Level Feature Modelling\\u00a7r\\n\\n\\u00a78\\u00a7oHao Hao Tan\\nDorien Herremans\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2007.15474\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nProc. of 21st International Society of Music Information Retrieval\\n  Conference, ISMIR 2020\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 29 Jul 2020 16:01:45 GMT)\\u00a7r"}']}
{title:'Pepino et al. (§72020§r)', author: 'Leonardo Pepino; Pablo Riera; Lara Gauder; Agustín Gravano; Luciana Ferrer', display:{Lore:['[{"text": "arXiv:2007.15711", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDetecting Distrust Towards the Skills of a Virtual Assistant Using Speech\\u00a7r\\n\\n\\u00a78\\u00a7oLeonardo Pepino\\nPablo Riera\\nLara Gauder\\nAgust\\u00edn Gravano\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2007.15711\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 30 Jul 2020 19:56:17 GMT)\\u00a7r"}']}
{title:'Dong et al. (§72020§r)', author: 'Xuan Dong; Donald S. Williamson', display:{Lore:['[{"text": "arXiv:2007.15797", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.MM\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Pyramid Recurrent Network for Predicting Crowdsourced Speech-Quality Ratings of Real-World Signals\\u00a7r\\n\\n\\u00a78\\u00a7oXuan Dong\\nDonald S. Williamson\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2007.15797\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 31 Jul 2020 01:46:06 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oProceeding of INTERSPEECH\\u00a7r"}']}
{title:'Horiguchi et al. (§72020§r)', author: 'Shota Horiguchi; Yusuke Fujita; Kenji Nagamatsu', display:{Lore:['[{"text": "arXiv:2007.15868", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lUtterance-Wise Meeting Transcription System Using Asynchronous Distributed Microphones\\u00a7r\\n\\n\\u00a78\\u00a7oShota Horiguchi\\nYusuke Fujita\\nKenji Nagamatsu\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2007.15868\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 31 Jul 2020 06:50:04 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted to INTERSPEECH 2020\\u00a7r"}']}
{title:'Kumar et al. (§72020§r)', author: 'Manoj Kumar; Tae Jin-Park; Somer Bishop; Shrikanth Narayanan', display:{Lore:['[{"text": "arXiv:2007.16196", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDesigning Neural Speaker Embeddings with Meta Learning\\u00a7r\\n\\n\\u00a78\\u00a7oManoj Kumar\\nTae Jin-Park\\nSomer Bishop\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2007.16196\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 31 Jul 2020 17:47:36 GMT)\\u00a7r"}']}
{title:'Hu et al. (§72020§r)', author: 'Hu Hu; Sabato Marco Siniscalchi; Yannan Wang; Xue Bai; Jun Du; Chin-Hui Lee', display:{Lore:['[{"text": "arXiv:2008.00107", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAn Acoustic Segment Model Based Segment Unit Selection Approach to Acoustic Scene Classification with Partial Utterances\\u00a7r\\n\\n\\u00a78\\u00a7oHu Hu\\nSabato Marco Siniscalchi\\nYannan Wang\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.00107\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 31 Jul 2020 23:01:53 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted by Interspeech 2020\\u00a7r"}']}
{title:'Hu et al. (§72020§r)', author: 'Hu Hu; Sabato Marco Siniscalchi; Yannan Wang; Chin-Hui Lee', display:{Lore:['[{"text": "arXiv:2008.00110", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lRelational Teacher Student Learning with Neural Label Embedding for Device Adaptation in Acoustic Scene Classification\\u00a7r\\n\\n\\u00a78\\u00a7oHu Hu\\nSabato Marco Siniscalchi\\nYannan Wang\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.00110\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 31 Jul 2020 23:07:20 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted by Interspeech 2020\\u00a7r"}']}
{title:'Song et al. (§72020§r)', author: 'Eunwoo Song; Min-Jae Hwang; Ryuichi Yamamoto; Jin-Seob Kim; Ohsung Kwon; Jae-Min Kim', display:{Lore:['[{"text": "arXiv:2008.00132", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lNeural text-to-speech with a modeling-by-generation excitation vocoder\\u00a7r\\n\\n\\u00a78\\u00a7oEunwoo Song\\nMin-Jae Hwang\\nRyuichi Yamamoto\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.00132\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 1 Aug 2020 00:30:47 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted to the conference of INTERSPEECH 2020\\u00a7r"}']}
{title:'Alvarez et al. (§72020§r)', author: 'Aitor Arronte Alvarez; Francisco Gomez-Martin', display:{Lore:['[{"text": "arXiv:2008.00198", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSinger Identification Using Convolutional Acoustic Motif Embeddings\\u00a7r\\n\\n\\u00a78\\u00a7oAitor Arronte Alvarez\\nFrancisco Gomez-Martin\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.00198\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 1 Aug 2020 07:27:18 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages\\u00a7r"}']}
{title:'Huang et al. (§72020§r)', author: 'Jiawen Huang; Yun-Ning Hung; Ashis Pati; Siddharth Kumar Gururani; Alexander Lerch', display:{Lore:['[{"text": "arXiv:2008.00203", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.IR\\u00a7r, \\u00a7acs.LG\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lScore-informed Networks for Music Performance Assessment\\u00a7r\\n\\n\\u00a78\\u00a7oJiawen Huang\\nYun-Ning Hung\\nAshis Pati\\nSiddharth Kumar Gururani\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.00203\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 1 Aug 2020 07:46:24 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oTo appear at 21st International Society for Music Information Retrieval Conference, Montr\\u00e9al, Canada, 2020\\u00a7r"}']}
{title:'Fuketa et al. (§72020§r)', author: 'Hiroshi Fuketa; Yukinori Morita', display:{Lore:['[{"text": "arXiv:2008.00209", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lNeural ODE with Temporal Convolution and Time Delay Neural Networks for Small-Footprint Keyword Spotting\\u00a7r\\n\\n\\u00a78\\u00a7oHiroshi Fuketa\\nYukinori Morita\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.00209\\u00a7r\\n\\nVersion:\\u00a77v2 (Sun, 6 Sep 2020 12:06:36 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 5 figures\\u00a7r"}']}
{title:'Hu et al. (§72020§r)', author: 'Yanxin Hu; Yun Liu; Shubo Lv; Mengtao Xing; Shimin Zhang; Yihui Fu; Jian Wu; Bihong Zhang; Lei Xie', display:{Lore:['[{"text": "arXiv:2008.00264", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDCCRN: Deep Complex Convolution Recurrent Network for Phase-Aware Speech Enhancement\\u00a7r\\n\\n\\u00a78\\u00a7oYanxin Hu\\nYun Liu\\nShubo Lv\\n+ 5 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.00264\\u00a7r\\n\\nVersion:\\u00a77v4 (Wed, 23 Sep 2020 03:16:28 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted by Interspeech 2020\\u00a7r"}']}
{title:'Abdullah et al. (§72020§r)', author: 'Badr M. Abdullah; Tania Avgustinova; Bernd Möbius; Dietrich Klakow', display:{Lore:['[{"text": "arXiv:2008.00545", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lCross-Domain Adaptation of Spoken Language Identification for Related Languages: The Curious Case of Slavic Languages\\u00a7r\\n\\n\\u00a78\\u00a7oBadr M. Abdullah\\nTania Avgustinova\\nBernd M\\u00f6bius\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.00545\\u00a7r\\n\\nVersion:\\u00a77v2 (Fri, 7 Aug 2020 00:31:40 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oTo appear in INTERSPEECH 2020\\u00a7r"}']}
{title:'Yang et al. (§72020§r)', author: 'Fengyu Yang; Shan Yang; Qinghua Wu; Yujun Wang; Lei Xie', display:{Lore:['[{"text": "arXiv:2008.00613", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lExploiting Deep Sentential Context for Expressive End-to-End Speech Synthesis\\u00a7r\\n\\n\\u00a78\\u00a7oFengyu Yang\\nShan Yang\\nQinghua Wu\\nYujun Wang\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.00613\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 3 Aug 2020 02:22:32 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted by Interspeech2020\\u00a7r"}']}
{title:'Hung et al. (§72020§r)', author: 'Yun-Ning Hung; Alexander Lerch', display:{Lore:['[{"text": "arXiv:2008.00616", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMultitask learning for instrument activation aware music source separation\\u00a7r\\n\\n\\u00a78\\u00a7oYun-Ning Hung\\nAlexander Lerch\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.00616\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 3 Aug 2020 02:35:00 GMT)\\u00a7r"}']}
{title:'Alvarez et al. (§72020§r)', author: 'Aitor Arronte Alvarez; Elsayed Sabry Abdelaal Issa', display:{Lore:['[{"text": "arXiv:2008.00667", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lLearning Intonation Pattern Embeddings for Arabic Dialect Identification\\u00a7r\\n\\n\\u00a78\\u00a7oAitor Arronte Alvarez\\nElsayed Sabry Abdelaal Issa\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.00667\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 3 Aug 2020 06:39:16 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted for INTERSPEECH 2020\\u00a7r"}']}
{title:'Sunkara et al. (§72020§r)', author: 'Monica Sunkara; Srikanth Ronanki; Dhanush Bekal; Sravan Bodapati; Katrin Kirchhoff', display:{Lore:['[{"text": "arXiv:2008.00702", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMultimodal Semi-supervised Learning Framework for Punctuation Prediction in Conversational Speech\\u00a7r\\n\\n\\u00a78\\u00a7oMonica Sunkara\\nSrikanth Ronanki\\nDhanush Bekal\\nSravan Bodapati\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.00702\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 3 Aug 2020 08:13:09 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted for Interspeech 2020\\u00a7r"}']}
{title:'Räsänen et al. (§72020§r)', author: 'Okko Räsänen; María Andrea Cruz Blandón', display:{Lore:['[{"text": "arXiv:2008.00731", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lUnsupervised Discovery of Recurring Speech Patterns Using Probabilistic Adaptive Metrics\\u00a7r\\n\\n\\u00a78\\u00a7oOkko R\\u00e4s\\u00e4nen\\nMar\\u00eda Andrea Cruz Bland\\u00f3n\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.00731\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 3 Aug 2020 09:09:12 GMT)\\u00a7r"}']}
{title:'A. et al. (§72020§r)', author: 'Rohit M. A.; Preeti Rao', display:{Lore:['[{"text": "arXiv:2008.00756", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.IR\\u00a7r, \\u00a7acs.LG\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lStructure and Automatic Segmentation of Dhrupad Vocal Bandish Audio\\u00a7r\\n\\n\\u00a78\\u00a7oRohit M. A.\\nPreeti Rao\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.00756\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 3 Aug 2020 10:16:42 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oPart of this work published inISMIR 2020\\u00a7r"}']}
{title:'Nekvinda et al. (§72020§r)', author: 'Tomáš Nekvinda; Ondřej Dušek', display:{Lore:['[{"text": "arXiv:2008.00768", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lOne Model, Many Languages: Meta-learning for Multilingual Text-to-Speech\\u00a7r\\n\\n\\u00a78\\u00a7oTom\\u00e1\\u0161 Nekvinda\\nOnd\\u0159ej Du\\u0161ek\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.00768\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 3 Aug 2020 10:43:30 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted to INTERSPEECH 2020; for the source files, see https://github.com/Tomiinek/Multilingual_Text_to_Speech\\u00a7r"}']}
{title:'Yuan et al. (§72020§r)', author: 'Weitao Yuan; Bofei Dong; Shengbei Wang; Masashi Unoki; Wenwu Wang', display:{Lore:['[{"text": "arXiv:2008.00816", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lEvolving Multi-Resolution Pooling CNN for Monaural Singing Voice Separation\\u00a7r\\n\\n\\u00a78\\u00a7oWeitao Yuan\\nBofei Dong\\nShengbei Wang\\nMasashi Unoki\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.00816\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 3 Aug 2020 12:09:42 GMT)\\u00a7r"}']}
{title:'Csapó (§72020§r)', author: 'Tamás Gábor Csapó', display:{Lore:['[{"text": "arXiv:2008.00889", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7eeess.IV\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSpeaker dependent articulatory-to-acoustic mapping using real-time MRI of the vocal tract\\u00a7r\\n\\n\\u00a78\\u00a7oTam\\u00e1s G\\u00e1bor Csap\\u00f3\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.00889\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 3 Aug 2020 14:09:28 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, accepted for publication at Interspeech 2020\\u00a7r"}']}
{title:'Liu et al. (§72020§r)', author: 'Qi Liu; Zhehuai Chen; Hao Li; Mingkun Huang; Yizhou Lu; Kai Yu', display:{Lore:['[{"text": "arXiv:2008.00953", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lModular End-to-end Automatic Speech Recognition Framework for Acoustic-to-word Model\\u00a7r\\n\\n\\u00a78\\u00a7oQi Liu\\nZhehuai Chen\\nHao Li\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.00953\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 31 Jul 2020 08:47:10 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted by IEEE TASLP\\u00a7r"}']}
{title:'Safari et al. (§72020§r)', author: 'Pooyan Safari; Miquel India; Javier Hernando', display:{Lore:['[{"text": "arXiv:2008.01077", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSelf-attention encoding and pooling for speaker recognition\\u00a7r\\n\\n\\u00a78\\u00a7oPooyan Safari\\nMiquel India\\nJavier Hernando\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.01077\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 3 Aug 2020 09:31:27 GMT)\\u00a7r"}']}
{title:'Gritsenko et al. (§72020§r)', author: 'Alexey A. Gritsenko; Tim Salimans; Rianne van den Berg; Jasper Snoek; Nal Kalchbrenner', display:{Lore:['[{"text": "arXiv:2008.01160", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Spectral Energy Distance for Parallel Speech Synthesis\\u00a7r\\n\\n\\u00a78\\u00a7oAlexey A. Gritsenko\\nTim Salimans\\nRianne van den Berg\\nJasper Snoek\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.01160\\u00a7r\\n\\nVersion:\\u00a77v2 (Fri, 23 Oct 2020 11:44:08 GMT)\\u00a7r"}']}
{title:'Cheng et al. (§72020§r)', author: 'Mengli Cheng; Chengyu Wang; Xu Hu; Jun Huang; Xiaobo Wang', display:{Lore:['[{"text": "arXiv:2008.01300", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lWeakly Supervised Construction of ASR Systems with Massive Video Data\\u00a7r\\n\\n\\u00a78\\u00a7oMengli Cheng\\nChengyu Wang\\nXu Hu\\nJun Huang\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.01300\\u00a7r\\n\\nVersion:\\u00a77v2 (Sat, 19 Sep 2020 07:22:35 GMT)\\u00a7r"}']}
{title:'Kwon et al. (§72020§r)', author: 'Yoohwan Kwon; Soo-Whan Chung; Hong-Goo Kang', display:{Lore:['[{"text": "arXiv:2008.01348", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lIntra-class variation reduction of speaker representation in disentanglement framework\\u00a7r\\n\\n\\u00a78\\u00a7oYoohwan Kwon\\nSoo-Whan Chung\\nHong-Goo Kang\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.01348\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 4 Aug 2020 05:55:49 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted for INTERSPEECH 2020\\u00a7r"}']}
{title:'Gorin et al. (§72020§r)', author: 'Arseniy Gorin; Daniil Kulko; Steven Grima; Alex Glasman', display:{Lore:['[{"text": "arXiv:2008.01504", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7l\\"This is Houston. Say again, please\\". The Behavox system for the Apollo-11 Fearless Steps Challenge (phase II)\\u00a7r\\n\\n\\u00a78\\u00a7oArseniy Gorin\\nDaniil Kulko\\nSteven Grima\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.01504\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 4 Aug 2020 13:18:28 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted to Interspeech 2020\\u00a7r"}']}
{title:'Han et al. (§72020§r)', author: 'Hyewon Han; Soo-Whan Chung; Hong-Goo Kang', display:{Lore:['[{"text": "arXiv:2008.01698", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMIRNet: Learning multiple identities representations in overlapped speech\\u00a7r\\n\\n\\u00a78\\u00a7oHyewon Han\\nSoo-Whan Chung\\nHong-Goo Kang\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.01698\\u00a7r\\n\\nVersion:\\u00a77v2 (Thu, 6 Aug 2020 16:44:34 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted in Interspeech 2020\\u00a7r"}']}
{title:'Liu et al. (§72020§r)', author: 'Qi Liu; Yanmin Qian; Kai Yu', display:{Lore:['[{"text": "arXiv:2008.01832", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lFuture Vector Enhanced LSTM Language Model for LVCSR\\u00a7r\\n\\n\\u00a78\\u00a7oQi Liu\\nYanmin Qian\\nKai Yu\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.01832\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 31 Jul 2020 08:38:56 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted by ASRU-2017\\u00a7r"}']}
{title:'Meseguer-Brocal et al. (§72020§r)', author: 'Gabriel Meseguer-Brocal; Geoffroy Peeters', display:{Lore:['[{"text": "arXiv:2008.02070", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lContent based singing voice source separation via strong conditioning using aligned phonemes\\u00a7r\\n\\n\\u00a78\\u00a7oGabriel Meseguer-Brocal\\nGeoffroy Peeters\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.02070\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 5 Aug 2020 12:25:24 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o21st International Society for Music Information Retrieval Conference 11-15 October 2020, Montreal, Canada\\u00a7r"}']}
{title:'Csapó (§72020§r)', author: 'Tamás Gábor Csapó', display:{Lore:['[{"text": "arXiv:2008.02098", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSpeaker dependent acoustic-to-articulatory inversion using real-time MRI of the vocal tract\\u00a7r\\n\\n\\u00a78\\u00a7oTam\\u00e1s G\\u00e1bor Csap\\u00f3\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.02098\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 4 Aug 2020 04:23:03 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, accepted for publication at Interspeech 2020. arXiv admin note: substantial text overlap with arXiv:2008.00889\\u00a7r"}']}
{title:'Adya et al. (§72020§r)', author: 'Saurabh Adya; Vineet Garg; Siddharth Sigtia; Pramod Simha; Chandra Dhir', display:{Lore:['[{"text": "arXiv:2008.02323", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.HC\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lHybrid Transformer/CTC Networks for Hardware Efficient Voice Triggering\\u00a7r\\n\\n\\u00a78\\u00a7oSaurabh Adya\\nVineet Garg\\nSiddharth Sigtia\\nPramod Simha\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.02323\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 5 Aug 2020 19:16:33 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oINTERSPEECH, 2020\\u00a7r"}']}
{title:'Zhang et al. (§72020§r)', author: 'Jing-Xuan Zhang; Zhen-Hua Ling; Li-Rong Dai', display:{Lore:['[{"text": "arXiv:2008.02371", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lRecognition-Synthesis Based Non-Parallel Voice Conversion with Adversarial Learning\\u00a7r\\n\\n\\u00a78\\u00a7oJing-Xuan Zhang\\nZhen-Hua Ling\\nLi-Rong Dai\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.02371\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 5 Aug 2020 21:25:32 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted to INTERSPEECH 2020\\u00a7r"}']}
{title:'Kawahara et al. (§72020§r)', author: 'Hideki Kawahara; Ken-Ichi Sakakibara; Mitsunori Mizumachi; Masanori Morise; Hideki Banno', display:{Lore:['[{"text": "arXiv:2008.02439", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSimultaneous measurement of time-invariant linear and nonlinear, and random and extra responses using frequency domain variant of velvet noise\\u00a7r\\n\\n\\u00a78\\u00a7oHideki Kawahara\\nKen-Ichi Sakakibara\\nMitsunori Mizumachi\\nMasanori Morise\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.02439\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7n2020 Asia-Pacific Signal and Information Processing Association\\n  Annual Summit and Conference (APSIPA ASC), Auckland, New Zealand, 2020, pp.\\n  174-183\\u00a7r\\n\\nVersion:\\u00a77v2 (Sun, 9 Aug 2020 13:49:42 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o10 pages, 15 figures, APSIPA ASC 2020\\u00a7r"}']}
{title:'Csapó et al. (§72020§r)', author: 'Tamás Gábor Csapó; Kele Xu', display:{Lore:['[{"text": "arXiv:2008.02470", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lQuantification of Transducer Misalignment in Ultrasound Tongue Imaging\\u00a7r\\n\\n\\u00a78\\u00a7oTam\\u00e1s G\\u00e1bor Csap\\u00f3\\nKele Xu\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.02470\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 6 Aug 2020 06:11:17 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, accepted for publication at Interspeech 2020\\u00a7r"}']}
{title:'Chiu et al. (§72020§r)', author: 'Ching-Yu Chiu; Wen-Yi Hsiao; Yin-Cheng Yeh; Yi-Hsuan Yang; Alvin Wen-Yu Su', display:{Lore:['[{"text": "arXiv:2008.02480", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMixing-Specific Data Augmentation Techniques for Improved Blind Violin/Piano Source Separation\\u00a7r\\n\\n\\u00a78\\u00a7oChing-Yu Chiu\\nWen-Yi Hsiao\\nYin-Cheng Yeh\\nYi-Hsuan Yang\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.02480\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 6 Aug 2020 07:02:24 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted to IEEE22nd International Workshop on Multimedia Signal Processing (MMSP 2020)\\u00a7r"}']}
{title:'Prieto et al. (§72020§r)', author: 'Santi Prieto; Alfonso Ortega; Iván López-Espejo; Eduardo Lleida', display:{Lore:['[{"text": "arXiv:2008.02487", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.HC\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lShouted Speech Compensation for Speaker Verification Robust to Vocal Effort Conditions\\u00a7r\\n\\n\\u00a78\\u00a7oSanti Prieto\\nAlfonso Ortega\\nIv\\u00e1n L\\u00f3pez-Espejo\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.02487\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 6 Aug 2020 07:25:57 GMT)\\u00a7r"}']}
{title:'Cong et al. (§72020§r)', author: 'Yahuan Cong; Ran Zhang; Jian Luan', display:{Lore:['[{"text": "arXiv:2008.02490", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lPPSpeech: Phrase based Parallel End-to-End TTS System\\u00a7r\\n\\n\\u00a78\\u00a7oYahuan Cong\\nRan Zhang\\nJian Luan\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.02490\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 6 Aug 2020 07:32:34 GMT)\\u00a7r"}']}
{title:'McCarthy et al. (§72020§r)', author: 'Ollie McCarthy; Zohaib Ahmed', display:{Lore:['[{"text": "arXiv:2008.02493", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lHooliGAN: Robust, High Quality Neural Vocoding\\u00a7r\\n\\n\\u00a78\\u00a7oOllie McCarthy\\nZohaib Ahmed\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.02493\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 6 Aug 2020 07:37:32 GMT)\\u00a7r"}']}
{title:'Li et al. (§72020§r)', author: 'Xiang Li; Xin Tian; Henry Luo; Jinyu Qian; Xihong Wu; Dingsheng Luo; Jing Chen', display:{Lore:['[{"text": "arXiv:2008.02519", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSpectral-change enhancement with prior SNR for the hearing impaired\\u00a7r\\n\\n\\u00a78\\u00a7oXiang Li\\nXin Tian\\nHenry Luo\\n+ 3 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.02519\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 6 Aug 2020 08:33:37 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted by 23rd International Congress on Acoustics (ICA 2019), see http://pub.dega-akustik.de/ICA2019/data/articles/000051.pdf\\u00a7r"}']}
{title:'Gaspers et al. (§72020§r)', author: 'Judith Gaspers; Quynh Do; Fabian Triefenbach', display:{Lore:['[{"text": "arXiv:2008.02603", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lData balancing for boosting performance of low-frequency classes in Spoken Language Understanding\\u00a7r\\n\\n\\u00a78\\u00a7oJudith Gaspers\\nQuynh Do\\nFabian Triefenbach\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.02603\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 6 Aug 2020 12:23:11 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oaccepted at InterSpeech 2020\\u00a7r"}']}
{title:'Granqvist et al. (§72020§r)', author: 'Filip Granqvist; Matt Seigel; Rogier van Dalen; Áine Cahill; Stephen Shum; Matthias Paulik', display:{Lore:['[{"text": "arXiv:2008.02651", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lImproving on-device speaker verification using federated learning with privacy\\u00a7r\\n\\n\\u00a78\\u00a7oFilip Granqvist\\nMatt Seigel\\nRogier van Dalen\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.02651\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 6 Aug 2020 13:37:14 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oTo appear in proceedings of INTERSPEECH 2020\\u00a7r"}']}
{title:'Wei et al. (§72020§r)', author: 'Liangfa Wei; Jie Zhang; Junfeng Hou; Lirong Dai', display:{Lore:['[{"text": "arXiv:2008.02686", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.MM\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAttentive Fusion Enhanced Audio-Visual Encoding for Transformer Based Robust Speech Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oLiangfa Wei\\nJie Zhang\\nJunfeng Hou\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.02686\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 6 Aug 2020 14:39:07 GMT)\\u00a7r"}']}
{title:'Grósz et al. (§72020§r)', author: 'Tamás Grósz; Mittul Singh; Sudarsana Reddy Kadiri; Hemant Kathania; Mikko Kurimo', display:{Lore:['[{"text": "arXiv:2008.02689", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAalto\'s End-to-End DNN systems for the INTERSPEECH 2020 Computational Paralinguistics Challenge\\u00a7r\\n\\n\\u00a78\\u00a7oTam\\u00e1s Gr\\u00f3sz\\nMittul Singh\\nSudarsana Reddy Kadiri\\nHemant Kathania\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.02689\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 6 Aug 2020 14:45:10 GMT)\\u00a7r"}']}
{title:'Polyak et al. (§72020§r)', author: 'Adam Polyak; Lior Wolf; Yossi Adi; Yaniv Taigman', display:{Lore:['[{"text": "arXiv:2008.02830", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lUnsupervised Cross-Domain Singing Voice Conversion\\u00a7r\\n\\n\\u00a78\\u00a7oAdam Polyak\\nLior Wolf\\nYossi Adi\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.02830\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 6 Aug 2020 18:29:11 GMT)\\u00a7r"}']}
{title:'Zhou et al. (§72020§r)', author: 'Sitong Zhou; Homayoon Beigi', display:{Lore:['[{"text": "arXiv:2008.02863", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.HC\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7eeess.SP\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Transfer Learning Method for Speech Emotion Recognition from Automatic Speech Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oSitong Zhou\\nHomayoon Beigi\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.02863\\u00a7r\\n\\nVersion:\\u00a77v2 (Sat, 15 Aug 2020 18:56:24 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o4 pages, 3 tables and 1 figure\\u00a7r"}']}
{title:'Villanueva et al. (§72020§r)', author: 'Chelsea Villanueva; Joshua Vincent; Alexander Slowinski; Mohammad-Parsa Hosseini', display:{Lore:['[{"text": "arXiv:2008.02900", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lRespiratory Sound Classification Using Long-Short Term Memory\\u00a7r\\n\\n\\u00a78\\u00a7oChelsea Villanueva\\nJoshua Vincent\\nAlexander Slowinski\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.02900\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 6 Aug 2020 23:11:57 GMT)\\u00a7r"}']}
{title:'Mitsui et al. (§72020§r)', author: 'Kentaro Mitsui; Tomoki Koriyama; Hiroshi Saruwatari', display:{Lore:['[{"text": "arXiv:2008.02950", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMulti-speaker Text-to-speech Synthesis Using Deep Gaussian Processes\\u00a7r\\n\\n\\u00a78\\u00a7oKentaro Mitsui\\nTomoki Koriyama\\nHiroshi Saruwatari\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.02950\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 7 Aug 2020 02:03:27 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, accepted for INTERSPEECH 2020\\u00a7r"}']}
{title:'Zhang et al. (§72020§r)', author: 'Liqiang Zhang; Chengzhu Yu; Heng Lu; Chao Weng; Chunlei Zhang; Yusong Wu; Xiang Xie; Zijin Li; Dong Yu', display:{Lore:['[{"text": "arXiv:2008.03009", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDurIAN-SC: Duration Informed Attention Network based Singing Voice Conversion System\\u00a7r\\n\\n\\u00a78\\u00a7oLiqiang Zhang\\nChengzhu Yu\\nHeng Lu\\n+ 5 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.03009\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 7 Aug 2020 06:41:13 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted by Interspeech 2020\\u00a7r"}']}
{title:'Kang et al. (§72020§r)', author: 'Woo Hyun Kang; Sung Hwan Mun; Min Hyun Han; Nam Soo Kim', display:{Lore:['[{"text": "arXiv:2008.03024", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDisentangled speaker and nuisance attribute embedding for robust speaker verification\\u00a7r\\n\\n\\u00a78\\u00a7oWoo Hyun Kang\\nSung Hwan Mun\\nMin Hyun Han\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.03024\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/ACCESS.2020.3012893\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 7 Aug 2020 07:31:21 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted in IEEE Access\\u00a7r"}']}
{title:'Wu et al. (§72020§r)', author: 'Yusong Wu; Shengchen Li; Chengzhu Yu; Heng Lu; Chao Weng; Liqiang Zhang; Dong Yu', display:{Lore:['[{"text": "arXiv:2008.03029", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lPeking Opera Synthesis via Duration Informed Attention Network\\u00a7r\\n\\n\\u00a78\\u00a7oYusong Wu\\nShengchen Li\\nChengzhu Yu\\n+ 3 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.03029\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 7 Aug 2020 08:04:41 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted by INTERSPEECH 2020\\u00a7r"}']}
{title:'Huang et al. (§72020§r)', author: 'Wen-Chin Huang; Tomoki Hayashi; Yi-Chiao Wu; Hirokazu Kameoka; Tomoki Toda', display:{Lore:['[{"text": "arXiv:2008.03088", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lPretraining Techniques for Sequence-to-Sequence Voice Conversion\\u00a7r\\n\\n\\u00a78\\u00a7oWen-Chin Huang\\nTomoki Hayashi\\nYi-Chiao Wu\\nHirokazu Kameoka\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.03088\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 7 Aug 2020 11:02:07 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oPreprint. Under review\\u00a7r"}']}
{title:'Mohan et al. (§72020§r)', author: 'Devang S Ram Mohan; Raphael Lenain; Lorenzo Foglianti; Tian Huey Teh; Marlene Staib; Alexandra Torresquintero; Jiameng Gao', display:{Lore:['[{"text": "arXiv:2008.03096", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lIncremental Text to Speech for Neural Sequence-to-Sequence Models using Reinforcement Learning\\u00a7r\\n\\n\\u00a78\\u00a7oDevang S Ram Mohan\\nRaphael Lenain\\nLorenzo Foglianti\\n+ 3 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.03096\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.21437/Interspeech.2020-1822\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 7 Aug 2020 11:48:05 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oTo be published in Interspeech 2020. 5 pages, 4 figures\\u00a7r"}']}
{title:'Seurin et al. (§72020§r)', author: 'Mathieu Seurin; Florian Strub; Philippe Preux; Olivier Pietquin', display:{Lore:['[{"text": "arXiv:2008.03127", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Machine of Few Words \\u2013 Interactive Speaker Recognition with Reinforcement Learning\\u00a7r\\n\\n\\u00a78\\u00a7oMathieu Seurin\\nFlorian Strub\\nPhilippe Preux\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.03127\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 7 Aug 2020 12:44:08 GMT)\\u00a7r"}']}
{title:'Shi et al. (§72020§r)', author: 'Ziqiang Shi; Rujie Liu; Jiqing Han', display:{Lore:['[{"text": "arXiv:2008.03149", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSpeech Separation Based on Multi-Stage Elaborated Dual-Path Deep BiLSTM with Auxiliary Identity Loss\\u00a7r\\n\\n\\u00a78\\u00a7oZiqiang Shi\\nRujie Liu\\nJiqing Han\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.03149\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 6 Aug 2020 07:36:50 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oTo appear in Interspeech 2020. arXiv admin note: substantial text overlap with arXiv:2001.08998, arXiv:1902.04891, arXiv:1902.00651\\u00a7r"}']}
{title:'Csapó et al. (§72020§r)', author: 'Tamás Gábor Csapó; Csaba Zainkó; László Tóth; Gábor Gosztolya; Alexandra Markó', display:{Lore:['[{"text": "arXiv:2008.03152", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lUltrasound-based Articulatory-to-Acoustic Mapping with WaveGlow Speech Synthesis\\u00a7r\\n\\n\\u00a78\\u00a7oTam\\u00e1s G\\u00e1bor Csap\\u00f3\\nCsaba Zaink\\u00f3\\nL\\u00e1szl\\u00f3 T\\u00f3th\\nG\\u00e1bor Gosztolya\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.03152\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 6 Aug 2020 04:55:44 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, accepted for publication at Interspeech 2020. arXiv admin note: substantial text overlap with arXiv:1906.09885\\u00a7r"}']}
{title:'Gosztolya et al. (§72020§r)', author: 'Gábor Gosztolya; László Tóth', display:{Lore:['[{"text": "arXiv:2008.03183", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lApplying Speech Tempo-Derived Features, BoAW and Fisher Vectors to Detect Elderly Emotion and Speech in Surgical Masks\\u00a7r\\n\\n\\u00a78\\u00a7oG\\u00e1bor Gosztolya\\nL\\u00e1szl\\u00f3 T\\u00f3th\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.03183\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 7 Aug 2020 13:42:25 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7orejected from Interspeech, ComParE Challenge (Mask ElderlyEmotion Sub-Challenges)\\u00a7r"}']}
{title:'Ng et al. (§72020§r)', author: 'Si-Ioi Ng; Cymie Wing-Yee Ng; Jiarui Wang; Tan Lee; Kathy Yuet-Sheung Lee; Michael Chi-Fai Tong', display:{Lore:['[{"text": "arXiv:2008.03188", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lCUCHILD: A Large-Scale Cantonese Corpus of Child Speech for Phonology and Articulation Assessment\\u00a7r\\n\\n\\u00a78\\u00a7oSi-Ioi Ng\\nCymie Wing-Yee Ng\\nJiarui Wang\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.03188\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 7 Aug 2020 13:55:55 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted to INTERSPEECH 2020, Shanghai, China\\u00a7r"}']}
{title:'Ng et al. (§72020§r)', author: 'Si-Ioi Ng; Tan Lee', display:{Lore:['[{"text": "arXiv:2008.03193", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAutomatic Detection of Phonological Errors in Child Speech Using Siamese Recurrent Autoencoder\\u00a7r\\n\\n\\u00a78\\u00a7oSi-Ioi Ng\\nTan Lee\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.03193\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 7 Aug 2020 14:12:15 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted to INTERSPEECH 2020, Shanghai, China\\u00a7r"}']}
{title:'Purushothaman et al. (§72020§r)', author: 'Anurenjan Purushothaman; Anirudh Sreeram; Rohit Kumar; Sriram Ganapathy', display:{Lore:['[{"text": "arXiv:2008.03339", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7eeess.SP\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDeep Learning Based Dereverberation of Temporal Envelopesfor Robust Speech Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oAnurenjan Purushothaman\\nAnirudh Sreeram\\nRohit Kumar\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.03339\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 7 Aug 2020 19:05:18 GMT)\\u00a7r"}']}
{title:'Kao et al. (§72020§r)', author: 'Chieh-Chi Kao; Bowen Shi; Ming Sun; Chao Wang', display:{Lore:['[{"text": "arXiv:2008.03350", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Joint Framework for Audio Tagging and Weakly Supervised Acoustic Event Detection Using DenseNet with Global Average Pooling\\u00a7r\\n\\n\\u00a78\\u00a7oChieh-Chi Kao\\nBowen Shi\\nMing Sun\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.03350\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 7 Aug 2020 19:46:33 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted by Interspeech 2020\\u00a7r"}']}
{title:'Ai et al. (§72020§r)', author: 'Lin Ai; Shih-Ying Jeng; Homayoon Beigi', display:{Lore:['[{"text": "arXiv:2008.03359", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA New Approach to Accent Recognition and Conversion for Mandarin Chinese\\u00a7r\\n\\n\\u00a78\\u00a7oLin Ai\\nShih-Ying Jeng\\nHomayoon Beigi\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.03359\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 7 Aug 2020 20:06:33 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o11 pages, 7 figures, and 10tables\\u00a7r"}']}
{title:'Perez et al. (§72020§r)', author: 'Matthew Perez; Wenyu Jin; Duc Le; Noelle Carlozzi; Praveen Dayalu; Angela Roberts; Emily Mower Provost', display:{Lore:['[{"text": "arXiv:2008.03367", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lClassification of Huntington Disease using Acoustic and Lexical Features\\u00a7r\\n\\n\\u00a78\\u00a7oMatthew Perez\\nWenyu Jin\\nDuc Le\\n+ 3 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.03367\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.21437/Interspeech.2018-2029\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 7 Aug 2020 20:32:01 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o4 pages\\u00a7r"}']}
{title:'Morrison et al. (§72020§r)', author: 'Max Morrison; Zeyu Jin; Justin Salamon; Nicholas J. Bryan; Gautham J. Mysore', display:{Lore:['[{"text": "arXiv:2008.03388", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lControllable Neural Prosody Synthesis\\u00a7r\\n\\n\\u00a78\\u00a7oMax Morrison\\nZeyu Jin\\nJustin Salamon\\nNicholas J. Bryan\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.03388\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 11 Aug 2020 19:34:47 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oTo appear in proceedings of INTERSPEECH 2020\\u00a7r"}']}
{title:'Ali et al. (§72020§r)', author: 'Ahmed Ali; Steve Renals', display:{Lore:['[{"text": "arXiv:2008.03403", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lWord Error Rate Estimation Without ASR Output: e-WER2\\u00a7r\\n\\n\\u00a78\\u00a7oAhmed Ali\\nSteve Renals\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.03403\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 8 Aug 2020 00:19:09 GMT)\\u00a7r"}']}
{title:'Higuchi et al. (§72020§r)', author: 'Takuya Higuchi; Mohammad Ghasemzadeh; Kisun You; Chandra Dhir', display:{Lore:['[{"text": "arXiv:2008.03405", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lStacked 1D convolutional networks for end-to-end small footprint voice trigger detection\\u00a7r\\n\\n\\u00a78\\u00a7oTakuya Higuchi\\nMohammad Ghasemzadeh\\nKisun You\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.03405\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 8 Aug 2020 00:32:55 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted to INTERSPEECH 2020\\u00a7r"}']}
{title:'Sarı et al. (§72020§r)', author: 'Leda Sarı; Mark Hasegawa-Johnson', display:{Lore:['[{"text": "arXiv:2008.03425", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDeep F-measure Maximization for End-to-End Speech Understanding\\u00a7r\\n\\n\\u00a78\\u00a7oLeda Sar\\u0131\\nMark Hasegawa-Johnson\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.03425\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 8 Aug 2020 03:02:27 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oInterspeech 2020 submission (Accepted)\\u00a7r"}']}
{title:'P et al. (§72020§r)', author: 'Rahul T P; P R Aravind; Ranjith C; Usamath Nechiyil; Nandakumar Paramparambath', display:{Lore:['[{"text": "arXiv:2008.03464", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAudio Spoofing Verification using Deep Convolutional Neural Networks by Transfer Learning\\u00a7r\\n\\n\\u00a78\\u00a7oRahul T P\\nP R Aravind\\nRanjith C\\nUsamath Nechiyil\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.03464\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 8 Aug 2020 07:14:40 GMT)\\u00a7r"}']}
{title:'Chowdhury et al. (§72020§r)', author: 'Anurag Chowdhury; Austin Cozzo; Arun Ross', display:{Lore:['[{"text": "arXiv:2008.03507", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lJukeBox: A Multilingual Singer Recognition Dataset\\u00a7r\\n\\n\\u00a78\\u00a7oAnurag Chowdhury\\nAustin Cozzo\\nArun Ross\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.03507\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 8 Aug 2020 12:22:51 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oINTERSPEECH 2020 (To Appear)\\u00a7r"}']}
{title:'Chetupalli et al. (§72020§r)', author: 'Srikanth Raj Chetupalli; Sriram Ganapathy', display:{Lore:['[{"text": "arXiv:2008.03517", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lContext Dependent RNNLM for Automatic Transcription of Conversations\\u00a7r\\n\\n\\u00a78\\u00a7oSrikanth Raj Chetupalli\\nSriram Ganapathy\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.03517\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 8 Aug 2020 13:14:45 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oManuscript accepted for publication at INTERSPEECH 2020, Oct 25-29, Shanghai, China\\u00a7r"}']}
{title:'Zhang et al. (§72020§r)', author: 'Li Zhang; Jian Wu; Lei Xie', display:{Lore:['[{"text": "arXiv:2008.03521", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lNPU Speaker Verification System for INTERSPEECH 2020 Far-Field Speaker Verification Challenge\\u00a7r\\n\\n\\u00a78\\u00a7oLi Zhang\\nJian Wu\\nLei Xie\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.03521\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 8 Aug 2020 13:32:48 GMT)\\u00a7r"}']}
{title:'Sholokhov et al. (§72020§r)', author: 'Alexey Sholokhov; Tomi Kinnunen; Ville Vestman; Kong Aik Lee', display:{Lore:['[{"text": "arXiv:2008.03590", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lExtrapolating false alarm rates in automatic speaker verification\\u00a7r\\n\\n\\u00a78\\u00a7oAlexey Sholokhov\\nTomi Kinnunen\\nVille Vestman\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.03590\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 8 Aug 2020 20:31:57 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted for publication to Interspeech 2020\\u00a7r"}']}
{title:'Ravi et al. (§72020§r)', author: 'Vijay Ravi; Ruchao Fan; Amber Afshan; Huanhua Lu; Abeer Alwan', display:{Lore:['[{"text": "arXiv:2008.03615", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lExploring the Use of an Unsupervised Autoregressive Model as a Shared Encoder for Text-Dependent Speaker Verification\\u00a7r\\n\\n\\u00a78\\u00a7oVijay Ravi\\nRuchao Fan\\nAmber Afshan\\nHuanhua Lu\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.03615\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 8 Aug 2020 22:47:10 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted to Interspeech 2020\\u00a7r"}']}
{title:'Afshan et al. (§72020§r)', author: 'Amber Afshan; Jinxi Guo; Soo Jin Park; Vijay Ravi; Alan McCree; Abeer Alwan', display:{Lore:['[{"text": "arXiv:2008.03616", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.SP\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lVariable frame rate-based data augmentation to handle speaking-style variability for automatic speaker verification\\u00a7r\\n\\n\\u00a78\\u00a7oAmber Afshan\\nJinxi Guo\\nSoo Jin Park\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.03616\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 8 Aug 2020 22:47:12 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted to Interspeech 2020\\u00a7r"}']}
{title:'Afshan et al. (§72020§r)', author: 'Amber Afshan; Jody Kreiman; Abeer Alwan', display:{Lore:['[{"text": "arXiv:2008.03617", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.SP\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSpeaker discrimination in humans and machines: Effects of speaking style variability\\u00a7r\\n\\n\\u00a78\\u00a7oAmber Afshan\\nJody Kreiman\\nAbeer Alwan\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.03617\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 8 Aug 2020 22:59:46 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted to Interspeech 2020\\u00a7r"}']}
{title:'Sisman et al. (§72020§r)', author: 'Berrak Sisman; Junichi Yamagishi; Simon King; Haizhou Li', display:{Lore:['[{"text": "arXiv:2008.03648", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAn Overview of Voice Conversion and its Challenges: From Statistical Modeling to Deep Learning\\u00a7r\\n\\n\\u00a78\\u00a7oBerrak Sisman\\nJunichi Yamagishi\\nSimon King\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.03648\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 17 Nov 2020 04:42:31 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oaccepted by IEEE/ACM Transactionson Audio, Speech and Language Processing\\u00a7r"}']}
{title:'Xu et al. (§72020§r)', author: 'Jin Xu; Xu Tan; Yi Ren; Tao Qin; Jian Li; Sheng Zhao; Tie-Yan Liu', display:{Lore:['[{"text": "arXiv:2008.03687", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lLRSpeech: Extremely Low-Resource Speech Synthesis and Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oJin Xu\\nXu Tan\\nYi Ren\\n+ 3 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.03687\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nKDD 2020\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 9 Aug 2020 08:16:33 GMT)\\u00a7r"}']}
{title:'Choi et al. (§72020§r)', author: 'Yeunju Choi; Youngmoon Jung; Hoirin Kim', display:{Lore:['[{"text": "arXiv:2008.03710", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7eeess.SP\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDeep MOS Predictor for Synthetic Speech Using Cluster-Based Modeling\\u00a7r\\n\\n\\u00a78\\u00a7oYeunju Choi\\nYoungmoon Jung\\nHoirin Kim\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.03710\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.21437/Interspeech.2020-2111\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nProc. Interspeech 2020, pp. 1743-1747\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 9 Aug 2020 11:14:19 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 1 figure, accepted to Interspeech 2020\\u00a7r"}']}
{title:'Lee et al. (§72020§r)', author: 'Jongpil Lee; Nicholas J. Bryan; Justin Salamon; Zeyu Jin; Juhan Nam', display:{Lore:['[{"text": "arXiv:2008.03720", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDisentangled Multidimensional Metric Learning for Music Similarity\\u00a7r\\n\\n\\u00a78\\u00a7oJongpil Lee\\nNicholas J. Bryan\\nJustin Salamon\\nZeyu Jin\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.03720\\u00a7r\\n\\nVersion:\\u00a77v2 (Wed, 12 Aug 2020 21:54:00 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted for publication at the 45th International Conference on Acoustics, Speech, and Signal Processing (ICASSP 2020)\\u00a7r"}']}
{title:'Kreyssig et al. (§72020§r)', author: 'Florian L. Kreyssig; Philip C. Woodland', display:{Lore:['[{"text": "arXiv:2008.03756", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lCosine-Distance Virtual Adversarial Training for Semi-Supervised Speaker-Discriminative Acoustic Embeddings\\u00a7r\\n\\n\\u00a78\\u00a7oFlorian L. Kreyssig\\nPhilip C. Woodland\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.03756\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 9 Aug 2020 16:09:05 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted to Interspeech 2020\\u00a7r"}']}
{title:'Jose et al. (§72020§r)', author: 'Christin Jose; Yuriy Mishchenko; Thibaud Senechal; Anish Shah; Alex Escott; Shiv Vitaladevuni', display:{Lore:['[{"text": "arXiv:2008.03790", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAccurate Detection of Wake Word Start and End Using a CNN\\u00a7r\\n\\n\\u00a78\\u00a7oChristin Jose\\nYuriy Mishchenko\\nThibaud Senechal\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.03790\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.21437/Interspeech.2020-1491\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nInterspeech 2020\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 9 Aug 2020 19:02:41 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oProceedings of INTERSPEECH\\u00a7r"}']}
{title:'Vainer et al. (§72020§r)', author: 'Jan Vainer; Ondřej Dušek', display:{Lore:['[{"text": "arXiv:2008.03802", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSpeedySpeech: Efficient Neural Speech Synthesis\\u00a7r\\n\\n\\u00a78\\u00a7oJan Vainer\\nOnd\\u0159ej Du\\u0161ek\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.03802\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 9 Aug 2020 20:00:57 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 3 figures, Interspeech 2020\\u00a7r"}']}
{title:'Tao et al. (§72020§r)', author: 'Ruijie Tao; Rohan Kumar Das; Haizhou Li', display:{Lore:['[{"text": "arXiv:2008.03894", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAudio-visual Speaker Recognition with a Cross-modal Discriminative Network\\u00a7r\\n\\n\\u00a78\\u00a7oRuijie Tao\\nRohan Kumar Das\\nHaizhou Li\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.03894\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 10 Aug 2020 04:16:20 GMT)\\u00a7r"}']}
{title:'Fan et al. (§72020§r)', author: 'Wenzhi Fan; Jing Lu', display:{Lore:['[{"text": "arXiv:2008.03944", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7eeess.SP\\u00a7r\\u00a7r\\n\\u00a76\\u00a7limproving partition-block-based acoustic echo canceler in under-modeling scenarios\\u00a7r\\n\\n\\u00a78\\u00a7oWenzhi Fan\\nJing Lu\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.03944\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 10 Aug 2020 08:11:03 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oaccepted by interspeech2020\\u00a7r"}']}
{title:'Singh et al. (§72020§r)', author: 'Prachi Singh; Sriram Ganapathy', display:{Lore:['[{"text": "arXiv:2008.03960", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDeep Self-Supervised Hierarchical Clustering for Speaker Diarization\\u00a7r\\n\\n\\u00a78\\u00a7oPrachi Singh\\nSriram Ganapathy\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.03960\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.21437/Interspeech.2020-2297\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nProc. Interspeech 2020\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 10 Aug 2020 08:32:35 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, Accepted in Interspeech 2020\\u00a7r"}']}
{title:'Lu et al. (§72020§r)', author: 'Junchen Lu; Kun Zhou; Berrak Sisman; Haizhou Li', display:{Lore:['[{"text": "arXiv:2008.03992", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lVAW-GAN for Singing Voice Conversion with Non-parallel Training Data\\u00a7r\\n\\n\\u00a78\\u00a7oJunchen Lu\\nKun Zhou\\nBerrak Sisman\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.03992\\u00a7r\\n\\nVersion:\\u00a77v3 (Tue, 3 Nov 2020 10:58:10 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted to APSIPA ASC 2020\\u00a7r"}']}
{title:'Lakomkin et al. (§72020§r)', author: 'Egor Lakomkin; Jahn Heymann; Ilya Sklyar; Simon Wiesler', display:{Lore:['[{"text": "arXiv:2008.04034", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSubword Regularization: An Analysis of Scalability and Generalization for End-to-End Automatic Speech Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oEgor Lakomkin\\nJahn Heymann\\nIlya Sklyar\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.04034\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 10 Aug 2020 11:42:43 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted at Interspeech 2020\\u00a7r"}']}
{title:'Staib et al. (§72020§r)', author: 'Marlene Staib; Tian Huey Teh; Alexandra Torresquintero; Devang S Ram Mohan; Lorenzo Foglianti; Raphael Lenain; Jiameng Gao', display:{Lore:['[{"text": "arXiv:2008.04107", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lPhonological Features for 0-shot Multilingual Speech Synthesis\\u00a7r\\n\\n\\u00a78\\u00a7oMarlene Staib\\nTian Huey Teh\\nAlexandra Torresquintero\\n+ 3 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.04107\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.21437/Interspeech.2020-1821\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 6 Aug 2020 18:25:18 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, to be presented at INTERSPEECH 2020\\u00a7r"}']}
{title:'Wong et al. (§72020§r)', author: 'Alexander Wong; Mahmoud Famouri; Maya Pavlova; Siddharth Surana', display:{Lore:['[{"text": "arXiv:2008.04245", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.NE\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lTinySpeech: Attention Condensers for Deep Speech Recognition Neural Networks on Edge Devices\\u00a7r\\n\\n\\u00a78\\u00a7oAlexander Wong\\nMahmoud Famouri\\nMaya Pavlova\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.04245\\u00a7r\\n\\nVersion:\\u00a77v6 (Mon, 12 Oct 2020 19:07:39 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o10 pages\\u00a7r"}']}
{title:'Valin et al. (§72020§r)', author: 'Jean-Marc Valin; Umut Isik; Neerad Phansalkar; Ritwik Giri; Karim Helwani; Arvindh Krishnaswamy', display:{Lore:['[{"text": "arXiv:2008.04259", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Perceptually-Motivated Approach for Low-Complexity, Real-Time Enhancement of Fullband Speech\\u00a7r\\n\\n\\u00a78\\u00a7oJean-Marc Valin\\nUmut Isik\\nNeerad Phansalkar\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.04259\\u00a7r\\n\\nVersion:\\u00a77v2 (Thu, 27 Aug 2020 05:55:33 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oProc. INTERSPEECH 2020, 5 pages\\u00a7r"}']}
{title:'Cong et al. (§72020§r)', author: 'Jian Cong; Shan Yang; Lei Xie; Guoqiao Yu; Guanglu Wan', display:{Lore:['[{"text": "arXiv:2008.04265", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lData Efficient Voice Cloning from Noisy Samples with Domain Adversarial Training\\u00a7r\\n\\n\\u00a78\\u00a7oJian Cong\\nShan Yang\\nLei Xie\\nGuoqiao Yu\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.04265\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 11 Aug 2020 03:54:57 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted to INTERSPEECH 2020\\u00a7r"}']}
{title:'Isik et al. (§72020§r)', author: 'Umut Isik; Ritwik Giri; Neerad Phansalkar; Jean-Marc Valin; Karim Helwani; Arvindh Krishnaswamy', display:{Lore:['[{"text": "arXiv:2008.04470", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.NE\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lPoCoNet: Better Speech Enhancement with Frequency-Positional Embeddings, Semi-Supervised Conversational Data, and Biased Loss\\u00a7r\\n\\n\\u00a78\\u00a7oUmut Isik\\nRitwik Giri\\nNeerad Phansalkar\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.04470\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 11 Aug 2020 01:24:45 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 3 figures, INTERSPEECH 2020\\u00a7r"}']}
{title:'Chen et al. (§72020§r)', author: 'Xi Chen; Songyang Zhang; Dandan Song; Peng Ouyang; Shouyi Yin', display:{Lore:['[{"text": "arXiv:2008.04481", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lTransformer with Bidirectional Decoder for Speech Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oXi Chen\\nSongyang Zhang\\nDandan Song\\nPeng Ouyang\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.04481\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 11 Aug 2020 02:12:42 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted by InterSpeech 2020\\u00a7r"}']}
{title:'Jeon et al. (§72020§r)', author: 'Chang-Bin Jeon; Hyeong-Seok Choi; Kyogu Lee', display:{Lore:['[{"text": "arXiv:2008.04482", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lExploring Aligned Lyrics-Informed Singing Voice Separation\\u00a7r\\n\\n\\u00a78\\u00a7oChang-Bin Jeon\\nHyeong-Seok Choi\\nKyogu Lee\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.04482\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 11 Aug 2020 02:16:12 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o8 pages (2 for references), 7 figures,5 tables, Appearing in the proceedings of the 21st International Society for Music Information Retrieval Conference (ISMIR 2020) (camera-ready version)\\u00a7r"}']}
{title:'Corey et al. (§72020§r)', author: 'Ryan M. Corey; Uriah Jones; Andrew C. Singer', display:{Lore:['[{"text": "arXiv:2008.04521", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAcoustic effects of medical, cloth, and transparent face masks on speech signals\\u00a7r\\n\\n\\u00a78\\u00a7oRyan M. Corey\\nUriah Jones\\nAndrew C. Singer\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.04521\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1121/10.0002279\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nThe Journal of the Acoustical Society of America, 148(4), pp.\\n  2371-2375, Oct. 2020\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 11 Aug 2020 05:33:42 GMT)\\u00a7r"}']}
{title:'Ramoji et al. (§72020§r)', author: 'Shreyas Ramoji; Prashant Krishnan; Sriram Ganapathy', display:{Lore:['[{"text": "arXiv:2008.04527", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lNeural PLDA Modeling for End-to-End Speaker Verification\\u00a7r\\n\\n\\u00a78\\u00a7oShreyas Ramoji\\nPrashant Krishnan\\nSriram Ganapathy\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.04527\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 11 Aug 2020 05:54:54 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted in Interspeech 2020. GitHub Implementation Repos: https://github.com/iiscleap/E2E-NPLDAand https://github.com/iiscleap/NeuralPlda\\u00a7r"}']}
{title:'Kanda et al. (§72020§r)', author: 'Naoyuki Kanda; Xuankai Chang; Yashesh Gaur; Xiaofei Wang; Zhong Meng; Zhuo Chen; Takuya Yoshioka', display:{Lore:['[{"text": "arXiv:2008.04546", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lInvestigation of End-To-End Speaker-Attributed ASR for Continuous Multi-Talker Recordings\\u00a7r\\n\\n\\u00a78\\u00a7oNaoyuki Kanda\\nXuankai Chang\\nYashesh Gaur\\n+ 3 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.04546\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 11 Aug 2020 06:41:55 GMT)\\u00a7r"}']}
{title:'Zhang et al. (§72020§r)', author: 'Haitong Zhang; Yue Lin', display:{Lore:['[{"text": "arXiv:2008.04549", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lUnsupervised Learning For Sequence-to-sequence Text-to-speech For Low-resource Languages\\u00a7r\\n\\n\\u00a78\\u00a7oHaitong Zhang\\nYue Lin\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.04549\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 11 Aug 2020 06:48:36 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted to the conference of INTERSPEECH 2020\\u00a7r"}']}
{title:'Du et al. (§72020§r)', author: 'Zongyang Du; Kun Zhou; Berrak Sisman; Haizhou Li', display:{Lore:['[{"text": "arXiv:2008.04562", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSpectrum and Prosody Conversion for Cross-lingual Voice Conversion with CycleGAN\\u00a7r\\n\\n\\u00a78\\u00a7oZongyang Du\\nKun Zhou\\nBerrak Sisman\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.04562\\u00a7r\\n\\nVersion:\\u00a77v3 (Tue, 3 Nov 2020 16:34:35 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted to APSIPA ASC 2020\\u00a7r"}']}
{title:'Vipperla et al. (§72020§r)', author: 'Ravichander Vipperla; Sangjun Park; Kihyun Choo; Samin Ishtiaq; Kyoungbo Min; Sourav Bhattacharya; Abhinav Mehrotra; Alberto Gil C. P. Ramos; Nicholas D. Lane', display:{Lore:['[{"text": "arXiv:2008.04574", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lBunched LPCNet : Vocoder for Low-cost Neural Text-To-Speech Systems\\u00a7r\\n\\n\\u00a78\\u00a7oRavichander Vipperla\\nSangjun Park\\nKihyun Choo\\n+ 5 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.04574\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 11 Aug 2020 08:15:45 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oInterspeech 2020\\u00a7r"}']}
{title:'Hautamäki et al. (§72020§r)', author: 'Rosa González Hautamäki; Tomi Kinnunen', display:{Lore:['[{"text": "arXiv:2008.04578", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CY\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lWhy Did the x-Vector System Miss a Target Speaker? Impact of Acoustic Mismatch Upon Target Score on VoxCeleb Data\\u00a7r\\n\\n\\u00a78\\u00a7oRosa Gonz\\u00e1lez Hautam\\u00e4ki\\nTomi Kinnunen\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.04578\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 11 Aug 2020 08:33:20 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted to INTERSPEECH 2020\\u00a7r"}']}
{title:'Illium et al. (§72020§r)', author: 'Steffen Illium; Robert Müller; Andreas Sedlmeier; Claudia Linnhoff-Popien', display:{Lore:['[{"text": "arXiv:2008.04590", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CV\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSurgical Mask Detection with Convolutional Neural Networks and Data Augmentations on Spectrograms\\u00a7r\\n\\n\\u00a78\\u00a7oSteffen Illium\\nRobert M\\u00fcller\\nAndreas Sedlmeier\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.04590\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 11 Aug 2020 09:02:47 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 2 figures, 2 tables\\u00a7r"}']}
{title:'Campbell et al. (§72020§r)', author: 'Edward L. Campbell; Laura Docío-Fernández; Javier Jiménez Raboso; Carmen García-Mateo', display:{Lore:['[{"text": "arXiv:2008.04617", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAlzheimer\'s Dementia Detection from Audio and Text Modalities\\u00a7r\\n\\n\\u00a78\\u00a7oEdward L. Campbell\\nLaura Doc\\u00edo-Fern\\u00e1ndez\\nJavier Jim\\u00e9nez Raboso\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.04617\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 11 Aug 2020 10:34:22 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 2 figures\\u00a7r"}']}
{title:'Hou et al. (§72020§r)', author: 'Yuanbo Hou; Frank K. Soong; Jian Luan; Shengchen Li', display:{Lore:['[{"text": "arXiv:2008.04658", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lTransfer Learning for Improving Singing-voice Detection in Polyphonic Instrumental Music\\u00a7r\\n\\n\\u00a78\\u00a7oYuanbo Hou\\nFrank K. Soong\\nJian Luan\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.04658\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 11 Aug 2020 12:22:17 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted by INTERSPEECH 2020\\u00a7r"}']}
{title:'Georges et al. (§72020§r)', author: 'Munir Georges; Jonathan Huang; Tobias Bocklet', display:{Lore:['[{"text": "arXiv:2008.05011", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lCompact Speaker Embedding: lrx-vector\\u00a7r\\n\\n\\u00a78\\u00a7oMunir Georges\\nJonathan Huang\\nTobias Bocklet\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.05011\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nProc. Interspeech 2020\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 11 Aug 2020 21:32:16 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted to INTERSPEECH 2020\\u00a7r"}']}
{title:'Joshi et al. (§72020§r)', author: 'Vikas Joshi; Rui Zhao; Rupesh R. Mehta; Kshitiz Kumar; Jinyu Li', display:{Lore:['[{"text": "arXiv:2008.05086", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lTransfer Learning Approaches for Streaming End-to-End Speech Recognition System\\u00a7r\\n\\n\\u00a78\\u00a7oVikas Joshi\\nRui Zhao\\nRupesh R. Mehta\\nKshitiz Kumar\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.05086\\u00a7r\\n\\nVersion:\\u00a77v2 (Mon, 17 Aug 2020 14:27:06 GMT)\\u00a7r"}']}
{title:'Wu et al. (§72020§r)', author: 'Haiwei Wu; Lin Zhang; Lin Yang; Xuyang Wang; Junjie Wang; Dong Zhang; Ming Li', display:{Lore:['[{"text": "arXiv:2008.05175", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMask Detection and Breath Monitoring from Speech: on Data Augmentation, Feature Representation and Modeling\\u00a7r\\n\\n\\u00a78\\u00a7oHaiwei Wu\\nLin Zhang\\nLin Yang\\n+ 3 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.05175\\u00a7r\\n\\nVersion:\\u00a77v2 (Fri, 14 Aug 2020 08:44:19 GMT)\\u00a7r"}']}
{title:'Liu et al. (§72020§r)', author: 'Haohe Liu; Lei Xie; Jian Wu; Geng Yang', display:{Lore:['[{"text": "arXiv:2008.05216", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lChannel-wise Subband Input for Better Voice and Accompaniment Separation on High Resolution Music\\u00a7r\\n\\n\\u00a78\\u00a7oHaohe Liu\\nLei Xie\\nJian Wu\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.05216\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.21437/Interspeech.2020-2555\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nProc. Interspeech 2020\\u00a7r\\n\\nVersion:\\u00a77v2 (Thu, 13 Aug 2020 02:08:35 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted in INTERSPEECH 2020\\u00a7r"}']}
{title:'Mao et al. (§72020§r)', author: 'Shuiyang Mao; P. C. Ching; Tan Lee', display:{Lore:['[{"text": "arXiv:2008.05259", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lEmotion Profile Refinery for Speech Emotion Classification\\u00a7r\\n\\n\\u00a78\\u00a7oShuiyang Mao\\nP. C. Ching\\nTan Lee\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.05259\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 12 Aug 2020 12:09:58 GMT)\\u00a7r"}']}
{title:'Liu et al. (§72020§r)', author: 'Rui Liu; Berrak Sisman; Feilong Bao; Guanglai Gao; Haizhou Li', display:{Lore:['[{"text": "arXiv:2008.05284", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lModeling Prosodic Phrasing with Multi-Task Learning in Tacotron-based TTS\\u00a7r\\n\\n\\u00a78\\u00a7oRui Liu\\nBerrak Sisman\\nFeilong Bao\\nGuanglai Gao\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.05284\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/LSP.2020.3016564\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 11 Aug 2020 07:57:29 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oTo appear in IEEE Signal Processing Letters (SPL)\\u00a7r"}']}
{title:'Paul et al. (§72020§r)', author: 'Dipjyoti Paul; Yannis Pantazis; Yannis Stylianou', display:{Lore:['[{"text": "arXiv:2008.05289", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSpeaker Conditional WaveRNN: Towards Universal Neural Vocoder for Unseen Speaker and Recording Conditions\\u00a7r\\n\\n\\u00a78\\u00a7oDipjyoti Paul\\nYannis Pantazis\\nYannis Stylianou\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.05289\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 9 Aug 2020 13:54:46 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted in INTERSPEECH 2020\\u00a7r"}']}
{title:'Hsiao et al. (§72020§r)', author: 'Roger Hsiao; Dogan Can; Tim Ng; Ruchir Travadi; Arnab Ghoshal', display:{Lore:['[{"text": "arXiv:2008.05514", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lOnline Automatic Speech Recognition with Listen, Attend and Spell Model\\u00a7r\\n\\n\\u00a78\\u00a7oRoger Hsiao\\nDogan Can\\nTim Ng\\nRuchir Travadi\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.05514\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/LSP.2020.3031480\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 13 Oct 2020 18:40:28 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 4 figures, this version is submitted to IEEE Signal Processing Letters\\u00a7r"}']}
{title:'Zheng et al. (§72020§r)', author: 'Zhenpeng Zheng; Jianzong Wang; Ning Cheng; Jian Luo; Jing Xiao', display:{Lore:['[{"text": "arXiv:2008.05650", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMLNET: An Adaptive Multiple Receptive-field Attention Neural Network for Voice Activity Detection\\u00a7r\\n\\n\\u00a78\\u00a7oZhenpeng Zheng\\nJianzong Wang\\nNing Cheng\\nJian Luo\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.05650\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 13 Aug 2020 02:24:28 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7owill be presented in INTERSPEECH 2020\\u00a7r"}']}
{title:'Zeng et al. (§72020§r)', author: 'Zhen Zeng; Jianzong Wang; Ning Cheng; Jing Xiao', display:{Lore:['[{"text": "arXiv:2008.05656", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lProsody Learning Mechanism for Speech Synthesis System Without Text Length Limit\\u00a7r\\n\\n\\u00a78\\u00a7oZhen Zeng\\nJianzong Wang\\nNing Cheng\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.05656\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 13 Aug 2020 02:54:50 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7owill be presented in INTERSPEECH 2020\\u00a7r"}']}
{title:'Jia et al. (§72020§r)', author: 'Xueli Jia; Jianzong Wang; Zhiyong Zhang; Ning Cheng; Jing Xiao', display:{Lore:['[{"text": "arXiv:2008.05671", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lLarge-scale Transfer Learning for Low-resource Spoken Language Understanding\\u00a7r\\n\\n\\u00a78\\u00a7oXueli Jia\\nJianzong Wang\\nZhiyong Zhang\\nNing Cheng\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.05671\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 13 Aug 2020 03:43:05 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7owill be presented in INTERSPEECH 2020\\u00a7r"}']}
{title:'Qu et al. (§72020§r)', author: 'Xiaoyang Qu; Jianzong Wang; Jing Xiao', display:{Lore:['[{"text": "arXiv:2008.05695", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.NE\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lEvolutionary Algorithm Enhanced Neural Architecture Search for Text-Independent Speaker Verification\\u00a7r\\n\\n\\u00a78\\u00a7oXiaoyang Qu\\nJianzong Wang\\nJing Xiao\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.05695\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 13 Aug 2020 05:34:52 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7owill be presented in INTERSPEECH 2020\\u00a7r"}']}
{title:'Huang et al. (§72020§r)', author: 'Wenyong Huang; Wenchao Hu; Yu Ting Yeung; Xiao Chen', display:{Lore:['[{"text": "arXiv:2008.05750", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lConv-Transformer Transducer: Low Latency, Low Frame Rate, Streamable End-to-End Speech Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oWenyong Huang\\nWenchao Hu\\nYu Ting Yeung\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.05750\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 13 Aug 2020 08:20:02 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted by INTERSPEECH 2020\\u00a7r"}']}
{title:'Chen et al. (§72020§r)', author: 'Sanyuan Chen; Yu Wu; Zhuo Chen; Jian Wu; Jinyu Li; Takuya Yoshioka; Chengyi Wang; Shujie Liu; Ming Zhou', display:{Lore:['[{"text": "arXiv:2008.05773", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lContinuous Speech Separation with Conformer\\u00a7r\\n\\n\\u00a78\\u00a7oSanyuan Chen\\nYu Wu\\nZhuo Chen\\n+ 5 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.05773\\u00a7r\\n\\nVersion:\\u00a77v2 (Thu, 22 Oct 2020 12:38:51 GMT)\\u00a7r"}']}
{title:'Antipov et al. (§72020§r)', author: 'Grigory Antipov; Nicolas Gengembre; Olivier Le Blouch; Gaël Le Lan', display:{Lore:['[{"text": "arXiv:2008.05889", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.MM\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAutomatic Quality Assessment for Audio-Visual Verification Systems. The LOVe submission to NIST SRE Challenge 2019\\u00a7r\\n\\n\\u00a78\\u00a7oGrigory Antipov\\nNicolas Gengembre\\nOlivier Le Blouch\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.05889\\u00a7r\\n\\nVersion:\\u00a77v2 (Fri, 14 Aug 2020 07:33:03 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 1 figure, accepted at INTERSPEECH 2020. Corrected the reference [20]\\u00a7r"}']}
{title:'Kye et al. (§72020§r)', author: 'Seong Min Kye; Yoohwan Kwon; Joon Son Chung', display:{Lore:['[{"text": "arXiv:2008.05983", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lCross attentive pooling for speaker verification\\u00a7r\\n\\n\\u00a78\\u00a7oSeong Min Kye\\nYoohwan Kwon\\nJoon Son Chung\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.05983\\u00a7r\\n\\nVersion:\\u00a77v2 (Thu, 3 Dec 2020 14:16:59 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSLT 2021. Code available at https://github.com/seongmin-kye/CAP\\u00a7r"}']}
{title:'Datta et al. (§72020§r)', author: 'Arindrima Datta; Guanlong Zhao; Bhuvana Ramabhadran; Eugene Weinstein', display:{Lore:['[{"text": "arXiv:2008.06121", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lLSTM Acoustic Models Learn to Align and Pronounce with Graphemes\\u00a7r\\n\\n\\u00a78\\u00a7oArindrima Datta\\nGuanlong Zhao\\nBhuvana Ramabhadran\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.06121\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 13 Aug 2020 21:38:36 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 4 figures. This work was done between summer 2018 and spring 2019\\u00a7r"}']}
{title:'Park et al. (§72020§r)', author: 'Hyeonmook Park; Jungbae Park; Sang Wan Lee', display:{Lore:['[{"text": "arXiv:2008.06146", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lEnd-to-End Trainable Self-Attentive Shallow Network for Text-Independent Speaker Verification\\u00a7r\\n\\n\\u00a78\\u00a7oHyeonmook Park\\nJungbae Park\\nSang Wan Lee\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.06146\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 14 Aug 2020 00:46:50 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 3 figures, 3 tables\\u00a7r"}']}
{title:'Huang et al. (§72020§r)', author: 'Qiuchen Huang; Yang Ai; Zhenhua Ling', display:{Lore:['[{"text": "arXiv:2008.06182", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lOnline Speaker Adaptation for WaveNet-based Neural Vocoders\\u00a7r\\n\\n\\u00a78\\u00a7oQiuchen Huang\\nYang Ai\\nZhenhua Ling\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.06182\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 14 Aug 2020 03:55:20 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o6 pages, 2 figures, 4 tables\\u00a7r"}']}
{title:'Prinz et al. (§72020§r)', author: 'Katharina Prinz; Arthur Flexer; Gerhard Widmer', display:{Lore:['[{"text": "arXiv:2008.06273", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lThe Impact of Label Noise on a Music Tagger\\u00a7r\\n\\n\\u00a78\\u00a7oKatharina Prinz\\nArthur Flexer\\nGerhard Widmer\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.06273\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 14 Aug 2020 10:00:30 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oIn Proceedings of the 13th International Workshop on Machine Learning and Music, European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases\\u00a7r"}']}
{title:'Kum et al. (§72020§r)', author: 'Sangeun Kum; Jing-Hua Lin; Li Su; Juhan Nam', display:{Lore:['[{"text": "arXiv:2008.06358", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSemi-supervised learning using teacher-student models for vocal melody extraction\\u00a7r\\n\\n\\u00a78\\u00a7oSangeun Kum\\nJing-Hua Lin\\nLi Su\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.06358\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 14 Aug 2020 13:24:37 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o8 pages, 5 figures, accepted for the 21st International Society for Music Information Retrieval Conference (ISMIR 2020)\\u00a7r"}']}
{title:'Braun et al. (§72020§r)', author: 'Sebastian Braun; Ivan Tashev', display:{Lore:['[{"text": "arXiv:2008.06412", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lData augmentation and loss normalization for deep noise suppression\\u00a7r\\n\\n\\u00a78\\u00a7oSebastian Braun\\nIvan Tashev\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.06412\\u00a7r\\n\\nVersion:\\u00a77v2 (Thu, 24 Sep 2020 14:29:05 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oto appear in Proc. 22nd International Conference on Speech and Computer (SPECOM),2020\\u00a7r"}']}
{title:'Mao et al. (§72020§r)', author: 'Shuiyang Mao; P. C. Ching; Tan Lee', display:{Lore:['[{"text": "arXiv:2008.06665", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lEigenEmo: Spectral Utterance Representation Using Dynamic Mode Decomposition for Speech Emotion Classification\\u00a7r\\n\\n\\u00a78\\u00a7oShuiyang Mao\\nP. C. Ching\\nTan Lee\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.06665\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 15 Aug 2020 07:00:11 GMT)\\u00a7r"}']}
{title:'Mao et al. (§72020§r)', author: 'Shuiyang Mao; P. C. Ching; C. -C. Jay Kuo; Tan Lee', display:{Lore:['[{"text": "arXiv:2008.06667", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAdvancing Multiple Instance Learning with Attention Modeling for Categorical Speech Emotion Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oShuiyang Mao\\nP. C. Ching\\nC. -C. Jay Kuo\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.06667\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 15 Aug 2020 07:23:43 GMT)\\u00a7r"}']}
{title:'Siriwardhana et al. (§72020§r)', author: 'Shamane Siriwardhana; Andrew Reis; Rivindu Weerasekera; Suranga Nanayakkara', display:{Lore:['[{"text": "arXiv:2008.06682", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lJointly Fine-Tuning \\"BERT-like\\" Self Supervised Models to Improve Multimodal Speech Emotion Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oShamane Siriwardhana\\nAndrew Reis\\nRivindu Weerasekera\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.06682\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 15 Aug 2020 08:54:48 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted to INTERSPEECH 2020\\u00a7r"}']}
{title:'Kumar et al. (§72020§r)', author: 'Sanjay Kumar; Wong Sze Wing; Teng Mingbang; Heow Pueh Lee', display:{Lore:['[{"text": "arXiv:2008.06702", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lExperimental investigations of psychoacoustic characteristics of household vacuum cleaners\\u00a7r\\n\\n\\u00a78\\u00a7oSanjay Kumar\\nWong Sze Wing\\nTeng Mingbang\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.06702\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 15 Aug 2020 11:17:41 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o16 pages, 7 figures\\u00a7r"}']}
{title:'Joglekar et al. (§72020§r)', author: 'Aditya Joglekar; John H. L. Hansen; Meena Chandra Shekar; Abhijeet Sangwan', display:{Lore:['[{"text": "arXiv:2008.06764", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lFEARLESS STEPS Challenge (FS-2): Supervised Learning with Massive Naturalistic Apollo Data\\u00a7r\\n\\n\\u00a78\\u00a7oAditya Joglekar\\nJohn H. L. Hansen\\nMeena Chandra Shekar\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.06764\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 15 Aug 2020 18:52:29 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oPaper Accepted in the Interspeech 2020 Conference\\u00a7r"}']}
{title:'Yoon et al. (§72020§r)', author: 'Hyun-Wook Yoon; Sang-Hoon Lee; Hyeong-Rae Noh; Seong-Whan Lee', display:{Lore:['[{"text": "arXiv:2008.06867", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAudio Dequantization for High Fidelity Audio Generation in Flow-based Neural Vocoder\\u00a7r\\n\\n\\u00a78\\u00a7oHyun-Wook Yoon\\nSang-Hoon Lee\\nHyeong-Rae Noh\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.06867\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 16 Aug 2020 09:37:18 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted in INTERSPEECH2020\\u00a7r"}']}
{title:'Chen et al. (§72020§r)', author: 'Mingjie Chen; Thomas Hain', display:{Lore:['[{"text": "arXiv:2008.06892", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lUnsupervised Acoustic Unit Representation Learning for Voice Conversion using WaveNet Auto-encoders\\u00a7r\\n\\n\\u00a78\\u00a7oMingjie Chen\\nThomas Hain\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.06892\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 16 Aug 2020 12:16:29 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oTo be presented in Interspeech 2020\\u00a7r"}']}
{title:'Zhu et al. (§72020§r)', author: 'Youxiang Zhu; Xiaohui Liang', display:{Lore:['[{"text": "arXiv:2008.07052", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lExploiting Fully Convolutional Network and Visualization Techniques on Spontaneous Speech for Dementia Detection\\u00a7r\\n\\n\\u00a78\\u00a7oYouxiang Zhu\\nXiaohui Liang\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.07052\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 17 Aug 2020 01:37:39 GMT)\\u00a7r"}']}
{title:'Deshmukh et al. (§72020§r)', author: 'Soham Deshmukh; Bhiksha Raj; Rita Singh', display:{Lore:['[{"text": "arXiv:2008.07085", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMulti-Task Learning for Interpretable Weakly Labelled Sound Event Detection\\u00a7r\\n\\n\\u00a78\\u00a7oSoham Deshmukh\\nBhiksha Raj\\nRita Singh\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.07085\\u00a7r\\n\\nVersion:\\u00a77v2 (Thu, 29 Oct 2020 18:22:09 GMT)\\u00a7r"}']}
{title:'Wang et al. (§72020§r)', author: 'Ziyu Wang; Yiyi Zhang; Yixiao Zhang; Junyan Jiang; Ruihan Yang; Junbo Zhao; Gus Xia', display:{Lore:['[{"text": "arXiv:2008.07118", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lPIANOTREE VAE: Structured Representation Learning for Polyphonic Music\\u00a7r\\n\\n\\u00a78\\u00a7oZiyu Wang\\nYiyi Zhang\\nYixiao Zhang\\n+ 3 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.07118\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nIn Proceedings of 21st International Conference on Music\\n  Information Retrieval (ISMIR), Montreal, Canada (virtual conference), 2020\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 17 Aug 2020 06:48:59 GMT)\\u00a7r"}']}
{title:'Masztalski et al. (§72020§r)', author: 'Piotr Masztalski; Mateusz Matuszewski; Karol Piaskowski; Michał Romaniuk', display:{Lore:['[{"text": "arXiv:2008.07231", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lStoRIR: Stochastic Room Impulse Response Generation for Audio Data Augmentation\\u00a7r\\n\\n\\u00a78\\u00a7oPiotr Masztalski\\nMateusz Matuszewski\\nKarol Piaskowski\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.07231\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 17 Aug 2020 11:56:47 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted for INTERSPEECH 2020\\u00a7r"}']}
{title:'Romaniuk et al. (§72020§r)', author: 'Michał Romaniuk; Piotr Masztalski; Karol Piaskowski; Mateusz Matuszewski', display:{Lore:['[{"text": "arXiv:2008.07244", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lEfficient Low-Latency Speech Enhancement with Mobile Audio Streaming Networks\\u00a7r\\n\\n\\u00a78\\u00a7oMicha\\u0142 Romaniuk\\nPiotr Masztalski\\nKarol Piaskowski\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.07244\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 17 Aug 2020 12:18:34 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted for INTERSPEECH 2020\\u00a7r"}']}
{title:'Kwiatkowska et al. (§72020§r)', author: 'Zuzanna Kwiatkowska; Beniamin Kalinowski; Michał Kośmider; Krzysztof Rykaczewski', display:{Lore:['[{"text": "arXiv:2008.07247", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDeep Learning Based Open Set Acoustic Scene Classification\\u00a7r\\n\\n\\u00a78\\u00a7oZuzanna Kwiatkowska\\nBeniamin Kalinowski\\nMicha\\u0142 Ko\\u015bmider\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.07247\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 17 Aug 2020 12:23:27 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oThis paper was submitted to conference INTERSPEECH 2020\\u00a7r"}']}
{title:'Qi et al. (§72020§r)', author: 'Jun Qi; Jun Du; Sabato Marco Siniscalchi; Xiaoli Ma; Chin-Hui Lee', display:{Lore:['[{"text": "arXiv:2008.07281", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7eeess.SP\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lOn Mean Absolute Error for Deep Neural Network Based Vector-to-Vector Regression\\u00a7r\\n\\n\\u00a78\\u00a7oJun Qi\\nJun Du\\nSabato Marco Siniscalchi\\nXiaoli Ma\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.07281\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/LSP.2020.3016837\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nIEEE Signal Processing Letters, 2020\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 12 Aug 2020 22:41:26 GMT)\\u00a7r"}']}
{title:'Loukina et al. (§72020§r)', author: 'Anastassia Loukina; Keelan Evanini; Matthew Mulholland; Ian Blood; Klaus Zechner', display:{Lore:['[{"text": "arXiv:2008.07520", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.HC\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDo face masks introduce bias in speech technologies? The case of automated scoring of speaking proficiency\\u00a7r\\n\\n\\u00a78\\u00a7oAnastassia Loukina\\nKeelan Evanini\\nMatthew Mulholland\\nIan Blood\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.07520\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.21437/Interspeech.2020-1264\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nProceedings of Interspeech 2020, 1942-1946\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 3 Nov 2020 16:10:15 GMT)\\u00a7r"}']}
{title:'Lu et al. (§72020§r)', author: 'Yen-Ju Lu; Chien-Feng Liao; Xugang Lu; Jeih-weih Hung; Yu Tsao', display:{Lore:['[{"text": "arXiv:2008.07618", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lIncorporating Broad Phonetic Information for Speech Enhancement\\u00a7r\\n\\n\\u00a78\\u00a7oYen-Ju Lu\\nChien-Feng Liao\\nXugang Lu\\nJeih-weih Hung\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.07618\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 13 Aug 2020 09:38:08 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oto be published in Interspeech 2020\\u00a7r"}']}
{title:'Krishna et al. (§72020§r)', author: 'Gautam Krishna; Co Tran; Mason Carnahan; Morgan M Hagood; Ahmed H Tewfik', display:{Lore:['[{"text": "arXiv:2008.07621", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7eeess.SP\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSpeech Recognition using EEG signals recorded using dry electrodes\\u00a7r\\n\\n\\u00a78\\u00a7oGautam Krishna\\nCo Tran\\nMason Carnahan\\nMorgan M Hagood\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.07621\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 13 Aug 2020 09:56:45 GMT)\\u00a7r"}']}
{title:'Petermann et al. (§72020§r)', author: 'Darius Petermann; Pritish Chandna; Helena Cuesta; Jordi Bonada; Emilia Gomez', display:{Lore:['[{"text": "arXiv:2008.07645", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDeep Learning Based Source Separation Applied To Choir Ensembles\\u00a7r\\n\\n\\u00a78\\u00a7oDarius Petermann\\nPritish Chandna\\nHelena Cuesta\\nJordi Bonada\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.07645\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 17 Aug 2020 22:07:44 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oTo appear at the 21st International Society for Music Information Retrieval Conference, Montr\\u00e9al, Canada, 2020, audio examples available at: \\"https://darius522.github.io/satb-source-separation-results/\\"\\u00a7r"}']}
{title:'Jati et al. (§72020§r)', author: 'Arindam Jati; Chin-Cheng Hsu; Monisankha Pal; Raghuveer Peri; Wael AbdAlmageed; Shrikanth Narayanan', display:{Lore:['[{"text": "arXiv:2008.07685", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAdversarial Attack and Defense Strategies for Deep Speaker Recognition Systems\\u00a7r\\n\\n\\u00a78\\u00a7oArindam Jati\\nChin-Cheng Hsu\\nMonisankha Pal\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.07685\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1016/j.csl.2021.101199\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 18 Aug 2020 00:58:19 GMT)\\u00a7r"}']}
{title:'Wei et al. (§72020§r)', author: 'Wenqi Wei; Jianzong Wang; Jiteng Ma; Ning Cheng; Jing Xiao', display:{Lore:['[{"text": "arXiv:2008.07695", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Real-time Robot-based Auxiliary System for Risk Evaluation of COVID-19 Infection\\u00a7r\\n\\n\\u00a78\\u00a7oWenqi Wei\\nJianzong Wang\\nJiteng Ma\\nNing Cheng\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.07695\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 18 Aug 2020 01:58:52 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7owill be presented in INTERSPEECH 2020\\u00a7r"}']}
{title:'Ye et al. (§72020§r)', author: 'Shuaishuai Ye; Xinhui Hu; Xinkang Xu', display:{Lore:['[{"text": "arXiv:2008.07787", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lTdcgan: Temporal Dilated Convolutional Generative Adversarial Network for End-to-end Speech Enhancement\\u00a7r\\n\\n\\u00a78\\u00a7oShuaishuai Ye\\nXinhui Hu\\nXinkang Xu\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.07787\\u00a7r\\n\\nVersion:\\u00a77v2 (Wed, 30 Sep 2020 09:16:54 GMT)\\u00a7r"}']}
{title:'Patel et al. (§72020§r)', author: 'Maitreya Patel; Mirali Purohit; Jui Shah; Hemant A. Patil', display:{Lore:['[{"text": "arXiv:2008.07788", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lCinC-GAN for Effective F0 prediction for Whisper-to-Normal Speech Conversion\\u00a7r\\n\\n\\u00a78\\u00a7oMaitreya Patel\\nMirali Purohit\\nJui Shah\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.07788\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 18 Aug 2020 07:56:16 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted in 28th European Signal Processing Conference (EUSIPCO), 2020\\u00a7r"}']}
{title:'Agarwal et al. (§72020§r)', author: 'Rishika Agarwal; Xiaochuan Niu; Pranay Dighe; Srikanth Vishnubhotla; Sameer Badaskar; Devang Naik', display:{Lore:['[{"text": "arXiv:2008.08113", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lComplementary Language Model and Parallel Bi-LRNN for False Trigger Mitigation\\u00a7r\\n\\n\\u00a78\\u00a7oRishika Agarwal\\nXiaochuan Niu\\nPranay Dighe\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.08113\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 18 Aug 2020 18:21:33 GMT)\\u00a7r"}']}
{title:'Subramani et al. (§72020§r)', author: 'Krishna Subramani; Preeti Rao', display:{Lore:['[{"text": "arXiv:2008.08405", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lHpRNet : Incorporating Residual Noise Modeling for Violin in a Variational Parametric Synthesizer\\u00a7r\\n\\n\\u00a78\\u00a7oKrishna Subramani\\nPreeti Rao\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.08405\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 19 Aug 2020 12:48:32 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7ohttps://github.com/SubramaniKrishna/HpRNet\\u00a7r"}']}
{title:'Shi et al. (§72020§r)', author: 'Jiatong Shi; Nan Huo; Qin Jin', display:{Lore:['[{"text": "arXiv:2008.08647", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lContext-aware Goodness of Pronunciation for Computer-Assisted Pronunciation Training\\u00a7r\\n\\n\\u00a78\\u00a7oJiatong Shi\\nNan Huo\\nQin Jin\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.08647\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 19 Aug 2020 19:38:38 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted by Interspeech2020\\u00a7r"}']}
{title:'Wang et al. (§72020§r)', author: 'Qiongqiong Wang; Koji Okabe; Kong Aik Lee; Takafumi Koshinaka', display:{Lore:['[{"text": "arXiv:2008.08815", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Generalized Framework for Domain Adaptation of PLDA in Speaker Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oQiongqiong Wang\\nKoji Okabe\\nKong Aik Lee\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.08815\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 20 Aug 2020 07:38:38 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oICASSP 2020 (45th International Conference on Acoustics, Speech, and Signal Processing)\\u00a7r"}']}
{title:'Wang et al. (§72020§r)', author: 'Qiongqiong Wang; Kong Aik Lee; Takafumi Koshinaka', display:{Lore:['[{"text": "arXiv:2008.08865", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lUsing Multi-Resolution Feature Maps with Convolutional Neural Networks for Anti-Spoofing in ASV\\u00a7r\\n\\n\\u00a78\\u00a7oQiongqiong Wang\\nKong Aik Lee\\nTakafumi Koshinaka\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.08865\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 20 Aug 2020 10:00:03 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oOdyssey 2020 (The Speaker and Language Recognition Workshop)\\u00a7r"}']}
{title:'Liu et al. (§72020§r)', author: 'Tianchi Liu; Rohan Kumar Das; Maulik Madhavi; Shengmei Shen; Haizhou Li', display:{Lore:['[{"text": "arXiv:2008.08901", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7eeess.SP\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSpeaker-Utterance Dual Attention for Speaker and Utterance Verification\\u00a7r\\n\\n\\u00a78\\u00a7oTianchi Liu\\nRohan Kumar Das\\nMaulik Madhavi\\nShengmei Shen\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.08901\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 20 Aug 2020 11:37:57 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted by Interspeech 2020\\u00a7r"}']}
{title:'Chi et al. (§72020§r)', author: 'Wayne Chi; Prachi Kumar; Suri Yaddanapudi; Rahul Suresh; Umut Isik', display:{Lore:['[{"text": "arXiv:2008.08927", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lGenerating Music with a Self-Correcting Non-Chronological Autoregressive Model\\u00a7r\\n\\n\\u00a78\\u00a7oWayne Chi\\nPrachi Kumar\\nSuri Yaddanapudi\\nRahul Suresh\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.08927\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 18 Aug 2020 20:36:47 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o8 pages, 4 figures\\u00a7r"}']}
{title:'Urtans et al. (§72020§r)', author: 'Evalds Urtans; Ariel Tabaks', display:{Lore:['[{"text": "arXiv:2008.08965", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.HC\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lasya: Mindful verbal communication using deep learning\\u00a7r\\n\\n\\u00a78\\u00a7oEvalds Urtans\\nAriel Tabaks\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.08965\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 20 Aug 2020 13:37:49 GMT)\\u00a7r"}']}
{title:'Farias et al. (§72020§r)', author: 'F. Farias; R. Coelho', display:{Lore:['[{"text": "arXiv:2008.09175", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7eeess.SP\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lBlind Mask to Improve Intelligibility of Non-Stationary Noisy Speech\\u00a7r\\n\\n\\u00a78\\u00a7oF. Farias\\nR. Coelho\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.09175\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/LSP.2021.3086405\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 20 Aug 2020 19:41:30 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 Pages, 5 Figures, 3 Tables\\u00a7r"}']}
{title:'Chen et al. (§72020§r)', author: 'Huili Chen; Yue Zhang; Felix Weninger; Rosalind Picard; Cynthia Breazeal; Hae Won Park', display:{Lore:['[{"text": "arXiv:2008.09207", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDyadic Speech-based Affect Recognition using DAMI-P2C Parent-child Multimodal Interaction Dataset\\u00a7r\\n\\n\\u00a78\\u00a7oHuili Chen\\nYue Zhang\\nFelix Weninger\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.09207\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1145/3382507.3418842\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 20 Aug 2020 20:53:23 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted by the 2020 International Conference on Multimodal Interaction (ICMI\'20)\\u00a7r"}']}
{title:'Tits et al. (§72020§r)', author: 'Noé Tits; Kevin El Haddad; Thierry Dutoit', display:{Lore:['[{"text": "arXiv:2008.09483", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lLaughter Synthesis: Combining Seq2seq modeling with Transfer Learning\\u00a7r\\n\\n\\u00a78\\u00a7oNo\\u00e9 Tits\\nKevin El Haddad\\nThierry Dutoit\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.09483\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 20 Aug 2020 09:37:28 GMT)\\u00a7r"}']}
{title:'de Korte et al. (§72020§r)', author: 'Marcel de Korte; Jaebok Kim; Esther Klabbers', display:{Lore:['[{"text": "arXiv:2008.09659", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lEfficient neural speech synthesis for low-resource languages through multilingual modeling\\u00a7r\\n\\n\\u00a78\\u00a7oMarcel de Korte\\nJaebok Kim\\nEsther Klabbers\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.09659\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 20 Aug 2020 14:05:28 GMT)\\u00a7r"}']}
{title:'Egas-López (§72020§r)', author: 'José Vicente Egas-López', display:{Lore:['[{"text": "arXiv:2008.10014", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lThey are wearing a mask! Identification of Subjects Wearing a Surgical Mask from their Speech by means of x-vectors and Fisher Vectors\\u00a7r\\n\\n\\u00a78\\u00a7oJos\\u00e9 Vicente Egas-L\\u00f3pez\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.10014\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 23 Aug 2020 11:27:11 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oINTERSPEECH CONFERENCE FORMAT. 5 pages, 1 figure, 2 tables\\u00a7r"}']}
{title:'Jose (§72020§r)', author: 'Williard Joshua Jose', display:{Lore:['[{"text": "arXiv:2008.10233", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAMRConvNet: AMR-Coded Speech Enhancement Using Convolutional Neural Networks\\u00a7r\\n\\n\\u00a78\\u00a7oWilliard Joshua Jose\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.10233\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 24 Aug 2020 07:24:43 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oIEEE SMC 2020\\u00a7r"}']}
{title:'Kim et al. (§72020§r)', author: 'Taejun Kim; Minsuk Choi; Evan Sacks; Yi-Hsuan Yang; Juhan Nam', display:{Lore:['[{"text": "arXiv:2008.10267", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.IR\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Computational Analysis of Real-World DJ Mixes using Mix-To-Track Subsequence Alignment\\u00a7r\\n\\n\\u00a78\\u00a7oTaejun Kim\\nMinsuk Choi\\nEvan Sacks\\nYi-Hsuan Yang\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.10267\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 24 Aug 2020 08:54:19 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted for publication at 21st International Society for Music Information Retrieval Conference (ISMIR 2020)\\u00a7r"}']}
{title:'Peyser et al. (§72020§r)', author: 'Cal Peyser; Sepand Mavandadi; Tara N. Sainath; James Apfel; Ruoming Pang; Shankar Kumar', display:{Lore:['[{"text": "arXiv:2008.10491", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lImproving Tail Performance of a Deliberation E2E ASR Model Using a Large Text Corpus\\u00a7r\\n\\n\\u00a78\\u00a7oCal Peyser\\nSepand Mavandadi\\nTara N. Sainath\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.10491\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 25 Aug 2020 12:50:55 GMT)\\u00a7r"}']}
{title:'Perez et al. (§72020§r)', author: 'Matthew Perez; Zakaria Aldeneh; Emily Mower Provost', display:{Lore:['[{"text": "arXiv:2008.10788", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAphasic Speech Recognition using a Mixture of Speech Intelligibility Experts\\u00a7r\\n\\n\\u00a78\\u00a7oMatthew Perez\\nZakaria Aldeneh\\nEmily Mower Provost\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.10788\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.21437/Interspeech.2020-2049\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 25 Aug 2020 02:35:22 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o4 pages\\u00a7r"}']}
{title:'Tits et al. (§72020§r)', author: 'Noé Tits; Kevin El Haddad; Thierry Dutoit', display:{Lore:['[{"text": "arXiv:2008.11045", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lICE-Talk: an Interface for a Controllable Expressive Talking Machine\\u00a7r\\n\\n\\u00a78\\u00a7oNo\\u00e9 Tits\\nKevin El Haddad\\nThierry Dutoit\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.11045\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 25 Aug 2020 14:17:10 GMT)\\u00a7r"}']}
{title:'Mishra (§72020§r)', author: 'Prateek Mishra', display:{Lore:['[{"text": "arXiv:2008.11088", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lFew Shot Text-Independent speaker verification using 3D-CNN\\u00a7r\\n\\n\\u00a78\\u00a7oPrateek Mishra\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.11088\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 25 Aug 2020 15:03:29 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o7 pages, 2 figures\\u00a7r"}']}
{title:'Li (§72020§r)', author: 'Xi-Lin Li', display:{Lore:['[{"text": "arXiv:2008.11273", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lIndependent Vector Analysis with Deep Neural Network Source Priors\\u00a7r\\n\\n\\u00a78\\u00a7oXi-Lin Li\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.11273\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 6 Oct 2020 17:43:06 GMT)\\u00a7r"}']}
{title:'Ramires et al. (§72020§r)', author: 'Antonio Ramires; Frederic Font; Dmitry Bogdanov; Jordan B. L. Smith; Yi-Hsuan Yang; Joann Ching; Bo-Yu Chen; Yueh-Kao Wu; Hsu Wei-Han; Xavier Serra', display:{Lore:['[{"text": "arXiv:2008.11507", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lThe Freesound Loop Dataset and Annotation Tool\\u00a7r\\n\\n\\u00a78\\u00a7oAntonio Ramires\\nFrederic Font\\nDmitry Bogdanov\\n+ 6 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.11507\\u00a7r\\n\\nVersion:\\u00a77v2 (Wed, 23 Sep 2020 08:57:04 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oThis work will be presented in the 21st International Society for Music Information Retrieval (ISMIR2020). Annotator website: http://mtg.upf.edu/fslannotator Dataset: https://zenodo.org/record/3967852\\u00a7r"}']}
{title:'Ramires et al. (§72020§r)', author: 'António Ramires; Gilberto Bernardes; Matthew E. P. Davies; Xavier Serra', display:{Lore:['[{"text": "arXiv:2008.11529", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lTIV.lib: an open-source library for the tonal description of musical audio\\u00a7r\\n\\n\\u00a78\\u00a7oAnt\\u00f3nio Ramires\\nGilberto Bernardes\\nMatthew E. P. Davies\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.11529\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 26 Aug 2020 12:49:45 GMT)\\u00a7r"}']}
{title:'Sallo et al. (§72020§r)', author: 'Raymel Alfonso Sallo; Mohammad Esmaeilpour; Patrick Cardinal', display:{Lore:['[{"text": "arXiv:2008.11618", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAdversarially Training for Audio Classifiers\\u00a7r\\n\\n\\u00a78\\u00a7oRaymel Alfonso Sallo\\nMohammad Esmaeilpour\\nPatrick Cardinal\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.11618\\u00a7r\\n\\nVersion:\\u00a77v2 (Sun, 25 Oct 2020 17:43:52 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oPaper accepted to International Conference on PatternRecognition (ICPR) 2020\\u00a7r"}']}
{title:'Hammer et al. (§72020§r)', author: 'Hodaya Hammer; Shlomo E. Chazan; Jacob Goldberger; Sharon Gannot', display:{Lore:['[{"text": "arXiv:2008.11845", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lFCN Approach for Dynamically Locating Multiple Speakers\\u00a7r\\n\\n\\u00a78\\u00a7oHodaya Hammer\\nShlomo E. Chazan\\nJacob Goldberger\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.11845\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 26 Aug 2020 22:21:29 GMT)\\u00a7r"}']}
{title:'Lee et al. (§72020§r)', author: 'Joohyung Lee; Youngmoon Jung; Myunghun Jung; Hoirin Kim', display:{Lore:['[{"text": "arXiv:2008.11920", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDynamic Noise Embedding: Noise Aware Training and Adaptation for Speech Enhancement\\u00a7r\\n\\n\\u00a78\\u00a7oJoohyung Lee\\nYoungmoon Jung\\nMyunghun Jung\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.11920\\u00a7r\\n\\nVersion:\\u00a77v2 (Thu, 3 Dec 2020 08:51:46 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted to APSIPA ASC 2020\\u00a7r"}']}
{title:'Woo et al. (§72020§r)', author: 'Jeongwoo Woo; Masato Mimura; Kazuyoshi Yoshii; Tatsuya Kawahara', display:{Lore:['[{"text": "arXiv:2008.12048", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lEnd-to-end Music-mixed Speech Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oJeongwoo Woo\\nMasato Mimura\\nKazuyoshi Yoshii\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.12048\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 27 Aug 2020 10:51:26 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to APSIPA 2020\\u00a7r"}']}
{title:'Chen et al. (§72020§r)', author: 'Wenda Chen; Jonathan Huang; Tobias Bocklet', display:{Lore:['[{"text": "arXiv:2008.12218", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lLength- and Noise-aware Training Techniques for Short-utterance Speaker Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oWenda Chen\\nJonathan Huang\\nTobias Bocklet\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.12218\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 27 Aug 2020 16:15:52 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oTo be published in proceedings of Interspeech 2020\\u00a7r"}']}
{title:'Bacila et al. (§72020§r)', author: 'Bogdan Bacila; Hyunkook Lee', display:{Lore:['[{"text": "arXiv:2008.12255", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lListener-Position and Orientation Dependency of Auditory Perception in an Enclosed Space: Elicitation of Salient Attributes\\u00a7r\\n\\n\\u00a78\\u00a7oBogdan Bacila\\nHyunkook Lee\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.12255\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 27 Aug 2020 16:50:54 GMT)\\u00a7r"}']}
{title:'Kim et al. (§72020§r)', author: 'Yelin Kim; Joshua Levy; Yang Liu', display:{Lore:['[{"text": "arXiv:2008.12376", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSpeech Sentiment and Customer Satisfaction Estimation in Socialbot Conversations\\u00a7r\\n\\n\\u00a78\\u00a7oYelin Kim\\nJoshua Levy\\nYang Liu\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.12376\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 27 Aug 2020 21:34:53 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oTo be published in Interspeech 2020\\u00a7r"}']}
{title:'Zhao et al. (§72020§r)', author: 'Yi Zhao; Wen-Chin Huang; Xiaohai Tian; Junichi Yamagishi; Rohan Kumar Das; Tomi Kinnunen; Zhenhua Ling; Tomoki Toda', display:{Lore:['[{"text": "arXiv:2008.12527", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lVoice Conversion Challenge 2020: Intra-lingual semi-parallel and cross-lingual voice conversion\\u00a7r\\n\\n\\u00a78\\u00a7oYi Zhao\\nWen-Chin Huang\\nXiaohai Tian\\n+ 4 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.12527\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 28 Aug 2020 07:48:17 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to ISCAJoint Workshop for the Blizzard Challenge and Voice Conversion Challenge 2020\\u00a7r"}']}
{title:'Kameoka et al. (§72020§r)', author: 'Hirokazu Kameoka; Takuhiro Kaneko; Kou Tanaka; Nobukatsu Hojo', display:{Lore:['[{"text": "arXiv:2008.12604", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lNonparallel Voice Conversion with Augmented Classifier Star Generative Adversarial Networks\\u00a7r\\n\\n\\u00a78\\u00a7oHirokazu Kameoka\\nTakuhiro Kaneko\\nKou Tanaka\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.12604\\u00a7r\\n\\nVersion:\\u00a77v7 (Tue, 10 Nov 2020 09:57:32 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to IEEE/ACM Trans. ASLP. This paper is an extended full-paper version of arXiv:1806.02169\\u00a7r"}']}
{title:'Yang et al. (§72020§r)', author: 'Haici Yang; Kai Zhen; Seungkwon Beack; Minje Kim', display:{Lore:['[{"text": "arXiv:2008.12889", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSource-Aware Neural Speech Coding for Noisy Speech Compression\\u00a7r\\n\\n\\u00a78\\u00a7oHaici Yang\\nKai Zhen\\nSeungkwon Beack\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.12889\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 10 Nov 2020 15:00:57 GMT)\\u00a7r"}']}
{title:'Kathania et al. (§72020§r)', author: 'Hemant Kathania; Mittul Singh; Tamás Grósz; Mikko Kurimo', display:{Lore:['[{"text": "arXiv:2008.12914", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lData augmentation using prosody and false starts to recognize non-native children\'s speech\\u00a7r\\n\\n\\u00a78\\u00a7oHemant Kathania\\nMittul Singh\\nTam\\u00e1s Gr\\u00f3sz\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.12914\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 29 Aug 2020 05:32:32 GMT)\\u00a7r"}']}
{title:'Li et al. (§72020§r)', author: 'Wei Li; James Qin; Chung-Cheng Chiu; Ruoming Pang; Yanzhang He', display:{Lore:['[{"text": "arXiv:2008.13093", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lParallel Rescoring with Transformer for Streaming On-Device Speech Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oWei Li\\nJames Qin\\nChung-Cheng Chiu\\nRuoming Pang\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.13093\\u00a7r\\n\\nVersion:\\u00a77v3 (Wed, 2 Sep 2020 23:05:17 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oProceedings of Interspeech, 2020\\u00a7r"}']}
{title:'Michelashvili et al. (§72020§r)', author: 'Michael Michelashvili; Lior Wolf', display:{Lore:['[{"text": "arXiv:2008.13095", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lHierarchical Timbre-Painting and Articulation Generation\\u00a7r\\n\\n\\u00a78\\u00a7oMichael Michelashvili\\nLior Wolf\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.13095\\u00a7r\\n\\nVersion:\\u00a77v2 (Mon, 7 Sep 2020 14:49:37 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oaccepted in Proc. of the 21st International Society for Music Information Retrieval (ISMIR2020)\\u00a7r"}']}
{title:'Noé et al. (§72020§r)', author: 'Paul-Gauthier Noé; Jean-François Bonastre; Driss Matrouf; Natalia Tomashenko; Andreas Nautsch; Nicholas Evans', display:{Lore:['[{"text": "arXiv:2008.13144", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CR\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSpeech Pseudonymisation Assessment Using Voice Similarity Matrices\\u00a7r\\n\\n\\u00a78\\u00a7oPaul-Gauthier No\\u00e9\\nJean-Fran\\u00e7ois Bonastre\\nDriss Matrouf\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.13144\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 30 Aug 2020 11:31:07 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oInterspeech 2020\\u00a7r"}']}
{title:'Xie et al. (§72020§r)', author: 'Jiamin Xie; Suzanna Sia; Paola Garcia; Daniel Povey; Sanjeev Khudanpur', display:{Lore:['[{"text": "arXiv:2008.13213", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMixture of Speaker-type PLDAs for Children\'s Speech Diarization\\u00a7r\\n\\n\\u00a78\\u00a7oJiamin Xie\\nSuzanna Sia\\nPaola Garcia\\nDaniel Povey\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2008.13213\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 30 Aug 2020 16:45:23 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7osubmitted to Interspeech 2020\\u00a7r"}']}
{title:'Mo et al. (§72020§r)', author: 'Tong Mo; Yakun Yu; Mohammad Salameh; Di Niu; Shangling Jui', display:{Lore:['[{"text": "arXiv:2009.00165", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lNeural Architecture Search For Keyword Spotting\\u00a7r\\n\\n\\u00a78\\u00a7oTong Mo\\nYakun Yu\\nMohammad Salameh\\nDi Niu\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2009.00165\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.21437/Interspeech.2020-3132\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nProc. Interspeech 2020, 1982-1986\\u00a7r\\n\\nVersion:\\u00a77v2 (Wed, 2 Sep 2020 04:10:58 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7owill be presented in INTERSPEECH 2020\\u00a7r"}']}
{title:'Zegers et al. (§72020§r)', author: 'Jeroen Zegers; Hugo Van hamme', display:{Lore:['[{"text": "arXiv:2009.00551", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAnalysis of memory in LSTM-RNNs for source separation\\u00a7r\\n\\n\\u00a78\\u00a7oJeroen Zegers\\nHugo Van hamme\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2009.00551\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 1 Sep 2020 16:31:32 GMT)\\u00a7r"}']}
{title:'Sarawgi et al. (§72020§r)', author: 'Utkarsh Sarawgi; Wazeer Zulfikar; Nouran Soliman; Pattie Maes', display:{Lore:['[{"text": "arXiv:2009.00700", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMultimodal Inductive Transfer Learning for Detection of Alzheimer\'s Dementia and its Severity\\u00a7r\\n\\n\\u00a78\\u00a7oUtkarsh Sarawgi\\nWazeer Zulfikar\\nNouran Soliman\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2009.00700\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 30 Aug 2020 21:47:26 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oTo appear in INTERSPEECH 2020\\u00a7r"}']}
{title:'Chen et al. (§72020§r)', author: 'Nanxin Chen; Yu Zhang; Heiga Zen; Ron J. Weiss; Mohammad Norouzi; William Chan', display:{Lore:['[{"text": "arXiv:2009.00713", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lWaveGrad: Estimating Gradients for Waveform Generation\\u00a7r\\n\\n\\u00a78\\u00a7oNanxin Chen\\nYu Zhang\\nHeiga Zen\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2009.00713\\u00a7r\\n\\nVersion:\\u00a77v2 (Fri, 9 Oct 2020 15:21:58 GMT)\\u00a7r"}']}
{title:'Xia et al. (§72020§r)', author: 'Wei Xia; John H. L. Hansen', display:{Lore:['[{"text": "arXiv:2009.00768", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.SP\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSpeaker Representation Learning using Global Context Guided Channel and Time-Frequency Transformations\\u00a7r\\n\\n\\u00a78\\u00a7oWei Xia\\nJohn H. L. Hansen\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2009.00768\\u00a7r\\n\\nVersion:\\u00a77v2 (Wed, 9 Sep 2020 16:56:31 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted to Interspeech 2020\\u00a7r"}']}
{title:'Rahman et al. (§72020§r)', author: 'Wasifur Rahman; Sangwu Lee; Md. Saiful Islam; Victor Nikhil Antony; Harshil Ratnu; Mohammad Rafayet Ali; Abdullah Al Mamun; Ellen Wagner; Stella Jensen-Roberts; Max A. Little; Ray Dorsey; Ehsan Hoque', display:{Lore:['[{"text": "arXiv:2009.01231", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CY\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDetecting Parkinson\'s Disease From an Online Speech-task\\u00a7r\\n\\n\\u00a78\\u00a7oWasifur Rahman\\nSangwu Lee\\nMd. Saiful Islam\\n+ 8 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2009.01231\\u00a7r\\n\\nVersion:\\u00a77v4 (Tue, 15 Dec 2020 21:08:05 GMT)\\u00a7r"}']}
{title:'Cámbara et al. (§72020§r)', author: 'Guillermo Cámbara; Jordi Luque; Mireia Farrús', display:{Lore:['[{"text": "arXiv:2009.01309", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.AI\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7eeess.SP\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lConvolutional Speech Recognition with Pitch and Voice Quality Features\\u00a7r\\n\\n\\u00a78\\u00a7oGuillermo C\\u00e1mbara\\nJordi Luque\\nMireia Farr\\u00fas\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2009.01309\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 10 Nov 2020 11:37:09 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages\\u00a7r"}']}
{title:'Tan et al. (§72020§r)', author: 'Ke Tan; Buye Xu; Anurag Kumar; Eliya Nachmani; Yossi Adi', display:{Lore:['[{"text": "arXiv:2009.01381", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSAGRNN: Self-Attentive Gated RNN for Binaural Speaker Separation with Interaural Cue Preservation\\u00a7r\\n\\n\\u00a78\\u00a7oKe Tan\\nBuye Xu\\nAnurag Kumar\\nEliya Nachmani\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2009.01381\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/LSP.2020.3043977\\u00a7r\\n\\nVersion:\\u00a77v2 (Sat, 14 Nov 2020 17:34:11 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, accepted by IEEE Signal Processing Letters\\u00a7r"}']}
{title:'Zhang et al. (§72020§r)', author: 'Jing-Xuan Zhang; Li-Juan Liu; Yan-Nian Chen; Ya-Jun Hu; Yuan Jiang; Zhen-Hua Ling; Li-Rong Dai', display:{Lore:['[{"text": "arXiv:2009.01475", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7eeess.SP\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lVoice Conversion by Cascading Automatic Speech Recognition and Text-to-Speech Synthesis with Prosody Transfer\\u00a7r\\n\\n\\u00a78\\u00a7oJing-Xuan Zhang\\nLi-Juan Liu\\nYan-Nian Chen\\n+ 3 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2009.01475\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 3 Sep 2020 06:31:34 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to Joint Workshop for the Blizzard Challenge and Voice Conversion Challenge 2020, INTERSPEECH 2020\\u00a7r"}']}
{title:'Chang et al. (§72020§r)', author: 'Chun-Chieh Chang; Chieh-Chi Kao; Ming Sun; Chao Wang', display:{Lore:['[{"text": "arXiv:2009.01759", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lIntra-Utterance Similarity Preserving Knowledge Distillation for Audio Tagging\\u00a7r\\n\\n\\u00a78\\u00a7oChun-Chieh Chang\\nChieh-Chi Kao\\nMing Sun\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2009.01759\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 3 Sep 2020 15:50:13 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted to Interspeech 2020\\u00a7r"}']}
{title:'Chen et al. (§72020§r)', author: 'Jiawei Chen; Xu Tan; Jian Luan; Tao Qin; Tie-Yan Liu', display:{Lore:['[{"text": "arXiv:2009.01776", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lHiFiSinger: Towards High-Fidelity Neural Singing Voice Synthesis\\u00a7r\\n\\n\\u00a78\\u00a7oJiawei Chen\\nXu Tan\\nJian Luan\\nTao Qin\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2009.01776\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 3 Sep 2020 16:31:02 GMT)\\u00a7r"}']}
{title:'Stephenson et al. (§72020§r)', author: 'Brooke Stephenson; Laurent Besacier; Laurent Girin; Thomas Hueber', display:{Lore:['[{"text": "arXiv:2009.02035", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lWhat the Future Brings: Investigating the Impact of Lookahead for Incremental Neural TTS\\u00a7r\\n\\n\\u00a78\\u00a7oBrooke Stephenson\\nLaurent Besacier\\nLaurent Girin\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2009.02035\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 4 Sep 2020 07:30:57 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 4 figures\\u00a7r"}']}
{title:'Tagliasacchi et al. (§72020§r)', author: 'Marco Tagliasacchi; Yunpeng Li; Karolis Misiunas; Dominik Roblek', display:{Lore:['[{"text": "arXiv:2009.02095", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSEANet: A Multi-modal Speech Enhancement Network\\u00a7r\\n\\n\\u00a78\\u00a7oMarco Tagliasacchi\\nYunpeng Li\\nKarolis Misiunas\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2009.02095\\u00a7r\\n\\nVersion:\\u00a77v2 (Thu, 1 Oct 2020 17:26:35 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted to INTERSPEECH 2020\\u00a7r"}']}
{title:'Gonzalez-Lopez et al. (§72020§r)', author: 'Jose A. Gonzalez-Lopez; Alejandro Gomez-Alanis; Juan M. Martín-Doñas; José L. Pérez-Córdoba; Angel M. Gomez', display:{Lore:['[{"text": "arXiv:2009.02110", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.HC\\u00a7r, \\u00a7acs.LG\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSilent Speech Interfaces for Speech Restoration: A Review\\u00a7r\\n\\n\\u00a78\\u00a7oJose A. Gonzalez-Lopez\\nAlejandro Gomez-Alanis\\nJuan M. Mart\\u00edn-Do\\u00f1as\\nJos\\u00e9 L. P\\u00e9rez-C\\u00f3rdoba\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2009.02110\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/ACCESS.2020.3026579\\u00a7r\\n\\nVersion:\\u00a77v3 (Sun, 27 Sep 2020 08:50:17 GMT)\\u00a7r"}']}
{title:'Beveridge et al. (§72020§r)', author: 'Scott Beveridge; Steffen A. Herff; Estefanía Cano', display:{Lore:['[{"text": "arXiv:2009.02151", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDegradation effects of water immersion on earbud audio quality\\u00a7r\\n\\n\\u00a78\\u00a7oScott Beveridge\\nSteffen A. Herff\\nEstefan\\u00eda Cano\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2009.02151\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 2 Sep 2020 03:16:56 GMT)\\u00a7r"}']}
{title:'Wang et al. (§72020§r)', author: 'Zhenyu Wang; Wei Xia; John H. L. Hansen', display:{Lore:['[{"text": "arXiv:2009.02444", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lCross-domain Adaptation with Discrepancy Minimization for Text-independent Forensic Speaker Verification\\u00a7r\\n\\n\\u00a78\\u00a7oZhenyu Wang\\nWei Xia\\nJohn H. L. Hansen\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2009.02444\\u00a7r\\n\\nVersion:\\u00a77v2 (Wed, 9 Sep 2020 16:53:21 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oTo appear in INTERSPEECH 2020\\u00a7r"}']}
{title:'Wang et al. (§72020§r)', author: 'Zhenyu Wang; John H. L. Hansen; Yanlu Xie', display:{Lore:['[{"text": "arXiv:2009.02573", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA multi-view approach for Mandarin non-native mispronunciation verification\\u00a7r\\n\\n\\u00a78\\u00a7oZhenyu Wang\\nJohn H. L. Hansen\\nYanlu Xie\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2009.02573\\u00a7r\\n\\nVersion:\\u00a77v2 (Wed, 9 Sep 2020 16:41:45 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oICASSP 2020\\u00a7r"}']}
{title:'Liang et al. (§72020§r)', author: 'Jingjun Liang; Ruichen Li; Qin Jin', display:{Lore:['[{"text": "arXiv:2009.02598", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.MM\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSemi-supervised Multi-modal Emotion Recognition with Cross-Modal Distribution Matching\\u00a7r\\n\\n\\u00a78\\u00a7oJingjun Liang\\nRuichen Li\\nQin Jin\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2009.02598\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1145/3394171.3413579\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 5 Sep 2020 20:51:01 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o10 pages, 5 figures, to be published on ACM Multimedia 2020\\u00a7r"}']}
{title:'Mathur et al. (§72020§r)', author: 'Akhil Mathur; Fahim Kawsar; Nadia Berthouze; Nicholas D. Lane', display:{Lore:['[{"text": "arXiv:2009.02814", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lLibri-Adapt: A New Speech Dataset for Unsupervised Domain Adaptation\\u00a7r\\n\\n\\u00a78\\u00a7oAkhil Mathur\\nFahim Kawsar\\nNadia Berthouze\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2009.02814\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/ICASSP40776.2020.9053074\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7n2020 IEEE International Conference on Acoustics, Speech and Signal\\n  Processing (ICASSP), Barcelona, Spain, 2020, pp. 7439-7443\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 6 Sep 2020 20:47:20 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, Published at IEEE ICASSP 2020\\u00a7r"}']}
{title:'Wuth et al. (§72020§r)', author: 'Jorge Wuth; Richard M. Stern; Nestor Becerra Yoma', display:{Lore:['[{"text": "arXiv:2009.02832", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lNon causal deep learning based dereverberation\\u00a7r\\n\\n\\u00a78\\u00a7oJorge Wuth\\nRichard M. Stern\\nNestor Becerra Yoma\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2009.02832\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 6 Sep 2020 23:52:59 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o33 pages\\u00a7r"}']}
{title:'Chowdhury (§72020§r)', author: 'Jatin Chowdhury', display:{Lore:['[{"text": "arXiv:2009.02833", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Comparison of Virtual Analog Modelling Techniques for Desktop and Embedded Implementations\\u00a7r\\n\\n\\u00a78\\u00a7oJatin Chowdhury\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2009.02833\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 6 Sep 2020 23:56:41 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o8 pages, 12 figures. For associated code, see https://github.com/jatinchowdhury18/KlonCentaur . For associated audio examples, see https://www.youtube.com/playlist?list=PLrcXtWXbPsj11cNBamVyMmDcWY1SXZHvz\\u00a7r"}']}
{title:'Roberts et al. (§72020§r)', author: 'Timothy Roberts; Aaron Nicolson; Kuldip K. Paliwal', display:{Lore:['[{"text": "arXiv:2009.02940", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7eeess.SP\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDeep Learning-Based Single-Ended Objective Quality Measures for Time-Scale Modified Audio\\u00a7r\\n\\n\\u00a78\\u00a7oTimothy Roberts\\nAaron Nicolson\\nKuldip K. Paliwal\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2009.02940\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 7 Sep 2020 08:28:00 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o13 pages, 11 figures, Submitted to The Journal of the Acoustical Society of America\\u00a7r"}']}
{title:'Kim et al. (§72020§r)', author: 'Soohwan Kim; Seyoung Bae; Cheolhwang Won', display:{Lore:['[{"text": "arXiv:2009.03092", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lKoSpeech: Open-Source Toolkit for End-to-End Korean Speech Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oSoohwan Kim\\nSeyoung Bae\\nCheolhwang Won\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2009.03092\\u00a7r\\n\\nVersion:\\u00a77v2 (Sat, 26 Sep 2020 17:25:34 GMT)\\u00a7r"}']}
{title:'Wu et al. (§72020§r)', author: 'Jian Wu; Zhuo Chen; Jinyu Li; Takuya Yoshioka; Zhili Tan; Ed Lin; Yi Luo; Lei Xie', display:{Lore:['[{"text": "arXiv:2009.03141", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAn End-to-end Architecture of Online Multi-channel Speech Separation\\u00a7r\\n\\n\\u00a78\\u00a7oJian Wu\\nZhuo Chen\\nJinyu Li\\n+ 4 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2009.03141\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 7 Sep 2020 14:53:27 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 2 figures, accepted by Interspeech2020\\u00a7r"}']}
{title:'Das et al. (§72020§r)', author: 'Rohan Kumar Das; Tomi Kinnunen; Wen-Chin Huang; Zhenhua Ling; Junichi Yamagishi; Yi Zhao; Xiaohai Tian; Tomoki Toda', display:{Lore:['[{"text": "arXiv:2009.03554", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lPredictions of Subjective Ratings and Spoofing Assessments of Voice Conversion Challenge 2020 Submissions\\u00a7r\\n\\n\\u00a78\\u00a7oRohan Kumar Das\\nTomi Kinnunen\\nWen-Chin Huang\\n+ 4 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2009.03554\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 8 Sep 2020 07:17:58 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to ISCAJoint Workshop for the Blizzard Challenge and Voice Conversion Challenge 2020\\u00a7r"}']}
{title:'Shi et al. (§72020§r)', author: 'Ziqiang Shi; Jiqing Han', display:{Lore:['[{"text": "arXiv:2009.03692", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lToward Speech Separation in The Pre-Cocktail Party Problem with TasTas\\u00a7r\\n\\n\\u00a78\\u00a7oZiqiang Shi\\nJiqing Han\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2009.03692\\u00a7r\\n\\nVersion:\\u00a77v4 (Wed, 28 Oct 2020 02:06:30 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oarXiv admin note: substantial text overlap with arXiv:1902.04891\\u00a7r"}']}
{title:'Pan et al. (§72020§r)', author: 'Zexu Pan; Zhaojie Luo; Jichen Yang; Haizhou Li', display:{Lore:['[{"text": "arXiv:2009.04107", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.MM\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7eeess.IV\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMulti-modal Attention for Speech Emotion Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oZexu Pan\\nZhaojie Luo\\nJichen Yang\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2009.04107\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 9 Sep 2020 05:06:44 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted by Interspeech2020\\u00a7r"}']}
{title:'Cuesta et al. (§72020§r)', author: 'Helena Cuesta; Brian McFee; Emilia Gómez', display:{Lore:['[{"text": "arXiv:2009.04172", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMultiple F0 Estimation in Vocal Ensembles using Convolutional Neural Networks\\u00a7r\\n\\n\\u00a78\\u00a7oHelena Cuesta\\nBrian McFee\\nEmilia G\\u00f3mez\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2009.04172\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 9 Sep 2020 09:11:49 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted to the 21st International Society for Music Information Retrieval (ISMIR) Conference (2020)\\u00a7r"}']}
{title:'Wang et al. (§72020§r)', author: 'Quan Wang; Ignacio Lopez Moreno; Mert Saglam; Kevin Wilson; Alan Chiao; Renjie Liu; Yanzhang He; Wei Li; Jason Pelecanos; Marily Nika; Alexander Gruenstein', display:{Lore:['[{"text": "arXiv:2009.04323", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7eeess.SP\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lVoiceFilter-Lite: Streaming Targeted Voice Separation for On-Device Speech Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oQuan Wang\\nIgnacio Lopez Moreno\\nMert Saglam\\n+ 7 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2009.04323\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 9 Sep 2020 14:26:56 GMT)\\u00a7r"}']}
{title:'Sridhar et al. (§72020§r)', author: 'Kusha Sridhar; Ross Cutler; Ando Saabas; Tanel Parnamaa; Markus Loide; Hannes Gamper; Sebastian Braun; Robert Aichner; Sriram Srinivasan', display:{Lore:['[{"text": "arXiv:2009.04972", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lICASSP 2021 Acoustic Echo Cancellation Challenge: Datasets, Testing Framework, and Results\\u00a7r\\n\\n\\u00a78\\u00a7oKusha Sridhar\\nRoss Cutler\\nAndo Saabas\\n+ 5 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2009.04972\\u00a7r\\n\\nVersion:\\u00a77v3 (Fri, 30 Oct 2020 22:39:25 GMT)\\u00a7r"}']}
{title:'S et al. (§72020§r)', author: 'Karthik Pandia D S; Anusha Prakash; Mano Ranjith Kumar; Hema A Murthy', display:{Lore:['[{"text": "arXiv:2009.04983", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lExploration of End-to-end Synthesisers forZero Resource Speech Challenge 2020\\u00a7r\\n\\n\\u00a78\\u00a7oKarthik Pandia D S\\nAnusha Prakash\\nMano Ranjith Kumar\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2009.04983\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 10 Sep 2020 16:46:33 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted for publication in Interspeech 2020\\u00a7r"}']}
{title:'Scheibler (§72020§r)', author: 'Robin Scheibler', display:{Lore:['[{"text": "arXiv:2009.05288", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7eeess.SP\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lGeneralized Minimal Distortion Principle for Blind Source Separation\\u00a7r\\n\\n\\u00a78\\u00a7oRobin Scheibler\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2009.05288\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 11 Sep 2020 08:43:03 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 1 figure, 2 tables, Accepted at INTERSPEECH 2020\\u00a7r"}']}
{title:'Li et al. (§72020§r)', author: 'Jingyu Li; Tan Lee', display:{Lore:['[{"text": "arXiv:2009.05485", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lText-Independent Speaker Verification with Dual Attention Network\\u00a7r\\n\\n\\u00a78\\u00a7oJingyu Li\\nTan Lee\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2009.05485\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 11 Sep 2020 15:07:13 GMT)\\u00a7r"}']}
{title:'Stan (§72020§r)', author: 'Adriana Stan', display:{Lore:['[{"text": "arXiv:2009.05493", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lRECOApy: Data recording, pre-processing and phonetic transcription for end-to-end speech-based applications\\u00a7r\\n\\n\\u00a78\\u00a7oAdriana Stan\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2009.05493\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 15 Sep 2020 09:07:33 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted for publication at Interspeech 2020\\u00a7r"}']}
{title:'Phan et al. (§72020§r)', author: 'Huy Phan; Lam Pham; Philipp Koch; Ngoc Q. K. Duong; Ian McLoughlin; Alfred Mertins', display:{Lore:['[{"text": "arXiv:2009.05527", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lOn Multitask Loss Function for Audio Event Detection and Localization\\u00a7r\\n\\n\\u00a78\\u00a7oHuy Phan\\nLam Pham\\nPhilipp Koch\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2009.05527\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 11 Sep 2020 16:59:03 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted for publication in DCASE 2020 Workshop\\u00a7r"}']}
{title:'Bu et al. (§72020§r)', author: 'Yaohua Bu; Weijun Li; Tianyi Ma; Shengqi Chen; Jia Jia; Kun Li; Xiaobo Lu', display:{Lore:['[{"text": "arXiv:2009.05748", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.AI\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lVisual-speech Synthesis of Exaggerated Corrective Feedback\\u00a7r\\n\\n\\u00a78\\u00a7oYaohua Bu\\nWeijun Li\\nTianyi Ma\\n+ 3 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2009.05748\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 15 Dec 2020 13:16:53 GMT)\\u00a7r"}']}
{title:'Reddy et al. (§72020§r)', author: 'Chandan K A Reddy; Harishchandra Dubey; Vishak Gopal; Ross Cutler; Sebastian Braun; Hannes Gamper; Robert Aichner; Sriram Srinivasan', display:{Lore:['[{"text": "arXiv:2009.06122", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lICASSP 2021 Deep Noise Suppression Challenge\\u00a7r\\n\\n\\u00a78\\u00a7oChandan K A Reddy\\nHarishchandra Dubey\\nVishak Gopal\\n+ 4 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2009.06122\\u00a7r\\n\\nVersion:\\u00a77v2 (Mon, 26 Oct 2020 22:22:53 GMT)\\u00a7r"}']}
{title:'Raitio et al. (§72020§r)', author: 'Tuomo Raitio; Ramya Rasipuram; Dan Castellani', display:{Lore:['[{"text": "arXiv:2009.06775", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lControllable neural text-to-speech synthesis using intuitive prosodic features\\u00a7r\\n\\n\\u00a78\\u00a7oTuomo Raitio\\nRamya Rasipuram\\nDan Castellani\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2009.06775\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 14 Sep 2020 22:37:44 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted for publication in Interspeech 2020\\u00a7r"}']}
{title:'Zheng et al. (§72020§r)', author: 'Linlin Zheng; Jiakang Li; Meng Sun; Xiongwei Zhang; Thomas Fang Zheng', display:{Lore:['[{"text": "arXiv:2009.06863", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CR\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lWhen Automatic Voice Disguise Meets Automatic Speaker Verification\\u00a7r\\n\\n\\u00a78\\u00a7oLinlin Zheng\\nJiakang Li\\nMeng Sun\\nXiongwei Zhang\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2009.06863\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nIEEE Transactions on Information Forensics and Security, 2020\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 15 Sep 2020 04:41:52 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oaccepted for publication\\u00a7r"}']}
{title:'Chen et al. (§72020§r)', author: 'Wenda Chen; Jonathan Huang; Mark Hasegawa-Johnson', display:{Lore:['[{"text": "arXiv:2009.08064", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lUtterance-level Intent Recognition from Keywords\\u00a7r\\n\\n\\u00a78\\u00a7oWenda Chen\\nJonathan Huang\\nMark Hasegawa-Johnson\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2009.08064\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 17 Sep 2020 04:45:39 GMT)\\u00a7r"}']}
{title:'Li et al. (§72020§r)', author: 'Xiang Li; Yucheng Zhao; Chong Luo; Wenjun Zeng', display:{Lore:['[{"text": "arXiv:2009.08162", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lOnline Speaker Diarization with Relation Network\\u00a7r\\n\\n\\u00a78\\u00a7oXiang Li\\nYucheng Zhao\\nChong Luo\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2009.08162\\u00a7r\\n\\nVersion:\\u00a77v2 (Sat, 19 Sep 2020 01:33:39 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oWe findpotential incorrectness in our experimental results which may lead to a wrong conclusion. We decide to rerun the experiments to check our experimental results and temporarily withdraw this paper\\u00a7r"}']}
{title:'Haeb-Umbach et al. (§72020§r)', author: 'Reinhold Haeb-Umbach; Jahn Heymann; Lukas Drude; Shinji Watanabe; Marc Delcroix; Tomohiro Nakatani', display:{Lore:['[{"text": "arXiv:2009.09395", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lFar-Field Automatic Speech Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oReinhold Haeb-Umbach\\nJahn Heymann\\nLukas Drude\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2009.09395\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 20 Sep 2020 09:31:59 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oaccepted for Proceedings of the IEEE\\u00a7r"}']}
{title:'Brendel et al. (§72020§r)', author: 'Andreas Brendel; Walter Kellermann', display:{Lore:['[{"text": "arXiv:2009.09402", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAccelerating Auxiliary Function-based Independent Vector Analysis\\u00a7r\\n\\n\\u00a78\\u00a7oAndreas Brendel\\nWalter Kellermann\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2009.09402\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 20 Sep 2020 10:16:36 GMT)\\u00a7r"}']}
{title:'Sang et al. (§72020§r)', author: 'Mufan Sang; Wei Xia; John H. L. Hansen', display:{Lore:['[{"text": "arXiv:2009.09556", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lOpen-set Short Utterance Forensic Speaker Verification using Teacher-Student Network with Explicit Inductive Bias\\u00a7r\\n\\n\\u00a78\\u00a7oMufan Sang\\nWei Xia\\nJohn H. L. Hansen\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2009.09556\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 21 Sep 2020 00:58:40 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted to INTERSPEECH 2020\\u00a7r"}']}
{title:'Mandal et al. (§72020§r)', author: 'Sayan Mandal; Sarthak Yadav; Atul Rai', display:{Lore:['[{"text": "arXiv:2009.09615", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lEnd-to-End Bengali Speech Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oSayan Mandal\\nSarthak Yadav\\nAtul Rai\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2009.09615\\u00a7r\\n\\nVersion:\\u00a77v2 (Wed, 11 Nov 2020 05:30:57 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o4 pages, 2 figures, 3 tables\\u00a7r"}']}
{title:'Wu et al. (§72020§r)', author: 'Zhenzong Wu; Rohan Kumar Das; Jichen Yang; Haizhou Li', display:{Lore:['[{"text": "arXiv:2009.09637", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lLight Convolutional Neural Network with Feature Genuinization for Detection of Synthetic Speech Attacks\\u00a7r\\n\\n\\u00a78\\u00a7oZhenzong Wu\\nRohan Kumar Das\\nJichen Yang\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2009.09637\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 21 Sep 2020 06:38:19 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted for publication in Interspeech 2020\\u00a7r"}']}
{title:'Chandna et al. (§72020§r)', author: 'Pritish Chandna; Helena Cuesta; Emilia Gómez', display:{Lore:['[{"text": "arXiv:2009.09875", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Deep Learning Based Analysis-Synthesis Framework For Unison Singing\\u00a7r\\n\\n\\u00a78\\u00a7oPritish Chandna\\nHelena Cuesta\\nEmilia G\\u00f3mez\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2009.09875\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 21 Sep 2020 13:48:01 GMT)\\u00a7r"}']}
{title:'Chen et al. (§72020§r)', author: 'Yefei Chen; Shuai Wang; Yanmin Qian; Kai Yu', display:{Lore:['[{"text": "arXiv:2009.09906", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lEnd-to-End Speaker-Dependent Voice Activity Detection\\u00a7r\\n\\n\\u00a78\\u00a7oYefei Chen\\nShuai Wang\\nYanmin Qian\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2009.09906\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 21 Sep 2020 14:26:12 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oPublished in NCMMSC 2019\\u00a7r"}']}
{title:'Jafarzadeh et al. (§72020§r)', author: 'Mohsen Jafarzadeh; Yonas Tadesse', display:{Lore:['[{"text": "arXiv:2009.10283", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.RO\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7acs.SY\\u00a7r, \\u00a7eeess.SY\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lEnd-to-End Learning of Speech 2D Feature-Trajectory for Prosthetic Hands\\u00a7r\\n\\n\\u00a78\\u00a7oMohsen Jafarzadeh\\nYonas Tadesse\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2009.10283\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/TransAI49837.2020.00010\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7n2020 Second International Conference on Transdisciplinary AI\\n  (TransAI), pages 25-33\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 22 Sep 2020 02:31:00 GMT)\\u00a7r"}']}
{title:'Lou et al. (§72020§r)', author: 'Paria Jamshid Lou; Mark Johnson', display:{Lore:['[{"text": "arXiv:2009.10298", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lEnd-to-End Speech Recognition and Disfluency Removal\\u00a7r\\n\\n\\u00a78\\u00a7oParia Jamshid Lou\\nMark Johnson\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2009.10298\\u00a7r\\n\\nVersion:\\u00a77v3 (Mon, 28 Sep 2020 23:07:21 GMT)\\u00a7r"}']}
{title:'Priyasad et al. (§72020§r)', author: 'Darshana Priyasad; Tharindu Fernando; Simon Denman; Clinton Fookes; Sridha Sridharan', display:{Lore:['[{"text": "arXiv:2009.10991", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.HC\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAttention Driven Fusion for Multi-Modal Emotion Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oDarshana Priyasad\\nTharindu Fernando\\nSimon Denman\\nClinton Fookes\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2009.10991\\u00a7r\\n\\nVersion:\\u00a77v2 (Sat, 10 Oct 2020 22:25:20 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAn updated version of the ICASSP 2020 paper\\u00a7r"}']}
{title:'Mathad et al. (§72020§r)', author: 'Vikram C. Mathad; Nancy Scherer; Kathy Chapman; Julie M. Liss; Visar Berisha', display:{Lore:['[{"text": "arXiv:2009.11354", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Deep Learning Algorithm for Objective Assessment of Hypernasality in Children with Cleft Palate\\u00a7r\\n\\n\\u00a78\\u00a7oVikram C. Mathad\\nNancy Scherer\\nKathy Chapman\\nJulie M. Liss\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2009.11354\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 23 Sep 2020 19:53:39 GMT)\\u00a7r"}']}
{title:'Kourkounakis et al. (§72020§r)', author: 'Tedd Kourkounakis; Amirhossein Hajavi; Ali Etemad', display:{Lore:['[{"text": "arXiv:2009.11394", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lFluentNet: End-to-End Detection of Speech Disfluency with Deep Learning\\u00a7r\\n\\n\\u00a78\\u00a7oTedd Kourkounakis\\nAmirhossein Hajavi\\nAli Etemad\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2009.11394\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 23 Sep 2020 21:51:29 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o13 pages, 6 figures\\u00a7r"}']}
{title:'Takeuchi et al. (§72020§r)', author: 'Daiki Takeuchi; Yuma Koizumi; Yasunori Ohishi; Noboru Harada; Kunio Kashino', display:{Lore:['[{"text": "arXiv:2009.11436", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lEffects of Word-frequency based Pre- and Post- Processings for Audio Captioning\\u00a7r\\n\\n\\u00a78\\u00a7oDaiki Takeuchi\\nYuma Koizumi\\nYasunori Ohishi\\nNoboru Harada\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2009.11436\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 24 Sep 2020 01:07:33 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted to DCASE2020 Workshop\\u00a7r"}']}
{title:'Delgado et al. (§72020§r)', author: 'Alejandro Delgado; SKoT McDonald; Ning Xu; Mark Sandler', display:{Lore:['[{"text": "arXiv:2009.11737", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA New Dataset for Amateur Vocal Percussion Analysis\\u00a7r\\n\\n\\u00a78\\u00a7oAlejandro Delgado\\nSKoT McDonald\\nNing Xu\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2009.11737\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1145/3356590.3356844\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 24 Sep 2020 14:57:10 GMT)\\u00a7r"}']}
{title:'Purohit et al. (§72020§r)', author: 'Harsh Purohit; Ryo Tanabe; Takashi Endo; Kaori Suefusa; Yuki Nikaido; Yohei Kawaguchi', display:{Lore:['[{"text": "arXiv:2009.12042", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDeep Autoencoding GMM-based Unsupervised Anomaly Detection in Acoustic Signals and its Hyper-parameter Optimization\\u00a7r\\n\\n\\u00a78\\u00a7oHarsh Purohit\\nRyo Tanabe\\nTakashi Endo\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2009.12042\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 25 Sep 2020 06:14:59 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, to appear in DCASE 2020 Workshop\\u00a7r"}']}
{title:'Braun et al. (§72020§r)', author: 'Sebastian Braun; Ivan Tashev', display:{Lore:['[{"text": "arXiv:2009.12286", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA consolidated view of loss functions for supervised deep learning-based speech enhancement\\u00a7r\\n\\n\\u00a78\\u00a7oSebastian Braun\\nIvan Tashev\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2009.12286\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 25 Sep 2020 15:17:26 GMT)\\u00a7r"}']}
{title:'Hajavi et al. (§72020§r)', author: 'Amirhossein Hajavi; Ali Etemad', display:{Lore:['[{"text": "arXiv:2009.13480", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSiamese Capsule Network for End-to-End Speaker Recognition In The Wild\\u00a7r\\n\\n\\u00a78\\u00a7oAmirhossein Hajavi\\nAli Etemad\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2009.13480\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 28 Sep 2020 17:11:11 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to ICASSP2021\\u00a7r"}']}
{title:'Surana et al. (§72020§r)', author: 'Aayush Surana; Yash Goyal; Vinoo Alluri', display:{Lore:['[{"text": "arXiv:2009.13685", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.IR\\u00a7r, \\u00a7acs.MM\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lStatic and Dynamic Measures of Active Music Listening as Indicators of Depression Risk\\u00a7r\\n\\n\\u00a78\\u00a7oAayush Surana\\nYash Goyal\\nVinoo Alluri\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2009.13685\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 28 Sep 2020 23:29:53 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAppearing in the proceedings of the Speech, Music and Mind Workshop 2020, a satellite workshop of INTERSPEECH 2020\\u00a7r"}']}
{title:'Li et al. (§72020§r)', author: 'Ke Li; Daniel Povey; Sanjeev Khudanpur', display:{Lore:['[{"text": "arXiv:2009.13774", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lNeural Language Modeling With Implicit Cache Pointers\\u00a7r\\n\\n\\u00a78\\u00a7oKe Li\\nDaniel Povey\\nSanjeev Khudanpur\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2009.13774\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 29 Sep 2020 04:19:55 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oTo appear at Interspeech 2020\\u00a7r"}']}
{title:'Heo et al. (§72020§r)', author: 'Hee Soo Heo; Bong-Jin Lee; Jaesung Huh; Joon Son Chung', display:{Lore:['[{"text": "arXiv:2009.14153", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lClova Baseline System for the VoxCeleb Speaker Recognition Challenge 2020\\u00a7r\\n\\n\\u00a78\\u00a7oHee Soo Heo\\nBong-Jin Lee\\nJaesung Huh\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2009.14153\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 29 Sep 2020 16:55:25 GMT)\\u00a7r"}']}
{title:'Schiller et al. (§72020§r)', author: 'Dominik Schiller; Silvan Mertes; Elisabeth André', display:{Lore:['[{"text": "arXiv:2009.14523", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lEmbedded Emotions \\u2013 A Data Driven Approach to Learn Transferable Feature Representations from Raw Speech Input for Emotion Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oDominik Schiller\\nSilvan Mertes\\nElisabeth Andr\\u00e9\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2009.14523\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 30 Sep 2020 09:18:31 GMT)\\u00a7r"}']}
{title:'Chang (§72020§r)', author: 'Che-Jui Chang', display:{Lore:['[{"text": "arXiv:2009.14668", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lTransfer Learning from Monolingual ASR to Transcription-free Cross-lingual Voice Conversion\\u00a7r\\n\\n\\u00a78\\u00a7oChe-Jui Chang\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2009.14668\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 30 Sep 2020 13:44:35 GMT)\\u00a7r"}']}
{title:'Cao et al. (§72020§r)', author: 'Yin Cao; Turab Iqbal; Qiuqiang Kong; Yue Zhong; Wenwu Wang; Mark D. Plumbley', display:{Lore:['[{"text": "arXiv:2010.00140", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lEvent-Independent Network for Polyphonic Sound Event Localization and Detection\\u00a7r\\n\\n\\u00a78\\u00a7oYin Cao\\nTurab Iqbal\\nQiuqiang Kong\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.00140\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 30 Sep 2020 23:01:33 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oconference\\u00a7r"}']}
{title:'Sridhar et al. (§72020§r)', author: 'Sripathi Sridhar; Vincent Lostanlen', display:{Lore:['[{"text": "arXiv:2010.00673", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lHelicality: An Isomap-based Measure of Octave Equivalence in Audio Data\\u00a7r\\n\\n\\u00a78\\u00a7oSripathi Sridhar\\nVincent Lostanlen\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.00673\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 1 Oct 2020 20:30:05 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o3 pages, 3 figures. To be presented at the 21st International Society for Music Information Retrieval (ISMIR) Conference. Montreal, Canada, October 2020\\u00a7r"}']}
{title:'Parthasarathy et al. (§72020§r)', author: 'Srinivas Parthasarathy; Shiva Sundaram', display:{Lore:['[{"text": "arXiv:2010.00734", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7eeess.IV\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lTraining Strategies to Handle Missing Modalities for Audio-Visual Expression Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oSrinivas Parthasarathy\\nShiva Sundaram\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.00734\\u00a7r\\n\\nVersion:\\u00a77v2 (Mon, 30 Nov 2020 19:47:45 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oICMI 2020 workshop on \\"MODELING SOCIO-EMOTIONAL AND COGNITIVE PROCESSES FROM MULTIMODAL DATA IN THE WILD\\"\\u00a7r"}']}
{title:'Kwon et al. (§72020§r)', author: 'Taegyun Kwon; Dasaem Jeong; Juhan Nam', display:{Lore:['[{"text": "arXiv:2010.01104", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lPolyphonic Piano Transcription Using Autoregressive Multi-State Note Model\\u00a7r\\n\\n\\u00a78\\u00a7oTaegyun Kwon\\nDasaem Jeong\\nJuhan Nam\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.01104\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 2 Oct 2020 17:03:19 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o6+2 pages, 5 figures, Camera-ready version.To be published in ISMIR2020. Project page is available at https://TaegyunKwon.github.io/ar_multi_transcription\\u00a7r"}']}
{title:'Takamichi et al. (§72020§r)', author: 'Shinnosuke Takamichi; Mamoru Komachi; Naoko Tanji; Hiroshi Saruwatari', display:{Lore:['[{"text": "arXiv:2010.01793", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lJSSS: free Japanese speech corpus for summarization and simplification\\u00a7r\\n\\n\\u00a78\\u00a7oShinnosuke Takamichi\\nMamoru Komachi\\nNaoko Tanji\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.01793\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 5 Oct 2020 05:46:10 GMT)\\u00a7r"}']}
{title:'Gillespie et al. (§72020§r)', author: 'Kellen Gillespie; Ioannis C. Konstantakopoulos; Xingzhi Guo; Vishal Thanvantri Vasudevan; Abhinav Sethy', display:{Lore:['[{"text": "arXiv:2010.01949", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lImproving Device Directedness Classification of Utterances with Semantic Lexical Features\\u00a7r\\n\\n\\u00a78\\u00a7oKellen Gillespie\\nIoannis C. Konstantakopoulos\\nXingzhi Guo\\nVishal Thanvantri Vasudevan\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.01949\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/ICASSP40776.2020.9054304\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7n2020 IEEE International Conference on Acoustics, Speech and Signal\\n  Processing (ICASSP), Barcelona, Spain, 2020, pp. 7859-7863\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 29 Sep 2020 20:13:58 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted and Published at ICASSP 2020\\u00a7r"}']}
{title:'Huang et al. (§72020§r)', author: 'Wen-Chin Huang; Tomoki Hayashi; Shinji Watanabe; Tomoki Toda', display:{Lore:['[{"text": "arXiv:2010.02434", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lThe Sequence-to-Sequence Baseline for the Voice Conversion Challenge 2020: Cascading ASR and TTS\\u00a7r\\n\\n\\u00a78\\u00a7oWen-Chin Huang\\nTomoki Hayashi\\nShinji Watanabe\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.02434\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 6 Oct 2020 02:27:38 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted to the ISCA Joint Workshop for the Blizzard Challenge and Voice Conversion Challenge 2020\\u00a7r"}']}
{title:'Jung et al. (§72020§r)', author: 'Youngmoon Jung; Yeunju Choi; Hyungjun Lim; Hoirin Kim', display:{Lore:['[{"text": "arXiv:2010.02477", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7cstat.ML\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Unified Deep Learning Framework for Short-Duration Speaker Verification in Adverse Environments\\u00a7r\\n\\n\\u00a78\\u00a7oYoungmoon Jung\\nYeunju Choi\\nHyungjun Lim\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.02477\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/ACCESS.2020.3025941\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nin IEEE Access, vol. 8, pp. 175448-175466, 2020\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 6 Oct 2020 04:51:45 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o19 pages, 10 figures, 13 tables\\u00a7r"}']}
{title:'Peng et al. (§72020§r)', author: 'Yu-Huai Peng; Cheng-Hung Hu; Alexander Kang; Hung-Shin Lee; Pin-Yuan Chen; Yu Tsao; Hsin-Min Wang', display:{Lore:['[{"text": "arXiv:2010.02669", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lThe Academia Sinica Systems of Voice Conversion for VCC2020\\u00a7r\\n\\n\\u00a78\\u00a7oYu-Huai Peng\\nCheng-Hung Hu\\nAlexander Kang\\n+ 3 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.02669\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 6 Oct 2020 12:40:06 GMT)\\u00a7r"}']}
{title:'Gaddy et al. (§72020§r)', author: 'David Gaddy; Dan Klein', display:{Lore:['[{"text": "arXiv:2010.02960", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDigital Voicing of Silent Speech\\u00a7r\\n\\n\\u00a78\\u00a7oDavid Gaddy\\nDan Klein\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.02960\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 6 Oct 2020 18:23:35 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oEMNLP 2020\\u00a7r"}']}
{title:'Madikeri et al. (§72020§r)', author: 'Srikanth Madikeri; Sibo Tong; Juan Zuluaga-Gomez; Apoorv Vyas; Petr Motlicek; Hervé Bourlard', display:{Lore:['[{"text": "arXiv:2010.03466", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lPkwrap: a PyTorch Package for LF-MMI Training of Acoustic Models\\u00a7r\\n\\n\\u00a78\\u00a7oSrikanth Madikeri\\nSibo Tong\\nJuan Zuluaga-Gomez\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.03466\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 7 Oct 2020 15:02:11 GMT)\\u00a7r"}']}
{title:'Luong et al. (§72020§r)', author: 'Hieu-Thi Luong; Junichi Yamagishi', display:{Lore:['[{"text": "arXiv:2010.03717", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lLatent linguistic embedding for cross-lingual text-to-speech and voice conversion\\u00a7r\\n\\n\\u00a78\\u00a7oHieu-Thi Luong\\nJunichi Yamagishi\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.03717\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 8 Oct 2020 01:25:07 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted to Voice Conversion Challenge 2020 Online Workshop\\u00a7r"}']}
{title:'Das et al. (§72020§r)', author: 'Rohan Kumar Das; Ruijie Tao; Jichen Yang; Wei Rao; Cheng Yu; Haizhou Li', display:{Lore:['[{"text": "arXiv:2010.03905", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lHLT-NUS Submission for NIST 2019 Multimedia Speaker Recognition Evaluation\\u00a7r\\n\\n\\u00a78\\u00a7oRohan Kumar Das\\nRuijie Tao\\nJichen Yang\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.03905\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 8 Oct 2020 11:21:41 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted for publication in APSIPA ASC 2020\\u00a7r"}']}
{title:'Das et al. (§72020§r)', author: 'Rohan Kumar Das; Haizhou Li', display:{Lore:['[{"text": "arXiv:2010.03907", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lClassification of Speech with and without Face Mask using Acoustic Features\\u00a7r\\n\\n\\u00a78\\u00a7oRohan Kumar Das\\nHaizhou Li\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.03907\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 8 Oct 2020 11:36:32 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted for publication in APSIPA ASC 2020\\u00a7r"}']}
{title:'Sarma et al. (§72020§r)', author: 'Biswajit Dev Sarma; Rohan Kumar Das', display:{Lore:['[{"text": "arXiv:2010.03909", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lEmotion Invariant Speaker Embeddings for Speaker Identification with Emotional Speech\\u00a7r\\n\\n\\u00a78\\u00a7oBiswajit Dev Sarma\\nRohan Kumar Das\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.03909\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 8 Oct 2020 11:43:16 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted for publication in APSIPA ASC 2020\\u00a7r"}']}
{title:'Mayor et al. (§72020§r)', author: 'Oriol Barbany Mayor; Milos Cernak', display:{Lore:['[{"text": "arXiv:2010.04185", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lFastVC: Fast Voice Conversion with non-parallel data\\u00a7r\\n\\n\\u00a78\\u00a7oOriol Barbany Mayor\\nMilos Cernak\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.04185\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.21437/VCC_BC.2020-21\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 8 Oct 2020 18:05:30 GMT)\\u00a7r"}']}
{title:'Artem et al. (§72020§r)', author: 'Sokolov Artem; Andrey V. Savchenko', display:{Lore:['[{"text": "arXiv:2010.04224", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lGender domain adaptation for automatic speech recognition task\\u00a7r\\n\\n\\u00a78\\u00a7oSokolov Artem\\nAndrey V. Savchenko\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.04224\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 17 Nov 2020 11:40:01 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oDraft of paper for SAMI conference\\u00a7r"}']}
{title:'Huang et al. (§72020§r)', author: 'Wen-Chin Huang; Patrick Lumban Tobing; Yi-Chiao Wu; Kazuhiro Kobayashi; Tomoki Toda', display:{Lore:['[{"text": "arXiv:2010.04446", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lThe NU Voice Conversion System for the Voice Conversion Challenge 2020: On the Effectiveness of Sequence-to-sequence Models and Autoregressive Neural Vocoders\\u00a7r\\n\\n\\u00a78\\u00a7oWen-Chin Huang\\nPatrick Lumban Tobing\\nYi-Chiao Wu\\nKazuhiro Kobayashi\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.04446\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 9 Oct 2020 09:19:37 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted to the ISCA Joint Workshop for the Blizzard Challenge and Voice Conversion Challenge 2020\\u00a7r"}']}
{title:'Hu et al. (§72020§r)', author: 'Shichao Hu; Bin Zhang; Beici Liang; Ethan Zhao; Simon Lui', display:{Lore:['[{"text": "arXiv:2010.04506", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lPhase-aware music super-resolution using generative adversarial networks\\u00a7r\\n\\n\\u00a78\\u00a7oShichao Hu\\nBin Zhang\\nBeici Liang\\nEthan Zhao\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.04506\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 9 Oct 2020 11:34:39 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oThis paper has been accepted to Interspeech 2020 (http://www.interspeech2020.org/)\\u00a7r"}']}
{title:'Korse et al. (§72020§r)', author: 'Srikanth Korse; Kishan Gupta; Guillaume Fuchs', display:{Lore:['[{"text": "arXiv:2010.05571", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7eeess.SP\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lEnhancement Of Coded Speech Using a Mask-Based Post-Filter\\u00a7r\\n\\n\\u00a78\\u00a7oSrikanth Korse\\nKishan Gupta\\nGuillaume Fuchs\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.05571\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/ICASSP40776.2020.9053283\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 12 Oct 2020 09:48:09 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oICASSP 2020 - 2020 IEEE InternationalConference on Acoustics, Speech and Signal Processing (ICASSP)\\u00a7r"}']}
{title:'Camerer (§72020§r)', author: 'Florian Camerer', display:{Lore:['[{"text": "arXiv:2010.05877", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDesigning a 9-channel location microphone from scratch\\u00a7r\\n\\n\\u00a78\\u00a7oFlorian Camerer\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.05877\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 12 Oct 2020 17:27:39 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oThis is a long version of an AES e-Brief to be held at the 149th AES convention in Oct 2020\\u00a7r"}']}
{title:'Dawalatabad et al. (§72020§r)', author: 'Nauman Dawalatabad; Srikanth Madikeri; C. Chandra Sekhar; Hema A. Murthy', display:{Lore:['[{"text": "arXiv:2010.06304", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lNovel Architectures for Unsupervised Information Bottleneck based Speaker Diarization of Meetings\\u00a7r\\n\\n\\u00a78\\u00a7oNauman Dawalatabad\\nSrikanth Madikeri\\nC. Chandra Sekhar\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.06304\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/TASLP.2020.3036231\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nIEEE/ACM Transactions on Audio, Speech, and Language Processing,\\n  vol. 29, 2021, pp 14-27\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 13 Oct 2020 11:44:02 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted in IEEE/ACM TRANSACTIONS ON AUDIO, SPEECH, AND LANGUAGE PROCESSING\\u00a7r"}']}
{title:'Ronchini et al. (§72020§r)', author: 'Francesca Ronchini; Daniel Arteaga; Andrés Pérez-López', display:{Lore:['[{"text": "arXiv:2010.06422", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSound event localization and detection based on crnn using rectangular filters and channel rotation data augmentation\\u00a7r\\n\\n\\u00a78\\u00a7oFrancesca Ronchini\\nDaniel Arteaga\\nAndr\\u00e9s P\\u00e9rez-L\\u00f3pez\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.06422\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nProceedings of the Detection and Classification of Acoustic Scenes\\n  and Events 2020 Workshop (DCASE2020)\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 13 Oct 2020 14:30:38 GMT)\\u00a7r"}']}
{title:'Gao et al. (§72020§r)', author: 'Yixin Gao; Yuriy Mishchenko; Anish Shah; Spyros Matsoukas; Shiv Vitaladevuni', display:{Lore:['[{"text": "arXiv:2010.06659", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lTowards Data-efficient Modeling for Wake Word Spotting\\u00a7r\\n\\n\\u00a78\\u00a7oYixin Gao\\nYuriy Mishchenko\\nAnish Shah\\nSpyros Matsoukas\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.06659\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nProc. ICASSP 2020\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 13 Oct 2020 19:50:26 GMT)\\u00a7r"}']}
{title:'Gao et al. (§72020§r)', author: 'Yixin Gao; Noah D. Stein; Chieh-Chi Kao; Yunliang Cai; Ming Sun; Tao Zhang; Shiv Vitaladevuni', display:{Lore:['[{"text": "arXiv:2010.06676", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lOn Front-end Gain Invariant Modeling for Wake Word Spotting\\u00a7r\\n\\n\\u00a78\\u00a7oYixin Gao\\nNoah D. Stein\\nChieh-Chi Kao\\n+ 3 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.06676\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 13 Oct 2020 20:23:47 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oIn Proc. Interspeech 2020\\u00a7r"}']}
{title:'Kürzinger et al. (§72020§r)', author: 'Ludwig Kürzinger; Nicolas Lindae; Palle Klewitz; Gerhard Rigoll', display:{Lore:['[{"text": "arXiv:2010.07597", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7eeess.SP\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lLightweight End-to-End Speech Recognition from Raw Audio Data Using Sinc-Convolutions\\u00a7r\\n\\n\\u00a78\\u00a7oLudwig K\\u00fcrzinger\\nNicolas Lindae\\nPalle Klewitz\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.07597\\u00a7r\\n\\nVersion:\\u00a77v2 (Fri, 16 Oct 2020 07:34:01 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted at INTERSPEECH 2020\\u00a7r"}']}
{title:'Chettri et al. (§72020§r)', author: 'Bhusan Chettri; Emmanouil Benetos; Bob L. T. Sturm', display:{Lore:['[{"text": "arXiv:2010.07913", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDataset artefacts in anti-spoofing systems: a case study on the ASVspoof 2017 benchmark\\u00a7r\\n\\n\\u00a78\\u00a7oBhusan Chettri\\nEmmanouil Benetos\\nBob L. T. Sturm\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.07913\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 15 Oct 2020 17:46:49 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted to IEEE/ACM Transactionson Audio, Speech, and Language Processing, 2020\\u00a7r"}']}
{title:'Wang et al. (§72020§r)', author: 'Rui Wang; Zhihua Wei; Yibin Zhan; Zhuoxi Chen', display:{Lore:['[{"text": "arXiv:2010.08179", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lTongji University Team for the VoxCeleb Speaker Recognition Challenge 2020\\u00a7r\\n\\n\\u00a78\\u00a7oRui Wang\\nZhihua Wei\\nYibin Zhan\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.08179\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 16 Oct 2020 05:51:02 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o4 pages, 1 figures, interspeech workshop\\u00a7r"}']}
{title:'Romana et al. (§72020§r)', author: 'Amrit Romana; John Bandon; Noelle Carlozzi; Angela Roberts; Emily Mower Provost', display:{Lore:['[{"text": "arXiv:2010.08503", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lClassification of Manifest Huntington Disease using Vowel Distortion Measures\\u00a7r\\n\\n\\u00a78\\u00a7oAmrit Romana\\nJohn Bandon\\nNoelle Carlozzi\\nAngela Roberts\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.08503\\u00a7r\\n\\nVersion:\\u00a77v2 (Mon, 19 Oct 2020 16:34:09 GMT)\\u00a7r"}']}
{title:'Vuong et al. (§72020§r)', author: 'Tyler Vuong; Yangyang Xia; Richard Stern', display:{Lore:['[{"text": "arXiv:2010.09151", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lLearnable Spectro-temporal Receptive Fields for Robust Voice Type Discrimination\\u00a7r\\n\\n\\u00a78\\u00a7oTyler Vuong\\nYangyang Xia\\nRichard Stern\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.09151\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.21437/Interspeech.2020-1878\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 19 Oct 2020 00:29:02 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted Interspeech 2020. Video: http://www.interspeech2020.org/index.php?m=content c=index a=show catid=311 id=712\\u00a7r"}']}
{title:'Han et al. (§72020§r)', author: 'Jiangyu Han; Xinyuan Zhou; Yanhua Long; Yijie Li', display:{Lore:['[{"text": "arXiv:2010.09191", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMulti-channel target speech extraction with channel decorrelation and target speaker adaptation\\u00a7r\\n\\n\\u00a78\\u00a7oJiangyu Han\\nXinyuan Zhou\\nYanhua Long\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.09191\\u00a7r\\n\\nVersion:\\u00a77v2 (Thu, 22 Oct 2020 00:53:48 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 3 figures. Submitted to ICASSP 2021\\u00a7r"}']}
{title:'Yasuda et al. (§72020§r)', author: 'Yusuke Yasuda; Xin Wang; Junichi Yamagishi', display:{Lore:['[{"text": "arXiv:2010.09602", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lEnd-to-End Text-to-Speech using Latent Duration based on VQ-VAE\\u00a7r\\n\\n\\u00a78\\u00a7oYusuke Yasuda\\nXin Wang\\nJunichi Yamagishi\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.09602\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 20 Oct 2020 13:46:35 GMT)\\u00a7r"}']}
{title:'Li et al. (§72020§r)', author: 'Ximin Li; Xiaodong Wei; Xiaowei Qin', display:{Lore:['[{"text": "arXiv:2010.09960", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSmall-Footprint Keyword Spotting with Multi-Scale Temporal Convolution\\u00a7r\\n\\n\\u00a78\\u00a7oXimin Li\\nXiaodong Wei\\nXiaowei Qin\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.09960\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 20 Oct 2020 02:07:07 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted in INTERSPEECH 2020\\u00a7r"}']}
{title:'Steinmetz et al. (§72020§r)', author: 'Christian J. Steinmetz; Jordi Pons; Santiago Pascual; Joan Serrà', display:{Lore:['[{"text": "arXiv:2010.10291", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAutomatic multitrack mixing with a differentiable mixing console of neural audio effects\\u00a7r\\n\\n\\u00a78\\u00a7oChristian J. Steinmetz\\nJordi Pons\\nSantiago Pascual\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.10291\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 20 Oct 2020 14:04:22 GMT)\\u00a7r"}']}
{title:'Dighe et al. (§72020§r)', author: 'Pranay Dighe; Erik Marchi; Srikanth Vishnubhotla; Sachin Kajarekar; Devang Naik', display:{Lore:['[{"text": "arXiv:2010.10591", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lKnowledge Transfer for Efficient On-device False Trigger Mitigation\\u00a7r\\n\\n\\u00a78\\u00a7oPranay Dighe\\nErik Marchi\\nSrikanth Vishnubhotla\\nSachin Kajarekar\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.10591\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 20 Oct 2020 20:01:44 GMT)\\u00a7r"}']}
{title:'Ismail et al. (§72020§r)', author: 'Mahmoud Al Ismail; Soham Deshmukh; Rita Singh', display:{Lore:['[{"text": "arXiv:2010.10707", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDetection of COVID-19 through the analysis of vocal fold oscillations\\u00a7r\\n\\n\\u00a78\\u00a7oMahmoud Al Ismail\\nSoham Deshmukh\\nRita Singh\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.10707\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 21 Oct 2020 01:44:42 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 6 figures\\u00a7r"}']}
{title:'Jiao (§72020§r)', author: 'Yang Jiao', display:{Lore:['[{"text": "arXiv:2010.10892", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lBERT for Joint Multichannel Speech Dereverberation with Spatial-aware Tasks\\u00a7r\\n\\n\\u00a78\\u00a7oYang Jiao\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.10892\\u00a7r\\n\\nVersion:\\u00a77v2 (Thu, 22 Oct 2020 02:41:39 GMT)\\u00a7r"}']}
{title:'Khan et al. (§72020§r)', author: 'Umair Khan; Javier Hernando', display:{Lore:['[{"text": "arXiv:2010.10937", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lThe UPC Speaker Verification System Submitted to VoxCeleb Speaker Recognition Challenge 2020 (VoxSRC-20)\\u00a7r\\n\\n\\u00a78\\u00a7oUmair Khan\\nJavier Hernando\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.10937\\u00a7r\\n\\nVersion:\\u00a77v2 (Tue, 27 Oct 2020 16:07:30 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oVoxSRC-20 Workshop (Interspeech2020 Conference)\\u00a7r"}']}
{title:'Brazier et al. (§72020§r)', author: 'Charles Brazier; Gerhard Widmer', display:{Lore:['[{"text": "arXiv:2010.11013", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAddressing the Recitative Problem in Real-time Opera Tracking\\u00a7r\\n\\n\\u00a78\\u00a7oCharles Brazier\\nGerhard Widmer\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.11013\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 21 Oct 2020 13:52:47 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o12 pages, 1 figure, In Proceedings of the 25th International Symposium on Frontiersof Research in Speech and Music (FRSM 2020), Silchar, India\\u00a7r"}']}
{title:'Ajisafe et al. (§72020§r)', author: 'Daniel Ajisafe; Oluwabukola Adegboro; Esther Oduntan; Tayo Arulogun', display:{Lore:['[{"text": "arXiv:2010.11123", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.AI\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lTowards End-to-End Training of Automatic Speech Recognition for Nigerian Pidgin\\u00a7r\\n\\n\\u00a78\\u00a7oDaniel Ajisafe\\nOluwabukola Adegboro\\nEsther Oduntan\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.11123\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 21 Oct 2020 16:32:58 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oTo appear in ICASSP 2021\\u00a7r"}']}
{title:'Cho et al. (§72020§r)', author: 'Jaejin Cho; Piotr Zelasko; Jesus Villalba; Shinji Watanabe; Najim Dehak', display:{Lore:['[{"text": "arXiv:2010.11221", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lLearning Speaker Embedding from Text-to-Speech\\u00a7r\\n\\n\\u00a78\\u00a7oJaejin Cho\\nPiotr Zelasko\\nJesus Villalba\\nShinji Watanabe\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.11221\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 21 Oct 2020 18:03:16 GMT)\\u00a7r"}']}
{title:'Mun et al. (§72020§r)', author: 'Sung Hwan Mun; Woo Hyun Kang; Min Hyun Han; Nam Soo Kim', display:{Lore:['[{"text": "arXiv:2010.11408", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lRobust Text-Dependent Speaker Verification via Character-Level Information Preservation for the SdSV Challenge 2020\\u00a7r\\n\\n\\u00a78\\u00a7oSung Hwan Mun\\nWoo Hyun Kang\\nMin Hyun Han\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.11408\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 22 Oct 2020 03:22:24 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted in INTERSPEECH 2020\\u00a7r"}']}
{title:'Li et al. (§72020§r)', author: 'Qiujia Li; David Qiu; Yu Zhang; Bo Li; Yanzhang He; Philip C. Woodland; Liangliang Cao; Trevor Strohman', display:{Lore:['[{"text": "arXiv:2010.11428", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lConfidence Estimation for Attention-based Sequence-to-sequence Models for Speech Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oQiujia Li\\nDavid Qiu\\nYu Zhang\\n+ 4 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.11428\\u00a7r\\n\\nVersion:\\u00a77v2 (Fri, 23 Oct 2020 18:49:07 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to ICASSP 2021\\u00a7r"}']}
{title:'Mun et al. (§72020§r)', author: 'Sung Hwan Mun; Woo Hyun Kang; Min Hyun Han; Nam Soo Kim', display:{Lore:['[{"text": "arXiv:2010.11433", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lUnsupervised Representation Learning for Speaker Recognition via Contrastive Equilibrium Learning\\u00a7r\\n\\n\\u00a78\\u00a7oSung Hwan Mun\\nWoo Hyun Kang\\nMin Hyun Han\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.11433\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 22 Oct 2020 04:25:13 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 1 figure, 4 tables\\u00a7r"}']}
{title:'Lee et al. (§72020§r)', author: 'Jangho Lee; Jaihyun Koh; Sungroh Yoon', display:{Lore:['[{"text": "arXiv:2010.11457", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMomentum Contrast Speaker Representation Learning\\u00a7r\\n\\n\\u00a78\\u00a7oJangho Lee\\nJaihyun Koh\\nSungroh Yoon\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.11457\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 22 Oct 2020 05:46:13 GMT)\\u00a7r"}']}
{title:'Xiao et al. (§72020§r)', author: 'Xiong Xiao; Naoyuki Kanda; Zhuo Chen; Tianyan Zhou; Takuya Yoshioka; Sanyuan Chen; Yong Zhao; Gang Liu; Yu Wu; Jian Wu; Shujie Liu; Jinyu Li; Yifan Gong', display:{Lore:['[{"text": "arXiv:2010.11458", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMicrosoft Speaker Diarization System for the VoxCeleb Speaker Recognition Challenge 2020\\u00a7r\\n\\n\\u00a78\\u00a7oXiong Xiao\\nNaoyuki Kanda\\nZhuo Chen\\n+ 9 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.11458\\u00a7r\\n\\nVersion:\\u00a77v2 (Fri, 23 Oct 2020 01:12:12 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 3 figures, 2 tables\\u00a7r"}']}
{title:'Zhang et al. (§72020§r)', author: 'Haobo Zhang; Tingzhi Mao; Haihua Xu; Hao Huang', display:{Lore:['[{"text": "arXiv:2010.11489", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lThe NTU-AISG Text-to-speech System for Blizzard Challenge 2020\\u00a7r\\n\\n\\u00a78\\u00a7oHaobo Zhang\\nTingzhi Mao\\nHaihua Xu\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.11489\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 22 Oct 2020 07:18:08 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, Technical Report\\u00a7r"}']}
{title:'Kato et al. (§72020§r)', author: 'Shuhei Kato; Yusuke Yasuda; Xin Wang; Erica Cooper; Junichi Yamagishi', display:{Lore:['[{"text": "arXiv:2010.11549", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lHow Similar or Different Is Rakugo Speech Synthesizer to Professional Performers?\\u00a7r\\n\\n\\u00a78\\u00a7oShuhei Kato\\nYusuke Yasuda\\nXin Wang\\nErica Cooper\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.11549\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 22 Oct 2020 09:21:26 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to ICASSP 2021\\u00a7r"}']}
{title:'Aroudi et al. (§72020§r)', author: 'Ali Aroudi; Sebastian Braun', display:{Lore:['[{"text": "arXiv:2010.11566", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.AI\\u00a7r, \\u00a7eeess.SP\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDBNET: DOA-driven beamforming network for end-to-end farfield sound source separation\\u00a7r\\n\\n\\u00a78\\u00a7oAli Aroudi\\nSebastian Braun\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.11566\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 22 Oct 2020 09:52:05 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 4 figures\\u00a7r"}']}
{title:'Miriyala et al. (§72020§r)', author: 'Venkata Pavan Kumar Miriyala; Masatoshi Ishii', display:{Lore:['[{"text": "arXiv:2010.11741", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a75cond-mat.dis-nn\\u00a7r, \\u00a7acs.AR\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lUltra-low power on-chip learning of speech commands with phase-change memories\\u00a7r\\n\\n\\u00a78\\u00a7oVenkata Pavan Kumar Miriyala\\nMasatoshi Ishii\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.11741\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 21 Oct 2020 04:08:46 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oThis work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\\u00a7r"}']}
{title:'Kataria et al. (§72020§r)', author: 'Saurabh Kataria; Jesús Villalba; Najim Dehak', display:{Lore:['[{"text": "arXiv:2010.11860", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lPerceptual Loss based Speech Denoising with an ensemble of Audio Pattern Recognition and Self-Supervised Models\\u00a7r\\n\\n\\u00a78\\u00a7oSaurabh Kataria\\nJes\\u00fas Villalba\\nNajim Dehak\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.11860\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 22 Oct 2020 16:51:04 GMT)\\u00a7r"}']}
{title:'Shan et al. (§72020§r)', author: 'Mengyi Shan; TJ Tsai', display:{Lore:['[{"text": "arXiv:2010.12173", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Cross-Verification Approach for Protecting World Leaders from Fake and Tampered Audio\\u00a7r\\n\\n\\u00a78\\u00a7oMengyi Shan\\nTJ Tsai\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.12173\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 23 Oct 2020 05:34:51 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 4 figures, 1 table\\u00a7r"}']}
{title:'Luo et al. (§72020§r)', author: 'Yin-Jyun Luo; Yuen-Jen Lin; Li Su', display:{Lore:['[{"text": "arXiv:2010.12196", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lToward Expressive Singing Voice Correction: On Perceptual Validity of Evaluation Metrics for Vocal Melody Extraction\\u00a7r\\n\\n\\u00a78\\u00a7oYin-Jyun Luo\\nYuen-Jen Lin\\nLi Su\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.12196\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 23 Oct 2020 07:08:13 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to ICASSP 2021\\u00a7r"}']}
{title:'Huang et al. (§72020§r)', author: 'Wen-Chin Huang; Yi-Chiao Wu; Tomoki Hayashi; Tomoki Toda', display:{Lore:['[{"text": "arXiv:2010.12231", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAny-to-One Sequence-to-Sequence Voice Conversion using Self-Supervised Discrete Speech Representations\\u00a7r\\n\\n\\u00a78\\u00a7oWen-Chin Huang\\nYi-Chiao Wu\\nTomoki Hayashi\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.12231\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 23 Oct 2020 08:34:52 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to ICASSP 2021\\u00a7r"}']}
{title:'Thienpondt et al. (§72020§r)', author: 'Jenthe Thienpondt; Brecht Desplanques; Kris Demuynck', display:{Lore:['[{"text": "arXiv:2010.12468", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lThe IDLAB VoxCeleb Speaker Recognition Challenge 2020 System Description\\u00a7r\\n\\n\\u00a78\\u00a7oJenthe Thienpondt\\nBrecht Desplanques\\nKris Demuynck\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.12468\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 23 Oct 2020 15:10:23 GMT)\\u00a7r"}']}
{title:'Koluguri et al. (§72020§r)', author: 'Nithin Rao Koluguri; Jason Li; Vitaly Lavrukhin; Boris Ginsburg', display:{Lore:['[{"text": "arXiv:2010.12653", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSpeakerNet: 1D Depth-wise Separable Convolutional Network for Text-Independent Speaker Recognition and Verification\\u00a7r\\n\\n\\u00a78\\u00a7oNithin Rao Koluguri\\nJason Li\\nVitaly Lavrukhin\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.12653\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 23 Oct 2020 20:34:54 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oPreprint, submitted to ICASSP 2021\\u00a7r"}']}
{title:'Balam et al. (§72020§r)', author: 'Jagadeesh Balam; Jocelyn Huang; Vitaly Lavrukhin; Slyne Deng; Somshubra Majumdar; Boris Ginsburg', display:{Lore:['[{"text": "arXiv:2010.12715", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lImproving Noise Robustness of an End-to-End Neural Model for Automatic Speech Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oJagadeesh Balam\\nJocelyn Huang\\nVitaly Lavrukhin\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.12715\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 23 Oct 2020 23:46:29 GMT)\\u00a7r"}']}
{title:'Wang et al. (§72020§r)', author: 'Weiqing Wang; Danwei Cai; Xiaoyi Qin; Ming Li', display:{Lore:['[{"text": "arXiv:2010.12731", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lThe DKU-DukeECE Systems for VoxCeleb Speaker Recognition Challenge 2020\\u00a7r\\n\\n\\u00a78\\u00a7oWeiqing Wang\\nDanwei Cai\\nXiaoyi Qin\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.12731\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 24 Oct 2020 01:16:59 GMT)\\u00a7r"}']}
{title:'Zhang et al. (§72020§r)', author: 'Zining Zhang; Bingsheng He; Zhenjie Zhang', display:{Lore:['[{"text": "arXiv:2010.12766", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lX-TaSNet: Robust and Accurate Time-Domain Speaker Extraction Network\\u00a7r\\n\\n\\u00a78\\u00a7oZining Zhang\\nBingsheng He\\nZhenjie Zhang\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.12766\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 24 Oct 2020 03:57:19 GMT)\\u00a7r"}']}
{title:'Guo et al. (§72020§r)', author: 'Xinwei Guo; Minmin Yuan; Chengshi Zheng; Xiaodong Li', display:{Lore:['[{"text": "arXiv:2010.13334", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDistributed Node-Specific Block-Diagonal LCMV Beamforming in Wireless Acoustic Sensor Networks\\u00a7r\\n\\n\\u00a78\\u00a7oXinwei Guo\\nMinmin Yuan\\nChengshi Zheng\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.13334\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 26 Oct 2020 04:28:06 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oA novel distributed node-specific LCMV beamforming in wirelessacoustic sensor networks is proposed inthis paper\\u00a7r"}']}
{title:'Su et al. (§72020§r)', author: 'Bin Su; Shaoguang Mao; Frank Soong; Yan Xia; Jonathan Tien; Zhiyong Wu', display:{Lore:['[{"text": "arXiv:2010.13339", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lImproving pronunciation assessment via ordinal regression with anchored reference samples\\u00a7r\\n\\n\\u00a78\\u00a7oBin Su\\nShaoguang Mao\\nFrank Soong\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.13339\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 26 Oct 2020 04:53:17 GMT)\\u00a7r"}']}
{title:'Hwang et al. (§72020§r)', author: 'Min-Jae Hwang; Ryuichi Yamamoto; Eunwoo Song; Jae-Min Kim', display:{Lore:['[{"text": "arXiv:2010.13421", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lTTS-by-TTS: TTS-driven Data Augmentation for Fast and High-Quality Speech Synthesis\\u00a7r\\n\\n\\u00a78\\u00a7oMin-Jae Hwang\\nRyuichi Yamamoto\\nEunwoo Song\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.13421\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 26 Oct 2020 08:44:27 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to ICASSP 2021\\u00a7r"}']}
{title:'Ferroni et al. (§72020§r)', author: 'Giacomo Ferroni; Nicolas Turpault; Juan Azcarreta; Francesco Tuveri; Romain Serizel; Çagdaş Bilen; Sacha Krstulović', display:{Lore:['[{"text": "arXiv:2010.13648", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lImproving Sound Event Detection Metrics: Insights from DCASE 2020\\u00a7r\\n\\n\\u00a78\\u00a7oGiacomo Ferroni\\nNicolas Turpault\\nJuan Azcarreta\\n+ 3 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.13648\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 26 Oct 2020 15:11:23 GMT)\\u00a7r"}']}
{title:'Guo et al. (§72020§r)', author: 'Pengcheng Guo; Florian Boyer; Xuankai Chang; Tomoki Hayashi; Yosuke Higuchi; Hirofumi Inaguma; Naoyuki Kamo; Chenda Li; Daniel Garcia-Romero; Jiatong Shi; Jing Shi; Shinji Watanabe; Kun Wei; Wangyou Zhang; Yuekai Zhang', display:{Lore:['[{"text": "arXiv:2010.13956", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lRecent Developments on ESPnet Toolkit Boosted by Conformer\\u00a7r\\n\\n\\u00a78\\u00a7oPengcheng Guo\\nFlorian Boyer\\nXuankai Chang\\n+ 11 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.13956\\u00a7r\\n\\nVersion:\\u00a77v2 (Thu, 29 Oct 2020 16:44:51 GMT)\\u00a7r"}']}
{title:'Goswami et al. (§72020§r)', author: 'Raktim Gautam Goswami; Sivaganesh Andhavarapu; K Sri Rama Murty', display:{Lore:['[{"text": "arXiv:2010.14122", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.AI\\u00a7r, \\u00a7eeess.SP\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lPhase Aware Speech Enhancement using Realisation of Complex-valued LSTM\\u00a7r\\n\\n\\u00a78\\u00a7oRaktim Gautam Goswami\\nSivaganesh Andhavarapu\\nK Sri Rama Murty\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.14122\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 27 Oct 2020 08:16:58 GMT)\\u00a7r"}']}
{title:'Zhou et al. (§72020§r)', author: 'Henry Zhou; Alexei Baevski; Michael Auli', display:{Lore:['[{"text": "arXiv:2010.14230", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.AI\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Comparison of Discrete Latent Variable Models for Speech Representation Learning\\u00a7r\\n\\n\\u00a78\\u00a7oHenry Zhou\\nAlexei Baevski\\nMichael Auli\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.14230\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 24 Oct 2020 01:22:14 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o7 pages, 4 figures\\u00a7r"}']}
{title:'Chi et al. (§72020§r)', author: 'Ethan A. Chi; Julian Salazar; Katrin Kirchhoff', display:{Lore:['[{"text": "arXiv:2010.14233", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAlign-Refine: Non-Autoregressive Speech Recognition via Iterative Realignment\\u00a7r\\n\\n\\u00a78\\u00a7oEthan A. Chi\\nJulian Salazar\\nKatrin Kirchhoff\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.14233\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 24 Oct 2020 09:35:37 GMT)\\u00a7r"}']}
{title:'Westhausen et al. (§72020§r)', author: 'Nils L. Westhausen; Bernd T. Meyer', display:{Lore:['[{"text": "arXiv:2010.14337", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAcoustic echo cancellation with the dual-signal transformation LSTM network\\u00a7r\\n\\n\\u00a78\\u00a7oNils L. Westhausen\\nBernd T. Meyer\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.14337\\u00a7r\\n\\nVersion:\\u00a77v2 (Mon, 23 Nov 2020 10:47:25 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted in to ICASSP 2021\\u00a7r"}']}
{title:'Narayanan et al. (§72020§r)', author: 'Arun Narayanan; Tara N. Sainath; Ruoming Pang; Jiahui Yu; Chung-Cheng Chiu; Rohit Prabhavalkar; Ehsan Variani; Trevor Strohman', display:{Lore:['[{"text": "arXiv:2010.14606", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lCascaded encoders for unifying streaming and non-streaming ASR\\u00a7r\\n\\n\\u00a78\\u00a7oArun Narayanan\\nTara N. Sainath\\nRuoming Pang\\n+ 4 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.14606\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 27 Oct 2020 20:59:50 GMT)\\u00a7r"}']}
{title:'Cai et al. (§72020§r)', author: 'Danwei Cai; Weiqing Wang; Ming Li', display:{Lore:['[{"text": "arXiv:2010.14751", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAn iterative framework for self-supervised deep speaker representation learning\\u00a7r\\n\\n\\u00a78\\u00a7oDanwei Cai\\nWeiqing Wang\\nMing Li\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.14751\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 25 Oct 2020 16:16:22 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oarXiv admin note: text overlapwith arXiv:2010.12731\\u00a7r"}']}
{title:'Fabbro et al. (§72020§r)', author: 'Giorgio Fabbro; Vladimir Golkov; Thomas Kemp; Daniel Cremers', display:{Lore:['[{"text": "arXiv:2010.15084", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSpeech Synthesis and Control Using Differentiable DSP\\u00a7r\\n\\n\\u00a78\\u00a7oGiorgio Fabbro\\nVladimir Golkov\\nThomas Kemp\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.15084\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 28 Oct 2020 16:55:38 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o6 pages, 3 figures, for associated audio files, see https://thesmith1.github.io/DDSPeech/\\u00a7r"}']}
{title:'Hao et al. (§72020§r)', author: 'Xiang Hao; Xiangdong Su; Zhiyu Wang; Hui Zhang; Batushiren', display:{Lore:['[{"text": "arXiv:2010.15521", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7eeess.SP\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lUNetGAN: A Robust Speech Enhancement Approach in Time Domain for Extremely Low Signal-to-noise Ratio Condition\\u00a7r\\n\\n\\u00a78\\u00a7oXiang Hao\\nXiangdong Su\\nZhiyu Wang\\nHui Zhang\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.15521\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.21437/Interspeech.2019-1567\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 29 Oct 2020 12:33:22 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oPublished in Interspeech 2019\\u00a7r"}']}
{title:'Pal et al. (§72020§r)', author: 'Monisankha Pal; Arindam Jati; Raghuveer Peri; Chin-Cheng Hsu; Wael AbdAlmageed; Shrikanth Narayanan', display:{Lore:['[{"text": "arXiv:2010.16038", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAdversarial defense for deep speaker recognition using hybrid adversarial training\\u00a7r\\n\\n\\u00a78\\u00a7oMonisankha Pal\\nArindam Jati\\nRaghuveer Peri\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.16038\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 30 Oct 2020 03:05:58 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to ICASSP 2021\\u00a7r"}']}
{title:'Riad et al. (§72020§r)', author: 'Rachid Riad; Hadrien Titeux; Laurie Lemoine; Justine Montillot; Agnes Sliwinski; Jennifer Hamet Bagnou; Xuan Nga Cao; Anne-Catherine Bachoud-Lévi; Emmanuel Dupoux', display:{Lore:['[{"text": "arXiv:2010.16131", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lComparison of Speaker Role Recognition and Speaker Enrollment Protocol for conversational Clinical Interviews\\u00a7r\\n\\n\\u00a78\\u00a7oRachid Riad\\nHadrien Titeux\\nLaurie Lemoine\\n+ 5 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.16131\\u00a7r\\n\\nVersion:\\u00a77v2 (Thu, 5 Nov 2020 08:09:11 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to ICASSP 2021,1 pages ofsupplementary materialappear only in the arxivversion\\u00a7r"}']}
{title:'Lehmann et al. (§72020§r)', author: 'Marius Lehmann; Daniel Ernst; Marc Schneider; Carsten Spehr; Markus Lummer', display:{Lore:['[{"text": "arXiv:2010.16140", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lBeamforming for measurements under disturbed propagation conditions using numerically calculated Green\'s functions\\u00a7r\\n\\n\\u00a78\\u00a7oMarius Lehmann\\nDaniel Ernst\\nMarc Schneider\\nCarsten Spehr\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.16140\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 30 Oct 2020 09:27:10 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oPreprint subitted to \\"Journal of Sound and Vibration\\"\\u00a7r"}']}
{title:'Deshmukh et al. (§72020§r)', author: 'Soham Deshmukh; Mahmoud Al Ismail; Rita Singh', display:{Lore:['[{"text": "arXiv:2010.16318", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lInterpreting glottal flow dynamics for detecting COVID-19 from voice\\u00a7r\\n\\n\\u00a78\\u00a7oSoham Deshmukh\\nMahmoud Al Ismail\\nRita Singh\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2010.16318\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/ICASSP39728.2021.9414530\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 29 Oct 2020 13:16:57 GMT)\\u00a7r"}']}
{title:'Subramanian et al. (§72020§r)', author: 'Aswin Shanmugam Subramanian; Chao Weng; Shinji Watanabe; Meng Yu; Yong Xu; Shi-Xiong Zhang; Dong Yu', display:{Lore:['[{"text": "arXiv:2011.00091", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDirectional ASR: A New Paradigm for E2E Multi-Speaker Speech Recognition with Source Localization\\u00a7r\\n\\n\\u00a78\\u00a7oAswin Shanmugam Subramanian\\nChao Weng\\nShinji Watanabe\\n+ 3 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.00091\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 30 Oct 2020 20:26:28 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7osubmitted to ICASSP 2021\\u00a7r"}']}
{title:'Chen et al. (§72020§r)', author: 'Yen-Hao Chen; Da-Yi Wu; Tsung-Han Wu; Hung-yi Lee', display:{Lore:['[{"text": "arXiv:2011.00316", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAGAIN-VC: A One-shot Voice Conversion using Activation Guidance and Adaptive Instance Normalization\\u00a7r\\n\\n\\u00a78\\u00a7oYen-Hao Chen\\nDa-Yi Wu\\nTsung-Han Wu\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.00316\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 31 Oct 2020 17:09:19 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to ICASSP 2021\\u00a7r"}']}
{title:'Hamdan et al. (§72020§r)', author: 'Eric C. Hamdan; Filippo Maria Fazi', display:{Lore:['[{"text": "arXiv:2011.00502", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lFocusing Phenomena in Linear Discrete Inverse Problems in Acoustics\\u00a7r\\n\\n\\u00a78\\u00a7oEric C. Hamdan\\nFilippo Maria Fazi\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.00502\\u00a7r\\n\\nVersion:\\u00a77v2 (Wed, 18 Nov 2020 11:26:42 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o33 pages, 23 figures, submitted for review to the Journal of Sound and Vibration; fixed typos and minor revision in sections 6.1.4-6.1.5 and 6.2\\u00a7r"}']}
{title:'Lin et al. (§72020§r)', author: 'Wanqiu Lin; Maulik Madhavi; Rohan Kumar Das; Haizhou Li', display:{Lore:['[{"text": "arXiv:2011.00699", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lTransformer-based Arabic Dialect Identification\\u00a7r\\n\\n\\u00a78\\u00a7oWanqiu Lin\\nMaulik Madhavi\\nRohan Kumar Das\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.00699\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 2 Nov 2020 03:10:34 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted for publication in International Conference on Asian Language Processing (IALP) 2020\\u00a7r"}']}
{title:'Agrawal et al. (§72020§r)', author: 'Purvi Agrawal; Sriram Ganapathy', display:{Lore:['[{"text": "arXiv:2011.00721", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lRobust Raw Waveform Speech Recognition Using Relevance Weighted Representations\\u00a7r\\n\\n\\u00a78\\u00a7oPurvi Agrawal\\nSriram Ganapathy\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.00721\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.21437/Interspeech.2020-2301\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nProc. Interspeech 2020, 1649-1653 (2020)\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 29 Oct 2020 19:32:50 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oarXiv admin note: text overlapwith arXiv:2001.07067\\u00a7r"}']}
{title:'Tian et al. (§72020§r)', author: 'Qiao Tian; Zewang Zhang; Chao Liu; Heng Lu; Linghui Chen; Bin Wei; Pujiang He; Shan Liu', display:{Lore:['[{"text": "arXiv:2011.00935", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lFeatherTTS: Robust and Efficient attention based Neural TTS\\u00a7r\\n\\n\\u00a78\\u00a7oQiao Tian\\nZewang Zhang\\nChao Liu\\n+ 4 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.00935\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 2 Nov 2020 12:33:11 GMT)\\u00a7r"}']}
{title:'Chen et al. (§72020§r)', author: 'Nanxin Chen; Piotr Żelasko; Jesús Villalba; Najim Dehak', display:{Lore:['[{"text": "arXiv:2011.01210", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lFocus on the present: a regularization method for the ASR source-target attention layer\\u00a7r\\n\\n\\u00a78\\u00a7oNanxin Chen\\nPiotr \\u017belasko\\nJes\\u00fas Villalba\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.01210\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 2 Nov 2020 18:56:33 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7osubmitted to ICASSP2021. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for "}','{"text": "advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted componentof this work in other works\\u00a7r"}']}
{title:'Huang et al. (§72020§r)', author: 'Mingkun Huang; Meng Cai; Jun Zhang; Yang Zhang; Yongbin You; Yi He; Zejun Ma', display:{Lore:['[{"text": "arXiv:2011.01570", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDynamic latency speech recognition with asynchronous revision\\u00a7r\\n\\n\\u00a78\\u00a7oMingkun Huang\\nMeng Cai\\nJun Zhang\\n+ 3 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.01570\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 3 Nov 2020 08:50:43 GMT)\\u00a7r"}']}
{title:'Huang et al. (§72020§r)', author: 'Mingkun Huang; Jun Zhang; Meng Cai; Yang Zhang; Jiali Yao; Yongbin You; Yi He; Zejun Ma', display:{Lore:['[{"text": "arXiv:2011.01576", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lImproving RNN transducer with normalized jointer network\\u00a7r\\n\\n\\u00a78\\u00a7oMingkun Huang\\nJun Zhang\\nMeng Cai\\n+ 4 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.01576\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 3 Nov 2020 09:03:59 GMT)\\u00a7r"}']}
{title:'Wang et al. (§72020§r)', author: 'Disong Wang; Jianwei Yu; Xixin Wu; Lifa Sun; Xunying Liu; Helen Meng', display:{Lore:['[{"text": "arXiv:2011.01686", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lImproved End-to-End Dysarthric Speech Recognition via Meta-learning Based Model Re-initialization\\u00a7r\\n\\n\\u00a78\\u00a7oDisong Wang\\nJianwei Yu\\nXixin Wu\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.01686\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 3 Nov 2020 13:21:51 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oTo appear in ISCSLP2021\\u00a7r"}']}
{title:'Díaz et al. (§72020§r)', author: 'Alejandro Díaz; Diego Pincheira; Rodrigo Mahu; Nestor Becerra Yoma', display:{Lore:['[{"text": "arXiv:2011.01965", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lShort-time deep-learning based source separation for speech enhancement in reverberant environments with beamforming\\u00a7r\\n\\n\\u00a78\\u00a7oAlejandro D\\u00edaz\\nDiego Pincheira\\nRodrigo Mahu\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.01965\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 3 Nov 2020 19:18:53 GMT)\\u00a7r"}']}
{title:'Sung et al. (§72020§r)', author: 'Man-Ling Sung; Siyuan Feng; Tan Lee', display:{Lore:['[{"text": "arXiv:2011.01986", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lUnsupervised Pattern Discovery from Thematic Speech Archives Based on Multilingual Bottleneck Features\\u00a7r\\n\\n\\u00a78\\u00a7oMan-Ling Sung\\nSiyuan Feng\\nTan Lee\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.01986\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.23919/APSIPA.2018.8659619\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 3 Nov 2020 20:06:48 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o8 pages, accepted and presented in APSIPA-APC 2018. This work was done when Man-Ling Sung and Siyuan Feng were postgraduate studentsin the Chinese University of Hong Kong\\u00a7r"}']}
{title:'Meng et al. (§72020§r)', author: 'Zhong Meng; Sarangarajan Parthasarathy; Eric Sun; Yashesh Gaur; Naoyuki Kanda; Liang Lu; Xie Chen; Rui Zhao; Jinyu Li; Yifan Gong', display:{Lore:['[{"text": "arXiv:2011.01991", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lInternal Language Model Estimation for Domain-Adaptive End-to-End Speech Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oZhong Meng\\nSarangarajan Parthasarathy\\nEric Sun\\n+ 6 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.01991\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7n2021 IEEE Spoken Language Technology Workshop (SLT)\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 3 Nov 2020 20:11:04 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o8 pages, 2 figures, SLT 2021\\u00a7r"}']}
{title:'Raj et al. (§72020§r)', author: 'Desh Raj; Leibny Paola Garcia-Perera; Zili Huang; Shinji Watanabe; Daniel Povey; Andreas Stolcke; Sanjeev Khudanpur', display:{Lore:['[{"text": "arXiv:2011.01997", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDOVER-Lap: A Method for Combining Overlap-aware Diarization Outputs\\u00a7r\\n\\n\\u00a78\\u00a7oDesh Raj\\nLeibny Paola Garcia-Perera\\nZili Huang\\n+ 3 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.01997\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 3 Nov 2020 20:29:15 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted to IEEESLT 2021\\u00a7r"}']}
{title:'Zhang et al. (§72020§r)', author: 'Yixuan Zhang; Yuzhou Liu; DeLiang Wang', display:{Lore:['[{"text": "arXiv:2011.02008", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lComplex ratio masking for singing voice separation\\u00a7r\\n\\n\\u00a78\\u00a7oYixuan Zhang\\nYuzhou Liu\\nDeLiang Wang\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.02008\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 3 Nov 2020 21:19:36 GMT)\\u00a7r"}']}
{title:'Raj et al. (§72020§r)', author: 'Desh Raj; Pavel Denisov; Zhuo Chen; Hakan Erdogan; Zili Huang; Maokui He; Shinji Watanabe; Jun Du; Takuya Yoshioka; Yi Luo; Naoyuki Kanda; Jinyu Li; Scott Wisdom; John R. Hershey', display:{Lore:['[{"text": "arXiv:2011.02014", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lIntegration of speech separation, diarization, and recognition for multi-speaker meetings: System description, comparison, and analysis\\u00a7r\\n\\n\\u00a78\\u00a7oDesh Raj\\nPavel Denisov\\nZhuo Chen\\n+ 10 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.02014\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 3 Nov 2020 21:33:29 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted to IEEESLT 2021\\u00a7r"}']}
{title:'N (§72020§r)', author: 'Krishna D N', display:{Lore:['[{"text": "arXiv:2011.02132", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMulti-Modal Transformers Utterance-Level Code-Switching Detection\\u00a7r\\n\\n\\u00a78\\u00a7oKrishna D N\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.02132\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 4 Nov 2020 05:26:09 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o8 pages, 2 figures\\u00a7r"}']}
{title:'Agrawal et al. (§72020§r)', author: 'Purvi Agrawal; Sriram Ganapathy', display:{Lore:['[{"text": "arXiv:2011.02136", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lInterpretable Representation Learning for Speech and Audio Signals Based on Relevance Weighting\\u00a7r\\n\\n\\u00a78\\u00a7oPurvi Agrawal\\nSriram Ganapathy\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.02136\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/TASLP.2020.3030489\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nIEEE Transactions and Audio, Speech and Language Processing, Vol.\\n  28, pp. 2823 - 2836, 2020\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 29 Oct 2020 20:36:25 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oarXiv admin note: text overlapwith arXiv:2011.00721\\u00a7r"}']}
{title:'Kwon et al. (§72020§r)', author: 'Yoohwan Kwon; Soo-Whan Chung; Hee-Soo Heo; Hong-Goo Kang', display:{Lore:['[{"text": "arXiv:2011.02168", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lLearning in your voice: Non-parallel voice conversion based on speaker consistency loss\\u00a7r\\n\\n\\u00a78\\u00a7oYoohwan Kwon\\nSoo-Whan Chung\\nHee-Soo Heo\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.02168\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 4 Nov 2020 07:58:35 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oICASSP 2021 submitted\\u00a7r"}']}
{title:'Karlapati et al. (§72020§r)', author: 'Sri Karlapati; Ammar Abbas; Zack Hodari; Alexis Moinet; Arnaud Joly; Penny Karanasou; Thomas Drugman', display:{Lore:['[{"text": "arXiv:2011.02252", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lProsodic Representation Learning and Contextual Sampling for Neural Text-to-Speech\\u00a7r\\n\\n\\u00a78\\u00a7oSri Karlapati\\nAmmar Abbas\\nZack Hodari\\n+ 3 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.02252\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 4 Nov 2020 12:20:21 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages and 3 figures\\u00a7r"}']}
{title:'Gfeller et al. (§72020§r)', author: 'Beat Gfeller; Dominik Roblek; Marco Tagliasacchi', display:{Lore:['[{"text": "arXiv:2011.02421", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lOne-shot conditional audio filtering of arbitrary sounds\\u00a7r\\n\\n\\u00a78\\u00a7oBeat Gfeller\\nDominik Roblek\\nMarco Tagliasacchi\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.02421\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 4 Nov 2020 17:20:42 GMT)\\u00a7r"}']}
{title:'Wang et al. (§72020§r)', author: 'You Wang; Chuyao Feng; David V. Anderson', display:{Lore:['[{"text": "arXiv:2011.02561", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Multi-Channel Temporal Attention Convolutional Neural Network Model for Environmental Sound Classification\\u00a7r\\n\\n\\u00a78\\u00a7oYou Wang\\nChuyao Feng\\nDavid V. Anderson\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.02561\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 4 Nov 2020 22:05:57 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 4 figures\\u00a7r"}']}
{title:'Zhu et al. (§72020§r)', author: 'Junzhe Zhu; Mark Hasegawa-Johnson; Nancy McElwain', display:{Lore:['[{"text": "arXiv:2011.02698", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Comparison Study on Infant-Parent Voice Diarization\\u00a7r\\n\\n\\u00a78\\u00a7oJunzhe Zhu\\nMark Hasegawa-Johnson\\nNancy McElwain\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.02698\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 5 Nov 2020 08:21:05 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oICASSP 2021\\u00a7r"}']}
{title:'Zhu et al. (§72020§r)', author: 'Han Zhu; Li Wang; Pengyuan Zhang; Yonghong Yan', display:{Lore:['[{"text": "arXiv:2011.02774", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMulti-Accent Adaptation based on Gate Mechanism\\u00a7r\\n\\n\\u00a78\\u00a7oHan Zhu\\nLi Wang\\nPengyuan Zhang\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.02774\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 5 Nov 2020 11:58:36 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted in INTERSPEECH 2019\\u00a7r"}']}
{title:'Zhu et al. (§72020§r)', author: 'Han Zhu; Jiangjiang Zhao; Yuling Ren; Li Wang; Pengyuan Zhang', display:{Lore:['[{"text": "arXiv:2011.02782", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDomain Adaptation Using Class Similarity for Robust Speech Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oHan Zhu\\nJiangjiang Zhao\\nYuling Ren\\nLi Wang\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.02782\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 5 Nov 2020 12:26:43 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted in INTERSPEECH 2020\\u00a7r"}']}
{title:'Raj et al. (§72020§r)', author: 'Desh Raj; Zili Huang; Sanjeev Khudanpur', display:{Lore:['[{"text": "arXiv:2011.02900", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMulti-class Spectral Clustering with Overlaps for Speaker Diarization\\u00a7r\\n\\n\\u00a78\\u00a7oDesh Raj\\nZili Huang\\nSanjeev Khudanpur\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.02900\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 5 Nov 2020 15:21:28 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted at IEEESLT 2021\\u00a7r"}']}
{title:'Kanda et al. (§72020§r)', author: 'Naoyuki Kanda; Zhong Meng; Liang Lu; Yashesh Gaur; Xiaofei Wang; Zhuo Chen; Takuya Yoshioka', display:{Lore:['[{"text": "arXiv:2011.02921", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMinimum Bayes Risk Training for End-to-End Speaker-Attributed ASR\\u00a7r\\n\\n\\u00a78\\u00a7oNaoyuki Kanda\\nZhong Meng\\nLiang Lu\\n+ 3 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.02921\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 3 Nov 2020 22:28:57 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to ICASSP 2021. arXiv admin note: text overlapwith arXiv:2006.10930, arXiv:2008.04546\\u00a7r"}']}
{title:'Primus et al. (§72020§r)', author: 'Paul Primus; Verena Haunschmid; Patrick Praher; Gerhard Widmer', display:{Lore:['[{"text": "arXiv:2011.02949", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAnomalous Sound Detection as a Simple Binary Classification Problem with Careful Selection of Proxy Outlier Examples\\u00a7r\\n\\n\\u00a78\\u00a7oPaul Primus\\nVerena Haunschmid\\nPatrick Praher\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.02949\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 5 Nov 2020 16:22:46 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7opublished in DCASE 2020 Workshop\\u00a7r"}']}
{title:'Wang et al. (§72020§r)', author: 'Xiaofei Wang; Naoyuki Kanda; Yashesh Gaur; Zhuo Chen; Zhong Meng; Takuya Yoshioka', display:{Lore:['[{"text": "arXiv:2011.03110", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lExploring End-to-End Multi-channel ASR with Bias Information for Meeting Transcription\\u00a7r\\n\\n\\u00a78\\u00a7oXiaofei Wang\\nNaoyuki Kanda\\nYashesh Gaur\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.03110\\u00a7r\\n\\nVersion:\\u00a77v2 (Wed, 25 Nov 2020 23:22:45 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted to SLT2021\\u00a7r"}']}
{title:'Yusuf et al. (§72020§r)', author: 'Bolaji Yusuf; Lucas Ondel; Lukas Burget; Jan Cernocky; Murat Saraclar', display:{Lore:['[{"text": "arXiv:2011.03115", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Hierarchical Subspace Model for Language-Attuned Acoustic Unit Discovery\\u00a7r\\n\\n\\u00a78\\u00a7oBolaji Yusuf\\nLucas Ondel\\nLukas Burget\\nJan Cernocky\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.03115\\u00a7r\\n\\nVersion:\\u00a77v2 (Mon, 9 Nov 2020 06:55:48 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to ICASSP 2021\\u00a7r"}']}
{title:'Padhi et al. (§72020§r)', author: 'Trideba Padhi; Astik Biswas; Febe De Wet; Ewald van der Westhuizen; Thomas Niesler', display:{Lore:['[{"text": "arXiv:2011.03118", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMultilingual Bottleneck Features for Improving ASR Performance of Code-Switched Speech in Under-Resourced Languages\\u00a7r\\n\\n\\u00a78\\u00a7oTrideba Padhi\\nAstik Biswas\\nFebe De Wet\\nEwald van der Westhuizen\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.03118\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nhttp://festvox.org/cedar/WSTCSMC2020.pdf\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 31 Oct 2020 18:51:42 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oIn Proceedings of The First Workshop on Speech Technologies for Code-Switching in Multilingual Communities\\u00a7r"}']}
{title:'Miller et al. (§72020§r)', author: 'Gabriel F Miller; Andreas Brendel; Walter Kellermann; Sharon Gannot', display:{Lore:['[{"text": "arXiv:2011.03432", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMisalignment Recognition in Acoustic Sensor Networks using a Semi-supervised Source Estimation Method and Markov Random Fields\\u00a7r\\n\\n\\u00a78\\u00a7oGabriel F Miller\\nAndreas Brendel\\nWalter Kellermann\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.03432\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 6 Nov 2020 15:29:01 GMT)\\u00a7r"}']}
{title:'Li et al. (§72020§r)', author: 'Chenda Li; Jing Shi; Wangyou Zhang; Aswin Shanmugam Subramanian; Xuankai Chang; Naoyuki Kamo; Moto Hira; Tomoki Hayashi; Christoph Boeddeker; Zhuo Chen; Shinji Watanabe', display:{Lore:['[{"text": "arXiv:2011.03706", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lESPnet-se: end-to-end speech enhancement and separation toolkit designed for asr integration\\u00a7r\\n\\n\\u00a78\\u00a7oChenda Li\\nJing Shi\\nWangyou Zhang\\n+ 7 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.03706\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/SLT48900.2021.9383615\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 7 Nov 2020 06:14:18 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted by SLT 2021\\u00a7r"}']}
{title:'Das et al. (§72020§r)', author: 'Sneha Das; Tom Bäckström', display:{Lore:['[{"text": "arXiv:2011.03810", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lEnhancement by postfiltering for speech and audio coding in ad-hoc sensor networks\\u00a7r\\n\\n\\u00a78\\u00a7oSneha Das\\nTom B\\u00e4ckstr\\u00f6m\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.03810\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 7 Nov 2020 17:06:18 GMT)\\u00a7r"}']}
{title:'Ghorbani et al. (§72020§r)', author: 'Shahram Ghorbani; Yashesh Gaur; Yu Shi; Jinyu Li', display:{Lore:['[{"text": "arXiv:2011.04084", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7eeess.IV\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lListen, Look and Deliberate: Visual context-aware speech recognition using pre-trained text-video representations\\u00a7r\\n\\n\\u00a78\\u00a7oShahram Ghorbani\\nYashesh Gaur\\nYu Shi\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.04084\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 8 Nov 2020 21:26:17 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted at SLT 2021\\u00a7r"}']}
{title:'Shetu et al. (§72020§r)', author: 'Shrishti Saha Shetu; Soumitro Chakrabarty; Emanuël A. P. Habets', display:{Lore:['[{"text": "arXiv:2011.04359", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CV\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7eeess.IV\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAn Empirical Study of Visual Features for DNN based Audio-Visual Speech Enhancement in Multi-talker Environments\\u00a7r\\n\\n\\u00a78\\u00a7oShrishti Saha Shetu\\nSoumitro Chakrabarty\\nEmanu\\u00ebl A. P. Habets\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.04359\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/ICASSP39728.2021.9414000\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 9 Nov 2020 11:48:14 GMT)\\u00a7r"}']}
{title:'Hübner et al. (§72020§r)', author: 'Fabian Hübner; Wolfgang Mack; Emanuël A. P. Habets', display:{Lore:['[{"text": "arXiv:2011.04456", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lEfficient Training Data Generation for Phase-Based DOA Estimation\\u00a7r\\n\\n\\u00a78\\u00a7oFabian H\\u00fcbner\\nWolfgang Mack\\nEmanu\\u00ebl A. P. Habets\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.04456\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/ICASSP39728.2021.9414070\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 9 Nov 2020 14:25:03 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to ICASSP 2021\\u00a7r"}']}
{title:'Zhang et al. (§72020§r)', author: 'Xiaohui Zhang; Frank Zhang; Chunxi Liu; Kjell Schubert; Julian Chan; Pradyot Prakash; Jun Liu; Ching-Feng Yeh; Fuchun Peng; Yatharth Saraf; Geoffrey Zweig', display:{Lore:['[{"text": "arXiv:2011.04785", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lBenchmarking LF-MMI, CTC and RNN-T Criteria for Streaming ASR\\u00a7r\\n\\n\\u00a78\\u00a7oXiaohui Zhang\\nFrank Zhang\\nChunxi Liu\\n+ 7 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.04785\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 9 Nov 2020 21:34:38 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted for publication at IEEE Spoken Language Technology Workshop (SLT), 2021\\u00a7r"}']}
{title:'Li et al. (§72020§r)', author: 'Haoyu Li; Yang Ai; Junichi Yamagishi', display:{Lore:['[{"text": "arXiv:2011.05038", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lEnhancing Low-Quality Voice Recordings Using Disentangled Channel Factor and Neural Waveform Model\\u00a7r\\n\\n\\u00a78\\u00a7oHaoyu Li\\nYang Ai\\nJunichi Yamagishi\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.05038\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 10 Nov 2020 11:00:20 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o8 pages. Accepted to IEEE SLT 2021\\u00a7r"}']}
{title:'Xu et al. (§72020§r)', author: 'Guanghui Xu; Wei Song; Zhengchen Zhang; Chao Zhang; Xiaodong He; Bowen Zhou', display:{Lore:['[{"text": "arXiv:2011.05161", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lImproving Prosody Modelling with Cross-Utterance BERT Embeddings for End-to-end Speech Synthesis\\u00a7r\\n\\n\\u00a78\\u00a7oGuanghui Xu\\nWei Song\\nZhengchen Zhang\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.05161\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 6 Nov 2020 10:03:11 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 4 figures\\u00a7r"}']}
{title:'Scheibler et al. (§72020§r)', author: 'Robin Scheibler; Masahito Togami', display:{Lore:['[{"text": "arXiv:2011.05540", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7eeess.SP\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSurrogate Source Model Learning for Determined Source Separation\\u00a7r\\n\\n\\u00a78\\u00a7oRobin Scheibler\\nMasahito Togami\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.05540\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 11 Nov 2020 04:30:30 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 3 figures, 1 table. Submitted to ICASSP 2021\\u00a7r"}']}
{title:'Zheng et al. (§72020§r)', author: 'Huahuan Zheng; Keyu An; Zhijian Ou', display:{Lore:['[{"text": "arXiv:2011.05649", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lEfficient Neural Architecture Search for End-to-end Speech Recognition via Straight-Through Gradients\\u00a7r\\n\\n\\u00a78\\u00a7oHuahuan Zheng\\nKeyu An\\nZhijian Ou\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.05649\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 11 Nov 2020 09:18:58 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted by IEEE SLT 2021\\u00a7r"}']}
{title:'Zhang et al. (§72020§r)', author: 'Jisi Zhang; Catalin Zorila; Rama Doddipatla; Jon Barker', display:{Lore:['[{"text": "arXiv:2011.05958", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lOn End-to-end Multi-channel Time Domain Speech Separation in Reverberant Environments\\u00a7r\\n\\n\\u00a78\\u00a7oJisi Zhang\\nCatalin Zorila\\nRama Doddipatla\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.05958\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/ICASSP40776.2020.9053833\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nProc. ICASSP (2020) 6389-6393\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 11 Nov 2020 18:25:07 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oPresented at IEEE ICASSP 2020\\u00a7r"}']}
{title:'Panchapagesan et al. (§72020§r)', author: 'Sankaran Panchapagesan; Daniel S. Park; Chung-Cheng Chiu; Yuan Shangguan; Qiao Liang; Alexander Gruenstein', display:{Lore:['[{"text": "arXiv:2011.06110", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lEfficient Knowledge Distillation for RNN-Transducer Models\\u00a7r\\n\\n\\u00a78\\u00a7oSankaran Panchapagesan\\nDaniel S. Park\\nChung-Cheng Chiu\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.06110\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 11 Nov 2020 22:58:15 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 1 figure, 2 tables; submitted to ICASSP 2021\\u00a7r"}']}
{title:'Ng et al. (§72020§r)', author: 'Si-Ioi Ng; Wei Liu; Zhiyuan Peng; Siyuan Feng; Hing-Pang Huang; Odette Scharenborg; Tan Lee', display:{Lore:['[{"text": "arXiv:2011.06239", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lThe CUHK-TUDELFT System for The SLT 2021 Children Speech Recognition Challenge\\u00a7r\\n\\n\\u00a78\\u00a7oSi-Ioi Ng\\nWei Liu\\nZhiyuan Peng\\n+ 3 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.06239\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 12 Nov 2020 07:31:19 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to 2021 SLT Children Speech Recognition Challenge (CSRC)\\u00a7r"}']}
{title:'Shifas et al. (§72020§r)', author: 'Muhammed PV Shifas; Anna Sfakianaki; Theognosia Chimona; Yannis Stylianou', display:{Lore:['[{"text": "arXiv:2011.06548", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lEvaluating the Intelligibility Benefits of Neural Speech Enrichment for Listeners with Normal Hearing and Hearing Impairment using the Greek Harvard Corpus\\u00a7r\\n\\n\\u00a78\\u00a7oMuhammed PV Shifas\\nAnna Sfakianaki\\nTheognosia Chimona\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.06548\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 12 Nov 2020 18:07:30 GMT)\\u00a7r"}']}
{title:'Ananthram et al. (§72020§r)', author: 'Amith Ananthram; Kailash Karthik Saravanakumar; Jessica Huynh; Homayoon Beigi', display:{Lore:['[{"text": "arXiv:2011.07065", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.HC\\u00a7r, \\u00a7acs.LG\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMulti-Modal Emotion Detection with Transfer Learning\\u00a7r\\n\\n\\u00a78\\u00a7oAmith Ananthram\\nKailash Karthik Saravanakumar\\nJessica Huynh\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.07065\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 13 Nov 2020 18:58:59 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o11 pages, 7 tables, 2 figures\\u00a7r"}']}
{title:'Luo et al. (§72020§r)', author: 'Yi Luo; Cong Han; Nima Mesgarani', display:{Lore:['[{"text": "arXiv:2011.07338", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDistortion-controlled Training for End-to-end Reverberant Speech Separation with Auxiliary Autoencoding Loss\\u00a7r\\n\\n\\u00a78\\u00a7oYi Luo\\nCong Han\\nNima Mesgarani\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.07338\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 14 Nov 2020 17:03:22 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSLT 2021\\u00a7r"}']}
{title:'Horiguchi et al. (§72020§r)', author: 'Shota Horiguchi; Yusuke Fujita; Kenji Nagamatsu', display:{Lore:['[{"text": "arXiv:2011.07791", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7eeess.SP\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lBlock-Online Guided Source Separation\\u00a7r\\n\\n\\u00a78\\u00a7oShota Horiguchi\\nYusuke Fujita\\nKenji Nagamatsu\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.07791\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 16 Nov 2020 08:50:34 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted to SLT 2021\\u00a7r"}']}
{title:'Nguyen et al. (§72020§r)', author: 'Thi Ngoc Tho Nguyen; Ngoc Khanh Nguyen; Huy Phan; Lam Pham; Kenneth Ooi; Douglas L. Jones; Woon-Seng Gan', display:{Lore:['[{"text": "arXiv:2011.07859", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA General Network Architecture for Sound Event Localization and Detection Using Transfer Learning and Recurrent Neural Network\\u00a7r\\n\\n\\u00a78\\u00a7oThi Ngoc Tho Nguyen\\nNgoc Khanh Nguyen\\nHuy Phan\\n+ 3 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.07859\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 16 Nov 2020 10:57:02 GMT)\\u00a7r"}']}
{title:'Chen et al. (§72020§r)', author: 'Liu Chen; Meysam Asgari', display:{Lore:['[{"text": "arXiv:2011.08346", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lRefining Automatic Speech Recognition System for older adults\\u00a7r\\n\\n\\u00a78\\u00a7oLiu Chen\\nMeysam Asgari\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.08346\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 17 Nov 2020 00:00:45 GMT)\\u00a7r"}']}
{title:'Luo et al. (§72020§r)', author: 'Yi Luo; Cong Han; Nima Mesgarani', display:{Lore:['[{"text": "arXiv:2011.08397", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lUltra-Lightweight Speech Separation via Group Communication\\u00a7r\\n\\n\\u00a78\\u00a7oYi Luo\\nCong Han\\nNima Mesgarani\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.08397\\u00a7r\\n\\nVersion:\\u00a77v3 (Fri, 20 Nov 2020 05:05:28 GMT)\\u00a7r"}']}
{title:'Luo et al. (§72020§r)', author: 'Yi Luo; Zhuo Chen; Cong Han; Chenda Li; Tianyan Zhou; Nima Mesgarani', display:{Lore:['[{"text": "arXiv:2011.08400", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lRethinking the Separation Layers in Speech Separation Networks\\u00a7r\\n\\n\\u00a78\\u00a7oYi Luo\\nZhuo Chen\\nCong Han\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.08400\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 17 Nov 2020 03:26:19 GMT)\\u00a7r"}']}
{title:'Luo et al. (§72020§r)', author: 'Yi Luo; Nima Mesgarani', display:{Lore:['[{"text": "arXiv:2011.08401", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lImplicit Filter-and-sum Network for Multi-channel Speech Separation\\u00a7r\\n\\n\\u00a78\\u00a7oYi Luo\\nNima Mesgarani\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.08401\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 17 Nov 2020 03:30:18 GMT)\\u00a7r"}']}
{title:'Wang et al. (§72020§r)', author: 'Xi Wang; Huaiping Ming; Lei He; Frank K. Soong', display:{Lore:['[{"text": "arXiv:2011.08480", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7ls-Transformer: Segment-Transformer for Robust Neural Speech Synthesis\\u00a7r\\n\\n\\u00a78\\u00a7oXi Wang\\nHuaiping Ming\\nLei He\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.08480\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 17 Nov 2020 07:24:04 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 5 figures\\u00a7r"}']}
{title:'Ni et al. (§72020§r)', author: 'Zhaoheng Ni; Yong Xu; Meng Yu; Bo Wu; Shixiong Zhang; Dong Yu; Michael I Mandel', display:{Lore:['[{"text": "arXiv:2011.09162", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lWPD++: An Improved Neural Beamformer for Simultaneous Speech Separation and Dereverberation\\u00a7r\\n\\n\\u00a78\\u00a7oZhaoheng Ni\\nYong Xu\\nMeng Yu\\n+ 3 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.09162\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 18 Nov 2020 09:06:03 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oaccepted by SLT 2021\\u00a7r"}']}
{title:'Rashid et al. (§72020§r)', author: 'Meemnur Rashid; Kaisar Ahmed Alman; Khaled Hasan; John H. L. Hansen; Taufiq Hasan', display:{Lore:['[{"text": "arXiv:2011.09270", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lRespiratory Distress Detection from Telephone Speech using Acoustic and Prosodic Features\\u00a7r\\n\\n\\u00a78\\u00a7oMeemnur Rashid\\nKaisar Ahmed Alman\\nKhaled Hasan\\nJohn H. L. Hansen\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.09270\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 15 Nov 2020 13:32:45 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o5 pages, 4 figures\\u00a7r"}']}
{title:'Ribeiro et al. (§72020§r)', author: 'Manuel Sam Ribeiro; Jennifer Sanger; Jing-Xuan Zhang; Aciel Eshky; Alan Wrench; Korin Richmond; Steve Renals', display:{Lore:['[{"text": "arXiv:2011.09804", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.CV\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7eeess.IV\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lTaL: a synchronised multi-speaker corpus of ultrasound tongue imaging, audio, and lip videos\\u00a7r\\n\\n\\u00a78\\u00a7oManuel Sam Ribeiro\\nJennifer Sanger\\nJing-Xuan Zhang\\n+ 3 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.09804\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 19 Nov 2020 13:11:46 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o8 pages, 4 figures, Accepted to SLT2021, IEEE Spoken Language Technology Workshop\\u00a7r"}']}
{title:'Tammen et al. (§72020§r)', author: 'Marvin Tammen; Simon Doclo', display:{Lore:['[{"text": "arXiv:2011.10345", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7eeess.SP\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDeep Multi-Frame MVDR Filtering for Single-Microphone Speech Enhancement\\u00a7r\\n\\n\\u00a78\\u00a7oMarvin Tammen\\nSimon Doclo\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.10345\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/ICASSP39728.2021.9413775\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 20 Nov 2020 11:20:17 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7osubmitted to the 2021 IEEE InternationalConference on Acoustics, Speech and Signal Processing (ICASSP), Toronto, Ontario, Canada\\u00a7r"}']}
{title:'Park et al. (§72020§r)', author: 'Tae Jin Park; Manoj Kumar; Shrikanth Narayanan', display:{Lore:['[{"text": "arXiv:2011.10527", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMulti-Scale Speaker Diarization With Neural Affinity Score Fusion\\u00a7r\\n\\n\\u00a78\\u00a7oTae Jin Park\\nManoj Kumar\\nShrikanth Narayanan\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.10527\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 20 Nov 2020 17:57:12 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to ICASSP 2021\\u00a7r"}']}
{title:'Luo et al. (§72020§r)', author: 'Jian Luo; Jianzong Wang; Ning Cheng; Guilin Jiang; Jing Xiao', display:{Lore:['[{"text": "arXiv:2011.11315", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lEnd-to-end Silent Speech Recognition with Acoustic Sensing\\u00a7r\\n\\n\\u00a78\\u00a7oJian Luo\\nJianzong Wang\\nNing Cheng\\nGuilin Jiang\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.11315\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 23 Nov 2020 10:29:23 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7owill be presented in SLT 2021\\u00a7r"}']}
{title:'Huang et al. (§72020§r)', author: 'Yiling Huang; Yutian Chen; Jason Pelecanos; Quan Wang', display:{Lore:['[{"text": "arXiv:2011.11818", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSynth2Aug: Cross-domain speaker recognition with TTS synthesized speech\\u00a7r\\n\\n\\u00a78\\u00a7oYiling Huang\\nYutian Chen\\nJason Pelecanos\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.11818\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 24 Nov 2020 00:48:54 GMT)\\u00a7r"}']}
{title:'Zmolikova et al. (§72020§r)', author: 'Katerina Zmolikova; Marc Delcroix; Lukáš Burget; Tomohiro Nakatani; Jan "Honza" Černocký', display:{Lore:['[{"text": "arXiv:2011.11984", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lIntegration of variational autoencoder and spatial clustering for adaptive multi-channel neural speech separation\\u00a7r\\n\\n\\u00a78\\u00a7oKaterina Zmolikova\\nMarc Delcroix\\nLuk\\u00e1\\u0161 Burget\\nTomohiro Nakatani\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.11984\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 24 Nov 2020 09:28:46 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o8 pages, 3 figures, to be published in SLT2021\\u00a7r"}']}
{title:'Tian et al. (§72020§r)', author: 'Qiao Tian; Yi Chen; Zewang Zhang; Heng Lu; Linghui Chen; Lei Xie; Shan Liu', display:{Lore:['[{"text": "arXiv:2011.12206", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lTFGAN: Time and Frequency Domain Based Generative Adversarial Network for High-fidelity Speech Synthesis\\u00a7r\\n\\n\\u00a78\\u00a7oQiao Tian\\nYi Chen\\nZewang Zhang\\n+ 3 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.12206\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 24 Nov 2020 16:55:48 GMT)\\u00a7r"}']}
{title:'Wang et al. (§72020§r)', author: 'Pu Wang; Hugo Van hamme', display:{Lore:['[{"text": "arXiv:2011.12221", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA light transformer for speech-to-intent applications\\u00a7r\\n\\n\\u00a78\\u00a7oPu Wang\\nHugo Van hamme\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.12221\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 24 Nov 2020 17:13:27 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oTo be published in SLT 2021\\u00a7r"}']}
{title:'Khursheed et al. (§72020§r)', author: 'Mohammad Omar Khursheed; Christin Jose; Rajath Kumar; Gengshen Fu; Brian Kulis; Santosh Kumar Cheekatmalla', display:{Lore:['[{"text": "arXiv:2011.12941", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSmall Footprint Convolutional Recurrent Networks for Streaming Wakeword Detection\\u00a7r\\n\\n\\u00a78\\u00a7oMohammad Omar Khursheed\\nChristin Jose\\nRajath Kumar\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.12941\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 25 Nov 2020 18:47:25 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oo\\u0327p\\u0327y\\u0327\\u0157i\\u0327\\u0123\\u1e29\\u0163 2021 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for "}','{"text": "advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted componentof this work in other works\\u00a7r"}']}
{title:'Valk et al. (§72020§r)', author: 'Jörgen Valk; Tanel Alumäe', display:{Lore:['[{"text": "arXiv:2011.12998", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lVoxLingua107: a Dataset for Spoken Language Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oJ\\u00f6rgen Valk\\nTanel Alum\\u00e4e\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.12998\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 25 Nov 2020 19:47:38 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted at IEEESpoken Language Technology Workshop (SLT) 2021\\u00a7r"}']}
{title:'Luo et al. (§72020§r)', author: 'Jian Luo; Jianzong Wang; Ning Cheng; Guilin Jiang; Jing Xiao', display:{Lore:['[{"text": "arXiv:2011.13090", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMulti-QuartzNet: Multi-Resolution Convolution for Speech Recognition with Multi-Layer Feature Fusion\\u00a7r\\n\\n\\u00a78\\u00a7oJian Luo\\nJianzong Wang\\nNing Cheng\\nGuilin Jiang\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.13090\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 26 Nov 2020 02:01:03 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7owill be presented in SLT 2021\\u00a7r"}']}
{title:'Li et al. (§72020§r)', author: 'Mohan Li; Catalin Zorila; Rama Doddipatla', display:{Lore:['[{"text": "arXiv:2011.13834", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lTransformer-based Online Speech Recognition with Decoder-end Adaptive Computation Steps\\u00a7r\\n\\n\\u00a78\\u00a7oMohan Li\\nCatalin Zorila\\nRama Doddipatla\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.13834\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 27 Nov 2020 17:02:55 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o7 pages, 1 figure, accepted at SLT 2021\\u00a7r"}']}
{title:'Sung (§72020§r)', author: 'Man-Ling Sung', display:{Lore:['[{"text": "arXiv:2011.14060", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lUnsupervised Spoken Term Discovery on Untranscribed Speech\\u00a7r\\n\\n\\u00a78\\u00a7oMan-Ling Sung\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2011.14060\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 28 Nov 2020 03:46:04 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oThesissubmitted in September 2019 for the M.Phil degree in Electronic Engineering at The Chinese University of Hong Kong (CUHK)\\u00a7r"}']}
{title:'Parthasarathy et al. (§72020§r)', author: 'Srinivas Parthasarathy; Shiva Sundaram', display:{Lore:['[{"text": "arXiv:2012.00063", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7eeess.IV\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDetecting expressions with multimodal transformers\\u00a7r\\n\\n\\u00a78\\u00a7oSrinivas Parthasarathy\\nShiva Sundaram\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2012.00063\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 30 Nov 2020 19:31:03 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oIEEE Spoken Language Technology Workshop 2021\\u00a7r"}']}
{title:'Cai et al. (§72020§r)', author: 'Weicheng Cai; Ming Li', display:{Lore:['[{"text": "arXiv:2012.00486", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Unified Deep Speaker Embedding Framework for Mixed-Bandwidth Speech Data\\u00a7r\\n\\n\\u00a78\\u00a7oWeicheng Cai\\nMing Li\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2012.00486\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 1 Dec 2020 13:45:38 GMT)\\u00a7r"}']}
{title:'Kwasny et al. (§72020§r)', author: 'Damian Kwasny; Daria Hemmerling', display:{Lore:['[{"text": "arXiv:2012.01551", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lJoint gender and age estimation based on speech signals using x-vectors and transfer learning\\u00a7r\\n\\n\\u00a78\\u00a7oDamian Kwasny\\nDaria Hemmerling\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2012.01551\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 2 Dec 2020 21:46:01 GMT)\\u00a7r"}']}
{title:'Wolters et al. (§72020§r)', author: 'Piper Wolters; Chris Careaga; Brian Hutchinson; Lauren Phillips', display:{Lore:['[{"text": "arXiv:2012.01573", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.NE\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Study of Few-Shot Audio Classification\\u00a7r\\n\\n\\u00a78\\u00a7oPiper Wolters\\nChris Careaga\\nBrian Hutchinson\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2012.01573\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 2 Dec 2020 22:19:16 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oPresented at GHC 2020\\u00a7r"}']}
{title:'Peng et al. (§72020§r)', author: 'Puyuan Peng; Herman Kamper; Karen Livescu', display:{Lore:['[{"text": "arXiv:2012.02221", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lA Correspondence Variational Autoencoder for Unsupervised Acoustic Word Embeddings\\u00a7r\\n\\n\\u00a78\\u00a7oPuyuan Peng\\nHerman Kamper\\nKaren Livescu\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2012.02221\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 3 Dec 2020 19:24:42 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o10 pages, 6 figures, NeurIPS 2020 WorkshopSelf-Supervised Learning for Speech and Audio Processing\\u00a7r"}']}
{title:'Sun et al. (§72020§r)', author: 'Aolan Sun; Jianzong Wang; Ning Cheng; Huayi Peng; Zhen Zeng; Lingwei Kong; Jing Xiao', display:{Lore:['[{"text": "arXiv:2012.02626", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lGraphPB: Graphical Representations of Prosody Boundary in Speech Synthesis\\u00a7r\\n\\n\\u00a78\\u00a7oAolan Sun\\nJianzong Wang\\nNing Cheng\\n+ 3 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2012.02626\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 3 Dec 2020 03:34:05 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oAccepted to SLT 2021\\u00a7r"}']}
{title:'Zhao et al. (§72020§r)', author: 'Yuanjun Zhao; Roberto Togneri; Victor Sreeram', display:{Lore:['[{"text": "arXiv:2012.03154", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CR\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMulti-task Learning Based Spoofing-Robust Automatic Speaker Verification System\\u00a7r\\n\\n\\u00a78\\u00a7oYuanjun Zhao\\nRoberto Togneri\\nVictor Sreeram\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2012.03154\\u00a7r\\n\\nVersion:\\u00a77v1 (Sun, 6 Dec 2020 01:03:35 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o12 pages, 6 figures, codesused in the experimental section can be found at https://github.com/zhaoyj1122/SRASV\\u00a7r"}']}
{title:'Pratap et al. (§72020§r)', author: 'Vineel Pratap; Qiantong Xu; Anuroop Sriram; Gabriel Synnaeve; Ronan Collobert', display:{Lore:['[{"text": "arXiv:2012.03411", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMLS: A Large-Scale Multilingual Dataset for Speech Research\\u00a7r\\n\\n\\u00a78\\u00a7oVineel Pratap\\nQiantong Xu\\nAnuroop Sriram\\nGabriel Synnaeve\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2012.03411\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.21437/Interspeech.2020-2826\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nInterspeech 2020\\u00a7r\\n\\nVersion:\\u00a77v2 (Sat, 19 Dec 2020 09:18:21 GMT)\\u00a7r"}']}
{title:'Miao et al. (§72020§r)', author: 'Chenfeng Miao; Shuang Liang; Zhencheng Liu; Minchuan Chen; Jun Ma; Shaojun Wang; Jing Xiao', display:{Lore:['[{"text": "arXiv:2012.03500", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lEfficientTTS: An Efficient and High-Quality Text-to-Speech Architecture\\u00a7r\\n\\n\\u00a78\\u00a7oChenfeng Miao\\nShuang Liang\\nZhencheng Liu\\n+ 3 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2012.03500\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 7 Dec 2020 07:46:46 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o15 pages, 9 figures\\u00a7r"}']}
{title:'Corey et al. (§72020§r)', author: 'Ryan M. Corey; Andrew C. Singer', display:{Lore:['[{"text": "arXiv:2012.03860", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lModeling the effects of dynamic range compression on signals in noise\\u00a7r\\n\\n\\u00a78\\u00a7oRyan M. Corey\\nAndrew C. Singer\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2012.03860\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1121/10.0005314\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 7 Dec 2020 17:09:48 GMT)\\u00a7r"}']}
{title:'Moing et al. (§72020§r)', author: 'Guillaume Le Moing; Phongtharin Vinayavekhin; Tadanobu Inoue; Jayakorn Vongkulbhisal; Asim Munawar; Ryuki Tachibana; Don Joven Agravante', display:{Lore:['[{"text": "arXiv:2012.05515", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lLearning Multiple Sound Source 2D Localization\\u00a7r\\n\\n\\u00a78\\u00a7oGuillaume Le Moing\\nPhongtharin Vinayavekhin\\nTadanobu Inoue\\n+ 3 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2012.05515\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 10 Dec 2020 08:51:16 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oPublished in: 2019 IEEE 21st International Workshopon Multimedia Signal Processing (MMSP)\\u00a7r"}']}
{title:'Tsai et al. (§72020§r)', author: 'Kun-Hsi Tsai; Wei-Chien Wang; Chui-Hsuan Cheng; Chan-Yen Tsai; Jou-Kou Wang; Tzu-Hao Lin; Shih-Hau Fang; Li-Chin Chen; Yu Tsao', display:{Lore:['[{"text": "arXiv:2012.06275", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lBlind Monaural Source Separation on Heart and Lung Sounds Based on Periodic-Coded Deep Autoencoder\\u00a7r\\n\\n\\u00a78\\u00a7oKun-Hsi Tsai\\nWei-Chien Wang\\nChui-Hsuan Cheng\\n+ 5 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2012.06275\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/JBHI.2020.3016831\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 11 Dec 2020 12:13:46 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o13 pages, 11 figures, Accepted by IEEE Journal of Biomedical and Health Informatics\\u00a7r"}']}
{title:'Ling et al. (§72020§r)', author: 'Shaoshi Ling; Yuzong Liu', display:{Lore:['[{"text": "arXiv:2012.06659", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDeCoAR 2.0: Deep Contextualized Acoustic Representations with Vector Quantization\\u00a7r\\n\\n\\u00a78\\u00a7oShaoshi Ling\\nYuzong Liu\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2012.06659\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 11 Dec 2020 22:07:23 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to ICASSP 2021\\u00a7r"}']}
{title:'Kumar et al. (§72020§r)', author: 'Neeraj Kumar; Srishti Goel; Ankur Narang; Brejesh Lall', display:{Lore:['[{"text": "arXiv:2012.07252", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lFew Shot Adaptive Normalization Driven Multi-Speaker Speech Synthesis\\u00a7r\\n\\n\\u00a78\\u00a7oNeeraj Kumar\\nSrishti Goel\\nAnkur Narang\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2012.07252\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 14 Dec 2020 04:37:07 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to AAAI2020\\u00a7r"}']}
{title:'Lee et al. (§72020§r)', author: 'Sang-Hoon Lee; Hyun-Wook Yoon; Hyeong-Rae Noh; Ji-Hoon Kim; Seong-Whan Lee', display:{Lore:['[{"text": "arXiv:2012.07267", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lMulti-SpectroGAN: High-Diversity and High-Fidelity Spectrogram Generation with Adversarial Style Combination for Speech Synthesis\\u00a7r\\n\\n\\u00a78\\u00a7oSang-Hoon Lee\\nHyun-Wook Yoon\\nHyeong-Rae Noh\\nJi-Hoon Kim\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2012.07267\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 14 Dec 2020 05:33:26 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o9 pages, 3 figures, Accepted paper in AAAI Conference on Artificial Intelligence (AAAI), 2021\\u00a7r"}']}
{title:'Koizumi et al. (§72020§r)', author: 'Yuma Koizumi; Yasunori Ohishi; Daisuke Niizumi; Daiki Takeuchi; Masahiro Yasuda', display:{Lore:['[{"text": "arXiv:2012.07331", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAudio Captioning using Pre-Trained Large-Scale Language Model Guided by Audio-based Similar Caption Retrieval\\u00a7r\\n\\n\\u00a78\\u00a7oYuma Koizumi\\nYasunori Ohishi\\nDaisuke Niizumi\\nDaiki Takeuchi\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2012.07331\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 14 Dec 2020 08:27:36 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to ICASSP 2021\\u00a7r"}']}
{title:'Sterpu et al. (§72020§r)', author: 'George Sterpu; Naomi Harte', display:{Lore:['[{"text": "arXiv:2012.07467", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAV Taris: Online Audio-Visual Speech Recognition\\u00a7r\\n\\n\\u00a78\\u00a7oGeorge Sterpu\\nNaomi Harte\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2012.07467\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 14 Dec 2020 12:39:02 GMT)\\u00a7r"}']}
{title:'Queiroz et al. (§72020§r)', author: 'A. Queiroz; R. Coelho', display:{Lore:['[{"text": "arXiv:2012.08227", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lF0-based Gammatone Filtering for Intelligibility Gain of Acoustic Noisy Signals\\u00a7r\\n\\n\\u00a78\\u00a7oA. Queiroz\\nR. Coelho\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2012.08227\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1109/LSP.2021.3084561\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 15 Dec 2020 11:39:27 GMT)\\u00a7r"}']}
{title:'Zhang et al. (§72020§r)', author: 'Chen Zhang; Yi Ren; Xu Tan; Jinglin Liu; Kejun Zhang; Tao Qin; Sheng Zhao; Tie-Yan Liu', display:{Lore:['[{"text": "arXiv:2012.09547", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lDenoiSpeech: Denoising Text to Speech with Frame-Level Noise Modeling\\u00a7r\\n\\n\\u00a78\\u00a7oChen Zhang\\nYi Ren\\nXu Tan\\n+ 4 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2012.09547\\u00a7r\\n\\nVersion:\\u00a77v2 (Fri, 18 Dec 2020 05:54:35 GMT)\\u00a7r"}']}
{title:'Rohnke et al. (§72020§r)', author: 'Jonas Rohnke; Tom Merritt; Jaime Lorenzo-Trueba; Adam Gabrys; Vatsal Aggarwal; Alexis Moinet; Roberto Barra-Chicote', display:{Lore:['[{"text": "arXiv:2012.09703", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lParallel WaveNet conditioned on VAE latent vectors\\u00a7r\\n\\n\\u00a78\\u00a7oJonas Rohnke\\nTom Merritt\\nJaime Lorenzo-Trueba\\n+ 3 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2012.09703\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 17 Dec 2020 16:14:32 GMT)\\u00a7r"}']}
{title:'Han et al. (§72020§r)', author: 'Cong Han; Yi Luo; Chenda Li; Tianyan Zhou; Keisuke Kinoshita; Shinji Watanabe; Marc Delcroix; Hakan Erdogan; John R. Hershey; Nima Mesgarani; Zhuo Chen', display:{Lore:['[{"text": "arXiv:2012.09727", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r, \\u00a7eeess.SP\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lContinuous Speech Separation Using Speaker Inventory for Long Multi-talker Recording\\u00a7r\\n\\n\\u00a78\\u00a7oCong Han\\nYi Luo\\nChenda Li\\n+ 7 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2012.09727\\u00a7r\\n\\nVersion:\\u00a77v2 (Fri, 18 Dec 2020 15:59:48 GMT)\\u00a7r"}']}
{title:'Horiguchi et al. (§72020§r)', author: 'Shota Horiguchi; Paola Garcia; Yusuke Fujita; Shinji Watanabe; Kenji Nagamatsu', display:{Lore:['[{"text": "arXiv:2012.10055", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lEnd-to-End Speaker Diarization as Post-Processing\\u00a7r\\n\\n\\u00a78\\u00a7oShota Horiguchi\\nPaola Garcia\\nYusuke Fujita\\nShinji Watanabe\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2012.10055\\u00a7r\\n\\nVersion:\\u00a77v2 (Wed, 23 Dec 2020 15:56:02 GMT)\\u00a7r"}']}
{title:'Peter et al. (§72020§r)', author: 'David Peter; Wolfgang Roth; Franz Pernkopf', display:{Lore:['[{"text": "arXiv:2012.10138", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lResource-efficient DNNs for Keyword Spotting using Neural Architecture Search and Quantization\\u00a7r\\n\\n\\u00a78\\u00a7oDavid Peter\\nWolfgang Roth\\nFranz Pernkopf\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2012.10138\\u00a7r\\n\\nVersion:\\u00a77v1 (Fri, 18 Dec 2020 09:53:55 GMT)\\u00a7r"}']}
{title:'Cai et al. (§72020§r)', author: 'Xiong Cai; Zhiyong Wu; Kuo Zhong; Bin Su; Dongyang Dai; Helen Meng', display:{Lore:['[{"text": "arXiv:2012.11174", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.AI\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lUnsupervised Cross-Lingual Speech Emotion Recognition Using DomainAdversarial Neural Network\\u00a7r\\n\\n\\u00a78\\u00a7oXiong Cai\\nZhiyong Wu\\nKuo Zhong\\n+ 2 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2012.11174\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 21 Dec 2020 08:21:11 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oThis paper has been accepted by ISCSLP2021\\u00a7r"}']}
{title:'Watanabe et al. (§72020§r)', author: 'Shinji Watanabe; Florian Boyer; Xuankai Chang; Pengcheng Guo; Tomoki Hayashi; Yosuke Higuchi; Takaaki Hori; Wen-Chin Huang; Hirofumi Inaguma; Naoyuki Kamo; Shigeki Karita; Chenda Li; Jing Shi; Aswin Shanmugam Subramanian; Wangyou Zhang', display:{Lore:['[{"text": "arXiv:2012.13006", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lThe 2020 ESPnet update: new features, broadened applications, performance improvements, and future plans\\u00a7r\\n\\n\\u00a78\\u00a7oShinji Watanabe\\nFlorian Boyer\\nXuankai Chang\\n+ 11 others\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2012.13006\\u00a7r\\n\\nVersion:\\u00a77v1 (Wed, 23 Dec 2020 22:25:23 GMT)\\u00a7r"}']}
{title:'Shrestha et al. (§72020§r)', author: 'Sundar Shrestha; Anand Koirala; Maksym Spiryagin; Qing Wu', display:{Lore:['[{"text": "arXiv:2012.13096", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lWheel-Rail Interface Condition Estimation (W-RICE)\\u00a7r\\n\\n\\u00a78\\u00a7oSundar Shrestha\\nAnand Koirala\\nMaksym Spiryagin\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2012.13096\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1115/JRC2020-8037\\u00a7r\\n\\nVersion:\\u00a77v1 (Thu, 24 Dec 2020 04:40:27 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o8 pages, 3 figures, JRC2020 conference\\u00a7r"}']}
{title:'Sun et al. (§72020§r)', author: 'Qinghua Sun; Kenji Nagamatsu', display:{Lore:['[{"text": "arXiv:2012.14039", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lBuilding Multi lingual TTS using Cross Lingual Voice Conversion\\u00a7r\\n\\n\\u00a78\\u00a7oQinghua Sun\\nKenji Nagamatsu\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2012.14039\\u00a7r\\n\\nVersion:\\u00a77v1 (Mon, 28 Dec 2020 00:28:14 GMT)\\u00a7r"}']}
{title:'Landini et al. (§72020§r)', author: 'Federico Landini; Ján Profant; Mireia Diez; Lukáš Burget', display:{Lore:['[{"text": "arXiv:2012.14952", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lBayesian HMM clustering of x-vector sequences (VBx) in speaker diarization: theory, implementation and analysis on standard tasks\\u00a7r\\n\\n\\u00a78\\u00a7oFederico Landini\\nJ\\u00e1n Profant\\nMireia Diez\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2012.14952\\u00a7r\\n\\nVersion:\\u00a77v1 (Tue, 29 Dec 2020 21:41:19 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7oSubmitted to Computer Speech and Language, Special Issue on Separation, Recognition, and Diarization of Conversational Speech\\u00a7r"}']}
{title:'Alagrami et al. (§72020§r)', author: 'Ali M. Alagrami; Maged M. Eljazzar', display:{Lore:['[{"text": "arXiv:2101.04200", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a7acs.CL\\u00a7r, \\u00a7acs.LG\\u00a7r, \\u00a7acs.SD\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lSmartajweed Automatic Recognition of Arabic Quranic Recitation Rules\\u00a7r\\n\\n\\u00a78\\u00a7oAli M. Alagrami\\nMaged M. Eljazzar\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2101.04200\\u00a7r\\n\\nJournal reference:\\u00a71\\u00a7nairccse 2020\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 26 Dec 2020 11:24:03 GMT)\\u00a7r\\n\\n"}','{"text": "Comments: \\u00a77\\u00a7o8 pages, the paper already published in airccse\\u00a7r"}']}
{title:'Zhao et al. (§72020§r)', author: 'Xuanyi Zhao; Luca Colombo; Cristian Cassella', display:{Lore:['[{"text": "arXiv:2105.11232", "color": "red"}]']}, pages:['{"text": "\\u00a7n\\u00a7eeess.AS\\u00a7r, \\u00a75physics.app-ph\\u00a7r\\u00a7r\\n\\u00a76\\u00a7lAluminum Nitride Two-Dimensional-Resonant-Rods\\u00a7r\\n\\n\\u00a78\\u00a7oXuanyi Zhao\\nLuca Colombo\\nCristian Cassella\\u00a7r\\n\\n\\u00a772020\\u00a7r"}','{"text": "arXiv:\\u00a7c\\u00a7n2105.11232\\u00a7r\\n\\nDOI:\\u00a76\\u00a7n10.1063/5.0005203\\u00a7r\\n\\nVersion:\\u00a77v1 (Sat, 22 Feb 2020 13:32:53 GMT)\\u00a7r"}']}
